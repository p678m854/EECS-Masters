{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization Benchmarks\n",
    "\n",
    "This notebook is for benchmarking the roughness regularization penalty against other preexisting regularization methods used in neural networks.\n",
    "\n",
    "## Regularizations\n",
    "\n",
    "Note that all external github repos are not included with\n",
    "\n",
    "1. $L_1$/$L_2$ weight regularization\n",
    "3. Drop outs between layers\n",
    "2. [Gaussian Processes](https://github.com/brain-research/nngp)\n",
    "4. [Adaptive regularization](https://github.com/yaohungt/Adaptive-Regularization-Neural-Network) which uses `PyTorch` rather than `TensorFlow`\n",
    " \n",
    " \n",
    "## Setup\n",
    "\n",
    "Initially load all libraries needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.special import comb\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import torch\n",
    "\n",
    "# Take care of a Blas GEMM launch failure\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "# Import custom functions\n",
    "sys.path.append(os.path.abspath('../functions'))  # Maybe change to src\n",
    "import read_blackbird_dataset as rbd\n",
    "import custom_loss_functions as clf\n",
    "\n",
    "# Other experimental regularizations (not hosted in this github repo)\n",
    "sys.path.append(os.path.abspath('../adaptive_regularizations'))\n",
    "sys.path.append(os.path.abspath('../nngp'))\n",
    "\n",
    "# Add in model path for manipulating weights\n",
    "sys.path.append(os.path.abspath('../models'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Testing Data\n",
    "\n",
    "This will use BlackBird Flight Test Data in an optimal control setting to test the regularizations on real application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 781699 entries, 1526617312016142000 to 1526617526748159000\n",
      "Data columns (total 95 columns):\n",
      " #   Column                          Non-Null Count   Dtype  \n",
      "---  ------                          --------------   -----  \n",
      " 0   PWM1                            39823 non-null   float64\n",
      " 1   PWM1_f                          39823 non-null   float64\n",
      " 2   PWM2                            39823 non-null   float64\n",
      " 3   PWM2_f                          39823 non-null   float64\n",
      " 4   PWM3                            39823 non-null   float64\n",
      " 5   PWM3_f                          39823 non-null   float64\n",
      " 6   PWM4                            39823 non-null   float64\n",
      " 7   PWM4_f                          39823 non-null   float64\n",
      " 8   angular_velocity_covariance     21298 non-null   object \n",
      " 9   ax_B_[m/s2]                     77287 non-null   float64\n",
      " 10  ax_I_[m/s2]                     77287 non-null   float64\n",
      " 11  ax_[m/s2]                       21298 non-null   float64\n",
      " 12  ax_g|B_[m/s2]                   77287 non-null   float64\n",
      " 13  ay_B_[m/s2]                     77287 non-null   float64\n",
      " 14  ay_I_[m/s2]                     77287 non-null   float64\n",
      " 15  ay_[m/s2]                       21298 non-null   float64\n",
      " 16  ay_g|B_[m/s2]                   77287 non-null   float64\n",
      " 17  az_B_[m/s2]                     77287 non-null   float64\n",
      " 18  az_I_[m/s2]                     77287 non-null   float64\n",
      " 19  az_[m/s2]                       21298 non-null   float64\n",
      " 20  az_g|B_[m/s2]                   77287 non-null   float64\n",
      " 21  linear_acceleration_covariance  21298 non-null   object \n",
      " 22  motor1_[rps]_est                39824 non-null   float64\n",
      " 23  motor1dot_[rps2]                39824 non-null   float64\n",
      " 24  motor2_[rps]_est                39824 non-null   float64\n",
      " 25  motor2dot_[rps2]                39824 non-null   float64\n",
      " 26  motor3_[rps]_est                39824 non-null   float64\n",
      " 27  motor3dot_[rps2]                39824 non-null   float64\n",
      " 28  motor4_[rps]_est                39824 non-null   float64\n",
      " 29  motor4dot_[rps2]                39824 non-null   float64\n",
      " 30  omegadotx_est                   21298 non-null   float64\n",
      " 31  omegadotx_qest                  77287 non-null   float64\n",
      " 32  omegadoty_est                   21298 non-null   float64\n",
      " 33  omegadoty_qest                  77287 non-null   float64\n",
      " 34  omegadotz_est                   21298 non-null   float64\n",
      " 35  omegadotz_qest                  77287 non-null   float64\n",
      " 36  omegax_[dps]                    21298 non-null   float64\n",
      " 37  omegax_est                      21298 non-null   float64\n",
      " 38  omegax_qest                     77287 non-null   float64\n",
      " 39  omegaxdot_B_[rps]               77287 non-null   float64\n",
      " 40  omegay_[dps]                    21298 non-null   float64\n",
      " 41  omegay_est                      21298 non-null   float64\n",
      " 42  omegay_qest                     77287 non-null   float64\n",
      " 43  omegaydot_B_[rps]               77287 non-null   float64\n",
      " 44  omegaz_[dps]                    21298 non-null   float64\n",
      " 45  omegaz_est                      21298 non-null   float64\n",
      " 46  omegaz_qest                     77287 non-null   float64\n",
      " 47  omegazdot_B_[rps]               77287 non-null   float64\n",
      " 48  orientation_covariance          21298 non-null   object \n",
      " 49  pitch_[rad]                     77286 non-null   float64\n",
      " 50  pitch_ref_[rad]                 38130 non-null   float64\n",
      " 51  px_[m]                          77287 non-null   float64\n",
      " 52  px_[m]_est                      77287 non-null   float64\n",
      " 53  pxr_[m]                         38131 non-null   float64\n",
      " 54  py_[m]                          77287 non-null   float64\n",
      " 55  py_[m]_est                      77287 non-null   float64\n",
      " 56  pyr_[m]                         38131 non-null   float64\n",
      " 57  pz_[m]                          77287 non-null   float64\n",
      " 58  pz_[m]_est                      77287 non-null   float64\n",
      " 59  pzr_[m]                         38131 non-null   float64\n",
      " 60  qdotdotw                        77287 non-null   float64\n",
      " 61  qdotdotx                        77287 non-null   float64\n",
      " 62  qdotdoty                        77287 non-null   float64\n",
      " 63  qdotdotz                        77287 non-null   float64\n",
      " 64  qdotw                           77287 non-null   float64\n",
      " 65  qdotx                           77287 non-null   float64\n",
      " 66  qdoty                           77287 non-null   float64\n",
      " 67  qdotz                           77287 non-null   float64\n",
      " 68  qw                              77287 non-null   float64\n",
      " 69  qw_est                          77287 non-null   float64\n",
      " 70  qwr                             38131 non-null   float64\n",
      " 71  qx                              77287 non-null   float64\n",
      " 72  qx_est                          77287 non-null   float64\n",
      " 73  qxr                             38131 non-null   float64\n",
      " 74  qy                              77287 non-null   float64\n",
      " 75  qy_est                          77287 non-null   float64\n",
      " 76  qyr                             38131 non-null   float64\n",
      " 77  qz                              77287 non-null   float64\n",
      " 78  qz_est                          77287 non-null   float64\n",
      " 79  qzr                             38131 non-null   float64\n",
      " 80  roll_[rad]                      77286 non-null   float64\n",
      " 81  roll_ref_[rad]                  38130 non-null   float64\n",
      " 82  rpm1                            39824 non-null   float64\n",
      " 83  rpm2                            39824 non-null   float64\n",
      " 84  rpm3                            39824 non-null   float64\n",
      " 85  rpm4                            39824 non-null   float64\n",
      " 86  vx_B_[m/s]                      77287 non-null   float64\n",
      " 87  vx_I_[m/s]                      77287 non-null   float64\n",
      " 88  vy_B_[m/s]                      77287 non-null   float64\n",
      " 89  vy_I_[m/s]                      77287 non-null   float64\n",
      " 90  vz_B_[m/s]                      77287 non-null   float64\n",
      " 91  vz_I_[m/s]                      77287 non-null   float64\n",
      " 92  yaw_[rad]                       77286 non-null   float64\n",
      " 93  yaw_ref_[rad]                   38130 non-null   float64\n",
      " 94  is_flying                       781699 non-null  bool   \n",
      "dtypes: bool(1), float64(91), object(3)\n",
      "memory usage: 587.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Initial read in flight test\n",
    "def cleaned_blackbird_test(maneuver, yaw_direction, max_speed):\n",
    "    test_df = rbd.read_blackbird_test(maneuver, yaw_direction, max_speed)\n",
    "    rbd.imu_installation_correction(test_df)\n",
    "    test_df = rbd.inertial_position_derivatives_estimation(test_df)\n",
    "    test_df = rbd.gyroscope_derivatives_estimation(test_df)\n",
    "    test_df = rbd.consistent_quaternions(test_df)\n",
    "    test_df = rbd.inertial_quaternion_derivatives_estimation(test_df)\n",
    "    test_df = rbd.body_quaternion_angular_derivative_estimate(test_df)\n",
    "    test_df = rbd.motor_scaling(test_df)\n",
    "    test_df = rbd.motor_rates(test_df)\n",
    "    test_df = rbd.quaternion_body_acceleration(test_df)\n",
    "    test_df = rbd.detrend_pwm(test_df)\n",
    "    test_df = rbd.scale_and_filter_pwms(test_df)\n",
    "    test_df = rbd.on_ground(test_df)  # Must be last function\n",
    "    return test_df\n",
    "\n",
    "test_df = cleaned_blackbird_test('figure8', 'Constant', 0.5)\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vicon position': (71, 0.002777999999999281), 'vicon attitude': (71, 0.002777999999999281), 'reference position': (37, 0.005305999999990263), 'reference attitude': (37, 0.005305999999990263), 'motor speeds': (37, 0.00532200000000671), 'accelerometer': (20, 0.00999999999999801), 'gyroscope': (20, 0.00999999999999801), 'PWM': (37, 0.00532100000000213)}\n"
     ]
    }
   ],
   "source": [
    "# Get testing input/output data\n",
    "past_window = .2\n",
    "future_window = .2\n",
    "X, Y, tvec_y, info = rbd.generate_opt_control_test_data(\n",
    "    test_df,\n",
    "    past_window,\n",
    "    future_window\n",
    ")\n",
    "\n",
    "print(info)\n",
    "Y = Y[:, :int(Y.shape[1]/4)]  # Reduce Y to just PWM 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 38288\n",
      "Input shape: (1024,)\n",
      "Output shape: (37,)\n"
     ]
    }
   ],
   "source": [
    "N = X.shape[0]\n",
    "dX = X.shape[1]\n",
    "dY = Y.shape[1]\n",
    "\n",
    "print(\"Number of examples: %i\" % N)\n",
    "print(\"Input shape: (%i,)\" % dX)\n",
    "print(\"Output shape: (%i,)\" % dY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Models\n",
    "\n",
    "Create the various neural network models. All models will have the same depth but the parameters and width of the network may be different.\n",
    "\n",
    "### Default Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 37)                37925     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 37)                1406      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 37)                1406      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 37)                1406      \n",
      "=================================================================\n",
      "Total params: 42,143\n",
      "Trainable params: 42,143\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "depth = 4\n",
    "default_weight_location = '../models/reg_benchmark_default_weights.keras'\n",
    "\n",
    "default = tf.keras.Sequential()\n",
    "for i in range(depth):\n",
    "    if i == 0:\n",
    "        default.add(tf.keras.layers.Dense(dY, activation=tf.nn.relu, input_shape=(dX,)))\n",
    "    else:\n",
    "        default.add(tf.keras.layers.Dense(dY, activation=tf.nn.relu, input_shape=(dY,)))\n",
    "\n",
    "default.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.mse,\n",
    "    metrics=['mse'],\n",
    "    loss_weights=None,\n",
    "    weighted_metrics=None,\n",
    "    run_eagerly=None,\n",
    ")\n",
    "default.summary()\n",
    "\n",
    "default.save_weights(default_weight_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roughness Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 37)                37925     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 37)                1406      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 37)                1406      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 37)                1406      \n",
      "=================================================================\n",
      "Total params: 42,143\n",
      "Trainable params: 42,143\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "roughness = tf.keras.Sequential()\n",
    "for i in range(depth):\n",
    "    if i == 0:\n",
    "        roughness.add(tf.keras.layers.Dense(dY, activation=tf.nn.relu, input_shape=(dX,)))\n",
    "    else:\n",
    "        roughness.add(tf.keras.layers.Dense(dY, activation=tf.nn.relu, input_shape=(dY,)))\n",
    "\n",
    "@tf.function\n",
    "def loss_fun(yact, ypred):\n",
    "    \"\"\"Matches default from L1 and L2\"\"\"\n",
    "    return clf.mse_and_roughness(yact, ypred, degree=3, alpha=0.01)\n",
    "\n",
    "roughness.compile(\n",
    "    optimizer='adam',\n",
    "    loss=loss_fun,\n",
    "    metrics=['mse'],\n",
    "    loss_weights=None,\n",
    "    weighted_metrics=None,\n",
    "    run_eagerly=None,\n",
    ")\n",
    "roughness.summary()\n",
    "\n",
    "roughness.load_weights(default_weight_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $L_1$ Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 37)                37925     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 37)                1406      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 37)                1406      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 37)                1406      \n",
      "=================================================================\n",
      "Total params: 42,143\n",
      "Trainable params: 42,143\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lone = tf.keras.Sequential()\n",
    "for i in range(depth):\n",
    "    if i == 0:\n",
    "        lone.add(tf.keras.layers.Dense(dY, activation=tf.nn.relu, kernel_regularizer='l1', input_shape=(dX,)))\n",
    "    else:\n",
    "        lone.add(tf.keras.layers.Dense(dY, activation=tf.nn.relu, kernel_regularizer='l1', input_shape=(dY,)))\n",
    "\n",
    "lone.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.mse,\n",
    "    metrics=['mse'],\n",
    "    loss_weights=None,\n",
    "    weighted_metrics=None,\n",
    "    run_eagerly=None,\n",
    ")\n",
    "lone.summary()\n",
    "\n",
    "lone.load_weights(default_weight_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $L_2$ Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 37)                37925     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 37)                1406      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 37)                1406      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 37)                1406      \n",
      "=================================================================\n",
      "Total params: 42,143\n",
      "Trainable params: 42,143\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ltwo = tf.keras.Sequential()\n",
    "for i in range(depth):\n",
    "    if i == 0:\n",
    "        ltwo.add(tf.keras.layers.Dense(dY, activation=tf.nn.relu, kernel_regularizer='l2', input_shape=(dX,)))\n",
    "    else:\n",
    "        ltwo.add(tf.keras.layers.Dense(dY, activation=tf.nn.relu, kernel_regularizer='l2', input_shape=(dY,)))\n",
    "\n",
    "ltwo.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.mse,\n",
    "    metrics=['mse'],\n",
    "    loss_weights=None,\n",
    "    weighted_metrics=None,\n",
    "    run_eagerly=None,\n",
    ")\n",
    "ltwo.summary()\n",
    "\n",
    "ltwo.load_weights(default_weight_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 37)                37925     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 37)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 37)                1406      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 37)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 37)                1406      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 37)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 37)                1406      \n",
      "=================================================================\n",
      "Total params: 42,143\n",
      "Trainable params: 42,143\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "drop_rate = 0.2  # 20 % dropout rate\n",
    "\n",
    "dropout = tf.keras.Sequential()\n",
    "for i in range(depth):\n",
    "    if i == 0:\n",
    "        dropout.add(tf.keras.layers.Dense(dY, activation=tf.nn.relu, input_shape=(dX,)))\n",
    "    else:\n",
    "        dropout.add(tf.keras.layers.Dropout(drop_rate))\n",
    "        dropout.add(tf.keras.layers.Dense(dY, activation=tf.nn.relu, input_shape=(dY,)))\n",
    "\n",
    "dropout.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.mse,\n",
    "    metrics=['mse'],\n",
    "    loss_weights=None,\n",
    "    weighted_metrics=None,\n",
    "    run_eagerly=None,\n",
    ")\n",
    "dropout.summary()\n",
    "\n",
    "dropout.load_weights(default_weight_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Regularization\n",
    "\n",
    "This is essentially a copy-paste from the linked GitHub Repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OurNet(\n",
      "  (l1): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (l2): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (l3): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (l4): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=37, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "adaregnn_width = 10\n",
    "\n",
    "class AdaRegNN(torch.nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(AdaRegNN, self).__init__()\n",
    "        \n",
    "        # Layers\n",
    "        self.l1 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(\n",
    "                dX,  # input features\n",
    "                adaregnn_width  # output features\n",
    "            ),  # xA^T + b\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        self.l2 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(\n",
    "                adaregnn_width,  # input features\n",
    "                adaregnn_width  # output features\n",
    "            ),  # xA^T + b\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        self.l3 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(\n",
    "                adaregnn_width,  # input features\n",
    "                adaregnn_width  # output features\n",
    "            ),  # xA^T + b\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        self.l4 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(\n",
    "                adaregnn_width,  # input features\n",
    "                dY  # output features\n",
    "            ),  # xA^T + b\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        \"\"\"\n",
    "        self.layers = []\n",
    "        for i in range(depth):\n",
    "            self.layers.append(\n",
    "                torch.nn.Sequential(\n",
    "                    torch.nn.Linear(\n",
    "                        dX if i == 0 else dY,  # input features\n",
    "                        dY  # output features\n",
    "                    ),  # xA^T + b\n",
    "                    torch.nn.ReLU()\n",
    "                )\n",
    "            )\n",
    "        \"\"\"\n",
    "    \n",
    "    def forward(self, f, if_decov=False):\n",
    "        feat = f\n",
    "        feat = self.l1(feat)\n",
    "        feat = self.l2(feat)\n",
    "        feat = self.l3(feat)\n",
    "        feat = self.l4(feat)\n",
    "        return feat\n",
    "        \n",
    "\n",
    "def BayesNet(args):\n",
    "    class OurNet(AdaRegNN):\n",
    "        \"\"\"\n",
    "        The network with empirical bayes assumptions on weights.\n",
    "        We're going to update cov with this class, while the update for weights we simply use gradient descent method.\n",
    "        \"\"\"\n",
    "        def __init__(self, args):\n",
    "            super(OurNet, self).__init__(args)\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                self.cuda()\n",
    "                \n",
    "            self.sqrt_cov_prev = []\n",
    "            self.sqrt_cov_next = []\n",
    "            self.cov_weight  = []\n",
    "            \n",
    "            name, module = list(self.named_children())[-1]\n",
    "            # print(name)\n",
    "            shape = list(module.parameters())[0].shape\n",
    "            sqt_cov_pre = torch.nn.Parameter(torch.eye(shape[1]), requires_grad = False)\n",
    "            sqt_cov_nex = torch.nn.Parameter(torch.eye(shape[0]), requires_grad = False)\n",
    "            if torch.cuda.is_available():\n",
    "                sqt_cov_pre = sqt_cov_pre.cuda()\n",
    "                sqt_cov_nex = sqt_cov_nex.cuda()\n",
    "            self.sqrt_cov_prev.append(sqt_cov_pre)\n",
    "            self.sqrt_cov_next.append(sqt_cov_nex)\n",
    "            self.cov_weight.append(list(module.parameters())[0])\n",
    "            \n",
    "            \"\"\"\n",
    "            for name, module in self.named_children():\n",
    "                # print(name)\n",
    "                shape = list(module.parameters())[0].shape\n",
    "                if len(shape) == 4: # conv layer\n",
    "                    if args.regu_type == 'ALL' or args.regu_type == 'CONV':\n",
    "                        sqt_cov_pre = torch.nn.Parameter(torch.eye(shape[1] * shape[2] * shape[3]), requires_grad = False)\n",
    "                        sqt_cov_nex = torch.nn.Parameter(torch.eye(shape[0]), requires_grad = False)\n",
    "                        if torch.cuda.is_available():\n",
    "                            sqt_cov_pre = sqt_cov_pre.cuda()\n",
    "                            sqt_cov_nex = sqt_cov_nex.cuda()\n",
    "                        # we view conv weights as a 2d matrix (shape[0], shape[1] * shape[2] * shape[3])\n",
    "                        self.sqrt_cov_prev.append(sqt_cov_pre)\n",
    "                        self.sqrt_cov_next.append(sqt_cov_nex)\n",
    "                        self.cov_weight.append(list(module.parameters())[0].view(shape[0], -1))\n",
    "                elif len(shape) == 2: # MLP layer\n",
    "                    sqt_cov_pre = torch.nn.Parameter(torch.eye(shape[1]), requires_grad = False)\n",
    "                    sqt_cov_nex = torch.nn.Parameter(torch.eye(shape[0]), requires_grad = False)\n",
    "                    if torch.cuda.is_available():\n",
    "                        sqt_cov_pre = sqt_cov_pre.cuda()\n",
    "                        sqt_cov_nex = sqt_cov_nex.cuda()\n",
    "                    self.sqrt_cov_prev.append(sqt_cov_pre)\n",
    "                    self.sqrt_cov_next.append(sqt_cov_nex)\n",
    "                    self.cov_weight.append(list(module.parameters())[0])\n",
    "            \"\"\"\n",
    "            \n",
    "        def regularizer(self):\n",
    "            \"\"\"\n",
    "            Compute the weight regularizer in the network (layer by layer).\n",
    "            \"\"\"\n",
    "            r = []\n",
    "            for i in range(len(self.cov_weight)):\n",
    "                r_sqrt = torch.mm(torch.mm(self.sqrt_cov_next[i], self.cov_weight[i]), self.sqrt_cov_prev[i])\n",
    "                r.append(torch.sum(r_sqrt * r_sqrt))\n",
    "            return r\n",
    "        \n",
    "        def _thresholding(self, sv, lower, upper):\n",
    "            \"\"\"\n",
    "            Two-way soft-thresholding of singular values.\n",
    "            :param sv:  A list of singular values.\n",
    "            :param lower:   Lower bound for soft-thresholding.\n",
    "            :param upper:   Upper bound for soft-thresholding.\n",
    "            :return:    Thresholded singular values.\n",
    "            \"\"\"\n",
    "            uidx = sv > upper\n",
    "            lidx = sv < lower\n",
    "            sv[uidx] = upper\n",
    "            sv[lidx] = lower\n",
    "            return sv\n",
    "        \n",
    "        def update_covs(self, lower, upper):\n",
    "            \"\"\"\n",
    "            Layer by layer, update both the covariance matrix over tasks and over features, using the closed form solutions. \n",
    "            :param lower: Lower bound of the truncation.\n",
    "            :param upper: Upper bound of the truncation.\n",
    "            \"\"\"\n",
    "            for i in range(len(self.cov_weight)):\n",
    "                cov_next = torch.mm(self.sqrt_cov_next[i], self.sqrt_cov_next[i].t())\n",
    "                \n",
    "                # dim: {(p x n) * (n x n)} * (n x p) = (p x p)\n",
    "                cov_prev_weight = torch.mm(torch.mm(self.cov_weight[i].t(), cov_next), self.cov_weight[i])\n",
    "                \n",
    "                # compute SVD\n",
    "                # U, S, V = SVD(A): A is the input matrix\n",
    "                u, s, _ = torch.svd(cov_prev_weight.data)\n",
    "                \n",
    "                # inverse and do truncation on inverse singular values\n",
    "                s = s.shape[0] / s\n",
    "                s = self._thresholding(s, lower, upper)\n",
    "                \n",
    "                # recompute the sqrt_cov\n",
    "                s = torch.sqrt(s)\n",
    "                # dim for u and s: (p x p)\n",
    "                self.sqrt_cov_prev[i].data = torch.mm(torch.mm(u, torch.diag(s)), u.t())\n",
    "                \n",
    "            for i in range(len(self.cov_weight)):\n",
    "                cov_prev = torch.mm(self.sqrt_cov_prev[i], self.sqrt_cov_prev[i].t())\n",
    "                \n",
    "                # dim: {(n x p) * (p x p)} * (p x n) = (n x n)\n",
    "                cov_next_weight = torch.mm(torch.mm(self.cov_weight[i], cov_prev), self.cov_weight[i].t())\n",
    "                \n",
    "                # compute SVD\n",
    "                # U, S, V = SVD(A): A is the input matrix\n",
    "                u, s, _ = torch.svd(cov_next_weight.data)\n",
    "                \n",
    "                # inverse and do truncation on inverse singular values\n",
    "                s = s.shape[0] / s\n",
    "                s = self._thresholding(s, lower, upper)\n",
    "                \n",
    "                # recompute the sqrt_cov\n",
    "                s = torch.sqrt(s)\n",
    "                # dim for u and s: (p x p)\n",
    "                self.sqrt_cov_next[i].data = torch.mm(torch.mm(u, torch.diag(s)), u.t())\n",
    "\n",
    "    return OurNet(args)\n",
    "\n",
    "def bayes_training_evaluation(myNet, optimizer, train_loader, test_loader, args):  \n",
    "    _inside_loss = np.zeros((args.outer_loop*args.inner_epoch, 1))\n",
    "    \n",
    "    for k in range(args.outer_loop):\n",
    "        # optimize the model parameters\n",
    "        #print('in outer_loop ' + str(k) + '.....')\n",
    "        for t in range(args.inner_epoch):\n",
    "            print('in epoch ' + str(k*args.inner_epoch + t) + '.....')\n",
    "            myNet.train()\n",
    "            for xs, ys in train_loader:\n",
    "                if torch.cuda.is_available():\n",
    "                    xs, ys = xs.cuda(), ys.cuda()\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                y_pred = myNet(xs)\n",
    "                closs = criterion(y_pred, ys)\n",
    "                rloss_list = myNet.regularizer()\n",
    "                rloss = 0\n",
    "                for i in range(len(rloss_list)):\n",
    "                    rloss = rloss + rloss_list[i]\n",
    "                \n",
    "                loss = closs + args.rho * rloss\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "            loss = closs.cpu().detach()\n",
    "            print(loss)\n",
    "            _inside_loss[k*args.inner_epoch+t] = loss\n",
    "                \n",
    "        # Optimize covariance matrices, using SVD closed form solutions.\n",
    "        myNet.update_covs(args.lower_threshold, args.upper_threshold)\n",
    "    return _inside_loss\n",
    "\n",
    "adareg = BayesNet(None)\n",
    "print(adareg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Each network shall be trained for the same amount of epochs with the training and validation loss tracked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standards for training\n",
    "epochs = 10\n",
    "verbose = 0\n",
    "validation_split = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time per epoch: 3.191489 [s]\n"
     ]
    }
   ],
   "source": [
    "# Training Default Network\n",
    "tstart = time.time()\n",
    "default_h = default.fit(x=X, y=Y, epochs=epochs, verbose=verbose, validation_split=validation_split)\n",
    "tstop = time.time()\n",
    "\n",
    "print(\"Average time per epoch: %f [s]\" % ((tstop - tstart)/epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Patrick\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time per epoch: 4.739409 [s]\n"
     ]
    }
   ],
   "source": [
    "# Training Roughness\n",
    "tstart = time.time()\n",
    "roughness_h = roughness.fit(x=X, y=Y, epochs=epochs, verbose=verbose, validation_split=validation_split)\n",
    "tstop = time.time()\n",
    "\n",
    "print(\"Average time per epoch: %f [s]\" % ((tstop - tstart)/epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time per epoch: 3.351980 [s]\n"
     ]
    }
   ],
   "source": [
    "# Training L1\n",
    "tstart = time.time()\n",
    "lone_h = lone.fit(x=X, y=Y, epochs=epochs, verbose=verbose, validation_split=validation_split)\n",
    "tstop = time.time()\n",
    "\n",
    "print(\"Average time per epoch: %f [s]\" % ((tstop - tstart)/epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time per epoch: 3.405986 [s]\n"
     ]
    }
   ],
   "source": [
    "# Training L2\n",
    "tstart = time.time()\n",
    "ltwo_h = ltwo.fit(x=X, y=Y, epochs=epochs, verbose=verbose, validation_split=validation_split)\n",
    "tstop = time.time()\n",
    "\n",
    "print(\"Average time per epoch: %f [s]\" % ((tstop - tstart)/epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time per epoch: 3.430637 [s]\n"
     ]
    }
   ],
   "source": [
    "# Training Dropout\n",
    "tstart = time.time()\n",
    "dropout_h = ltwo.fit(x=X, y=Y, epochs=epochs, verbose=verbose, validation_split=validation_split)\n",
    "tstop = time.time()\n",
    "\n",
    "print(\"Average time per epoch: %f [s]\" % ((tstop - tstart)/epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loaded interpolation grid from ../models\\grid_relu_ng5_ns5_nc4_mv4_mg4\n",
      "WARNING:tensorflow:From C:\\Users\\Patrick\\Documents\\GitHub\\EECS-Masters\\nngp\\interp.py:98: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "import gpr\n",
    "import nngp  # Because of the flags I cannot use importlib.reload\n",
    "\n",
    "sys.argv = sys.argv[:1]  # correction for flags\n",
    "\n",
    "nngp_kernel = nngp.NNGPKernel(\n",
    "    depth=1,  # depth,\n",
    "    weight_var=1.3,\n",
    "    bias_var=0.2,\n",
    "    nonlin_fn=tf.nn.relu,\n",
    "    grid_path='../models',\n",
    "    n_gauss=5,  # 501,\n",
    "    n_var=5,  # 501,\n",
    "    n_corr=4,  # 500,\n",
    "    max_gauss=4,\n",
    "    max_var=4,\n",
    "    use_fixed_point_norm=False\n",
    ")\n",
    "\n",
    "gp_model = gpr.GaussianProcessRegression(\n",
    "    X, Y, kern=nngp_kernel\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training NNGP\n",
    "\n",
    "gp_pred, stab_eps = gp_model.predict(\n",
    "    X, tf.compat.v1.keras.backend.get_session()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Training AdaReg\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, adareg.parameters()),\n",
    "    lr=5e-4,\n",
    "    weight_decay=1e-2\n",
    ")\n",
    "\n",
    "split_index = int(X.shape[0]*0.8)\n",
    "\n",
    "train_loader = torch.utils.data.TensorDataset(\n",
    "    torch.Tensor(X[:split_index,:]),\n",
    "    torch.Tensor(Y[:split_index,:])\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.TensorDataset(\n",
    "    torch.Tensor(X[split_index:,:]),\n",
    "    torch.Tensor(Y[split_index:,:])\n",
    ")\n",
    "\n",
    "class customArg():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "args = customArg()\n",
    "args.outer_loop = int(0.25*epochs)\n",
    "args.inner_epoch = 1\n",
    "args.rho = 1e-4\n",
    "args.lower_threshold = 1e-3\n",
    "args.upper_threshold = 1e3\n",
    "\n",
    "tstart = time.time()\n",
    "\n",
    "adareg_h = bayes_training_evaluation(\n",
    "    adareg, optimizer, train_loader, test_loader, args\n",
    ")\n",
    "\n",
    "tstop = time.time()\n",
    "\n",
    "print(\"Average time per epoch: %f [s]\" % ((tstop - tstart)/args.outer_loop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Plotting the training histories of each of the networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_list = [default_h, roughness_h, lone_h, ltwo_h, dropout_h]\n",
    "label_list = ['Default', 'Roughness', '$L_1$', '$L_2$', 'Dropout']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "\n",
    "# Figure setup\n",
    "fig.set_figheight(6)\n",
    "fig.set_figwidth(8)\n",
    "\n",
    "# Plotting\n",
    "for hist, label in zip(hist_list, label_list):\n",
    "    yplot = hist.history['mse']\n",
    "    xplot = np.arange(len(yplot))\n",
    "    ax.plot(xplot, yplot, label=label)\n",
    "\n",
    "# AdaReg is Pytorch which is not a history\n",
    "ax.plot(np.arange(adareg_h.shape[0]), adareg_h[:, 0], label='AdaReg')\n",
    "    \n",
    "# Adjusting axis\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Mean Squared Error')\n",
    "ax.set_xlim(left=0)\n",
    "ax.set_ylim(bottom=0)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
