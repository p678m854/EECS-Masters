{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization Benchmarks\n",
    "\n",
    "This notebook is for benchmarking the roughness regularization penalty against other preexisting regularization methods used in neural networks.\n",
    "\n",
    "## Regularizations\n",
    "\n",
    "Note that all external github repos are not included with\n",
    "\n",
    "1. $L_1$/$L_2$ weight regularization\n",
    "3. Drop outs between layers\n",
    "4. [Adaptive regularization](https://github.com/yaohungt/Adaptive-Regularization-Neural-Network) which uses `PyTorch` rather than `TensorFlow`\n",
    " \n",
    " \n",
    "## Setup\n",
    "\n",
    "Initially load all libraries needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.special import comb\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import torch\n",
    "\n",
    "# Take care of a Blas GEMM launch failure\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "# Import custom functions\n",
    "#sys.path.append(os.path.abspath('../functions'))  # Maybe change to src\n",
    "#import read_blackbird_dataset as rbd\n",
    "#import custom_loss_functions as clf\n",
    "from thesis.data import blackbird_dataset as rbd\n",
    "from thesis.modules import loss_functions as clf\n",
    "\n",
    "# Other experimental regularizations (not hosted in this github repo)\n",
    "sys.path.append(os.path.abspath('../adaptive_regularizations'))\n",
    "#  sys.path.append(os.path.abspath('../nngp'))\n",
    "sys.path.append(os.path.abspath('../nngp_tf2'))\n",
    "\n",
    "# Add in model path for manipulating weights\n",
    "sys.path.append(os.path.abspath('../models'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up Matplotlib parameters for saving figures\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = ['Times New Roman'] + plt.rcParams['font.serif']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Testing Data\n",
    "\n",
    "This will use BlackBird Flight Test Data in an optimal control setting to test the regularizations on real application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 781699 entries, 1526617312016142000 to 1526617526748159000\n",
      "Data columns (total 95 columns):\n",
      " #   Column                          Non-Null Count   Dtype  \n",
      "---  ------                          --------------   -----  \n",
      " 0   PWM1                            39823 non-null   float64\n",
      " 1   PWM1_f                          39823 non-null   float64\n",
      " 2   PWM2                            39823 non-null   float64\n",
      " 3   PWM2_f                          39823 non-null   float64\n",
      " 4   PWM3                            39823 non-null   float64\n",
      " 5   PWM3_f                          39823 non-null   float64\n",
      " 6   PWM4                            39823 non-null   float64\n",
      " 7   PWM4_f                          39823 non-null   float64\n",
      " 8   angular_velocity_covariance     21298 non-null   object \n",
      " 9   ax_B_[m/s2]                     77287 non-null   float64\n",
      " 10  ax_I_[m/s2]                     77287 non-null   float64\n",
      " 11  ax_[m/s2]                       21298 non-null   float64\n",
      " 12  ax_g|B_[m/s2]                   77287 non-null   float64\n",
      " 13  ay_B_[m/s2]                     77287 non-null   float64\n",
      " 14  ay_I_[m/s2]                     77287 non-null   float64\n",
      " 15  ay_[m/s2]                       21298 non-null   float64\n",
      " 16  ay_g|B_[m/s2]                   77287 non-null   float64\n",
      " 17  az_B_[m/s2]                     77287 non-null   float64\n",
      " 18  az_I_[m/s2]                     77287 non-null   float64\n",
      " 19  az_[m/s2]                       21298 non-null   float64\n",
      " 20  az_g|B_[m/s2]                   77287 non-null   float64\n",
      " 21  linear_acceleration_covariance  21298 non-null   object \n",
      " 22  motor1_[rps]_est                39824 non-null   float64\n",
      " 23  motor1dot_[rps2]                39824 non-null   float64\n",
      " 24  motor2_[rps]_est                39824 non-null   float64\n",
      " 25  motor2dot_[rps2]                39824 non-null   float64\n",
      " 26  motor3_[rps]_est                39824 non-null   float64\n",
      " 27  motor3dot_[rps2]                39824 non-null   float64\n",
      " 28  motor4_[rps]_est                39824 non-null   float64\n",
      " 29  motor4dot_[rps2]                39824 non-null   float64\n",
      " 30  omegadotx_est                   21298 non-null   float64\n",
      " 31  omegadotx_qest                  77287 non-null   float64\n",
      " 32  omegadoty_est                   21298 non-null   float64\n",
      " 33  omegadoty_qest                  77287 non-null   float64\n",
      " 34  omegadotz_est                   21298 non-null   float64\n",
      " 35  omegadotz_qest                  77287 non-null   float64\n",
      " 36  omegax_[dps]                    21298 non-null   float64\n",
      " 37  omegax_est                      21298 non-null   float64\n",
      " 38  omegax_qest                     77287 non-null   float64\n",
      " 39  omegaxdot_B_[rps]               77287 non-null   float64\n",
      " 40  omegay_[dps]                    21298 non-null   float64\n",
      " 41  omegay_est                      21298 non-null   float64\n",
      " 42  omegay_qest                     77287 non-null   float64\n",
      " 43  omegaydot_B_[rps]               77287 non-null   float64\n",
      " 44  omegaz_[dps]                    21298 non-null   float64\n",
      " 45  omegaz_est                      21298 non-null   float64\n",
      " 46  omegaz_qest                     77287 non-null   float64\n",
      " 47  omegazdot_B_[rps]               77287 non-null   float64\n",
      " 48  orientation_covariance          21298 non-null   object \n",
      " 49  pitch_[rad]                     77286 non-null   float64\n",
      " 50  pitch_ref_[rad]                 38130 non-null   float64\n",
      " 51  px_[m]                          77287 non-null   float64\n",
      " 52  px_[m]_est                      77287 non-null   float64\n",
      " 53  pxr_[m]                         38131 non-null   float64\n",
      " 54  py_[m]                          77287 non-null   float64\n",
      " 55  py_[m]_est                      77287 non-null   float64\n",
      " 56  pyr_[m]                         38131 non-null   float64\n",
      " 57  pz_[m]                          77287 non-null   float64\n",
      " 58  pz_[m]_est                      77287 non-null   float64\n",
      " 59  pzr_[m]                         38131 non-null   float64\n",
      " 60  qdotdotw                        77287 non-null   float64\n",
      " 61  qdotdotx                        77287 non-null   float64\n",
      " 62  qdotdoty                        77287 non-null   float64\n",
      " 63  qdotdotz                        77287 non-null   float64\n",
      " 64  qdotw                           77287 non-null   float64\n",
      " 65  qdotx                           77287 non-null   float64\n",
      " 66  qdoty                           77287 non-null   float64\n",
      " 67  qdotz                           77287 non-null   float64\n",
      " 68  qw                              77287 non-null   float64\n",
      " 69  qw_est                          77287 non-null   float64\n",
      " 70  qwr                             38131 non-null   float64\n",
      " 71  qx                              77287 non-null   float64\n",
      " 72  qx_est                          77287 non-null   float64\n",
      " 73  qxr                             38131 non-null   float64\n",
      " 74  qy                              77287 non-null   float64\n",
      " 75  qy_est                          77287 non-null   float64\n",
      " 76  qyr                             38131 non-null   float64\n",
      " 77  qz                              77287 non-null   float64\n",
      " 78  qz_est                          77287 non-null   float64\n",
      " 79  qzr                             38131 non-null   float64\n",
      " 80  roll_[rad]                      77286 non-null   float64\n",
      " 81  roll_ref_[rad]                  38130 non-null   float64\n",
      " 82  rpm1                            39824 non-null   float64\n",
      " 83  rpm2                            39824 non-null   float64\n",
      " 84  rpm3                            39824 non-null   float64\n",
      " 85  rpm4                            39824 non-null   float64\n",
      " 86  vx_B_[m/s]                      77287 non-null   float64\n",
      " 87  vx_I_[m/s]                      77287 non-null   float64\n",
      " 88  vy_B_[m/s]                      77287 non-null   float64\n",
      " 89  vy_I_[m/s]                      77287 non-null   float64\n",
      " 90  vz_B_[m/s]                      77287 non-null   float64\n",
      " 91  vz_I_[m/s]                      77287 non-null   float64\n",
      " 92  yaw_[rad]                       77286 non-null   float64\n",
      " 93  yaw_ref_[rad]                   38130 non-null   float64\n",
      " 94  is_flying                       781699 non-null  bool   \n",
      "dtypes: bool(1), float64(91), object(3)\n",
      "memory usage: 587.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Initial read in flight test\n",
    "def cleaned_blackbird_test(maneuver, yaw_direction, max_speed):\n",
    "    test_df = rbd.read_blackbird_test(maneuver, yaw_direction, max_speed)\n",
    "    rbd.imu_installation_correction(test_df)\n",
    "    test_df = rbd.inertial_position_derivatives_estimation(test_df)\n",
    "    test_df = rbd.gyroscope_derivatives_estimation(test_df)\n",
    "    test_df = rbd.consistent_quaternions(test_df)\n",
    "    test_df = rbd.inertial_quaternion_derivatives_estimation(test_df)\n",
    "    test_df = rbd.body_quaternion_angular_derivative_estimate(test_df)\n",
    "    test_df = rbd.motor_scaling(test_df)\n",
    "    test_df = rbd.motor_rates(test_df)\n",
    "    test_df = rbd.quaternion_body_acceleration(test_df)\n",
    "    test_df = rbd.detrend_pwm(test_df)\n",
    "    test_df = rbd.scale_and_filter_pwms(test_df)\n",
    "    test_df = rbd.on_ground(test_df)  # Must be last function\n",
    "    return test_df\n",
    "\n",
    "test_df = cleaned_blackbird_test('figure8', 'Constant', 0.5)\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vicon position': (71, 0.002777999999999281, 3), 'vicon attitude': (71, 0.002777999999999281, 4), 'reference position': (37, 0.005305999999990263, 3), 'reference attitude': (37, 0.005305999999990263, 4), 'motor speeds': (37, 0.00532200000000671, 4), 'accelerometer': (20, 0.00999999999999801, 3), 'gyroscope': (20, 0.00999999999999801, 3), 'PWM': (37, 0.005320999999980813, 4), 'input variables': ['vicon position', 'vicon attitude', 'reference position', 'reference attitude', 'motor speeds', 'accelerometer', 'gyroscope'], 'output variables': ['PWM'], 'future variables': ['reference position', 'reference attitude', 'PWM'], 'past variables': ['vicon position', 'vicon attitude', 'motor speeds', 'accelerometer', 'gyroscope']}\n"
     ]
    }
   ],
   "source": [
    "# Get testing input/output data\n",
    "past_window = .2\n",
    "future_window = .2\n",
    "X, Y, tvec_y, info = rbd.generate_opt_control_test_data(\n",
    "    test_df,\n",
    "    past_window,\n",
    "    future_window\n",
    ")\n",
    "\n",
    "print(info)\n",
    "Y = Y[:, :int(Y.shape[1]/4)]  # Reduce Y to just PWM 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 37473\n",
      "Input shape: (1024,)\n",
      "Output shape: (37,)\n"
     ]
    }
   ],
   "source": [
    "N = X.shape[0]\n",
    "dX = X.shape[1]\n",
    "dY = Y.shape[1]\n",
    "\n",
    "print(\"Number of examples: %i\" % N)\n",
    "print(\"Input shape: (%i,)\" % dX)\n",
    "print(\"Output shape: (%i,)\" % dY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Models\n",
    "\n",
    "Create the various neural network models. All models will have the same depth but the parameters and width of the network may be different.\n",
    "\n",
    "### Default Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 37)                37925     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 37)                1406      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 37)                1406      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 37)                1406      \n",
      "=================================================================\n",
      "Total params: 42,143\n",
      "Trainable params: 42,143\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "depth = 4\n",
    "default_weight_location = '../models/reg_benchmark_default_weights.keras'\n",
    "\n",
    "default = tf.keras.Sequential()\n",
    "for i in range(depth):\n",
    "    if i == 0:\n",
    "        default.add(tf.keras.layers.Dense(dY, activation=tf.nn.relu, input_shape=(dX,)))\n",
    "    else:\n",
    "        default.add(tf.keras.layers.Dense(dY, activation=tf.nn.relu, input_shape=(dY,)))\n",
    "\n",
    "default.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.mse,\n",
    "    metrics=['mse'],\n",
    "    loss_weights=None,\n",
    "    weighted_metrics=None,\n",
    "    run_eagerly=None,\n",
    ")\n",
    "default.summary()\n",
    "\n",
    "default.save_weights(default_weight_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roughness Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function loss_fun at 0x00000196D1022F28> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function loss_fun at 0x00000196D1022F28> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:AutoGraph could not transform <function mse_and_roughness at 0x0000019697085A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function mse_and_roughness at 0x0000019697085A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:AutoGraph could not transform <function roughness_penalty at 0x0000019697085BF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "WARNING: AutoGraph could not transform <function roughness_penalty at 0x0000019697085BF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 37)                37925     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 37)                1406      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 37)                1406      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 37)                1406      \n",
      "=================================================================\n",
      "Total params: 42,143\n",
      "Trainable params: 42,143\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "roughness = tf.keras.Sequential()\n",
    "for i in range(depth):\n",
    "    if i == 0:\n",
    "        roughness.add(tf.keras.layers.Dense(dY, activation=tf.nn.relu, input_shape=(dX,)))\n",
    "    else:\n",
    "        roughness.add(tf.keras.layers.Dense(dY, activation=tf.nn.relu, input_shape=(dY,)))\n",
    "\n",
    "@tf.function\n",
    "def loss_fun(yact, ypred):\n",
    "    \"\"\"Matches default from L1 and L2\"\"\"\n",
    "    return clf.mse_and_roughness(yact, ypred, degree=3, alpha=0.01)\n",
    "\n",
    "roughness.compile(\n",
    "    optimizer='adam',\n",
    "    loss=loss_fun,\n",
    "    metrics=['mse'],\n",
    "    loss_weights=None,\n",
    "    weighted_metrics=None,\n",
    "    run_eagerly=None,\n",
    ")\n",
    "roughness.summary()\n",
    "\n",
    "roughness.load_weights(default_weight_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $L_1$ Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 37)                37925     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 37)                1406      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 37)                1406      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 37)                1406      \n",
      "=================================================================\n",
      "Total params: 42,143\n",
      "Trainable params: 42,143\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lone = tf.keras.Sequential()\n",
    "for i in range(depth):\n",
    "    if i == 0:\n",
    "        lone.add(tf.keras.layers.Dense(dY, activation=tf.nn.relu, kernel_regularizer='l1', input_shape=(dX,)))\n",
    "    else:\n",
    "        lone.add(tf.keras.layers.Dense(dY, activation=tf.nn.relu, kernel_regularizer='l1', input_shape=(dY,)))\n",
    "\n",
    "lone.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.mse,\n",
    "    metrics=['mse'],\n",
    "    loss_weights=None,\n",
    "    weighted_metrics=None,\n",
    "    run_eagerly=None,\n",
    ")\n",
    "lone.summary()\n",
    "\n",
    "lone.load_weights(default_weight_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $L_2$ Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 37)                37925     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 37)                1406      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 37)                1406      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 37)                1406      \n",
      "=================================================================\n",
      "Total params: 42,143\n",
      "Trainable params: 42,143\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ltwo = tf.keras.Sequential()\n",
    "for i in range(depth):\n",
    "    if i == 0:\n",
    "        ltwo.add(tf.keras.layers.Dense(dY, activation=tf.nn.relu, kernel_regularizer='l2', input_shape=(dX,)))\n",
    "    else:\n",
    "        ltwo.add(tf.keras.layers.Dense(dY, activation=tf.nn.relu, kernel_regularizer='l2', input_shape=(dY,)))\n",
    "\n",
    "ltwo.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.mse,\n",
    "    metrics=['mse'],\n",
    "    loss_weights=None,\n",
    "    weighted_metrics=None,\n",
    "    run_eagerly=None,\n",
    ")\n",
    "ltwo.summary()\n",
    "\n",
    "ltwo.load_weights(default_weight_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 37)                37925     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 37)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 37)                1406      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 37)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 37)                1406      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 37)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 37)                1406      \n",
      "=================================================================\n",
      "Total params: 42,143\n",
      "Trainable params: 42,143\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "drop_rate = 0.2  # 20 % dropout rate\n",
    "\n",
    "dropout = tf.keras.Sequential()\n",
    "for i in range(depth):\n",
    "    if i == 0:\n",
    "        dropout.add(tf.keras.layers.Dense(dY, activation=tf.nn.relu, input_shape=(dX,)))\n",
    "    else:\n",
    "        dropout.add(tf.keras.layers.Dropout(drop_rate))\n",
    "        dropout.add(tf.keras.layers.Dense(dY, activation=tf.nn.relu, input_shape=(dY,)))\n",
    "\n",
    "dropout.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.mse,\n",
    "    metrics=['mse'],\n",
    "    loss_weights=None,\n",
    "    weighted_metrics=None,\n",
    "    run_eagerly=None,\n",
    ")\n",
    "dropout.summary()\n",
    "\n",
    "dropout.load_weights(default_weight_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Regularization\n",
    "\n",
    "This is essentially a copy-paste from the linked GitHub Repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OurNet(\n",
      "  (l1): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (l2): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (l3): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (l4): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=37, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "adaregnn_width = 10\n",
    "\n",
    "class AdaRegNN(torch.nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(AdaRegNN, self).__init__()\n",
    "        \n",
    "        # Layers\n",
    "        self.l1 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(\n",
    "                dX,  # input features\n",
    "                adaregnn_width  # output features\n",
    "            ),  # xA^T + b\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        self.l2 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(\n",
    "                adaregnn_width,  # input features\n",
    "                adaregnn_width  # output features\n",
    "            ),  # xA^T + b\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        self.l3 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(\n",
    "                adaregnn_width,  # input features\n",
    "                adaregnn_width  # output features\n",
    "            ),  # xA^T + b\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        self.l4 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(\n",
    "                adaregnn_width,  # input features\n",
    "                dY  # output features\n",
    "            ),  # xA^T + b\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        \"\"\"\n",
    "        self.layers = []\n",
    "        for i in range(depth):\n",
    "            self.layers.append(\n",
    "                torch.nn.Sequential(\n",
    "                    torch.nn.Linear(\n",
    "                        dX if i == 0 else dY,  # input features\n",
    "                        dY  # output features\n",
    "                    ),  # xA^T + b\n",
    "                    torch.nn.ReLU()\n",
    "                )\n",
    "            )\n",
    "        \"\"\"\n",
    "    \n",
    "    def forward(self, f, if_decov=False):\n",
    "        feat = f\n",
    "        feat = self.l1(feat)\n",
    "        feat = self.l2(feat)\n",
    "        feat = self.l3(feat)\n",
    "        feat = self.l4(feat)\n",
    "        return feat\n",
    "        \n",
    "\n",
    "def BayesNet(args):\n",
    "    class OurNet(AdaRegNN):\n",
    "        \"\"\"\n",
    "        The network with empirical bayes assumptions on weights.\n",
    "        We're going to update cov with this class, while the update for weights we simply use gradient descent method.\n",
    "        \"\"\"\n",
    "        def __init__(self, args):\n",
    "            super(OurNet, self).__init__(args)\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                self.cuda()\n",
    "                \n",
    "            self.sqrt_cov_prev = []\n",
    "            self.sqrt_cov_next = []\n",
    "            self.cov_weight  = []\n",
    "            \n",
    "            name, module = list(self.named_children())[-1]\n",
    "            # print(name)\n",
    "            shape = list(module.parameters())[0].shape\n",
    "            sqt_cov_pre = torch.nn.Parameter(torch.eye(shape[1]), requires_grad = False)\n",
    "            sqt_cov_nex = torch.nn.Parameter(torch.eye(shape[0]), requires_grad = False)\n",
    "            if torch.cuda.is_available():\n",
    "                sqt_cov_pre = sqt_cov_pre.cuda()\n",
    "                sqt_cov_nex = sqt_cov_nex.cuda()\n",
    "            self.sqrt_cov_prev.append(sqt_cov_pre)\n",
    "            self.sqrt_cov_next.append(sqt_cov_nex)\n",
    "            self.cov_weight.append(list(module.parameters())[0])\n",
    "            \n",
    "            \"\"\"\n",
    "            for name, module in self.named_children():\n",
    "                # print(name)\n",
    "                shape = list(module.parameters())[0].shape\n",
    "                if len(shape) == 4: # conv layer\n",
    "                    if args.regu_type == 'ALL' or args.regu_type == 'CONV':\n",
    "                        sqt_cov_pre = torch.nn.Parameter(torch.eye(shape[1] * shape[2] * shape[3]), requires_grad = False)\n",
    "                        sqt_cov_nex = torch.nn.Parameter(torch.eye(shape[0]), requires_grad = False)\n",
    "                        if torch.cuda.is_available():\n",
    "                            sqt_cov_pre = sqt_cov_pre.cuda()\n",
    "                            sqt_cov_nex = sqt_cov_nex.cuda()\n",
    "                        # we view conv weights as a 2d matrix (shape[0], shape[1] * shape[2] * shape[3])\n",
    "                        self.sqrt_cov_prev.append(sqt_cov_pre)\n",
    "                        self.sqrt_cov_next.append(sqt_cov_nex)\n",
    "                        self.cov_weight.append(list(module.parameters())[0].view(shape[0], -1))\n",
    "                elif len(shape) == 2: # MLP layer\n",
    "                    sqt_cov_pre = torch.nn.Parameter(torch.eye(shape[1]), requires_grad = False)\n",
    "                    sqt_cov_nex = torch.nn.Parameter(torch.eye(shape[0]), requires_grad = False)\n",
    "                    if torch.cuda.is_available():\n",
    "                        sqt_cov_pre = sqt_cov_pre.cuda()\n",
    "                        sqt_cov_nex = sqt_cov_nex.cuda()\n",
    "                    self.sqrt_cov_prev.append(sqt_cov_pre)\n",
    "                    self.sqrt_cov_next.append(sqt_cov_nex)\n",
    "                    self.cov_weight.append(list(module.parameters())[0])\n",
    "            \"\"\"\n",
    "            \n",
    "        def regularizer(self):\n",
    "            \"\"\"\n",
    "            Compute the weight regularizer in the network (layer by layer).\n",
    "            \"\"\"\n",
    "            r = []\n",
    "            for i in range(len(self.cov_weight)):\n",
    "                r_sqrt = torch.mm(torch.mm(self.sqrt_cov_next[i], self.cov_weight[i]), self.sqrt_cov_prev[i])\n",
    "                r.append(torch.sum(r_sqrt * r_sqrt))\n",
    "            return r\n",
    "        \n",
    "        def _thresholding(self, sv, lower, upper):\n",
    "            \"\"\"\n",
    "            Two-way soft-thresholding of singular values.\n",
    "            :param sv:  A list of singular values.\n",
    "            :param lower:   Lower bound for soft-thresholding.\n",
    "            :param upper:   Upper bound for soft-thresholding.\n",
    "            :return:    Thresholded singular values.\n",
    "            \"\"\"\n",
    "            uidx = sv > upper\n",
    "            lidx = sv < lower\n",
    "            sv[uidx] = upper\n",
    "            sv[lidx] = lower\n",
    "            return sv\n",
    "        \n",
    "        def update_covs(self, lower, upper):\n",
    "            \"\"\"\n",
    "            Layer by layer, update both the covariance matrix over tasks and over features, using the closed form solutions. \n",
    "            :param lower: Lower bound of the truncation.\n",
    "            :param upper: Upper bound of the truncation.\n",
    "            \"\"\"\n",
    "            for i in range(len(self.cov_weight)):\n",
    "                cov_next = torch.mm(self.sqrt_cov_next[i], self.sqrt_cov_next[i].t())\n",
    "                \n",
    "                # dim: {(p x n) * (n x n)} * (n x p) = (p x p)\n",
    "                cov_prev_weight = torch.mm(torch.mm(self.cov_weight[i].t(), cov_next), self.cov_weight[i])\n",
    "                \n",
    "                # compute SVD\n",
    "                # U, S, V = SVD(A): A is the input matrix\n",
    "                u, s, _ = torch.svd(cov_prev_weight.data)\n",
    "                \n",
    "                # inverse and do truncation on inverse singular values\n",
    "                s = s.shape[0] / s\n",
    "                s = self._thresholding(s, lower, upper)\n",
    "                \n",
    "                # recompute the sqrt_cov\n",
    "                s = torch.sqrt(s)\n",
    "                # dim for u and s: (p x p)\n",
    "                self.sqrt_cov_prev[i].data = torch.mm(torch.mm(u, torch.diag(s)), u.t())\n",
    "                \n",
    "            for i in range(len(self.cov_weight)):\n",
    "                cov_prev = torch.mm(self.sqrt_cov_prev[i], self.sqrt_cov_prev[i].t())\n",
    "                \n",
    "                # dim: {(n x p) * (p x p)} * (p x n) = (n x n)\n",
    "                cov_next_weight = torch.mm(torch.mm(self.cov_weight[i], cov_prev), self.cov_weight[i].t())\n",
    "                \n",
    "                # compute SVD\n",
    "                # U, S, V = SVD(A): A is the input matrix\n",
    "                u, s, _ = torch.svd(cov_next_weight.data)\n",
    "                \n",
    "                # inverse and do truncation on inverse singular values\n",
    "                s = s.shape[0] / s\n",
    "                s = self._thresholding(s, lower, upper)\n",
    "                \n",
    "                # recompute the sqrt_cov\n",
    "                s = torch.sqrt(s)\n",
    "                # dim for u and s: (p x p)\n",
    "                self.sqrt_cov_next[i].data = torch.mm(torch.mm(u, torch.diag(s)), u.t())\n",
    "\n",
    "    return OurNet(args)\n",
    "\n",
    "def bayes_training_evaluation(myNet, optimizer, train_loader, test_loader, args):  \n",
    "    _inside_loss = np.zeros((args.outer_loop*args.inner_epoch, 1))\n",
    "    \n",
    "    for k in range(args.outer_loop):\n",
    "        # optimize the model parameters\n",
    "        #print('in outer_loop ' + str(k) + '.....')\n",
    "        for t in range(args.inner_epoch):\n",
    "            print('in epoch ' + str(k*args.inner_epoch + t) + '.....')\n",
    "            myNet.train()\n",
    "            for xs, ys in train_loader:\n",
    "                if torch.cuda.is_available():\n",
    "                    xs, ys = xs.cuda(), ys.cuda()\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                y_pred = myNet(xs)\n",
    "                closs = criterion(y_pred, ys)\n",
    "                rloss_list = myNet.regularizer()\n",
    "                rloss = 0\n",
    "                for i in range(len(rloss_list)):\n",
    "                    rloss = rloss + rloss_list[i]\n",
    "                \n",
    "                loss = closs + args.rho * rloss\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "            loss = closs.cpu().detach()\n",
    "            print(loss)\n",
    "            _inside_loss[k*args.inner_epoch+t] = loss\n",
    "                \n",
    "        # Optimize covariance matrices, using SVD closed form solutions.\n",
    "        myNet.update_covs(args.lower_threshold, args.upper_threshold)\n",
    "    return _inside_loss\n",
    "\n",
    "adareg = BayesNet(None)\n",
    "print(adareg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Each network shall be trained for the same amount of epochs with the training and validation loss tracked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standards for training\n",
    "epochs = 10\n",
    "verbose = 0\n",
    "validation_split = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time per epoch: 3.569959 [s]\n"
     ]
    }
   ],
   "source": [
    "# Training Default Network\n",
    "tstart = time.time()\n",
    "default_h = default.fit(x=X, y=Y, epochs=epochs, verbose=verbose, validation_split=validation_split)\n",
    "tstop = time.time()\n",
    "\n",
    "print(\"Average time per epoch: %f [s]\" % ((tstop - tstart)/epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Patrick\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time per epoch: 5.910889 [s]\n"
     ]
    }
   ],
   "source": [
    "# Training Roughness\n",
    "tstart = time.time()\n",
    "roughness_h = roughness.fit(x=X, y=Y, epochs=epochs, verbose=verbose, validation_split=validation_split)\n",
    "tstop = time.time()\n",
    "\n",
    "print(\"Average time per epoch: %f [s]\" % ((tstop - tstart)/epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time per epoch: 4.278264 [s]\n"
     ]
    }
   ],
   "source": [
    "# Training L1\n",
    "tstart = time.time()\n",
    "lone_h = lone.fit(x=X, y=Y, epochs=epochs, verbose=verbose, validation_split=validation_split)\n",
    "tstop = time.time()\n",
    "\n",
    "print(\"Average time per epoch: %f [s]\" % ((tstop - tstart)/epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time per epoch: 4.607603 [s]\n"
     ]
    }
   ],
   "source": [
    "# Training L2\n",
    "tstart = time.time()\n",
    "ltwo_h = ltwo.fit(x=X, y=Y, epochs=epochs, verbose=verbose, validation_split=validation_split)\n",
    "tstop = time.time()\n",
    "\n",
    "print(\"Average time per epoch: %f [s]\" % ((tstop - tstart)/epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time per epoch: 4.030020 [s]\n"
     ]
    }
   ],
   "source": [
    "# Training Dropout\n",
    "tstart = time.time()\n",
    "dropout_h = ltwo.fit(x=X, y=Y, epochs=epochs, verbose=verbose, validation_split=validation_split)\n",
    "tstop = time.time()\n",
    "\n",
    "print(\"Average time per epoch: %f [s]\" % ((tstop - tstart)/epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in epoch 0.....\n",
      "tensor(6.3565e-05)\n",
      "in epoch 1.....\n",
      "tensor(0.0001)\n",
      "Average time per epoch: -8900.719107 [s]\n"
     ]
    }
   ],
   "source": [
    "# Training AdaReg\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, adareg.parameters()),\n",
    "    lr=5e-4,\n",
    "    weight_decay=1e-2\n",
    ")\n",
    "\n",
    "split_index = int(X.shape[0]*0.8)\n",
    "\n",
    "train_loader = torch.utils.data.TensorDataset(\n",
    "    torch.Tensor(X[:split_index,:]),\n",
    "    torch.Tensor(Y[:split_index,:])\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.TensorDataset(\n",
    "    torch.Tensor(X[split_index:,:]),\n",
    "    torch.Tensor(Y[split_index:,:])\n",
    ")\n",
    "\n",
    "class customArg():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "args = customArg()\n",
    "args.outer_loop = int(0.25*epochs)\n",
    "args.inner_epoch = 1\n",
    "args.rho = 1e-4\n",
    "args.lower_threshold = 1e-3\n",
    "args.upper_threshold = 1e3\n",
    "\n",
    "tstart = time.time()\n",
    "\n",
    "adareg_h = bayes_training_evaluation(\n",
    "    adareg, optimizer, train_loader, test_loader, args\n",
    ")\n",
    "\n",
    "tstop = time.time()\n",
    "\n",
    "print(\"Average time per epoch: %f [s]\" % ((tstop - tstart)/args.outer_loop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Plotting the training histories of each of the networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_list = [default_h, roughness_h, lone_h, ltwo_h, dropout_h]\n",
    "label_list = ['Default', 'Roughness', '$L_1$', '$L_2$', 'Dropout']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "\n",
    "# Figure setup\n",
    "fig.set_figheight(3)\n",
    "fig.set_figwidth(6)\n",
    "\n",
    "# Plotting\n",
    "for hist, label in zip(hist_list, label_list):\n",
    "    yplot = hist.history['mse']\n",
    "    xplot = np.arange(len(yplot))\n",
    "    ax.plot(xplot, yplot, label=label)\n",
    "\n",
    "# AdaReg is Pytorch which is not a history\n",
    "# ax.plot(np.arange(adareg_h.shape[0]), adareg_h[:, 0], label='AdaReg')\n",
    "    \n",
    "# Adjusting axis\n",
    "ax.set_xlabel('Training Epoch')\n",
    "ax.set_ylabel('Mean Squared Error')\n",
    "ax.set_xlim(left=0)\n",
    "ax.set_ylim(bottom=0)\n",
    "ax.legend()\n",
    "\n",
    "fig.savefig(\"../report/project-report/figures/methodology/regularizers-preliminary-comparison.png\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
