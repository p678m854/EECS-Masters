{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blackbird Optimal Control\n",
    "\n",
    "This notebook goes into using neural networks for optimal control. The Blackbird set has multiple flight paths but control scheme for the quadcopter is a nonlinear inverse dynamic controller. This notebook is exploring various neural networks for trying to learn the optimal controller.\n",
    "\n",
    "## Load in data\n",
    "\n",
    "Setting up libraries that will be needed as well as a function to download a flight test from the Blackbird Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import importlib\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "# sys.path.append(os.path.abspath('../functions'))\n",
    "sys.path.append(os.path.abspath('../models'))\n",
    "\n",
    "from thesis.data import blackbird_dataset as rbd\n",
    "from thesis.modules import dsp, quaternions\n",
    "\n",
    "import math\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numba\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import model_selection\n",
    "import tensorflow as tf\n",
    "\n",
    "# Please work\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 781699 entries, 1526617312016142000 to 1526617526748159000\n",
      "Data columns (total 95 columns):\n",
      " #   Column                          Non-Null Count   Dtype  \n",
      "---  ------                          --------------   -----  \n",
      " 0   PWM1                            39823 non-null   float64\n",
      " 1   PWM1_f                          39823 non-null   float64\n",
      " 2   PWM2                            39823 non-null   float64\n",
      " 3   PWM2_f                          39823 non-null   float64\n",
      " 4   PWM3                            39823 non-null   float64\n",
      " 5   PWM3_f                          39823 non-null   float64\n",
      " 6   PWM4                            39823 non-null   float64\n",
      " 7   PWM4_f                          39823 non-null   float64\n",
      " 8   angular_velocity_covariance     21298 non-null   object \n",
      " 9   ax_B_[m/s2]                     77287 non-null   float64\n",
      " 10  ax_I_[m/s2]                     77287 non-null   float64\n",
      " 11  ax_[m/s2]                       21298 non-null   float64\n",
      " 12  ax_g|B_[m/s2]                   77287 non-null   float64\n",
      " 13  ay_B_[m/s2]                     77287 non-null   float64\n",
      " 14  ay_I_[m/s2]                     77287 non-null   float64\n",
      " 15  ay_[m/s2]                       21298 non-null   float64\n",
      " 16  ay_g|B_[m/s2]                   77287 non-null   float64\n",
      " 17  az_B_[m/s2]                     77287 non-null   float64\n",
      " 18  az_I_[m/s2]                     77287 non-null   float64\n",
      " 19  az_[m/s2]                       21298 non-null   float64\n",
      " 20  az_g|B_[m/s2]                   77287 non-null   float64\n",
      " 21  linear_acceleration_covariance  21298 non-null   object \n",
      " 22  motor1_[rps]_est                39824 non-null   float64\n",
      " 23  motor1dot_[rps2]                39824 non-null   float64\n",
      " 24  motor2_[rps]_est                39824 non-null   float64\n",
      " 25  motor2dot_[rps2]                39824 non-null   float64\n",
      " 26  motor3_[rps]_est                39824 non-null   float64\n",
      " 27  motor3dot_[rps2]                39824 non-null   float64\n",
      " 28  motor4_[rps]_est                39824 non-null   float64\n",
      " 29  motor4dot_[rps2]                39824 non-null   float64\n",
      " 30  omegadotx_est                   21298 non-null   float64\n",
      " 31  omegadotx_qest                  77287 non-null   float64\n",
      " 32  omegadoty_est                   21298 non-null   float64\n",
      " 33  omegadoty_qest                  77287 non-null   float64\n",
      " 34  omegadotz_est                   21298 non-null   float64\n",
      " 35  omegadotz_qest                  77287 non-null   float64\n",
      " 36  omegax_[dps]                    21298 non-null   float64\n",
      " 37  omegax_est                      21298 non-null   float64\n",
      " 38  omegax_qest                     77287 non-null   float64\n",
      " 39  omegaxdot_B_[rps]               77287 non-null   float64\n",
      " 40  omegay_[dps]                    21298 non-null   float64\n",
      " 41  omegay_est                      21298 non-null   float64\n",
      " 42  omegay_qest                     77287 non-null   float64\n",
      " 43  omegaydot_B_[rps]               77287 non-null   float64\n",
      " 44  omegaz_[dps]                    21298 non-null   float64\n",
      " 45  omegaz_est                      21298 non-null   float64\n",
      " 46  omegaz_qest                     77287 non-null   float64\n",
      " 47  omegazdot_B_[rps]               77287 non-null   float64\n",
      " 48  orientation_covariance          21298 non-null   object \n",
      " 49  pitch_[rad]                     77286 non-null   float64\n",
      " 50  pitch_ref_[rad]                 38130 non-null   float64\n",
      " 51  px_[m]                          77287 non-null   float64\n",
      " 52  px_[m]_est                      77287 non-null   float64\n",
      " 53  pxr_[m]                         38131 non-null   float64\n",
      " 54  py_[m]                          77287 non-null   float64\n",
      " 55  py_[m]_est                      77287 non-null   float64\n",
      " 56  pyr_[m]                         38131 non-null   float64\n",
      " 57  pz_[m]                          77287 non-null   float64\n",
      " 58  pz_[m]_est                      77287 non-null   float64\n",
      " 59  pzr_[m]                         38131 non-null   float64\n",
      " 60  qdotdotw                        77287 non-null   float64\n",
      " 61  qdotdotx                        77287 non-null   float64\n",
      " 62  qdotdoty                        77287 non-null   float64\n",
      " 63  qdotdotz                        77287 non-null   float64\n",
      " 64  qdotw                           77287 non-null   float64\n",
      " 65  qdotx                           77287 non-null   float64\n",
      " 66  qdoty                           77287 non-null   float64\n",
      " 67  qdotz                           77287 non-null   float64\n",
      " 68  qw                              77287 non-null   float64\n",
      " 69  qw_est                          77287 non-null   float64\n",
      " 70  qwr                             38131 non-null   float64\n",
      " 71  qx                              77287 non-null   float64\n",
      " 72  qx_est                          77287 non-null   float64\n",
      " 73  qxr                             38131 non-null   float64\n",
      " 74  qy                              77287 non-null   float64\n",
      " 75  qy_est                          77287 non-null   float64\n",
      " 76  qyr                             38131 non-null   float64\n",
      " 77  qz                              77287 non-null   float64\n",
      " 78  qz_est                          77287 non-null   float64\n",
      " 79  qzr                             38131 non-null   float64\n",
      " 80  roll_[rad]                      77286 non-null   float64\n",
      " 81  roll_ref_[rad]                  38130 non-null   float64\n",
      " 82  rpm1                            39824 non-null   float64\n",
      " 83  rpm2                            39824 non-null   float64\n",
      " 84  rpm3                            39824 non-null   float64\n",
      " 85  rpm4                            39824 non-null   float64\n",
      " 86  vx_B_[m/s]                      77287 non-null   float64\n",
      " 87  vx_I_[m/s]                      77287 non-null   float64\n",
      " 88  vy_B_[m/s]                      77287 non-null   float64\n",
      " 89  vy_I_[m/s]                      77287 non-null   float64\n",
      " 90  vz_B_[m/s]                      77287 non-null   float64\n",
      " 91  vz_I_[m/s]                      77287 non-null   float64\n",
      " 92  yaw_[rad]                       77286 non-null   float64\n",
      " 93  yaw_ref_[rad]                   38130 non-null   float64\n",
      " 94  is_flying                       781699 non-null  bool   \n",
      "dtypes: bool(1), float64(91), object(3)\n",
      "memory usage: 587.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Initial read in flight test\n",
    "def cleaned_blackbird_test(maneuver, yaw_direction, max_speed):\n",
    "    test_df = rbd.read_blackbird_test(maneuver, yaw_direction, max_speed)\n",
    "    rbd.imu_installation_correction(test_df)\n",
    "    test_df = rbd.inertial_position_derivatives_estimation(test_df)\n",
    "    test_df = rbd.gyroscope_derivatives_estimation(test_df)\n",
    "    test_df = rbd.consistent_quaternions(test_df)\n",
    "    test_df = rbd.inertial_quaternion_derivatives_estimation(test_df)\n",
    "    test_df = rbd.body_quaternion_angular_derivative_estimate(test_df)\n",
    "    test_df = rbd.motor_scaling(test_df)\n",
    "    test_df = rbd.motor_rates(test_df)\n",
    "    test_df = rbd.quaternion_body_acceleration(test_df)\n",
    "    test_df = rbd.detrend_pwm(test_df)\n",
    "    test_df = rbd.scale_and_filter_pwms(test_df)\n",
    "    test_df = rbd.on_ground(test_df)  # Must be last function\n",
    "    return test_df\n",
    "\n",
    "test_df = cleaned_blackbird_test('figure8', 'Constant', 0.5)\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (mpl.ratio !== 1) {\n",
       "            fig.send_message('set_dpi_ratio', { dpi_ratio: mpl.ratio });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    var resizeObserver = new ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * mpl.ratio);\n",
       "                canvas.setAttribute('height', height * mpl.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    resizeObserver.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / mpl.ratio,\n",
       "        fig.canvas.height / mpl.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch (cursor) {\n",
       "        case 0:\n",
       "            cursor = 'pointer';\n",
       "            break;\n",
       "        case 1:\n",
       "            cursor = 'default';\n",
       "            break;\n",
       "        case 2:\n",
       "            cursor = 'crosshair';\n",
       "            break;\n",
       "        case 3:\n",
       "            cursor = 'move';\n",
       "            break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = 'image/png';\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.which === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.which;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which !== 17) {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    if (event.altKey && event.which !== 18) {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    if (event.shiftKey && event.which !== 16) {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data']);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / mpl.ratio;\n",
       "    fig.root.removeEventListener('remove', this._remove_fig_handler);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / mpl.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function () {\n",
       "    this.close_ws(this, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "    el.addEventListener('remove', this._remove_fig_handler);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager) {\n",
       "        manager = IPython.keyboard_manager;\n",
       "    }\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id='4312eca5-6d17-4cf5-b624-b003e57df8c7'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pwms_df = test_df[['PWM1_f', 'PWM2_f', 'PWM3_f', 'PWM4_f']].dropna()\n",
    "tvec = (pwms_df.index - test_df.index[0]) * (10**-9)\n",
    "tvec = tvec.astype('float').values\n",
    "pwms = pwms_df.values\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "ax = fig.add_axes([0.15, 0.1, 0.8, 0.8])\n",
    "ax.plot(tvec, pwms[:, 0], label='PWM1')\n",
    "ax.plot(tvec, pwms[:, 1], label='PWM2')\n",
    "ax.plot(tvec, pwms[:, 2], label='PWM3')\n",
    "ax.plot(tvec, pwms[:, 3], label='PWM4')\n",
    "\n",
    "ax.set_xlabel(\"Time ($t$) [sec]\")\n",
    "ax.set_ylabel(\"Pulse Width Modulation [$\\mu$sec]\")\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Training and Test Sets\n",
    "\n",
    "The idea is that given the data in a past time window and given the future commanded position and orientation in future, then the a sequence of nominal command values can be given. The nominal command values can form the bases for a nonlinear control around some inner controller that closes the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 79.682909 [s]\n",
      "Output Summary\n",
      "\tvicon position: 17 [samples]\t359.971202 [Hz]\n",
      "\tvicon attitude: 17 [samples]\t359.971202 [Hz]\n",
      "\treference position: 9 [samples]\t188.465888 [Hz]\n",
      "\treference attitude: 9 [samples]\t188.465888 [Hz]\n",
      "\tmotor speeds: 9 [samples]\t187.899286 [Hz]\n",
      "\taccelerometer: 5 [samples]\t100.000000 [Hz]\n",
      "\tgyroscope: 5 [samples]\t100.000000 [Hz]\n",
      "\tPWM: 9 [samples]\t187.934599 [Hz]\n"
     ]
    }
   ],
   "source": [
    "# Get a function to generate data based on windowing\n",
    "def generate_test_data(test_df, past_delta_t, future_delta_t, downsample_dict=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        test_df (pd.DataFrame): Flight test data frame to look at\n",
    "        past_delta_t (float): time in seconds to gather past data in [current_time - past_delta_t, current_time] window.\n",
    "        future_delta_t (float): time in seconds to gather past data in [current_time, current_time + future_delta_t] window.\n",
    "        dowsample_dict (dict): dictionary whose keys are the variables used in training and tests with positive integers \n",
    "                                for relative downsample rate. The keys are stride_var with var being pos, att, pos_ref, \n",
    "                                att_ref, motor_speeds, accel, gyro, or pwms.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Dictionary default\n",
    "    if downsample_dict is None:\n",
    "        downsample_dict = {\n",
    "            'stride_pos': 1,\n",
    "            'stride_att': 1,\n",
    "            'stride_pos_ref': 1,\n",
    "            'stride_att_ref': 1,\n",
    "            'stride_motor_speeds': 1,\n",
    "            'stride_accel': 1,\n",
    "            'stride_gyro': 1,\n",
    "            'stride_pwms': 1\n",
    "        }\n",
    "    \n",
    "    # Get inputs to optimal control sequence\n",
    "    # pos., att., ref pos., ref att. ,motor speeds., acc., gyro\n",
    "    pos = test_df[['px_[m]', 'py_[m]', 'pz_[m]']].dropna()\n",
    "    pos_ref = test_df[['pxr_[m]', 'pyr_[m]', 'pzr_[m]']].dropna()\n",
    "    att = test_df[['qw', 'qx', 'qy', 'qz']].dropna()\n",
    "    att_ref = test_df[['qwr', 'qxr', 'qyr', 'qzr']].dropna()\n",
    "    motor_speeds = test_df[['rpm1', 'rpm2', 'rpm3', 'rpm4']].dropna()\n",
    "    accel = test_df[['ax_[m/s2]', 'ay_[m/s2]', 'az_[m/s2]']].dropna()\n",
    "    gyro = test_df[['omegax_[dps]', 'omegay_[dps]', 'omegaz_[dps]']].dropna()\n",
    "\n",
    "    # Get control\n",
    "    pwms = test_df[test_df['is_flying']]\n",
    "    pwms = pwms[['PWM1_f', 'PWM2_f', 'PWM3_f', 'PWM4_f']].dropna()\n",
    "    \n",
    "    # Get time vectors for history\n",
    "    def get_tvec(state_df):\n",
    "        tvec = (state_df.index - test_df.index[0]) * (10**-9)\n",
    "        tvec = tvec.astype('float')\n",
    "        return tvec.values\n",
    "    \n",
    "    # Time Vector\n",
    "    t_pos = get_tvec(pos)\n",
    "    t_att = get_tvec(att)\n",
    "    t_pref = get_tvec(pos_ref)\n",
    "    t_aref = get_tvec(att_ref)\n",
    "    t_motors = get_tvec(motor_speeds)\n",
    "    t_acc = get_tvec(accel)\n",
    "    t_gyro = get_tvec(gyro)\n",
    "    t_pwms = get_tvec(pwms)\n",
    "    \n",
    "    # Dataframe to numpy\n",
    "    def df_to_numpy(state_df):\n",
    "        return state_df.values\n",
    "    \n",
    "    pos = df_to_numpy(pos)\n",
    "    att = df_to_numpy(att)\n",
    "    pos_ref = df_to_numpy(pos_ref)\n",
    "    att_ref = df_to_numpy(att_ref)\n",
    "    motor_speeds = df_to_numpy(motor_speeds)\n",
    "    accel = df_to_numpy(accel)\n",
    "    gyro = df_to_numpy(gyro)\n",
    "    pwms = df_to_numpy(pwms)\n",
    "\n",
    "    # Scaling all numpy data to [0,1] range or [-1,1] range based either on flight test bounds or hardware bounds\n",
    "    pos = pos/5.  # All flight tests are within 10m cube with Z being [-5,0]\n",
    "    pos_ref = pos_ref/5.\n",
    "    # attitude is already a unit scaling\n",
    "    \"\"\"\n",
    "    From initial BB notebook, 0.125 change in frac. throttle gives ~2500 rpm change. Snail gives 2400 rpm/V so if\n",
    "    assuming linear scaling for rpm a max of 20,000 rpm and a voltage of 8.33 V. From reference it looks like 3S LiPo \n",
    "    battery with nominal voltage of 11.1 V. Seems to be short a cell for traditional race/freestyle quads.\n",
    "    \n",
    "    Snail:\n",
    "        https://www.dji.com/snail/info#specs\n",
    "        https://dl.djicdn.com/downloads/snail/20170315/SNAIL+2305+Racing+Motor_multi.pdf\n",
    "    Other:\n",
    "        https://www.getfpv.com/learn/new-to-fpv/all-about-multirotor-fpv-drone-battery/#:~:text=The%20lithium%20battery%20packs%20used,4.35V%20at%20full%20charge.\n",
    "    \"\"\"\n",
    "    motor_speeds = motor_speeds/20000.\n",
    "    # https://www.xsens.com/hubfs/Downloads/Manuals/MTi-1-series-datasheet.pdf?hsCtaTracking=6999e406-3b81-44e2-8e2d-5ecf00e23d87%7Ced790e48-f312-4c41-ad3b-50931a26a420\n",
    "    accel = accel/(2*9.81)  # Full scale is +/- 16 g's but I think 2 will be fine\n",
    "    gyro = gyro/1000.  # Full scale is +/- 20000 deg/s\n",
    "    pwms = (pwms - 1000.)/1000.\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Determine deltas for windowing\n",
    "    dt_pos = np.median(np.diff(t_pos))\n",
    "    dt_att = np.median(np.diff(t_att))\n",
    "    dt_pref = np.median(np.diff(t_pref))\n",
    "    dt_aref = np.median(np.diff(t_aref))\n",
    "    dt_motors = np.median(np.diff(t_motors))\n",
    "    dt_acc = np.median(np.diff(t_acc))\n",
    "    dt_gyro = np.median(np.diff(t_gyro))\n",
    "    dt_pwms = np.median(np.diff(t_pwms)) # The medium will take care of any gaps\n",
    "    \n",
    "    # Find number of state values\n",
    "    n_pos = int(np.floor(past_delta_t/dt_pos))\n",
    "    n_att = int(np.floor(past_delta_t/dt_att))\n",
    "    n_pref = int(np.floor(future_delta_t/dt_pref))\n",
    "    n_aref = int(np.floor(future_delta_t/dt_aref))\n",
    "    n_motors = int(np.floor(past_delta_t/dt_motors))\n",
    "    n_acc = int(np.floor(past_delta_t/dt_acc))\n",
    "    n_gyro = int(np.floor(past_delta_t/dt_gyro))\n",
    "    n_pwms = int(np.floor(future_delta_t/dt_pwms))\n",
    "    \n",
    "    # Record this in a dictionary\n",
    "    info = {\n",
    "        'vicon position': (n_pos, dt_pos),\n",
    "        'vicon attitude': (n_att, dt_att),\n",
    "        'reference position': (n_pref, dt_pref),\n",
    "        'reference attitude': (n_aref, dt_aref),\n",
    "        'motor speeds': (n_motors, dt_motors),\n",
    "        'accelerometer': (n_acc, dt_acc),\n",
    "        'gyroscope': (n_gyro, dt_gyro),\n",
    "        'PWM': (n_pwms, dt_pwms)\n",
    "    }\n",
    "    \n",
    "    # Preallocate input and output vectors\n",
    "    N = t_pwms.shape[0] - n_pwms + 1 # Edit N to mai\n",
    "    X = np.zeros((\n",
    "        N,\n",
    "        int(np.ceil(n_pos/downsample_dict['stride_pos']))*pos.shape[1] + \n",
    "        int(np.ceil(n_att/downsample_dict['stride_att']))*att.shape[1] + \n",
    "        int(np.ceil(n_pref/downsample_dict['stride_pos_ref']))*pos_ref.shape[1] + \n",
    "        int(np.ceil(n_aref/downsample_dict['stride_att_ref']))*att_ref.shape[1] + \n",
    "        int(np.ceil(n_motors/downsample_dict['stride_motor_speeds']))*motor_speeds.shape[1] +\n",
    "        int(np.ceil(n_acc/downsample_dict['stride_accel']))*accel.shape[1] + \n",
    "        int(np.ceil(n_gyro/downsample_dict['stride_gyro']))*gyro.shape[1]\n",
    "    ))\n",
    "    Y = np.zeros((N, int(np.ceil(n_pwms/downsample_dict['stride_pwms']))*pwms.shape[1]))\n",
    "    tvec_y = np.zeros((N, int(np.ceil(n_pwms/downsample_dict['stride_pwms']))))\n",
    "    \n",
    "    \"\"\"\n",
    "    # Loop through (~ 180 secs)\n",
    "    for i in range(N):\n",
    "        # allocate output values\n",
    "        Y[i,:] = pwms[i:i+n_pwms, :].flatten('F')\n",
    "        \n",
    "        # Sampling time\n",
    "        t_sample = t_pwms[i]\n",
    "        \n",
    "        # Accumulate input states\n",
    "        pos_line = pos[t_pos <= t_sample, :][-n_pos:, :].flatten('F')\n",
    "        att_line = att[t_att <= t_sample, :][-n_att:, :].flatten('F')\n",
    "        pref_line = pos_ref[t_sample <= t_pref, :][:n_pref, :].flatten('F')\n",
    "        aref_line = att_ref[t_sample <= t_aref, :][:n_aref, :].flatten('F')\n",
    "        motors_line = motor_speeds[t_motors <= t_sample, :][-n_motors:, :].flatten('F')\n",
    "        acc_line = accel[t_acc <= t_sample, :][-n_acc:, :].flatten('F')\n",
    "        gyro_line = gyro[t_gyro <= t_sample, :][-n_gyro:, :].flatten('F')\n",
    "        \n",
    "        # Put input states into input row already flattened\n",
    "        X[i, :] = np.concatenate((\n",
    "            pos_line, pref_line, att_line, aref_line, motors_line, acc_line, gyro_line\n",
    "        ))\n",
    "    \n",
    "        # Update expected time\n",
    "        tvec_y[i, :] = t_sample + dt_pwms*np.arange(0, n_pwms)\n",
    "    \"\"\"\n",
    "    \n",
    "    # ~100 secs\n",
    "    @numba.jit(nopython=True)\n",
    "    def fast_generator(\n",
    "        X, Y, tvec_y,\n",
    "        pos, att, pos_ref, att_ref, motor_speeds, accel, gyro, pwms,\n",
    "        n_pos, n_att, n_pref, n_aref, n_motors, n_acc, n_gyro, n_pwms,\n",
    "        stride_pos, stride_att, stride_pos_ref, stride_att_ref, stride_motor_speeds, stride_accel, stride_gyro, stride_pwms\n",
    "    ):\n",
    "        pwm_length = int(Y.shape[1]/4)\n",
    "        for i in numba.prange(N):\n",
    "            # allocate output values\n",
    "            for j in range(pwms.shape[1]):\n",
    "                Y[i,j*pwm_length:(j+1)*pwm_length] = pwms[i:i+n_pwms:stride_pwms, j]\n",
    "\n",
    "            # Sampling time\n",
    "            t_sample = t_pwms[i]\n",
    "\n",
    "            def numba_2d_fortran_flatten(X):\n",
    "                Xflattened = np.zeros((X.shape[0]*X.shape[1],))\n",
    "                ni = X.shape[0]\n",
    "                for j in range(X.shape[1]):\n",
    "                    Xflattened[j*ni:(j+1)*ni] = X[:,j]\n",
    "                return Xflattened\n",
    "            \n",
    "            # Accumulate input states\n",
    "            # Position\n",
    "            pos_line = numba_2d_fortran_flatten(pos[t_pos <= t_sample, :][-n_pos::stride_pos, :])\n",
    "            att_line = numba_2d_fortran_flatten(att[t_att <= t_sample, :][-n_att::stride_att, :])\n",
    "            pref_line = numba_2d_fortran_flatten(pos_ref[t_sample <= t_pref, :][:n_pref:stride_pos_ref, :])\n",
    "            aref_line = numba_2d_fortran_flatten(att_ref[t_sample <= t_aref, :][:n_aref:stride_att_ref, :])\n",
    "            motors_line = numba_2d_fortran_flatten(motor_speeds[t_motors <= t_sample, :][-n_motors::stride_motor_speeds, :])\n",
    "            acc_line = numba_2d_fortran_flatten(accel[t_acc <= t_sample, :][-n_acc::stride_accel, :])\n",
    "            gyro_line = numba_2d_fortran_flatten(gyro[t_gyro <= t_sample, :][-n_gyro::stride_gyro, :])\n",
    "\n",
    "            # Put input states into input row already flattened\n",
    "            if X.shape[1] == (pos_line.shape[0] + pref_line.shape[0] +\n",
    "                              att_line.shape[0] + aref_line.shape[0] +\n",
    "                              motors_line.shape[0] + \n",
    "                              acc_line.shape[0] + gyro_line.shape[0]):\n",
    "                X[i, :] = np.concatenate((\n",
    "                    pos_line, pref_line, att_line, aref_line, motors_line, acc_line, gyro_line\n",
    "                ))\n",
    "            else:\n",
    "                X[i, :] = np.nan\n",
    "\n",
    "            # Update expected time\n",
    "            tvec_y[i, :] = t_sample + dt_pwms*(np.arange(0, n_pwms)[::stride_pwms])\n",
    "    \n",
    "    fast_generator(\n",
    "        X, Y, tvec_y, \n",
    "        pos, att, pos_ref, att_ref, motor_speeds, accel, gyro, pwms,\n",
    "        n_pos, n_att, n_pref, n_aref, n_motors, n_acc, n_gyro, n_pwms,\n",
    "        **downsample_dict\n",
    "    )\n",
    "    \n",
    "    # Get rid of invalid segments\n",
    "    ind_valid = np.all(np.isfinite(X), axis=1)\n",
    "    X = X[ind_valid]\n",
    "    Y = Y[ind_valid]\n",
    "    tvec_y = tvec_y[ind_valid]\n",
    "    \n",
    "    return (X, Y, tvec_y, info)\n",
    "\n",
    "# It took 0.687284 seconds to do everything up to all the sorting\n",
    "\n",
    "if True:\n",
    "    t1 = time.time()\n",
    "    _, _, _, output = generate_test_data(test_df, 0.05, 0.05)\n",
    "    t2 = time.time()\n",
    "    print(\"Elapsed time is %f [s]\" % (t2-t1))\n",
    "    print(\"Output Summary\")\n",
    "    for k in output.keys():\n",
    "        n, dt = output[k]\n",
    "        print(\"\\t%s: %i [samples]\\t%f [Hz]\" %(k, n, 1./dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Training \n",
    "\n",
    "Training a simple network to get a baseline model before attempting to try and parameter tuning with regards to window lengths or network size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Summary\n",
      "\tvicon position: 10 [samples]\t9.999200 [Hz]\n",
      "\tvicon attitude: 10 [samples]\t9.999200 [Hz]\n",
      "\treference position: 10 [samples]\t9.919257 [Hz]\n",
      "\treference attitude: 10 [samples]\t9.919257 [Hz]\n",
      "\tmotor speeds: 10 [samples]\t9.889436 [Hz]\n",
      "\taccelerometer: 10 [samples]\t10.000000 [Hz]\n",
      "\tgyroscope: 10 [samples]\t10.000000 [Hz]\n",
      "\tPWM: 10 [samples]\t9.891295 [Hz]\n"
     ]
    }
   ],
   "source": [
    "downsample_dict = {\n",
    "            'stride_pos': 36,\n",
    "            'stride_att': 36,\n",
    "            'stride_pos_ref': 19,\n",
    "            'stride_att_ref': 19,\n",
    "            'stride_motor_speeds': 19,\n",
    "            'stride_accel': 10,\n",
    "            'stride_gyro': 10,\n",
    "            'stride_pwms': 19\n",
    "        }\n",
    "X, Y, tvec_y, output = generate_test_data(test_df, 1., 1., downsample_dict)\n",
    "print(\"Output Summary\")\n",
    "for ko, kd in zip(output.keys(), downsample_dict.keys()):\n",
    "    n, dt = output[ko]\n",
    "    d = downsample_dict[kd]\n",
    "    print(\"\\t%s: %i [samples]\\t%f [Hz]\" %(ko, int(np.ceil(n/d)), 1./(dt*d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 240)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 120)               28920     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 80)                9680      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 60)                4860      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 48)                2928      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 40)                1960      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 40)                1640      \n",
      "=================================================================\n",
      "Total params: 54,908\n",
      "Trainable params: 54,908\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dX = X.shape[1]\n",
    "dY = Y.shape[1]\n",
    "\n",
    "# Build model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=X.shape[1:]))\n",
    "for n in range(2,10):\n",
    "    model.add(tf.keras.layers.Dense(max(dY, int(dX/n)), activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(Y.shape[1], activation=tf.nn.relu))\n",
    "\n",
    "@tf.function\n",
    "def sse_and_max(y_actual, y_pred):  # degree is polynomial degree\n",
    "    sse = tf.keras.backend.sum(tf.keras.backend.square(y_pred - y_actual),  # squared error part\n",
    "                       axis=1)\n",
    "    max_error = tf.keras.backend.max(\n",
    "        tf.keras.backend.abs(y_pred - y_actual),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    return tf.keras.backend.sum(sse + max_error)\n",
    "\n",
    "@tf.function\n",
    "def sse_and_smoothness(\n",
    "    y_actual, y_pred,\n",
    "    degree=tf.constant(5), # degree is polynomial degree\n",
    "    alpha=tf.constant(0.1) #linear weighting between sse and smoothness\n",
    "):  \n",
    "    sse_points = tf.keras.backend.sum(\n",
    "        tf.keras.backend.square(y_pred - y_actual),  # squared error part\n",
    "    )    # axis=1  # This may be unnecessary\n",
    "    #)\n",
    "\n",
    "    # Compute X for LSE where input is simply and integer list\n",
    "    base, power = tf.meshgrid(\n",
    "        tf.keras.backend.cast_to_floatx(tf.range(tf.shape(Y)[1]/tf.constant(4))),\n",
    "        tf.keras.backend.cast_to_floatx(tf.range(degree + tf.constant(1))),\n",
    "        indexing='ij'\n",
    "    )\n",
    "    X = tf.math.pow(base, power)\n",
    "    XtXinvXt = tf.linalg.matmul(tf.linalg.inv(tf.linalg.matmul(X, X, transpose_a=True)), X, transpose_b=True)\n",
    "    \n",
    "    # With 4 PWMs being concatenated down, need to know length of individual PWM signal\n",
    "    pwm_offset = tf.cast(tf.shape(y_actual)[1]/tf.constant(4), tf.int32)\n",
    "\n",
    "    # Loop over given data\n",
    "    \"\"\"\n",
    "    sse_continuity = tf.constant(0.)\n",
    "    for i in tf.range(tf.shape(y_actual)[0]):\n",
    "        # Loop over PWM signals\n",
    "        for j in tf.range(4):\n",
    "            # Column y vector\n",
    "            y, _ = tf.meshgrid(\n",
    "                y_pred[i, j*pwm_offset:(j+tf.constant(1))*pwm_offset],\n",
    "                tf.keras.backend.cast_to_floatx(tf.range(tf.constant(1))),\n",
    "                indexing='ij'\n",
    "            )\n",
    "            # LS estimator\n",
    "            theta = tf.linalg.matmul(XtXinvXt, y)\n",
    "            error_continuity = y - tf.linalg.matmul(X, theta)\n",
    "            sse_continuity = sse_continuity + tf.keras.backend.sum(tf.keras.backend.square(error_continuity))\n",
    "    \"\"\"\n",
    "\n",
    "    def continuity_sse(pwm_channel):\n",
    "        \"\"\"Calculate SSE from polynomial\"\"\"\n",
    "        y, _ = tf.meshgrid(\n",
    "            pwm_channel,\n",
    "            tf.keras.backend.cast_to_floatx(tf.range(tf.constant(1))),\n",
    "            indexing='ij'\n",
    "        )\n",
    "        # LS estimator\n",
    "        theta = tf.linalg.matmul(XtXinvXt, y)\n",
    "        error_continuity = y - tf.linalg.matmul(X, theta)\n",
    "        return tf.keras.backend.sum(tf.keras.backend.square(error_continuity))\n",
    "    \n",
    "\n",
    "    def pwm_iterator(predicted_values):\n",
    "        pwm_channel = tf.reshape(predicted_values, [tf.constant(4), pwm_offset])\n",
    "        pwm_sse = tf.vectorized_map(fn=continuity_sse, elems=pwm_channel)\n",
    "        return tf.keras.backend.sum(pwm_sse)\n",
    "    \n",
    "    sse_continuity = tf.vectorized_map(\n",
    "        fn=pwm_iterator,\n",
    "        elems=y_pred\n",
    "    )\n",
    "    \n",
    "    return (tf.constant(1.) - alpha)*sse_points + alpha*tf.keras.backend.sum(sse_continuity)\n",
    "\n",
    "\n",
    "    \n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.mse,\n",
    "    # loss=sse_and_smoothness,\n",
    "    metrics=['mse'],\n",
    "    loss_weights=None,\n",
    "    weighted_metrics=None,\n",
    "    run_eagerly=None,\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26662 samples, validate on 11427 samples\n",
      "Epoch 1/100\n",
      "26662/26662 [==============================] - 2s 59us/sample - loss: 5.1409e-06 - mse: 5.1409e-06 - val_loss: 2.6295e-04 - val_mse: 2.6295e-04\n",
      "Epoch 2/100\n",
      "26662/26662 [==============================] - 0s 9us/sample - loss: 4.6805e-06 - mse: 4.6805e-06 - val_loss: 2.3589e-04 - val_mse: 2.3589e-04\n",
      "Epoch 3/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 5.1933e-06 - mse: 5.1933e-06 - val_loss: 2.4987e-04 - val_mse: 2.4987e-04\n",
      "Epoch 4/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 6.4074e-06 - mse: 6.4074e-06 - val_loss: 2.3911e-04 - val_mse: 2.3911e-04\n",
      "Epoch 5/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 5.3488e-06 - mse: 5.3488e-06 - val_loss: 3.0993e-04 - val_mse: 3.0993e-04\n",
      "Epoch 6/100\n",
      "26662/26662 [==============================] - 0s 9us/sample - loss: 5.0839e-06 - mse: 5.0839e-06 - val_loss: 3.0555e-04 - val_mse: 3.0555e-04\n",
      "Epoch 7/100\n",
      "26662/26662 [==============================] - 0s 9us/sample - loss: 4.8012e-06 - mse: 4.8012e-06 - val_loss: 2.6238e-04 - val_mse: 2.6238e-04\n",
      "Epoch 8/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.8610e-06 - mse: 4.8610e-06 - val_loss: 2.9213e-04 - val_mse: 2.9213e-04\n",
      "Epoch 9/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 5.7394e-06 - mse: 5.7394e-06 - val_loss: 2.4586e-04 - val_mse: 2.4586e-04\n",
      "Epoch 10/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.7366e-06 - mse: 4.7366e-06 - val_loss: 2.8420e-04 - val_mse: 2.8420e-04\n",
      "Epoch 11/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 5.4558e-06 - mse: 5.4558e-06 - val_loss: 2.7346e-04 - val_mse: 2.7346e-04\n",
      "Epoch 12/100\n",
      "26662/26662 [==============================] - 0s 9us/sample - loss: 6.9691e-06 - mse: 6.9691e-06 - val_loss: 2.0915e-04 - val_mse: 2.0915e-04\n",
      "Epoch 13/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 5.7712e-06 - mse: 5.7712e-06 - val_loss: 2.7390e-04 - val_mse: 2.7390e-04\n",
      "Epoch 14/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 5.2193e-06 - mse: 5.2193e-06 - val_loss: 2.4477e-04 - val_mse: 2.4477e-04\n",
      "Epoch 15/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 5.1219e-06 - mse: 5.1219e-06 - val_loss: 2.8189e-04 - val_mse: 2.8189e-04\n",
      "Epoch 16/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.5160e-06 - mse: 4.5160e-06 - val_loss: 2.5877e-04 - val_mse: 2.5877e-04\n",
      "Epoch 17/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.7024e-06 - mse: 4.7024e-06 - val_loss: 2.8156e-04 - val_mse: 2.8156e-04\n",
      "Epoch 18/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.8370e-06 - mse: 4.8370e-06 - val_loss: 2.3999e-04 - val_mse: 2.3999e-04\n",
      "Epoch 19/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 6.3743e-06 - mse: 6.3743e-06 - val_loss: 2.0047e-04 - val_mse: 2.0047e-04\n",
      "Epoch 20/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 5.1233e-06 - mse: 5.1233e-06 - val_loss: 2.6822e-04 - val_mse: 2.6822e-04\n",
      "Epoch 21/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.2891e-06 - mse: 4.2891e-06 - val_loss: 2.3702e-04 - val_mse: 2.3702e-04\n",
      "Epoch 22/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.4518e-06 - mse: 4.4518e-06 - val_loss: 2.6584e-04 - val_mse: 2.6584e-04\n",
      "Epoch 23/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.2143e-06 - mse: 4.2143e-06 - val_loss: 2.7821e-04 - val_mse: 2.7821e-04\n",
      "Epoch 24/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.3503e-06 - mse: 4.3503e-06 - val_loss: 2.5513e-04 - val_mse: 2.5513e-04\n",
      "Epoch 25/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.5459e-06 - mse: 4.5459e-06 - val_loss: 2.6546e-04 - val_mse: 2.6546e-04\n",
      "Epoch 26/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.4986e-06 - mse: 4.4986e-06 - val_loss: 2.3809e-04 - val_mse: 2.3809e-04\n",
      "Epoch 27/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.7892e-06 - mse: 4.7892e-06 - val_loss: 2.6416e-04 - val_mse: 2.6416e-04\n",
      "Epoch 28/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.8474e-06 - mse: 4.8474e-06 - val_loss: 1.8113e-04 - val_mse: 1.8113e-04\n",
      "Epoch 29/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.6784e-06 - mse: 4.6784e-06 - val_loss: 2.6190e-04 - val_mse: 2.6190e-04\n",
      "Epoch 30/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.4586e-06 - mse: 4.4586e-06 - val_loss: 2.6388e-04 - val_mse: 2.6388e-04\n",
      "Epoch 31/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.3599e-06 - mse: 4.3599e-06 - val_loss: 2.6364e-04 - val_mse: 2.6364e-04\n",
      "Epoch 32/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.2704e-06 - mse: 4.2704e-06 - val_loss: 2.6249e-04 - val_mse: 2.6249e-04\n",
      "Epoch 33/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.2213e-06 - mse: 4.2213e-06 - val_loss: 2.6170e-04 - val_mse: 2.6170e-04\n",
      "Epoch 34/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.8602e-06 - mse: 4.8602e-06 - val_loss: 2.4464e-04 - val_mse: 2.4464e-04\n",
      "Epoch 35/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.5228e-06 - mse: 4.5228e-06 - val_loss: 2.6521e-04 - val_mse: 2.6521e-04\n",
      "Epoch 36/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.3274e-06 - mse: 4.3274e-06 - val_loss: 2.3225e-04 - val_mse: 2.3225e-04\n",
      "Epoch 37/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.3257e-06 - mse: 4.3257e-06 - val_loss: 2.6099e-04 - val_mse: 2.6099e-04\n",
      "Epoch 38/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.5480e-06 - mse: 4.5480e-06 - val_loss: 2.6091e-04 - val_mse: 2.6091e-04\n",
      "Epoch 39/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.8332e-06 - mse: 4.8332e-06 - val_loss: 2.7256e-04 - val_mse: 2.7256e-04\n",
      "Epoch 40/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.4047e-06 - mse: 4.4047e-06 - val_loss: 2.3951e-04 - val_mse: 2.3951e-04\n",
      "Epoch 41/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.7245e-06 - mse: 4.7245e-06 - val_loss: 2.4384e-04 - val_mse: 2.4384e-04\n",
      "Epoch 42/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.8471e-06 - mse: 4.8471e-06 - val_loss: 2.4529e-04 - val_mse: 2.4529e-04\n",
      "Epoch 43/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.9349e-06 - mse: 4.9349e-06 - val_loss: 2.1944e-04 - val_mse: 2.1944e-04\n",
      "Epoch 44/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.3464e-06 - mse: 4.3464e-06 - val_loss: 2.4252e-04 - val_mse: 2.4252e-04\n",
      "Epoch 45/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.1848e-06 - mse: 4.1848e-06 - val_loss: 2.6864e-04 - val_mse: 2.6864e-04\n",
      "Epoch 46/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.3607e-06 - mse: 4.3607e-06 - val_loss: 2.7271e-04 - val_mse: 2.7271e-04\n",
      "Epoch 47/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.4661e-06 - mse: 4.4661e-06 - val_loss: 2.4781e-04 - val_mse: 2.4781e-04\n",
      "Epoch 48/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.2167e-06 - mse: 4.2168e-06 - val_loss: 2.8229e-04 - val_mse: 2.8229e-04\n",
      "Epoch 49/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 5.6939e-06 - mse: 5.6939e-06 - val_loss: 1.1785e-04 - val_mse: 1.1785e-04\n",
      "Epoch 50/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 5.3495e-06 - mse: 5.3495e-06 - val_loss: 2.0025e-04 - val_mse: 2.0025e-04\n",
      "Epoch 51/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 5.6220e-06 - mse: 5.6220e-06 - val_loss: 2.1372e-04 - val_mse: 2.1372e-04\n",
      "Epoch 52/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.5729e-06 - mse: 4.5729e-06 - val_loss: 2.2800e-04 - val_mse: 2.2800e-04\n",
      "Epoch 53/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.5513e-06 - mse: 4.5513e-06 - val_loss: 2.2282e-04 - val_mse: 2.2282e-04\n",
      "Epoch 54/100\n",
      "26662/26662 [==============================] - 0s 9us/sample - loss: 4.6132e-06 - mse: 4.6132e-06 - val_loss: 1.8831e-04 - val_mse: 1.8831e-04\n",
      "Epoch 55/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.1895e-06 - mse: 4.1895e-06 - val_loss: 1.8000e-04 - val_mse: 1.8000e-04\n",
      "Epoch 56/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.1087e-06 - mse: 4.1087e-06 - val_loss: 1.8851e-04 - val_mse: 1.8851e-04\n",
      "Epoch 57/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.2548e-06 - mse: 4.2548e-06 - val_loss: 1.7513e-04 - val_mse: 1.7513e-04\n",
      "Epoch 58/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 7.3002e-06 - mse: 7.3002e-06 - val_loss: 1.3240e-04 - val_mse: 1.3240e-04\n",
      "Epoch 59/100\n",
      "26662/26662 [==============================] - 0s 9us/sample - loss: 5.4542e-06 - mse: 5.4542e-06 - val_loss: 1.7834e-04 - val_mse: 1.7834e-04\n",
      "Epoch 60/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 5.3888e-06 - mse: 5.3888e-06 - val_loss: 2.3270e-04 - val_mse: 2.3270e-04\n",
      "Epoch 61/100\n",
      "26662/26662 [==============================] - 0s 9us/sample - loss: 5.1730e-06 - mse: 5.1730e-06 - val_loss: 2.5974e-04 - val_mse: 2.5974e-04\n",
      "Epoch 62/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.6561e-06 - mse: 4.6561e-06 - val_loss: 1.9912e-04 - val_mse: 1.9912e-04\n",
      "Epoch 63/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.8901e-06 - mse: 4.8901e-06 - val_loss: 2.0504e-04 - val_mse: 2.0504e-04\n",
      "Epoch 64/100\n",
      "26662/26662 [==============================] - 0s 9us/sample - loss: 4.2445e-06 - mse: 4.2445e-06 - val_loss: 2.2802e-04 - val_mse: 2.2802e-04\n",
      "Epoch 65/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.2641e-06 - mse: 4.2641e-06 - val_loss: 2.3698e-04 - val_mse: 2.3698e-04\n",
      "Epoch 66/100\n",
      "26662/26662 [==============================] - 0s 9us/sample - loss: 4.3165e-06 - mse: 4.3165e-06 - val_loss: 1.7553e-04 - val_mse: 1.7553e-04\n",
      "Epoch 67/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.2440e-06 - mse: 4.2440e-06 - val_loss: 1.7549e-04 - val_mse: 1.7549e-04\n",
      "Epoch 68/100\n",
      "26662/26662 [==============================] - 0s 9us/sample - loss: 4.0076e-06 - mse: 4.0076e-06 - val_loss: 1.9111e-04 - val_mse: 1.9111e-04\n",
      "Epoch 69/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.2291e-06 - mse: 4.2291e-06 - val_loss: 1.6499e-04 - val_mse: 1.6499e-04\n",
      "Epoch 70/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.4257e-06 - mse: 4.4257e-06 - val_loss: 2.0163e-04 - val_mse: 2.0163e-04\n",
      "Epoch 71/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.5414e-06 - mse: 4.5414e-06 - val_loss: 2.1791e-04 - val_mse: 2.1791e-04\n",
      "Epoch 72/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.3910e-06 - mse: 4.3910e-06 - val_loss: 1.8444e-04 - val_mse: 1.8444e-04\n",
      "Epoch 73/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.2360e-06 - mse: 4.2360e-06 - val_loss: 1.6173e-04 - val_mse: 1.6173e-04\n",
      "Epoch 74/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.7659e-06 - mse: 4.7659e-06 - val_loss: 2.2717e-04 - val_mse: 2.2717e-04\n",
      "Epoch 75/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.3731e-06 - mse: 4.3731e-06 - val_loss: 1.6968e-04 - val_mse: 1.6968e-04\n",
      "Epoch 76/100\n",
      "26662/26662 [==============================] - 0s 9us/sample - loss: 4.4875e-06 - mse: 4.4875e-06 - val_loss: 1.3314e-04 - val_mse: 1.3314e-04\n",
      "Epoch 77/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.9513e-06 - mse: 4.9513e-06 - val_loss: 1.6429e-04 - val_mse: 1.6429e-04\n",
      "Epoch 78/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 1.0971e-05 - mse: 1.0971e-05 - val_loss: 1.5409e-04 - val_mse: 1.5409e-04\n",
      "Epoch 79/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 1.0202e-05 - mse: 1.0202e-05 - val_loss: 2.6064e-04 - val_mse: 2.6064e-04\n",
      "Epoch 80/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 7.7031e-06 - mse: 7.7031e-06 - val_loss: 2.1430e-04 - val_mse: 2.1430e-04\n",
      "Epoch 81/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 5.2250e-06 - mse: 5.2250e-06 - val_loss: 2.0594e-04 - val_mse: 2.0594e-04\n",
      "Epoch 82/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 6.2861e-06 - mse: 6.2861e-06 - val_loss: 2.3033e-04 - val_mse: 2.3033e-04\n",
      "Epoch 83/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 5.4361e-06 - mse: 5.4361e-06 - val_loss: 2.0837e-04 - val_mse: 2.0837e-04\n",
      "Epoch 84/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 5.2886e-06 - mse: 5.2886e-06 - val_loss: 2.2402e-04 - val_mse: 2.2402e-04\n",
      "Epoch 85/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.6135e-06 - mse: 4.6135e-06 - val_loss: 2.9137e-04 - val_mse: 2.9137e-04\n",
      "Epoch 86/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.3784e-06 - mse: 4.3784e-06 - val_loss: 2.5355e-04 - val_mse: 2.5355e-04\n",
      "Epoch 87/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.1022e-06 - mse: 4.1022e-06 - val_loss: 2.3086e-04 - val_mse: 2.3086e-04\n",
      "Epoch 88/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.0723e-06 - mse: 4.0723e-06 - val_loss: 2.1248e-04 - val_mse: 2.1248e-04\n",
      "Epoch 89/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.0344e-06 - mse: 4.0344e-06 - val_loss: 2.3005e-04 - val_mse: 2.3005e-04\n",
      "Epoch 90/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 3.9199e-06 - mse: 3.9199e-06 - val_loss: 2.7649e-04 - val_mse: 2.7649e-04\n",
      "Epoch 91/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 3.9442e-06 - mse: 3.9442e-06 - val_loss: 2.2603e-04 - val_mse: 2.2603e-04\n",
      "Epoch 92/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.0043e-06 - mse: 4.0043e-06 - val_loss: 1.9601e-04 - val_mse: 1.9601e-04\n",
      "Epoch 93/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 3.8954e-06 - mse: 3.8954e-06 - val_loss: 2.2449e-04 - val_mse: 2.2449e-04\n",
      "Epoch 94/100\n",
      "26662/26662 [==============================] - 0s 9us/sample - loss: 4.0320e-06 - mse: 4.0320e-06 - val_loss: 2.1812e-04 - val_mse: 2.1812e-04\n",
      "Epoch 95/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.1304e-06 - mse: 4.1304e-06 - val_loss: 2.1545e-04 - val_mse: 2.1545e-04\n",
      "Epoch 96/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 3.9527e-06 - mse: 3.9527e-06 - val_loss: 2.1675e-04 - val_mse: 2.1675e-04\n",
      "Epoch 97/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 4.2457e-06 - mse: 4.2457e-06 - val_loss: 2.4560e-04 - val_mse: 2.4560e-04\n",
      "Epoch 98/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 3.8950e-06 - mse: 3.8950e-06 - val_loss: 1.9752e-04 - val_mse: 1.9752e-04\n",
      "Epoch 99/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 3.8648e-06 - mse: 3.8648e-06 - val_loss: 2.3656e-04 - val_mse: 2.3656e-04\n",
      "Epoch 100/100\n",
      "26662/26662 [==============================] - 0s 8us/sample - loss: 3.9136e-06 - mse: 3.9136e-06 - val_loss: 2.3760e-04 - val_mse: 2.3760e-04\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "tf.random.set_seed(42)  # Meaning of life\n",
    "\n",
    "hist = None\n",
    "\n",
    "weights_file = \"../models/optcon_model_weights.keras\"\n",
    "\n",
    "for i in range(1):\n",
    "    loss_fn = tf.keras.losses.mse if i == 0 else sse_and_smoothness\n",
    "    train_epochs = 100 if i == 0 else 1000\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=loss_fn,\n",
    "        # loss=sse_and_smoothness,\n",
    "        metrics=['mse'],\n",
    "        loss_weights=None,\n",
    "        weighted_metrics=None,\n",
    "        run_eagerly=None,\n",
    "    )\n",
    "\n",
    "    if True:\n",
    "        model.load_weights(weights_file)\n",
    "    if i != 0:\n",
    "        model.load_weights(weights_file)\n",
    "    \n",
    "    temp_hist = model.fit(\n",
    "        x=X, y=Y,\n",
    "        batch_size=1000,\n",
    "        epochs=train_epochs,\n",
    "        verbose=1,\n",
    "        validation_split=0.3,  # 70-30 train validation split\n",
    "        shuffle=True,\n",
    "        validation_freq=1,\n",
    "    )\n",
    "    \n",
    "    model.save_weights(weights_file)\n",
    "    \n",
    "    if hist is None:\n",
    "        hist = temp_hist\n",
    "    else:\n",
    "        for k in hist.history.keys():\n",
    "            hist.history[k] = hist.history[k] + temp_hist.history[k]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (mpl.ratio !== 1) {\n",
       "            fig.send_message('set_dpi_ratio', { dpi_ratio: mpl.ratio });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    var resizeObserver = new ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * mpl.ratio);\n",
       "                canvas.setAttribute('height', height * mpl.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    resizeObserver.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / mpl.ratio,\n",
       "        fig.canvas.height / mpl.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch (cursor) {\n",
       "        case 0:\n",
       "            cursor = 'pointer';\n",
       "            break;\n",
       "        case 1:\n",
       "            cursor = 'default';\n",
       "            break;\n",
       "        case 2:\n",
       "            cursor = 'crosshair';\n",
       "            break;\n",
       "        case 3:\n",
       "            cursor = 'move';\n",
       "            break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = 'image/png';\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.which === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.which;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which !== 17) {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    if (event.altKey && event.which !== 18) {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    if (event.shiftKey && event.which !== 16) {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data']);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / mpl.ratio;\n",
       "    fig.root.removeEventListener('remove', this._remove_fig_handler);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / mpl.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function () {\n",
       "    this.close_ws(this, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "    el.addEventListener('remove', this._remove_fig_handler);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager) {\n",
       "        manager = IPython.keyboard_manager;\n",
       "    }\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id='ac2c4f2f-232b-480a-9f0b-a71bcefc97ab'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot predicted versus actual outputs\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(8,4)\n",
    "\n",
    "ax = fig.add_axes([0.1, 0.15, 0.75, 0.8])\n",
    "\n",
    "ypred = 1000.*model.predict(X) + 1000.\n",
    "ypred = ypred.reshape((ypred.shape[0], int(ypred.shape[1]/4.), 4), order='F')\n",
    "\n",
    "n = 500 # 1000\n",
    "\n",
    "ax.plot(tvec, pwms[:,0], label='PWM1 Filtered')\n",
    "ax.plot(tvec, pwms[:,1], label='PWM2 Filtered')\n",
    "ax.plot(tvec, pwms[:,2], label='PWM3 Filtered')\n",
    "ax.plot(tvec, pwms[:,3], label='PWM4 Filtered')\n",
    "\n",
    "for i in range(int(ypred.shape[0]/n)):\n",
    "    for j in range(4):\n",
    "        ax.plot(\n",
    "            tvec_y[n*i, :],\n",
    "            ypred[n*i, :, j],\n",
    "            color=('C%i' % j),\n",
    "            marker='x',\n",
    "            alpha=0.6,\n",
    "            label=(('' if i == 0  else '_') + ('PWM%i' % (j+1)) + ' Predicted')\n",
    "        )\n",
    "\n",
    "ax.legend(bbox_to_anchor=(1, 1), loc='upper left', fontsize='xx-small', handlelength=1)\n",
    "\n",
    "ax.set_xlabel('Time ($t$), [sec]')\n",
    "ax.set_ylabel('Pulse Width Modulation [$\\mu$sec]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (mpl.ratio !== 1) {\n",
       "            fig.send_message('set_dpi_ratio', { dpi_ratio: mpl.ratio });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    var resizeObserver = new ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * mpl.ratio);\n",
       "                canvas.setAttribute('height', height * mpl.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    resizeObserver.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / mpl.ratio,\n",
       "        fig.canvas.height / mpl.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch (cursor) {\n",
       "        case 0:\n",
       "            cursor = 'pointer';\n",
       "            break;\n",
       "        case 1:\n",
       "            cursor = 'default';\n",
       "            break;\n",
       "        case 2:\n",
       "            cursor = 'crosshair';\n",
       "            break;\n",
       "        case 3:\n",
       "            cursor = 'move';\n",
       "            break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = 'image/png';\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.which === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.which;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which !== 17) {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    if (event.altKey && event.which !== 18) {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    if (event.shiftKey && event.which !== 16) {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data']);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / mpl.ratio;\n",
       "    fig.root.removeEventListener('remove', this._remove_fig_handler);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / mpl.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function () {\n",
       "    this.close_ws(this, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "    el.addEventListener('remove', this._remove_fig_handler);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager) {\n",
       "        manager = IPython.keyboard_manager;\n",
       "    }\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id='fb9f0ca0-0805-44a9-bc38-41bb5c010860'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax_t = plt.subplots(1, 1)\n",
    "\n",
    "lvec = np.array(hist.history['loss'])\n",
    "vlvec = np.array(hist.history['val_loss'])\n",
    "epoch_vec = np.array(list(range(lvec.shape[0])))\n",
    "    \n",
    "ax_t.plot(epoch_vec, lvec, label='Training loss')\n",
    "ax_t.plot(epoch_vec, vlvec, linestyle=':', label='Validation loss')\n",
    "\n",
    "ax_t.set_xlim(left=0)\n",
    "ax_t.set_ylim(bottom=0)\n",
    "\n",
    "fig.suptitle('Training Losses')\n",
    "ax_t.legend(fontsize='xx-small', handlelength=1)\n",
    "ax_t.set_xlabel('Epochs')\n",
    "ax_t.set_ylabel('Losses (MSE)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Training\n",
    "\n",
    "The initial model is trained for 800 epochs using the mean squared error model. This give predicted outputs that are in the correct range but not necessarily smooth control outputs. This next section will use the loss function with the smoothness loss function with different polynomial degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34280 samples, validate on 3809 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Patrick\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 2s 60us/sample - loss: 0.3675 - mse: 9.9113e-06 - val_loss: 6.9146 - val_mse: 2.2164e-04\n",
      "Epoch 2/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1865 - mse: 4.8796e-06 - val_loss: 5.8630 - val_mse: 1.8559e-04\n",
      "Epoch 3/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1633 - mse: 4.2519e-06 - val_loss: 10.1502 - val_mse: 3.3159e-04\n",
      "Epoch 4/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1698 - mse: 4.4369e-06 - val_loss: 7.9855 - val_mse: 2.5819e-04\n",
      "Epoch 5/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1320 - mse: 3.4693e-06 - val_loss: 8.4211 - val_mse: 2.7323e-04\n",
      "Epoch 6/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2735 - mse: 7.3608e-06 - val_loss: 4.3685 - val_mse: 1.3577e-04\n",
      "Epoch 7/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1820 - mse: 4.8353e-06 - val_loss: 2.5645 - val_mse: 7.3459e-05\n",
      "Epoch 8/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1876 - mse: 4.9689e-06 - val_loss: 3.2698 - val_mse: 9.6780e-05\n",
      "Epoch 9/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1377 - mse: 3.5806e-06 - val_loss: 7.9300 - val_mse: 2.5657e-04\n",
      "Epoch 10/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1147 - mse: 2.9172e-06 - val_loss: 3.3433 - val_mse: 1.0016e-04\n",
      "Epoch 11/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0935 - mse: 2.3380e-06 - val_loss: 3.4224 - val_mse: 1.0235e-04\n",
      "Epoch 12/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0808 - mse: 1.9623e-06 - val_loss: 4.2796 - val_mse: 1.3184e-04\n",
      "Epoch 13/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0909 - mse: 2.2476e-06 - val_loss: 6.1429 - val_mse: 1.9485e-04\n",
      "Epoch 14/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.0788 - mse: 1.9059e-06 - val_loss: 3.3362 - val_mse: 9.9436e-05\n",
      "Epoch 15/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0734 - mse: 1.7344e-06 - val_loss: 6.3392 - val_mse: 2.0157e-04\n",
      "Epoch 16/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0791 - mse: 1.8968e-06 - val_loss: 3.3654 - val_mse: 1.0055e-04\n",
      "Epoch 17/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1814 - mse: 4.7813e-06 - val_loss: 13.1787 - val_mse: 4.3381e-04\n",
      "Epoch 18/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1095 - mse: 2.8047e-06 - val_loss: 7.8580 - val_mse: 2.5322e-04\n",
      "Epoch 19/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0805 - mse: 1.9631e-06 - val_loss: 5.8932 - val_mse: 1.8593e-04\n",
      "Epoch 20/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0996 - mse: 2.4870e-06 - val_loss: 12.1704 - val_mse: 4.0066e-04\n",
      "Epoch 21/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0884 - mse: 2.1773e-06 - val_loss: 7.7260 - val_mse: 2.4848e-04\n",
      "Epoch 22/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0909 - mse: 2.2523e-06 - val_loss: 4.0898 - val_mse: 1.2433e-04\n",
      "Epoch 23/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1551 - mse: 4.0412e-06 - val_loss: 6.0522 - val_mse: 1.9143e-04\n",
      "Epoch 24/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1368 - mse: 3.5469e-06 - val_loss: 9.3589 - val_mse: 3.0566e-04\n",
      "Epoch 25/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0765 - mse: 1.8606e-06 - val_loss: 9.5004 - val_mse: 3.0851e-04\n",
      "Epoch 26/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0789 - mse: 1.9244e-06 - val_loss: 9.0678 - val_mse: 2.9442e-04\n",
      "Epoch 27/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0669 - mse: 1.5912e-06 - val_loss: 8.8193 - val_mse: 2.8559e-04\n",
      "Epoch 28/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0708 - mse: 1.6771e-06 - val_loss: 9.5217 - val_mse: 3.1013e-04\n",
      "Epoch 29/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1053 - mse: 2.6412e-06 - val_loss: 13.9891 - val_mse: 4.6246e-04\n",
      "Epoch 30/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1628 - mse: 4.2931e-06 - val_loss: 6.2880 - val_mse: 1.9927e-04\n",
      "Epoch 31/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0908 - mse: 2.2499e-06 - val_loss: 7.0494 - val_mse: 2.2677e-04\n",
      "Epoch 32/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0673 - mse: 1.5885e-06 - val_loss: 5.3982 - val_mse: 1.7027e-04\n",
      "Epoch 33/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0648 - mse: 1.5111e-06 - val_loss: 6.8101 - val_mse: 2.1860e-04\n",
      "Epoch 34/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0595 - mse: 1.3442e-06 - val_loss: 6.6079 - val_mse: 2.1130e-04\n",
      "Epoch 35/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0530 - mse: 1.1634e-06 - val_loss: 6.6044 - val_mse: 2.1118e-04\n",
      "Epoch 36/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0517 - mse: 1.1167e-06 - val_loss: 6.9492 - val_mse: 2.2235e-04\n",
      "Epoch 37/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0587 - mse: 1.3223e-06 - val_loss: 5.6106 - val_mse: 1.7735e-04\n",
      "Epoch 38/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0942 - mse: 2.3180e-06 - val_loss: 4.4548 - val_mse: 1.3717e-04\n",
      "Epoch 39/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2135 - mse: 5.6854e-06 - val_loss: 6.2299 - val_mse: 1.9922e-04\n",
      "Epoch 40/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2420 - mse: 6.5536e-06 - val_loss: 6.0734 - val_mse: 1.8990e-04\n",
      "Epoch 41/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2540 - mse: 6.8564e-06 - val_loss: 8.2142 - val_mse: 2.6629e-04\n",
      "Epoch 42/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1194 - mse: 3.0998e-06 - val_loss: 3.9429 - val_mse: 1.1771e-04\n",
      "Epoch 43/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0713 - mse: 1.7377e-06 - val_loss: 4.8045 - val_mse: 1.4709e-04\n",
      "Epoch 44/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0588 - mse: 1.3538e-06 - val_loss: 5.1018 - val_mse: 1.5749e-04\n",
      "Epoch 45/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0580 - mse: 1.3349e-06 - val_loss: 5.9665 - val_mse: 1.8776e-04\n",
      "Epoch 46/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0707 - mse: 1.6812e-06 - val_loss: 4.0654 - val_mse: 1.2255e-04\n",
      "Epoch 47/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3808 - mse: 1.0533e-05 - val_loss: 31.1350 - val_mse: 0.0010\n",
      "Epoch 48/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4409 - mse: 1.2185e-05 - val_loss: 5.0531 - val_mse: 1.5439e-04\n",
      "Epoch 49/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2210 - mse: 6.0119e-06 - val_loss: 6.4804 - val_mse: 2.0224e-04\n",
      "Epoch 50/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1525 - mse: 4.1196e-06 - val_loss: 6.5864 - val_mse: 2.0770e-04\n",
      "Epoch 51/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1131 - mse: 2.9271e-06 - val_loss: 7.9243 - val_mse: 2.5359e-04\n",
      "Epoch 52/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1125 - mse: 2.9124e-06 - val_loss: 6.8811 - val_mse: 2.1804e-04\n",
      "Epoch 53/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0721 - mse: 1.7386e-06 - val_loss: 7.4005 - val_mse: 2.3581e-04\n",
      "Epoch 54/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0584 - mse: 1.3562e-06 - val_loss: 7.1388 - val_mse: 2.2631e-04\n",
      "Epoch 55/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0567 - mse: 1.2930e-06 - val_loss: 8.0355 - val_mse: 2.5741e-04\n",
      "Epoch 56/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0531 - mse: 1.1831e-06 - val_loss: 6.7746 - val_mse: 2.1417e-04\n",
      "Epoch 57/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0504 - mse: 1.1128e-06 - val_loss: 6.9081 - val_mse: 2.1836e-04\n",
      "Epoch 58/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0457 - mse: 9.5537e-07 - val_loss: 6.5360 - val_mse: 2.0589e-04\n",
      "Epoch 59/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0456 - mse: 9.5595e-07 - val_loss: 6.8117 - val_mse: 2.1528e-04\n",
      "Epoch 60/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0485 - mse: 1.0273e-06 - val_loss: 6.3845 - val_mse: 2.0089e-04\n",
      "Epoch 61/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0601 - mse: 1.3672e-06 - val_loss: 7.3251 - val_mse: 2.3334e-04\n",
      "Epoch 62/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0486 - mse: 1.0298e-06 - val_loss: 5.6537 - val_mse: 1.7627e-04\n",
      "Epoch 63/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0608 - mse: 1.4177e-06 - val_loss: 7.2635 - val_mse: 2.3073e-04\n",
      "Epoch 64/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0651 - mse: 1.4918e-06 - val_loss: 5.6621 - val_mse: 1.7646e-04\n",
      "Epoch 65/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0808 - mse: 1.9463e-06 - val_loss: 6.3285 - val_mse: 1.9871e-04\n",
      "Epoch 66/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0457 - mse: 9.5438e-07 - val_loss: 6.3746 - val_mse: 2.0136e-04\n",
      "Epoch 67/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0511 - mse: 1.1040e-06 - val_loss: 5.4063 - val_mse: 1.6790e-04\n",
      "Epoch 68/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0565 - mse: 1.2515e-06 - val_loss: 8.5102 - val_mse: 2.7404e-04\n",
      "Epoch 69/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1064 - mse: 2.6568e-06 - val_loss: 4.7432 - val_mse: 1.4486e-04\n",
      "Epoch 70/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2635 - mse: 7.0960e-06 - val_loss: 8.6029 - val_mse: 2.7962e-04\n",
      "Epoch 71/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1883 - mse: 4.9789e-06 - val_loss: 6.8739 - val_mse: 2.1824e-04\n",
      "Epoch 72/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0914 - mse: 2.3097e-06 - val_loss: 5.4768 - val_mse: 1.7078e-04\n",
      "Epoch 73/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1330 - mse: 3.4245e-06 - val_loss: 4.0083 - val_mse: 1.2158e-04\n",
      "Epoch 74/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1892 - mse: 5.0423e-06 - val_loss: 5.1898 - val_mse: 1.6134e-04\n",
      "Epoch 75/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0939 - mse: 2.3625e-06 - val_loss: 4.0236 - val_mse: 1.2113e-04\n",
      "Epoch 76/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0673 - mse: 1.6009e-06 - val_loss: 5.0684 - val_mse: 1.5621e-04\n",
      "Epoch 77/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0574 - mse: 1.3320e-06 - val_loss: 4.0096 - val_mse: 1.2003e-04\n",
      "Epoch 78/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0512 - mse: 1.1212e-06 - val_loss: 4.6824 - val_mse: 1.4302e-04\n",
      "Epoch 79/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.0551 - mse: 1.2192e-06 - val_loss: 4.1575 - val_mse: 1.2498e-04\n",
      "Epoch 80/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0436 - mse: 8.9098e-07 - val_loss: 4.2769 - val_mse: 1.2905e-04\n",
      "Epoch 81/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0633 - mse: 1.4751e-06 - val_loss: 4.8505 - val_mse: 1.4790e-04\n",
      "Epoch 82/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0552 - mse: 1.2102e-06 - val_loss: 5.3403 - val_mse: 1.6284e-04\n",
      "Epoch 83/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0491 - mse: 1.0311e-06 - val_loss: 4.0874 - val_mse: 1.2179e-04\n",
      "Epoch 84/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.0449 - mse: 9.1890e-07 - val_loss: 5.0316 - val_mse: 1.5408e-04\n",
      "Epoch 85/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0678 - mse: 1.5607e-06 - val_loss: 4.1585 - val_mse: 1.2411e-04\n",
      "Epoch 86/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0770 - mse: 1.8449e-06 - val_loss: 5.1011 - val_mse: 1.5636e-04\n",
      "Epoch 87/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0616 - mse: 1.4059e-06 - val_loss: 5.4968 - val_mse: 1.6909e-04\n",
      "Epoch 88/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0619 - mse: 1.3976e-06 - val_loss: 4.5307 - val_mse: 1.3787e-04\n",
      "Epoch 89/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1070 - mse: 2.6875e-06 - val_loss: 3.5663 - val_mse: 1.0561e-04\n",
      "Epoch 90/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1326 - mse: 3.4582e-06 - val_loss: 7.9034 - val_mse: 2.5286e-04\n",
      "Epoch 91/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0953 - mse: 2.3911e-06 - val_loss: 6.8626 - val_mse: 2.1863e-04\n",
      "Epoch 92/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0530 - mse: 1.1801e-06 - val_loss: 5.9025 - val_mse: 1.8570e-04\n",
      "Epoch 93/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0540 - mse: 1.1914e-06 - val_loss: 6.0796 - val_mse: 1.9125e-04\n",
      "Epoch 94/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0453 - mse: 9.4005e-07 - val_loss: 7.0268 - val_mse: 2.2319e-04\n",
      "Epoch 95/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0584 - mse: 1.3181e-06 - val_loss: 5.0107 - val_mse: 1.5444e-04\n",
      "Epoch 96/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0472 - mse: 9.8449e-07 - val_loss: 5.0967 - val_mse: 1.5609e-04\n",
      "Epoch 97/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0667 - mse: 1.5303e-06 - val_loss: 6.9375 - val_mse: 2.1877e-04\n",
      "Epoch 98/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0527 - mse: 1.1519e-06 - val_loss: 7.3997 - val_mse: 2.3540e-04\n",
      "Epoch 99/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0680 - mse: 1.5754e-06 - val_loss: 4.9330 - val_mse: 1.5257e-04\n",
      "Epoch 100/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.0622 - mse: 1.4113e-06 - val_loss: 5.2025 - val_mse: 1.6003e-04\n",
      "Train on 34280 samples, validate on 3809 samples\n",
      "Epoch 1/100\n",
      "34280/34280 [==============================] - 1s 42us/sample - loss: 0.3669 - mse: 1.0009e-05 - val_loss: 7.8074 - val_mse: 2.5220e-04\n",
      "Epoch 2/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2132 - mse: 5.7447e-06 - val_loss: 11.5020 - val_mse: 3.7870e-04\n",
      "Epoch 3/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2469 - mse: 6.7051e-06 - val_loss: 2.5014 - val_mse: 7.1117e-05\n",
      "Epoch 4/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1762 - mse: 4.7388e-06 - val_loss: 2.7020 - val_mse: 7.8248e-05\n",
      "Epoch 5/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1203 - mse: 3.1693e-06 - val_loss: 2.6771 - val_mse: 7.7276e-05\n",
      "Epoch 6/100\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 0.1073 - mse: 2.7969e-06 - val_loss: 2.5425 - val_mse: 7.2587e-05\n",
      "Epoch 7/100\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 0.0908 - mse: 2.3265e-06 - val_loss: 2.4929 - val_mse: 7.1318e-05\n",
      "Epoch 8/100\n",
      "34280/34280 [==============================] - 0s 12us/sample - loss: 0.0849 - mse: 2.1552e-06 - val_loss: 2.4426 - val_mse: 6.9623e-05\n",
      "Epoch 9/100\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 0.1241 - mse: 3.2639e-06 - val_loss: 2.2514 - val_mse: 6.4382e-05\n",
      "Epoch 10/100\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1310 - mse: 3.4670e-06 - val_loss: 2.9038 - val_mse: 8.7022e-05\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1947 - mse: 5.2548e-06 - val_loss: 2.5114 - val_mse: 7.1870e-05\n",
      "Epoch 12/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0790 - mse: 2.0191e-06 - val_loss: 2.3942 - val_mse: 6.8359e-05\n",
      "Epoch 13/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.0669 - mse: 1.6680e-06 - val_loss: 2.4864 - val_mse: 7.1064e-05\n",
      "Epoch 14/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.0604 - mse: 1.5027e-06 - val_loss: 2.3778 - val_mse: 6.8035e-05\n",
      "Epoch 15/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0659 - mse: 1.6274e-06 - val_loss: 2.9646 - val_mse: 8.7779e-05\n",
      "Epoch 16/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.0584 - mse: 1.4191e-06 - val_loss: 2.4591 - val_mse: 7.0335e-05\n",
      "Epoch 17/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0745 - mse: 1.8723e-06 - val_loss: 2.3497 - val_mse: 6.7612e-05\n",
      "Epoch 18/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0757 - mse: 1.9091e-06 - val_loss: 2.7363 - val_mse: 7.8125e-05\n",
      "Epoch 19/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.0710 - mse: 1.7731e-06 - val_loss: 2.6585 - val_mse: 7.6107e-05\n",
      "Epoch 20/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.0494 - mse: 1.1513e-06 - val_loss: 2.5857 - val_mse: 7.4003e-05\n",
      "Epoch 21/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0542 - mse: 1.2915e-06 - val_loss: 3.6471 - val_mse: 1.0945e-04\n",
      "Epoch 22/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0834 - mse: 2.1329e-06 - val_loss: 3.0701 - val_mse: 8.8849e-05\n",
      "Epoch 23/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1066 - mse: 2.7694e-06 - val_loss: 2.6978 - val_mse: 7.9800e-05\n",
      "Epoch 24/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0748 - mse: 1.8876e-06 - val_loss: 2.5833 - val_mse: 7.3958e-05\n",
      "Epoch 25/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0586 - mse: 1.4299e-06 - val_loss: 3.0075 - val_mse: 8.8336e-05\n",
      "Epoch 26/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0572 - mse: 1.3835e-06 - val_loss: 2.7486 - val_mse: 7.8462e-05\n",
      "Epoch 27/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.0508 - mse: 1.2124e-06 - val_loss: 2.9421 - val_mse: 8.5515e-05\n",
      "Epoch 28/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0563 - mse: 1.3491e-06 - val_loss: 2.8358 - val_mse: 8.1181e-05\n",
      "Epoch 29/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0539 - mse: 1.2788e-06 - val_loss: 2.7201 - val_mse: 7.8764e-05\n",
      "Epoch 30/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1313 - mse: 3.4768e-06 - val_loss: 4.0187 - val_mse: 1.2492e-04\n",
      "Epoch 31/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1865 - mse: 5.0314e-06 - val_loss: 2.4152 - val_mse: 7.0244e-05\n",
      "Epoch 32/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1188 - mse: 3.1523e-06 - val_loss: 2.5906 - val_mse: 7.4817e-05\n",
      "Epoch 33/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1836 - mse: 4.9606e-06 - val_loss: 2.6706 - val_mse: 7.7041e-05\n",
      "Epoch 34/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.0838 - mse: 2.1613e-06 - val_loss: 2.6120 - val_mse: 7.5179e-05\n",
      "Epoch 35/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0859 - mse: 2.2053e-06 - val_loss: 3.0750 - val_mse: 9.0501e-05\n",
      "Epoch 36/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0785 - mse: 2.0009e-06 - val_loss: 2.8820 - val_mse: 8.4521e-05\n",
      "Epoch 37/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1051 - mse: 2.7459e-06 - val_loss: 2.7018 - val_mse: 7.8232e-05\n",
      "Epoch 38/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0511 - mse: 1.2228e-06 - val_loss: 2.9516 - val_mse: 8.6246e-05\n",
      "Epoch 39/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.0468 - mse: 1.1081e-06 - val_loss: 2.9369 - val_mse: 8.4593e-05\n",
      "Epoch 40/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0565 - mse: 1.3607e-06 - val_loss: 2.9213 - val_mse: 8.3895e-05\n",
      "Epoch 41/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0511 - mse: 1.2141e-06 - val_loss: 2.8117 - val_mse: 8.0732e-05\n",
      "Epoch 42/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0546 - mse: 1.3045e-06 - val_loss: 2.9647 - val_mse: 8.5165e-05\n",
      "Epoch 43/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.0453 - mse: 1.0491e-06 - val_loss: 3.1122 - val_mse: 9.0324e-05\n",
      "Epoch 44/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0557 - mse: 1.3401e-06 - val_loss: 3.5343 - val_mse: 1.0667e-04\n",
      "Epoch 45/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0945 - mse: 2.4521e-06 - val_loss: 2.9036 - val_mse: 8.3546e-05\n",
      "Epoch 46/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.0501 - mse: 1.1786e-06 - val_loss: 3.2363 - val_mse: 9.3515e-05\n",
      "Epoch 47/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0453 - mse: 1.0549e-06 - val_loss: 2.8497 - val_mse: 8.1801e-05\n",
      "Epoch 48/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0481 - mse: 1.1231e-06 - val_loss: 2.8302 - val_mse: 8.1150e-05\n",
      "Epoch 49/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0384 - mse: 8.5890e-07 - val_loss: 2.9458 - val_mse: 8.4650e-05\n",
      "Epoch 50/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.0345 - mse: 7.3474e-07 - val_loss: 4.0781 - val_mse: 1.2396e-04\n",
      "Epoch 51/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.0497 - mse: 1.1748e-06 - val_loss: 2.9659 - val_mse: 8.5725e-05\n",
      "Epoch 52/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0414 - mse: 9.3189e-07 - val_loss: 2.8606 - val_mse: 8.2303e-05\n",
      "Epoch 53/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0619 - mse: 1.4910e-06 - val_loss: 2.9242 - val_mse: 8.3889e-05\n",
      "Epoch 54/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4148 - mse: 1.1503e-05 - val_loss: 3.4773 - val_mse: 9.8692e-05\n",
      "Epoch 55/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.4472 - mse: 1.2470e-05 - val_loss: 2.8912 - val_mse: 8.2444e-05\n",
      "Epoch 56/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.3251 - mse: 9.0559e-06 - val_loss: 3.3045 - val_mse: 9.4482e-05\n",
      "Epoch 57/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2944 - mse: 8.1824e-06 - val_loss: 2.7180 - val_mse: 7.7969e-05\n",
      "Epoch 58/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2899 - mse: 8.0334e-06 - val_loss: 2.8869 - val_mse: 8.2943e-05\n",
      "Epoch 59/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1619 - mse: 4.4394e-06 - val_loss: 2.4858 - val_mse: 7.1327e-05\n",
      "Epoch 60/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1707 - mse: 4.6718e-06 - val_loss: 2.5475 - val_mse: 7.3461e-05\n",
      "Epoch 61/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1440 - mse: 3.9393e-06 - val_loss: 2.6711 - val_mse: 7.7099e-05\n",
      "Epoch 62/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.0790 - mse: 2.0825e-06 - val_loss: 2.7272 - val_mse: 7.8805e-05\n",
      "Epoch 63/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0554 - mse: 1.4006e-06 - val_loss: 2.7984 - val_mse: 8.0763e-05\n",
      "Epoch 64/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0526 - mse: 1.3076e-06 - val_loss: 2.7831 - val_mse: 8.0303e-05\n",
      "Epoch 65/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0441 - mse: 1.0471e-06 - val_loss: 2.7644 - val_mse: 7.9757e-05\n",
      "Epoch 66/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0482 - mse: 1.1550e-06 - val_loss: 2.8982 - val_mse: 8.3770e-05\n",
      "Epoch 67/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0506 - mse: 1.2214e-06 - val_loss: 2.6574 - val_mse: 7.7062e-05\n",
      "Epoch 68/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.0639 - mse: 1.5776e-06 - val_loss: 3.0968 - val_mse: 9.0671e-05\n",
      "Epoch 69/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0617 - mse: 1.5230e-06 - val_loss: 3.1296 - val_mse: 9.0057e-05\n",
      "Epoch 70/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1392 - mse: 3.6925e-06 - val_loss: 3.2934 - val_mse: 9.6514e-05\n",
      "Epoch 71/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.0935 - mse: 2.4276e-06 - val_loss: 2.7991 - val_mse: 8.0742e-05\n",
      "Epoch 72/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0713 - mse: 1.8083e-06 - val_loss: 2.8313 - val_mse: 8.2070e-05\n",
      "Epoch 73/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1487 - mse: 3.9752e-06 - val_loss: 4.3018 - val_mse: 1.3251e-04\n",
      "Epoch 74/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1183 - mse: 3.1364e-06 - val_loss: 2.8368 - val_mse: 8.2192e-05\n",
      "Epoch 75/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0448 - mse: 1.0630e-06 - val_loss: 2.6302 - val_mse: 7.5928e-05\n",
      "Epoch 76/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0457 - mse: 1.0762e-06 - val_loss: 2.5827 - val_mse: 7.4676e-05\n",
      "Epoch 77/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0524 - mse: 1.2607e-06 - val_loss: 2.6190 - val_mse: 7.6354e-05\n",
      "Epoch 78/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.0372 - mse: 8.2063e-07 - val_loss: 2.6700 - val_mse: 7.7650e-05\n",
      "Epoch 79/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0500 - mse: 1.1787e-06 - val_loss: 3.0548 - val_mse: 8.9705e-05\n",
      "Epoch 80/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0487 - mse: 1.1393e-06 - val_loss: 2.7644 - val_mse: 8.0497e-05\n",
      "Epoch 81/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0321 - mse: 6.8642e-07 - val_loss: 2.7689 - val_mse: 8.0817e-05\n",
      "Epoch 82/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.0388 - mse: 8.5579e-07 - val_loss: 2.5283 - val_mse: 7.3320e-05\n",
      "Epoch 83/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0374 - mse: 8.1252e-07 - val_loss: 2.5554 - val_mse: 7.4045e-05\n",
      "Epoch 84/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0501 - mse: 1.1676e-06 - val_loss: 2.7206 - val_mse: 7.9709e-05\n",
      "Epoch 85/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.0460 - mse: 1.0616e-06 - val_loss: 2.5703 - val_mse: 7.4538e-05\n",
      "Epoch 86/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0503 - mse: 1.2099e-06 - val_loss: 2.6676 - val_mse: 7.7160e-05\n",
      "Epoch 87/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0572 - mse: 1.3862e-06 - val_loss: 2.3341 - val_mse: 6.7696e-05\n",
      "Epoch 88/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.0379 - mse: 8.2510e-07 - val_loss: 2.5241 - val_mse: 7.2951e-05\n",
      "Epoch 89/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.0313 - mse: 6.3983e-07 - val_loss: 2.5268 - val_mse: 7.3149e-05\n",
      "Epoch 90/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.0494 - mse: 1.1507e-06 - val_loss: 2.5297 - val_mse: 7.3590e-05\n",
      "Epoch 91/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0496 - mse: 1.1703e-06 - val_loss: 2.6856 - val_mse: 7.7774e-05\n",
      "Epoch 92/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0344 - mse: 7.3090e-07 - val_loss: 2.6276 - val_mse: 7.6441e-05\n",
      "Epoch 93/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0302 - mse: 6.0309e-07 - val_loss: 2.6459 - val_mse: 7.6698e-05\n",
      "Epoch 94/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0283 - mse: 5.5125e-07 - val_loss: 2.6481 - val_mse: 7.6919e-05\n",
      "Epoch 95/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0292 - mse: 5.7669e-07 - val_loss: 2.6732 - val_mse: 7.7504e-05\n",
      "Epoch 96/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.0341 - mse: 7.2939e-07 - val_loss: 2.6185 - val_mse: 7.5994e-05\n",
      "Epoch 97/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0520 - mse: 1.2289e-06 - val_loss: 2.6228 - val_mse: 7.6008e-05\n",
      "Epoch 98/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0468 - mse: 1.0772e-06 - val_loss: 2.6640 - val_mse: 7.7163e-05\n",
      "Epoch 99/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0481 - mse: 1.1052e-06 - val_loss: 2.5868 - val_mse: 7.5144e-05\n",
      "Epoch 100/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1816 - mse: 4.8784e-06 - val_loss: 3.0482 - val_mse: 8.7985e-05\n",
      "Train on 34280 samples, validate on 3809 samples\n",
      "Epoch 1/100\n",
      "34280/34280 [==============================] - 1s 43us/sample - loss: 0.3637 - mse: 9.9929e-06 - val_loss: 5.0102 - val_mse: 1.5646e-04\n",
      "Epoch 2/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2028 - mse: 5.5021e-06 - val_loss: 8.4282 - val_mse: 2.7350e-04\n",
      "Epoch 3/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1510 - mse: 4.0637e-06 - val_loss: 5.4032 - val_mse: 1.7019e-04\n",
      "Epoch 4/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1246 - mse: 3.3230e-06 - val_loss: 5.4537 - val_mse: 1.7177e-04\n",
      "Epoch 5/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1080 - mse: 2.9229e-06 - val_loss: 5.0574 - val_mse: 1.5824e-04\n",
      "Epoch 6/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1107 - mse: 2.9718e-06 - val_loss: 9.9221 - val_mse: 3.2474e-04\n",
      "Epoch 7/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1790 - mse: 4.8442e-06 - val_loss: 7.2839 - val_mse: 2.3443e-04\n",
      "Epoch 8/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1794 - mse: 4.8701e-06 - val_loss: 2.4442 - val_mse: 6.9536e-05\n",
      "Epoch 9/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2974 - mse: 8.1567e-06 - val_loss: 3.3307 - val_mse: 9.8333e-05\n",
      "Epoch 10/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2121 - mse: 5.8210e-06 - val_loss: 6.6880 - val_mse: 2.1329e-04\n",
      "Epoch 11/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1381 - mse: 3.7652e-06 - val_loss: 10.2913 - val_mse: 3.3898e-04\n",
      "Epoch 12/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1404 - mse: 3.8059e-06 - val_loss: 9.1203 - val_mse: 2.9640e-04\n",
      "Epoch 13/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1344 - mse: 3.6400e-06 - val_loss: 10.2730 - val_mse: 3.3660e-04\n",
      "Epoch 14/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1417 - mse: 3.9178e-06 - val_loss: 10.6237 - val_mse: 3.4792e-04\n",
      "Epoch 15/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1126 - mse: 3.0243e-06 - val_loss: 10.1868 - val_mse: 3.3340e-04\n",
      "Epoch 16/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.0844 - mse: 2.2265e-06 - val_loss: 6.6365 - val_mse: 2.1215e-04\n",
      "Epoch 17/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0712 - mse: 1.8538e-06 - val_loss: 7.9131 - val_mse: 2.5523e-04\n",
      "Epoch 18/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0964 - mse: 2.5938e-06 - val_loss: 8.6567 - val_mse: 2.8197e-04\n",
      "Epoch 19/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1025 - mse: 2.7234e-06 - val_loss: 6.9788 - val_mse: 2.2297e-04\n",
      "Epoch 20/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0998 - mse: 2.6450e-06 - val_loss: 5.6538 - val_mse: 1.7793e-04\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0986 - mse: 2.6124e-06 - val_loss: 6.3268 - val_mse: 2.0098e-04\n",
      "Epoch 22/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0648 - mse: 1.6624e-06 - val_loss: 8.3839 - val_mse: 2.7234e-04\n",
      "Epoch 23/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.0539 - mse: 1.3533e-06 - val_loss: 6.2037 - val_mse: 1.9632e-04\n",
      "Epoch 24/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1135 - mse: 3.0248e-06 - val_loss: 7.7050 - val_mse: 2.4763e-04\n",
      "Epoch 25/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0735 - mse: 1.9152e-06 - val_loss: 7.9399 - val_mse: 2.5513e-04\n",
      "Epoch 26/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0554 - mse: 1.3958e-06 - val_loss: 7.6646 - val_mse: 2.4639e-04\n",
      "Epoch 27/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0502 - mse: 1.3149e-06 - val_loss: 9.5998 - val_mse: 3.1237e-04\n",
      "Epoch 28/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.0524 - mse: 1.3209e-06 - val_loss: 7.7726 - val_mse: 2.4969e-04\n",
      "Epoch 29/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0509 - mse: 1.2615e-06 - val_loss: 7.5250 - val_mse: 2.4217e-04\n",
      "Epoch 30/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0685 - mse: 1.7566e-06 - val_loss: 10.7549 - val_mse: 3.5264e-04\n",
      "Epoch 31/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0570 - mse: 1.4383e-06 - val_loss: 8.6722 - val_mse: 2.8250e-04\n",
      "Epoch 32/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0491 - mse: 1.2115e-06 - val_loss: 6.7890 - val_mse: 2.1653e-04\n",
      "Epoch 33/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0711 - mse: 1.8342e-06 - val_loss: 7.2195 - val_mse: 2.3164e-04\n",
      "Epoch 34/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1947 - mse: 5.2874e-06 - val_loss: 6.0604 - val_mse: 1.9263e-04\n",
      "Epoch 35/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1306 - mse: 3.5233e-06 - val_loss: 3.7106 - val_mse: 1.1234e-04\n",
      "Epoch 36/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0680 - mse: 1.7611e-06 - val_loss: 5.7450 - val_mse: 1.8097e-04\n",
      "Epoch 37/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0715 - mse: 1.8578e-06 - val_loss: 6.8153 - val_mse: 2.1856e-04\n",
      "Epoch 38/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0738 - mse: 1.9058e-06 - val_loss: 5.6856 - val_mse: 1.7757e-04\n",
      "Epoch 39/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.0748 - mse: 1.9457e-06 - val_loss: 5.8603 - val_mse: 1.8557e-04\n",
      "Epoch 40/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1279 - mse: 3.4395e-06 - val_loss: 6.3336 - val_mse: 2.0042e-04\n",
      "Epoch 41/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0809 - mse: 2.1157e-06 - val_loss: 7.9547 - val_mse: 2.5840e-04\n",
      "Epoch 42/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.0625 - mse: 1.5961e-06 - val_loss: 4.6496 - val_mse: 1.4378e-04\n",
      "Epoch 43/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0522 - mse: 1.3247e-06 - val_loss: 5.6792 - val_mse: 1.7908e-04\n",
      "Epoch 44/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0429 - mse: 1.0401e-06 - val_loss: 6.8928 - val_mse: 2.2174e-04\n",
      "Epoch 45/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0488 - mse: 1.2014e-06 - val_loss: 5.7103 - val_mse: 1.8117e-04\n",
      "Epoch 46/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0546 - mse: 1.3620e-06 - val_loss: 4.8568 - val_mse: 1.5228e-04\n",
      "Epoch 47/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0430 - mse: 1.0619e-06 - val_loss: 6.2504 - val_mse: 1.9980e-04\n",
      "Epoch 48/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0416 - mse: 9.9954e-07 - val_loss: 6.8328 - val_mse: 2.1897e-04\n",
      "Epoch 49/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0533 - mse: 1.3426e-06 - val_loss: 8.0700 - val_mse: 2.6221e-04\n",
      "Epoch 50/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0887 - mse: 2.3359e-06 - val_loss: 4.1450 - val_mse: 1.2662e-04\n",
      "Epoch 51/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0905 - mse: 2.3901e-06 - val_loss: 5.2222 - val_mse: 1.6586e-04\n",
      "Epoch 52/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0895 - mse: 2.3583e-06 - val_loss: 8.8849 - val_mse: 2.9208e-04\n",
      "Epoch 53/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1708 - mse: 4.6287e-06 - val_loss: 3.1494 - val_mse: 9.3660e-05\n",
      "Epoch 54/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1061 - mse: 2.8294e-06 - val_loss: 3.4926 - val_mse: 1.0381e-04\n",
      "Epoch 55/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0506 - mse: 1.2678e-06 - val_loss: 4.2234 - val_mse: 1.2765e-04\n",
      "Epoch 56/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0916 - mse: 2.4198e-06 - val_loss: 5.9391 - val_mse: 1.8629e-04\n",
      "Epoch 57/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1515 - mse: 4.1240e-06 - val_loss: 3.5988 - val_mse: 1.0510e-04\n",
      "Epoch 58/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1792 - mse: 4.8768e-06 - val_loss: 16.3455 - val_mse: 5.4547e-04\n",
      "Epoch 59/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2606 - mse: 7.1479e-06 - val_loss: 4.1218 - val_mse: 1.2686e-04\n",
      "Epoch 60/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1868 - mse: 5.1012e-06 - val_loss: 3.4647 - val_mse: 1.0581e-04\n",
      "Epoch 61/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1299 - mse: 3.5098e-06 - val_loss: 7.6271 - val_mse: 2.4761e-04\n",
      "Epoch 62/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.0723 - mse: 1.8953e-06 - val_loss: 4.9790 - val_mse: 1.5638e-04\n",
      "Epoch 63/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0647 - mse: 1.6688e-06 - val_loss: 6.1343 - val_mse: 1.9481e-04\n",
      "Epoch 64/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.0771 - mse: 2.0189e-06 - val_loss: 7.3255 - val_mse: 2.3623e-04\n",
      "Epoch 65/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.0522 - mse: 1.3230e-06 - val_loss: 5.7549 - val_mse: 1.8294e-04\n",
      "Epoch 66/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0451 - mse: 1.1087e-06 - val_loss: 8.2263 - val_mse: 2.6787e-04\n",
      "Epoch 67/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0647 - mse: 1.6782e-06 - val_loss: 7.0453 - val_mse: 2.2585e-04\n",
      "Epoch 68/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0464 - mse: 1.1376e-06 - val_loss: 6.8999 - val_mse: 2.2219e-04\n",
      "Epoch 69/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0576 - mse: 1.4500e-06 - val_loss: 5.0043 - val_mse: 1.5754e-04\n",
      "Epoch 70/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0537 - mse: 1.3464e-06 - val_loss: 6.1722 - val_mse: 1.9828e-04\n",
      "Epoch 71/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0645 - mse: 1.6463e-06 - val_loss: 5.7184 - val_mse: 1.8024e-04\n",
      "Epoch 72/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0624 - mse: 1.5958e-06 - val_loss: 7.2630 - val_mse: 2.3250e-04\n",
      "Epoch 73/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0681 - mse: 1.7448e-06 - val_loss: 6.2699 - val_mse: 2.0010e-04\n",
      "Epoch 74/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0484 - mse: 1.1976e-06 - val_loss: 6.6075 - val_mse: 2.1227e-04\n",
      "Epoch 75/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0374 - mse: 8.7717e-07 - val_loss: 5.5419 - val_mse: 1.7450e-04\n",
      "Epoch 76/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0392 - mse: 9.3003e-07 - val_loss: 6.6156 - val_mse: 2.1152e-04\n",
      "Epoch 77/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0634 - mse: 1.6279e-06 - val_loss: 6.4499 - val_mse: 2.0691e-04\n",
      "Epoch 78/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0801 - mse: 2.0795e-06 - val_loss: 6.4564 - val_mse: 2.0725e-04\n",
      "Epoch 79/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2863 - mse: 7.8523e-06 - val_loss: 11.7086 - val_mse: 3.8570e-04\n",
      "Epoch 80/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3047 - mse: 8.3695e-06 - val_loss: 5.5270 - val_mse: 1.7022e-04\n",
      "Epoch 81/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1334 - mse: 3.6497e-06 - val_loss: 7.2879 - val_mse: 2.2926e-04\n",
      "Epoch 82/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1126 - mse: 3.0302e-06 - val_loss: 6.1276 - val_mse: 1.8937e-04\n",
      "Epoch 83/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0583 - mse: 1.4949e-06 - val_loss: 6.6179 - val_mse: 2.0786e-04\n",
      "Epoch 84/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0421 - mse: 1.0329e-06 - val_loss: 6.3677 - val_mse: 1.9850e-04\n",
      "Epoch 85/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0414 - mse: 1.0068e-06 - val_loss: 5.0395 - val_mse: 1.5342e-04\n",
      "Epoch 86/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0614 - mse: 1.5746e-06 - val_loss: 5.9711 - val_mse: 1.8564e-04\n",
      "Epoch 87/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0412 - mse: 9.9711e-07 - val_loss: 7.7480 - val_mse: 2.4610e-04\n",
      "Epoch 88/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0435 - mse: 1.0561e-06 - val_loss: 5.2344 - val_mse: 1.5981e-04\n",
      "Epoch 89/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0731 - mse: 1.8924e-06 - val_loss: 4.5102 - val_mse: 1.3550e-04\n",
      "Epoch 90/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.3982 - mse: 1.1000e-05 - val_loss: 3.1027 - val_mse: 8.9995e-05\n",
      "Epoch 91/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2995 - mse: 8.2988e-06 - val_loss: 3.9585 - val_mse: 1.1306e-04\n",
      "Epoch 92/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1754 - mse: 4.8476e-06 - val_loss: 5.2059 - val_mse: 1.5617e-04\n",
      "Epoch 93/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0999 - mse: 2.6971e-06 - val_loss: 7.9344 - val_mse: 2.4565e-04\n",
      "Epoch 94/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0723 - mse: 1.9000e-06 - val_loss: 5.8580 - val_mse: 1.7914e-04\n",
      "Epoch 95/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0662 - mse: 1.7260e-06 - val_loss: 5.0066 - val_mse: 1.5077e-04\n",
      "Epoch 96/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0548 - mse: 1.3975e-06 - val_loss: 4.3233 - val_mse: 1.2574e-04\n",
      "Epoch 97/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0919 - mse: 2.4495e-06 - val_loss: 5.3005 - val_mse: 1.5856e-04\n",
      "Epoch 98/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1395 - mse: 3.7523e-06 - val_loss: 7.6643 - val_mse: 2.4173e-04\n",
      "Epoch 99/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0633 - mse: 1.6380e-06 - val_loss: 6.0305 - val_mse: 1.8446e-04\n",
      "Epoch 100/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.0429 - mse: 1.0600e-06 - val_loss: 7.1621 - val_mse: 2.2128e-04\n",
      "Train on 34280 samples, validate on 3809 samples\n",
      "Epoch 1/100\n",
      "34280/34280 [==============================] - 1s 42us/sample - loss: 4.1873 - mse: 8.7758e-06 - val_loss: 9.5637 - val_mse: 1.8298e-04\n",
      "Epoch 2/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 4.0665 - mse: 5.4455e-06 - val_loss: 16.2838 - val_mse: 4.1271e-04\n",
      "Epoch 3/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 4.1137 - mse: 6.7537e-06 - val_loss: 9.7518 - val_mse: 1.8923e-04\n",
      "Epoch 4/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 4.0259 - mse: 4.2882e-06 - val_loss: 8.6071 - val_mse: 1.4948e-04\n",
      "Epoch 5/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9968 - mse: 3.5180e-06 - val_loss: 11.4414 - val_mse: 2.4624e-04\n",
      "Epoch 6/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 4.0253 - mse: 4.2789e-06 - val_loss: 8.4519 - val_mse: 1.4345e-04\n",
      "Epoch 7/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9834 - mse: 3.1041e-06 - val_loss: 9.0677 - val_mse: 1.6508e-04\n",
      "Epoch 8/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 4.0109 - mse: 3.8850e-06 - val_loss: 9.5845 - val_mse: 1.8244e-04\n",
      "Epoch 9/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 4.0416 - mse: 4.7402e-06 - val_loss: 13.5173 - val_mse: 3.1916e-04\n",
      "Epoch 10/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 4.0663 - mse: 5.4449e-06 - val_loss: 10.6584 - val_mse: 2.1923e-04\n",
      "Epoch 11/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9791 - mse: 3.0025e-06 - val_loss: 10.8531 - val_mse: 2.2511e-04\n",
      "Epoch 12/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 3.9723 - mse: 2.7931e-06 - val_loss: 9.9923 - val_mse: 1.9601e-04\n",
      "Epoch 13/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9929 - mse: 3.3905e-06 - val_loss: 13.0482 - val_mse: 3.0193e-04\n",
      "Epoch 14/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 3.9704 - mse: 2.7650e-06 - val_loss: 8.5858 - val_mse: 1.4813e-04\n",
      "Epoch 15/100\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 3.9610 - mse: 2.4804e-06 - val_loss: 11.1908 - val_mse: 2.3733e-04\n",
      "Epoch 16/100\n",
      "34280/34280 [==============================] - 0s 12us/sample - loss: 3.9494 - mse: 2.1541e-06 - val_loss: 8.8130 - val_mse: 1.5565e-04\n",
      "Epoch 17/100\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 4.0069 - mse: 3.7727e-06 - val_loss: 8.8041 - val_mse: 1.5458e-04\n",
      "Epoch 18/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 4.0088 - mse: 3.8534e-06 - val_loss: 10.7561 - val_mse: 2.2203e-04\n",
      "Epoch 19/100\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 3.9536 - mse: 2.2749e-06 - val_loss: 10.6286 - val_mse: 2.1827e-04\n",
      "Epoch 20/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 3.9595 - mse: 2.4314e-06 - val_loss: 9.3633 - val_mse: 1.7302e-04\n",
      "Epoch 21/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 3.9633 - mse: 2.5466e-06 - val_loss: 9.7617 - val_mse: 1.8771e-04\n",
      "Epoch 22/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 3.9670 - mse: 2.6542e-06 - val_loss: 10.2442 - val_mse: 2.0363e-04\n",
      "Epoch 23/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9995 - mse: 3.6134e-06 - val_loss: 13.4263 - val_mse: 3.1364e-04\n",
      "Epoch 24/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 4.1311 - mse: 7.2655e-06 - val_loss: 12.1742 - val_mse: 2.6903e-04\n",
      "Epoch 25/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 4.0724 - mse: 5.6193e-06 - val_loss: 11.5940 - val_mse: 2.5089e-04\n",
      "Epoch 26/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 4.1345 - mse: 7.4385e-06 - val_loss: 6.7271 - val_mse: 8.4567e-05\n",
      "Epoch 27/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 4.0278 - mse: 4.4080e-06 - val_loss: 6.9607 - val_mse: 9.0891e-05\n",
      "Epoch 28/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9630 - mse: 2.5767e-06 - val_loss: 8.2330 - val_mse: 1.3514e-04\n",
      "Epoch 29/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 3.9514 - mse: 2.2269e-06 - val_loss: 8.8869 - val_mse: 1.5767e-04\n",
      "Epoch 30/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9595 - mse: 2.4535e-06 - val_loss: 11.8600 - val_mse: 2.5850e-04\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9455 - mse: 2.0557e-06 - val_loss: 10.0973 - val_mse: 1.9900e-04\n",
      "Epoch 32/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9372 - mse: 1.8115e-06 - val_loss: 9.7719 - val_mse: 1.8721e-04\n",
      "Epoch 33/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9446 - mse: 2.0435e-06 - val_loss: 10.6253 - val_mse: 2.1653e-04\n",
      "Epoch 34/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9422 - mse: 1.9499e-06 - val_loss: 10.4565 - val_mse: 2.1067e-04\n",
      "Epoch 35/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9431 - mse: 1.9732e-06 - val_loss: 9.2325 - val_mse: 1.6887e-04\n",
      "Epoch 36/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9537 - mse: 2.2753e-06 - val_loss: 11.3525 - val_mse: 2.4070e-04\n",
      "Epoch 37/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9848 - mse: 3.1486e-06 - val_loss: 7.0150 - val_mse: 9.2971e-05\n",
      "Epoch 38/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 4.0495 - mse: 4.9509e-06 - val_loss: 7.5734 - val_mse: 1.1128e-04\n",
      "Epoch 39/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 4.0992 - mse: 6.3591e-06 - val_loss: 13.8702 - val_mse: 3.2807e-04\n",
      "Epoch 40/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9866 - mse: 3.2131e-06 - val_loss: 9.1251 - val_mse: 1.6597e-04\n",
      "Epoch 41/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9757 - mse: 2.9053e-06 - val_loss: 7.4020 - val_mse: 1.0695e-04\n",
      "Epoch 42/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 4.0307 - mse: 4.4301e-06 - val_loss: 12.4910 - val_mse: 2.8055e-04\n",
      "Epoch 43/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 3.9667 - mse: 2.6853e-06 - val_loss: 8.2720 - val_mse: 1.3660e-04\n",
      "Epoch 44/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9521 - mse: 2.2411e-06 - val_loss: 7.8598 - val_mse: 1.2234e-04\n",
      "Epoch 45/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 3.9368 - mse: 1.8075e-06 - val_loss: 9.3048 - val_mse: 1.7158e-04\n",
      "Epoch 46/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9341 - mse: 1.7318e-06 - val_loss: 9.5540 - val_mse: 1.8022e-04\n",
      "Epoch 47/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 3.9332 - mse: 1.7278e-06 - val_loss: 10.2817 - val_mse: 2.0563e-04\n",
      "Epoch 48/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9341 - mse: 1.7287e-06 - val_loss: 10.9526 - val_mse: 2.2788e-04\n",
      "Epoch 49/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9344 - mse: 1.7486e-06 - val_loss: 10.6571 - val_mse: 2.1801e-04\n",
      "Epoch 50/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9449 - mse: 2.0309e-06 - val_loss: 12.1004 - val_mse: 2.6774e-04\n",
      "Epoch 51/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9470 - mse: 2.0988e-06 - val_loss: 12.9592 - val_mse: 2.9704e-04\n",
      "Epoch 52/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9907 - mse: 3.3246e-06 - val_loss: 9.0773 - val_mse: 1.6382e-04\n",
      "Epoch 53/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9584 - mse: 2.4017e-06 - val_loss: 8.2437 - val_mse: 1.3509e-04\n",
      "Epoch 54/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9400 - mse: 1.9008e-06 - val_loss: 8.8607 - val_mse: 1.5763e-04\n",
      "Epoch 55/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9585 - mse: 2.4055e-06 - val_loss: 10.8242 - val_mse: 2.2417e-04\n",
      "Epoch 56/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 3.9409 - mse: 1.9221e-06 - val_loss: 8.4358 - val_mse: 1.4131e-04\n",
      "Epoch 57/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9398 - mse: 1.8918e-06 - val_loss: 10.1116 - val_mse: 1.9888e-04\n",
      "Epoch 58/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9325 - mse: 1.6782e-06 - val_loss: 8.6845 - val_mse: 1.4992e-04\n",
      "Epoch 59/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9594 - mse: 2.4307e-06 - val_loss: 7.4416 - val_mse: 1.0858e-04\n",
      "Epoch 60/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 3.9616 - mse: 2.4857e-06 - val_loss: 8.6200 - val_mse: 1.4754e-04\n",
      "Epoch 61/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9527 - mse: 2.2500e-06 - val_loss: 7.5603 - val_mse: 1.1161e-04\n",
      "Epoch 62/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 4.0591 - mse: 5.2092e-06 - val_loss: 10.8019 - val_mse: 2.2216e-04\n",
      "Epoch 63/100\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 4.0871 - mse: 6.0959e-06 - val_loss: 15.6493 - val_mse: 3.9078e-04\n",
      "Epoch 64/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 4.1387 - mse: 7.5315e-06 - val_loss: 7.7302 - val_mse: 1.2015e-04\n",
      "Epoch 65/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 4.0913 - mse: 6.1681e-06 - val_loss: 7.5554 - val_mse: 1.1230e-04\n",
      "Epoch 66/100\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 3.9988 - mse: 3.6030e-06 - val_loss: 9.8993 - val_mse: 1.9509e-04\n",
      "Epoch 67/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9993 - mse: 3.5578e-06 - val_loss: 7.6441 - val_mse: 1.1439e-04\n",
      "Epoch 68/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9522 - mse: 2.2459e-06 - val_loss: 9.2592 - val_mse: 1.7136e-04\n",
      "Epoch 69/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9401 - mse: 1.9005e-06 - val_loss: 8.5181 - val_mse: 1.4534e-04\n",
      "Epoch 70/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9387 - mse: 1.8569e-06 - val_loss: 9.9209 - val_mse: 1.9367e-04\n",
      "Epoch 71/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9318 - mse: 1.6552e-06 - val_loss: 7.9479 - val_mse: 1.2612e-04\n",
      "Epoch 72/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 3.9282 - mse: 1.5498e-06 - val_loss: 8.4462 - val_mse: 1.4326e-04\n",
      "Epoch 73/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9428 - mse: 1.9667e-06 - val_loss: 9.1838 - val_mse: 1.6849e-04\n",
      "Epoch 74/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9820 - mse: 3.0956e-06 - val_loss: 9.2657 - val_mse: 1.7227e-04\n",
      "Epoch 75/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9800 - mse: 3.0010e-06 - val_loss: 7.5805 - val_mse: 1.1236e-04\n",
      "Epoch 76/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9414 - mse: 1.9280e-06 - val_loss: 10.0369 - val_mse: 1.9768e-04\n",
      "Epoch 77/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9468 - mse: 2.0877e-06 - val_loss: 9.5358 - val_mse: 1.8116e-04\n",
      "Epoch 78/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9377 - mse: 1.8242e-06 - val_loss: 7.2844 - val_mse: 1.0404e-04\n",
      "Epoch 79/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9293 - mse: 1.5860e-06 - val_loss: 8.4112 - val_mse: 1.4185e-04\n",
      "Epoch 80/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9308 - mse: 1.6293e-06 - val_loss: 8.8782 - val_mse: 1.5812e-04\n",
      "Epoch 81/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9444 - mse: 2.0815e-06 - val_loss: 8.3507 - val_mse: 1.4039e-04\n",
      "Epoch 82/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 4.0273 - mse: 4.3240e-06 - val_loss: 6.8699 - val_mse: 8.9974e-05\n",
      "Epoch 83/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9645 - mse: 2.5842e-06 - val_loss: 6.9918 - val_mse: 9.3626e-05\n",
      "Epoch 84/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9701 - mse: 2.7325e-06 - val_loss: 9.6623 - val_mse: 1.8621e-04\n",
      "Epoch 85/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 3.9408 - mse: 1.9208e-06 - val_loss: 9.2762 - val_mse: 1.7214e-04\n",
      "Epoch 86/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9271 - mse: 1.5539e-06 - val_loss: 7.8250 - val_mse: 1.2230e-04\n",
      "Epoch 87/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9278 - mse: 1.5402e-06 - val_loss: 8.1563 - val_mse: 1.3431e-04\n",
      "Epoch 88/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9352 - mse: 1.7416e-06 - val_loss: 8.8713 - val_mse: 1.5802e-04\n",
      "Epoch 89/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9575 - mse: 2.3748e-06 - val_loss: 6.8473 - val_mse: 8.9134e-05\n",
      "Epoch 90/100\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 3.9475 - mse: 2.1050e-06 - val_loss: 6.8186 - val_mse: 8.9126e-05\n",
      "Epoch 91/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9425 - mse: 1.9638e-06 - val_loss: 7.2873 - val_mse: 1.0491e-04\n",
      "Epoch 92/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9340 - mse: 1.7127e-06 - val_loss: 8.8965 - val_mse: 1.5957e-04\n",
      "Epoch 93/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9404 - mse: 1.8911e-06 - val_loss: 8.3075 - val_mse: 1.3972e-04\n",
      "Epoch 94/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9788 - mse: 2.9741e-06 - val_loss: 12.6842 - val_mse: 2.8794e-04\n",
      "Epoch 95/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 4.0261 - mse: 4.3074e-06 - val_loss: 6.3192 - val_mse: 7.3278e-05\n",
      "Epoch 96/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 4.0299 - mse: 4.4441e-06 - val_loss: 9.5716 - val_mse: 1.8351e-04\n",
      "Epoch 97/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 4.0427 - mse: 4.7715e-06 - val_loss: 9.8529 - val_mse: 1.9186e-04\n",
      "Epoch 98/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 4.0251 - mse: 4.2963e-06 - val_loss: 8.7909 - val_mse: 1.5358e-04\n",
      "Epoch 99/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9595 - mse: 2.4497e-06 - val_loss: 6.4717 - val_mse: 7.7328e-05\n",
      "Epoch 100/100\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 3.9549 - mse: 2.3166e-06 - val_loss: 13.2625 - val_mse: 3.0988e-04\n"
     ]
    }
   ],
   "source": [
    "# File of previous training\n",
    "weights_file = \"../models/optcon_model_weights_8e3_epochs_MSE.keras\"\n",
    "\n",
    "# History for training\n",
    "pred_hist = []\n",
    "training_hist = []\n",
    "\n",
    "for i in range(2, 6):\n",
    "    def loss_fn(y_actual, y_pred):\n",
    "        return sse_and_smoothness(y_actual, y_pred, tf.constant(i))\n",
    "    \n",
    "    train_epochs = 100 # 4000\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=loss_fn,\n",
    "        metrics=['mse'],\n",
    "        loss_weights=None,\n",
    "        weighted_metrics=None,\n",
    "        run_eagerly=None,\n",
    "    )\n",
    "\n",
    "    # Get the previous training\n",
    "    if True:\n",
    "        model.load_weights(weights_file)\n",
    "    \n",
    "    # Train with smoothness\n",
    "    hist = model.fit(\n",
    "        x=X, y=Y,\n",
    "        batch_size=1000,\n",
    "        epochs=train_epochs,\n",
    "        verbose=1,\n",
    "        validation_split=0.1,  # Adjust validation split?\n",
    "        shuffle=True,\n",
    "        validation_freq=1,\n",
    "    )\n",
    "    \n",
    "    ypred = 1000.*model.predict(X) + 1000.\n",
    "    ypred = ypred.reshape((ypred.shape[0], int(ypred.shape[1]/4.), 4), order='F')\n",
    "    \n",
    "    # Append the results\n",
    "    training_hist.append(hist)\n",
    "    pred_hist.append(ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (mpl.ratio !== 1) {\n",
       "            fig.send_message('set_dpi_ratio', { dpi_ratio: mpl.ratio });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    var resizeObserver = new ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * mpl.ratio);\n",
       "                canvas.setAttribute('height', height * mpl.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    resizeObserver.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / mpl.ratio,\n",
       "        fig.canvas.height / mpl.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch (cursor) {\n",
       "        case 0:\n",
       "            cursor = 'pointer';\n",
       "            break;\n",
       "        case 1:\n",
       "            cursor = 'default';\n",
       "            break;\n",
       "        case 2:\n",
       "            cursor = 'crosshair';\n",
       "            break;\n",
       "        case 3:\n",
       "            cursor = 'move';\n",
       "            break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = 'image/png';\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.which === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.which;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which !== 17) {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    if (event.altKey && event.which !== 18) {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    if (event.shiftKey && event.which !== 16) {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data']);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / mpl.ratio;\n",
       "    fig.root.removeEventListener('remove', this._remove_fig_handler);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / mpl.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function () {\n",
       "    this.close_ws(this, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "    el.addEventListener('remove', this._remove_fig_handler);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager) {\n",
       "        manager = IPython.keyboard_manager;\n",
       "    }\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id='796bf4fc-6d60-4451-8ad1-f8bfe5c2432b'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the control outputs\n",
    "fig, ax = plt.subplots(2,2)\n",
    "\n",
    "# Targets\n",
    "ax[0, 0].plot(tvec, pwms[:,0], label='PWM1 Filtered', color='C0')\n",
    "ax[0, 1].plot(tvec, pwms[:,1], label='PWM2 Filtered', color='C1')\n",
    "ax[1, 1].plot(tvec, pwms[:,2], label='PWM3 Filtered', color='C2')\n",
    "ax[1, 0].plot(tvec, pwms[:,3], label='PWM4 Filtered', color='C3')\n",
    "\n",
    "# Trained outputs\n",
    "n = 500 # 1000\n",
    "\n",
    "for d, ypred in enumerate(pred_hist):\n",
    "    pred_color = 'C%i' % d\n",
    "    for i in range(int(ypred.shape[0]/n)):\n",
    "        for j in range(4):\n",
    "            # Get right plot\n",
    "            if j == 0:\n",
    "                pax = ax[0, 0]\n",
    "            elif j == 1:\n",
    "                pax = ax[0, 1]\n",
    "            elif j == 2:\n",
    "                pax = ax[1, 1]\n",
    "            else:\n",
    "                pax = ax[1, 0]\n",
    "\n",
    "            pax.plot(\n",
    "                tvec_y[n*i, :],\n",
    "                ypred[n*i, :, j],\n",
    "                color=pred_color,\n",
    "                #marker='x',\n",
    "                alpha=0.6,\n",
    "                label=(\n",
    "                    ('' if i == 0 and j == 0 else '_') + \n",
    "                    ('Degree %i' % (d+2))\n",
    "                )\n",
    "            )\n",
    "ax[0,0].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (mpl.ratio !== 1) {\n",
       "            fig.send_message('set_dpi_ratio', { dpi_ratio: mpl.ratio });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    var resizeObserver = new ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * mpl.ratio);\n",
       "                canvas.setAttribute('height', height * mpl.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    resizeObserver.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / mpl.ratio,\n",
       "        fig.canvas.height / mpl.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch (cursor) {\n",
       "        case 0:\n",
       "            cursor = 'pointer';\n",
       "            break;\n",
       "        case 1:\n",
       "            cursor = 'default';\n",
       "            break;\n",
       "        case 2:\n",
       "            cursor = 'crosshair';\n",
       "            break;\n",
       "        case 3:\n",
       "            cursor = 'move';\n",
       "            break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = 'image/png';\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.which === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.which;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which !== 17) {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    if (event.altKey && event.which !== 18) {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    if (event.shiftKey && event.which !== 16) {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data']);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / mpl.ratio;\n",
       "    fig.root.removeEventListener('remove', this._remove_fig_handler);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / mpl.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function () {\n",
       "    this.close_ws(this, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "    el.addEventListener('remove', this._remove_fig_handler);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager) {\n",
       "        manager = IPython.keyboard_manager;\n",
       "    }\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id='df604e22-7750-4a60-baf7-e7d8c4953c8e'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "for d, hist in enumerate(training_hist):\n",
    "    c = 'C%i' % d\n",
    "    # Vectors for plotting\n",
    "    lvec = np.array(hist.history['loss'])\n",
    "    vlvec = np.array(hist.history['val_loss'])\n",
    "    epoch_vec = np.array(list(range(lvec.shape[0])))\n",
    "    \n",
    "    ax.plot(epoch_vec, lvec, color=c, label=('Degree %i training loss' % (d + 2)))\n",
    "    ax.plot(epoch_vec, vlvec, color=c, linestyle=':', label=('Degree %i validation loss' % (d + 2)))\n",
    "\n",
    "fig.suptitle('Training Losses')\n",
    "ax.legend(fontsize='xx-small', handlelength=1)\n",
    "\n",
    "ax.set_xlim(left=0)\n",
    "ax.set_ylim(bottom=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bezier Loss Function\n",
    "\n",
    "Trying out the Bezier loss function with training from scratch. Technically you could use aggregate training if you trained on only a few sample points to match and then added more for alterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_4 (Flatten)          (None, 240)               0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 120)               28920     \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 80)                9680      \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 60)                4860      \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 48)                2928      \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 40)                1960      \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 34)                1394      \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 30)                1050      \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 26)                806       \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 12)                324       \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 3, 4)              0         \n",
      "=================================================================\n",
      "Total params: 51,922\n",
      "Trainable params: 51,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Altering Y for Bezier loss function\n",
    "Yb = Y.reshape((Y.shape[0], Y.shape[1]//4, 4), order='F')  # NxMxK where K=4 i.e. dimension\n",
    "Yb_t = ((tvec_y - tvec_y[:,0].reshape((tvec_y.shape[0], 1)))/1.).reshape(tvec_y.shape + (1,))  # Get time vector into NxMx1\n",
    "Yb = np.append(Yb_t, Yb, axis=2)  # NxMx(1+K) by appending on the time vector on \n",
    "\n",
    "# Creating model shapes\n",
    "n_b_points = 3\n",
    "dX = X.shape[1]\n",
    "dY = 4*n_b_points  # Y.shape[1]\n",
    "\n",
    "\n",
    "\n",
    "# Build model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=X.shape[1:]))\n",
    "for n in range(2,10):\n",
    "    model.add(tf.keras.layers.Dense(max(dY, int(dX/n)), activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(dY, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Reshape((n_b_points, 4), input_shape=(dY,)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34280 samples, validate on 3809 samples\n",
      "Epoch 1/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Patrick\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 1s 42us/sample - loss: 80.2464 - val_loss: 154.5834\n",
      "Epoch 2/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.9656 - val_loss: 134.7849\n",
      "Epoch 3/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.8190 - val_loss: 133.3957\n",
      "Epoch 4/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7438 - val_loss: 132.6817\n",
      "Epoch 5/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6988 - val_loss: 139.5097\n",
      "Epoch 6/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6792 - val_loss: 138.1513\n",
      "Epoch 7/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7006 - val_loss: 140.8664\n",
      "Epoch 8/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6829 - val_loss: 123.5863\n",
      "Epoch 9/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7466 - val_loss: 142.9180\n",
      "Epoch 10/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.6832 - val_loss: 132.0520\n",
      "Epoch 11/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6770 - val_loss: 142.4061\n",
      "Epoch 12/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.6967 - val_loss: 137.8972\n",
      "Epoch 13/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6896 - val_loss: 133.5108\n",
      "Epoch 14/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.7128 - val_loss: 141.7527\n",
      "Epoch 15/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7383 - val_loss: 135.2793\n",
      "Epoch 16/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.6786 - val_loss: 144.4045\n",
      "Epoch 17/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6652 - val_loss: 146.2926\n",
      "Epoch 18/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7469 - val_loss: 147.0158\n",
      "Epoch 19/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6939 - val_loss: 140.3166\n",
      "Epoch 20/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 78.6645 - val_loss: 136.5034\n",
      "Epoch 21/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6815 - val_loss: 151.8183\n",
      "Epoch 22/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.7003 - val_loss: 145.1081\n",
      "Epoch 23/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6721 - val_loss: 162.6433\n",
      "Epoch 24/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7313 - val_loss: 137.1320\n",
      "Epoch 25/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7282 - val_loss: 151.6555\n",
      "Epoch 26/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7220 - val_loss: 163.6024\n",
      "Epoch 27/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.7656 - val_loss: 127.9489\n",
      "Epoch 28/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.7945 - val_loss: 144.3057\n",
      "Epoch 29/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6887 - val_loss: 143.6090\n",
      "Epoch 30/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6916 - val_loss: 143.5050\n",
      "Epoch 31/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7041 - val_loss: 142.0529\n",
      "Epoch 32/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6691 - val_loss: 146.1335\n",
      "Epoch 33/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.7131 - val_loss: 143.2467\n",
      "Epoch 34/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.7021 - val_loss: 136.8572\n",
      "Epoch 35/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.7153 - val_loss: 140.8981\n",
      "Epoch 36/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7016 - val_loss: 130.8919\n",
      "Epoch 37/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.6766 - val_loss: 135.1115\n",
      "Epoch 38/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.6756 - val_loss: 148.6502\n",
      "Epoch 39/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7247 - val_loss: 142.7899\n",
      "Epoch 40/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6741 - val_loss: 129.9919\n",
      "Epoch 41/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.7069 - val_loss: 148.4088\n",
      "Epoch 42/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7310 - val_loss: 150.9665\n",
      "Epoch 43/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.7562 - val_loss: 142.4829\n",
      "Epoch 44/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.6726 - val_loss: 141.4982\n",
      "Epoch 45/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6490 - val_loss: 154.8007\n",
      "Epoch 46/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.6899 - val_loss: 141.1011\n",
      "Epoch 47/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.6774 - val_loss: 147.6180\n",
      "Epoch 48/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.7143 - val_loss: 158.6844\n",
      "Epoch 49/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7379 - val_loss: 140.6162\n",
      "Epoch 50/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6853 - val_loss: 144.5058\n",
      "Epoch 51/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6786 - val_loss: 126.0593\n",
      "Epoch 52/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7689 - val_loss: 136.6928\n",
      "Epoch 53/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.6555 - val_loss: 145.7405\n",
      "Epoch 54/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6543 - val_loss: 132.9561\n",
      "Epoch 55/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6801 - val_loss: 138.0142\n",
      "Epoch 56/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6661 - val_loss: 140.8755\n",
      "Epoch 57/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.6820 - val_loss: 145.0351\n",
      "Epoch 58/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.7089 - val_loss: 142.0129\n",
      "Epoch 59/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.6747 - val_loss: 147.8936\n",
      "Epoch 60/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7458 - val_loss: 144.6098\n",
      "Epoch 61/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6619 - val_loss: 142.9186\n",
      "Epoch 62/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.6428 - val_loss: 143.1572\n",
      "Epoch 63/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.6729 - val_loss: 145.9482\n",
      "Epoch 64/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.7066 - val_loss: 147.8706\n",
      "Epoch 65/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.6607 - val_loss: 153.7733\n",
      "Epoch 66/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.6527 - val_loss: 140.1015\n",
      "Epoch 67/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.6531 - val_loss: 148.0912\n",
      "Epoch 68/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.6936 - val_loss: 135.4169\n",
      "Epoch 69/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.7345 - val_loss: 142.3092\n",
      "Epoch 70/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.6926 - val_loss: 143.7326\n",
      "Epoch 71/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.6688 - val_loss: 154.4853\n",
      "Epoch 72/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.7405 - val_loss: 156.2409\n",
      "Epoch 73/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.6737 - val_loss: 148.2877\n",
      "Epoch 74/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.7431 - val_loss: 146.9166\n",
      "Epoch 75/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.7325 - val_loss: 145.9179\n",
      "Epoch 76/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.7661 - val_loss: 144.1477\n",
      "Epoch 77/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.6783 - val_loss: 140.1316\n",
      "Epoch 78/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6992 - val_loss: 147.7537\n",
      "Epoch 79/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6632 - val_loss: 158.5016\n",
      "Epoch 80/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6481 - val_loss: 149.8139\n",
      "Epoch 81/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6424 - val_loss: 145.5512\n",
      "Epoch 82/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6478 - val_loss: 127.6706\n",
      "Epoch 83/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.7913 - val_loss: 143.7095\n",
      "Epoch 84/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.6724 - val_loss: 142.5566\n",
      "Epoch 85/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.6320 - val_loss: 152.7777\n",
      "Epoch 86/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.6708 - val_loss: 142.3103\n",
      "Epoch 87/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.6746 - val_loss: 138.8520\n",
      "Epoch 88/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.6759 - val_loss: 144.0076\n",
      "Epoch 89/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6944 - val_loss: 148.4955\n",
      "Epoch 90/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6561 - val_loss: 134.2948\n",
      "Epoch 91/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7419 - val_loss: 146.2820\n",
      "Epoch 92/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.6573 - val_loss: 139.1173\n",
      "Epoch 93/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7015 - val_loss: 150.6295\n",
      "Epoch 94/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6668 - val_loss: 154.4784\n",
      "Epoch 95/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.7097 - val_loss: 146.5161\n",
      "Epoch 96/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6975 - val_loss: 135.0129\n",
      "Epoch 97/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6401 - val_loss: 151.4007\n",
      "Epoch 98/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6407 - val_loss: 157.6626\n",
      "Epoch 99/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.6712 - val_loss: 132.4696\n",
      "Epoch 100/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7169 - val_loss: 146.4750\n",
      "Epoch 101/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7812 - val_loss: 155.0899\n",
      "Epoch 102/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6998 - val_loss: 151.9472\n",
      "Epoch 103/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7062 - val_loss: 149.5526\n",
      "Epoch 104/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6504 - val_loss: 160.7734\n",
      "Epoch 105/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6737 - val_loss: 154.5329\n",
      "Epoch 106/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.6316 - val_loss: 145.4171\n",
      "Epoch 107/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6618 - val_loss: 150.4824\n",
      "Epoch 108/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6421 - val_loss: 143.3131\n",
      "Epoch 109/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.6389 - val_loss: 159.5931\n",
      "Epoch 110/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6370 - val_loss: 156.3187\n",
      "Epoch 111/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6458 - val_loss: 140.4985\n",
      "Epoch 112/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.6684 - val_loss: 158.5170\n",
      "Epoch 113/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6968 - val_loss: 156.5161\n",
      "Epoch 114/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.7005 - val_loss: 134.1055\n",
      "Epoch 115/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7120 - val_loss: 153.9959\n",
      "Epoch 116/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6321 - val_loss: 159.1607\n",
      "Epoch 117/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.7100 - val_loss: 152.2196\n",
      "Epoch 118/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6920 - val_loss: 150.4921\n",
      "Epoch 119/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.7088 - val_loss: 141.3823\n",
      "Epoch 120/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6484 - val_loss: 153.5020\n",
      "Epoch 121/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6549 - val_loss: 150.7495\n",
      "Epoch 122/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6566 - val_loss: 161.2196\n",
      "Epoch 123/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6661 - val_loss: 152.9939\n",
      "Epoch 124/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.6785 - val_loss: 150.2604\n",
      "Epoch 125/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.6920 - val_loss: 147.2036\n",
      "Epoch 126/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6358 - val_loss: 148.5890\n",
      "Epoch 127/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.6496 - val_loss: 150.1601\n",
      "Epoch 128/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6837 - val_loss: 151.0160\n",
      "Epoch 129/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7036 - val_loss: 155.5728\n",
      "Epoch 130/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.6429 - val_loss: 147.4070\n",
      "Epoch 131/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6772 - val_loss: 151.5810\n",
      "Epoch 132/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6664 - val_loss: 146.7164\n",
      "Epoch 133/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6523 - val_loss: 163.4091\n",
      "Epoch 134/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6522 - val_loss: 158.8774\n",
      "Epoch 135/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6606 - val_loss: 142.8770\n",
      "Epoch 136/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.6653 - val_loss: 147.3200\n",
      "Epoch 137/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6413 - val_loss: 163.9280\n",
      "Epoch 138/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7173 - val_loss: 130.0535\n",
      "Epoch 139/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 78.7760 - val_loss: 139.3788\n",
      "Epoch 140/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 78.6450 - val_loss: 147.6421\n",
      "Epoch 141/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6397 - val_loss: 146.1303\n",
      "Epoch 142/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6623 - val_loss: 142.9166\n",
      "Epoch 143/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 78.6283 - val_loss: 156.8450\n",
      "Epoch 144/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6255 - val_loss: 149.4110\n",
      "Epoch 145/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.6858 - val_loss: 146.4833\n",
      "Epoch 146/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6768 - val_loss: 151.9570\n",
      "Epoch 147/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6490 - val_loss: 142.4818\n",
      "Epoch 148/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6512 - val_loss: 151.5401\n",
      "Epoch 149/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6682 - val_loss: 150.1760\n",
      "Epoch 150/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6263 - val_loss: 135.8632\n",
      "Epoch 151/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7290 - val_loss: 154.1112\n",
      "Epoch 152/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6938 - val_loss: 155.2921\n",
      "Epoch 153/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6639 - val_loss: 155.7688\n",
      "Epoch 154/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6357 - val_loss: 152.1784\n",
      "Epoch 155/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6596 - val_loss: 148.8434\n",
      "Epoch 156/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6516 - val_loss: 153.7124\n",
      "Epoch 157/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6703 - val_loss: 164.3323\n",
      "Epoch 158/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 78.6540 - val_loss: 151.7355\n",
      "Epoch 159/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6326 - val_loss: 139.6310\n",
      "Epoch 160/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7818 - val_loss: 164.2827\n",
      "Epoch 161/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6743 - val_loss: 162.0692\n",
      "Epoch 162/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6888 - val_loss: 166.8201\n",
      "Epoch 163/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7019 - val_loss: 164.0254\n",
      "Epoch 164/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6932 - val_loss: 158.9931\n",
      "Epoch 165/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6961 - val_loss: 155.5353\n",
      "Epoch 166/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6500 - val_loss: 163.1944\n",
      "Epoch 167/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6471 - val_loss: 156.6322\n",
      "Epoch 168/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6563 - val_loss: 155.5148\n",
      "Epoch 169/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6594 - val_loss: 158.1974\n",
      "Epoch 170/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6585 - val_loss: 149.4038\n",
      "Epoch 171/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6786 - val_loss: 166.3324\n",
      "Epoch 172/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6664 - val_loss: 156.0508\n",
      "Epoch 173/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6669 - val_loss: 161.8672\n",
      "Epoch 174/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7040 - val_loss: 158.3272\n",
      "Epoch 175/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6534 - val_loss: 160.0543\n",
      "Epoch 176/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6386 - val_loss: 151.7095\n",
      "Epoch 177/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7577 - val_loss: 158.0321\n",
      "Epoch 178/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6516 - val_loss: 159.0882\n",
      "Epoch 179/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6681 - val_loss: 153.7503\n",
      "Epoch 180/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6466 - val_loss: 147.7279\n",
      "Epoch 181/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7313 - val_loss: 155.8016\n",
      "Epoch 182/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6541 - val_loss: 147.9374\n",
      "Epoch 183/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6639 - val_loss: 158.9267\n",
      "Epoch 184/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7292 - val_loss: 156.9279\n",
      "Epoch 185/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6386 - val_loss: 155.6141\n",
      "Epoch 186/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 78.6453 - val_loss: 153.7411\n",
      "Epoch 187/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6397 - val_loss: 163.9853\n",
      "Epoch 188/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6659 - val_loss: 164.3549\n",
      "Epoch 189/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7635 - val_loss: 159.2547\n",
      "Epoch 190/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7317 - val_loss: 152.3139\n",
      "Epoch 191/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6607 - val_loss: 155.6298\n",
      "Epoch 192/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6333 - val_loss: 156.5619\n",
      "Epoch 193/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6418 - val_loss: 155.3618\n",
      "Epoch 194/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6918 - val_loss: 171.1463\n",
      "Epoch 195/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7539 - val_loss: 161.7387\n",
      "Epoch 196/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7125 - val_loss: 148.8547\n",
      "Epoch 197/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6737 - val_loss: 152.6151\n",
      "Epoch 198/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6571 - val_loss: 162.2926\n",
      "Epoch 199/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 78.6721 - val_loss: 166.2168\n",
      "Epoch 200/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6487 - val_loss: 154.5494\n",
      "Epoch 201/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6544 - val_loss: 158.2585\n",
      "Epoch 202/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6319 - val_loss: 156.0014\n",
      "Epoch 203/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6363 - val_loss: 152.3374\n",
      "Epoch 204/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6224 - val_loss: 155.0370\n",
      "Epoch 205/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7748 - val_loss: 172.2836\n",
      "Epoch 206/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7326 - val_loss: 157.7315\n",
      "Epoch 207/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6672 - val_loss: 158.1980\n",
      "Epoch 208/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6507 - val_loss: 154.9729\n",
      "Epoch 209/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6572 - val_loss: 150.9473\n",
      "Epoch 210/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6423 - val_loss: 156.6542\n",
      "Epoch 211/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6531 - val_loss: 157.8381\n",
      "Epoch 212/10000\n",
      "34280/34280 [==============================] - ETA: 0s - loss: 79.14 - 0s 10us/sample - loss: 78.6770 - val_loss: 148.8270\n",
      "Epoch 213/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 78.6964 - val_loss: 157.7246\n",
      "Epoch 214/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6284 - val_loss: 154.2152\n",
      "Epoch 215/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6562 - val_loss: 143.6465\n",
      "Epoch 216/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7065 - val_loss: 154.4892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 78.6398 - val_loss: 153.0022\n",
      "Epoch 218/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6309 - val_loss: 156.2795\n",
      "Epoch 219/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6416 - val_loss: 155.6895\n",
      "Epoch 220/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6624 - val_loss: 144.2420\n",
      "Epoch 221/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6939 - val_loss: 163.0298\n",
      "Epoch 222/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7378 - val_loss: 149.4490\n",
      "Epoch 223/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6676 - val_loss: 149.6357\n",
      "Epoch 224/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6312 - val_loss: 155.8907\n",
      "Epoch 225/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6187 - val_loss: 152.8387\n",
      "Epoch 226/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6081 - val_loss: 157.7652\n",
      "Epoch 227/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6625 - val_loss: 164.2652\n",
      "Epoch 228/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7275 - val_loss: 151.3561\n",
      "Epoch 229/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6648 - val_loss: 163.0992\n",
      "Epoch 230/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6666 - val_loss: 156.4591\n",
      "Epoch 231/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6760 - val_loss: 150.9064\n",
      "Epoch 232/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6660 - val_loss: 148.3486\n",
      "Epoch 233/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6591 - val_loss: 154.4951\n",
      "Epoch 234/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6296 - val_loss: 149.5906\n",
      "Epoch 235/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7119 - val_loss: 140.2817\n",
      "Epoch 236/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 78.6694 - val_loss: 150.3147\n",
      "Epoch 237/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6496 - val_loss: 156.1444\n",
      "Epoch 238/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7047 - val_loss: 145.1829\n",
      "Epoch 239/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7055 - val_loss: 142.4024\n",
      "Epoch 240/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6795 - val_loss: 152.7938\n",
      "Epoch 241/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6793 - val_loss: 151.1772\n",
      "Epoch 242/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6564 - val_loss: 152.3434\n",
      "Epoch 243/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6486 - val_loss: 156.9302\n",
      "Epoch 244/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6752 - val_loss: 149.0160\n",
      "Epoch 245/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6319 - val_loss: 150.5783\n",
      "Epoch 246/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6162 - val_loss: 155.5514\n",
      "Epoch 247/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6960 - val_loss: 146.6707\n",
      "Epoch 248/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6912 - val_loss: 151.9024\n",
      "Epoch 249/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6241 - val_loss: 152.0465\n",
      "Epoch 250/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6801 - val_loss: 155.8413\n",
      "Epoch 251/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6688 - val_loss: 154.4366\n",
      "Epoch 252/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6303 - val_loss: 158.5689\n",
      "Epoch 253/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6644 - val_loss: 150.1585\n",
      "Epoch 254/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6417 - val_loss: 150.0239\n",
      "Epoch 255/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6320 - val_loss: 150.4183\n",
      "Epoch 256/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 78.6402 - val_loss: 146.8116\n",
      "Epoch 257/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6668 - val_loss: 150.5512\n",
      "Epoch 258/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6363 - val_loss: 151.3622\n",
      "Epoch 259/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6319 - val_loss: 154.9393\n",
      "Epoch 260/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6377 - val_loss: 156.0356\n",
      "Epoch 261/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6605 - val_loss: 150.8445\n",
      "Epoch 262/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6160 - val_loss: 156.3457\n",
      "Epoch 263/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6867 - val_loss: 153.5605\n",
      "Epoch 264/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6957 - val_loss: 147.5514\n",
      "Epoch 265/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6547 - val_loss: 151.7290\n",
      "Epoch 266/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6582 - val_loss: 148.5168\n",
      "Epoch 267/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6158 - val_loss: 145.3741\n",
      "Epoch 268/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6328 - val_loss: 148.4247\n",
      "Epoch 269/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6398 - val_loss: 142.1620\n",
      "Epoch 270/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6291 - val_loss: 144.7845\n",
      "Epoch 271/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6207 - val_loss: 151.5033\n",
      "Epoch 272/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7054 - val_loss: 153.0969\n",
      "Epoch 273/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6769 - val_loss: 144.6688\n",
      "Epoch 274/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6618 - val_loss: 151.3385\n",
      "Epoch 275/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6396 - val_loss: 154.7382\n",
      "Epoch 276/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6272 - val_loss: 154.8124\n",
      "Epoch 277/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6443 - val_loss: 150.6499\n",
      "Epoch 278/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6239 - val_loss: 153.1093\n",
      "Epoch 279/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6725 - val_loss: 147.8802\n",
      "Epoch 280/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6478 - val_loss: 146.9764\n",
      "Epoch 281/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6696 - val_loss: 155.8517\n",
      "Epoch 282/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6540 - val_loss: 147.4070\n",
      "Epoch 283/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6802 - val_loss: 141.2711\n",
      "Epoch 284/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6162 - val_loss: 146.4123\n",
      "Epoch 285/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6903 - val_loss: 151.0462\n",
      "Epoch 286/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.8361 - val_loss: 147.2982\n",
      "Epoch 287/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6853 - val_loss: 150.8955\n",
      "Epoch 288/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6474 - val_loss: 152.8340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 289/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6621 - val_loss: 162.2208\n",
      "Epoch 290/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7592 - val_loss: 146.2831\n",
      "Epoch 291/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6599 - val_loss: 146.1004\n",
      "Epoch 292/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 78.6403 - val_loss: 147.2483\n",
      "Epoch 293/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6118 - val_loss: 152.1336\n",
      "Epoch 294/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6288 - val_loss: 152.8554\n",
      "Epoch 295/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6117 - val_loss: 147.8936\n",
      "Epoch 296/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6573 - val_loss: 151.4700\n",
      "Epoch 297/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6201 - val_loss: 150.6421\n",
      "Epoch 298/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6278 - val_loss: 152.2564\n",
      "Epoch 299/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6554 - val_loss: 144.2772\n",
      "Epoch 300/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 78.6280 - val_loss: 146.8779\n",
      "Epoch 301/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6120 - val_loss: 143.3824\n",
      "Epoch 302/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7461 - val_loss: 150.7694\n",
      "Epoch 303/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6289 - val_loss: 152.0099\n",
      "Epoch 304/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6411 - val_loss: 143.8540\n",
      "Epoch 305/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6505 - val_loss: 150.9303\n",
      "Epoch 306/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6259 - val_loss: 146.9109\n",
      "Epoch 307/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6174 - val_loss: 142.0090\n",
      "Epoch 308/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6714 - val_loss: 143.9266\n",
      "Epoch 309/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.6996 - val_loss: 148.5802\n",
      "Epoch 310/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6600 - val_loss: 154.0483\n",
      "Epoch 311/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7018 - val_loss: 151.4697\n",
      "Epoch 312/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6319 - val_loss: 147.4417\n",
      "Epoch 313/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6316 - val_loss: 145.7696\n",
      "Epoch 314/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6575 - val_loss: 150.8564\n",
      "Epoch 315/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6514 - val_loss: 144.8605\n",
      "Epoch 316/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 78.6325 - val_loss: 145.6850\n",
      "Epoch 317/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6443 - val_loss: 148.3775\n",
      "Epoch 318/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6416 - val_loss: 147.0726\n",
      "Epoch 319/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6599 - val_loss: 144.0015\n",
      "Epoch 320/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6453 - val_loss: 142.1713\n",
      "Epoch 321/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6667 - val_loss: 151.3770\n",
      "Epoch 322/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6410 - val_loss: 140.3253\n",
      "Epoch 323/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 78.6164 - val_loss: 145.8499\n",
      "Epoch 324/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6584 - val_loss: 142.7726\n",
      "Epoch 325/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6817 - val_loss: 143.4458\n",
      "Epoch 326/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6441 - val_loss: 144.6201\n",
      "Epoch 327/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6367 - val_loss: 146.1772\n",
      "Epoch 328/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6291 - val_loss: 147.5836\n",
      "Epoch 329/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6012 - val_loss: 149.5086\n",
      "Epoch 330/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6115 - val_loss: 151.9071\n",
      "Epoch 331/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6385 - val_loss: 150.7097\n",
      "Epoch 332/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6388 - val_loss: 151.7940\n",
      "Epoch 333/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6551 - val_loss: 151.4211\n",
      "Epoch 334/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6866 - val_loss: 153.1224\n",
      "Epoch 335/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6110 - val_loss: 153.8908\n",
      "Epoch 336/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6247 - val_loss: 153.9048\n",
      "Epoch 337/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6061 - val_loss: 148.3195\n",
      "Epoch 338/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6540 - val_loss: 152.4315\n",
      "Epoch 339/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6372 - val_loss: 152.2358\n",
      "Epoch 340/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6483 - val_loss: 149.7268\n",
      "Epoch 341/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6207 - val_loss: 150.7286\n",
      "Epoch 342/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6971 - val_loss: 147.3302\n",
      "Epoch 343/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6491 - val_loss: 146.7380\n",
      "Epoch 344/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6273 - val_loss: 147.8430\n",
      "Epoch 345/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6256 - val_loss: 155.1699\n",
      "Epoch 346/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6257 - val_loss: 151.3657\n",
      "Epoch 347/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6349 - val_loss: 150.9585\n",
      "Epoch 348/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6851 - val_loss: 145.5638\n",
      "Epoch 349/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6371 - val_loss: 152.0083\n",
      "Epoch 350/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6241 - val_loss: 150.3708\n",
      "Epoch 351/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6212 - val_loss: 148.3102\n",
      "Epoch 352/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6780 - val_loss: 159.0164\n",
      "Epoch 353/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7690 - val_loss: 147.9354\n",
      "Epoch 354/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6506 - val_loss: 151.2256\n",
      "Epoch 355/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6501 - val_loss: 156.2303\n",
      "Epoch 356/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6608 - val_loss: 150.9555\n",
      "Epoch 357/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6194 - val_loss: 158.4405\n",
      "Epoch 358/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6203 - val_loss: 157.0206\n",
      "Epoch 359/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6727 - val_loss: 148.7706\n",
      "Epoch 360/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6802 - val_loss: 153.2358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6214 - val_loss: 155.3458\n",
      "Epoch 362/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6132 - val_loss: 152.5872\n",
      "Epoch 363/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6280 - val_loss: 145.1638\n",
      "Epoch 364/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7372 - val_loss: 143.6202\n",
      "Epoch 365/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7243 - val_loss: 146.9764\n",
      "Epoch 366/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6478 - val_loss: 148.5623\n",
      "Epoch 367/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6447 - val_loss: 145.4041\n",
      "Epoch 368/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6531 - val_loss: 148.4110\n",
      "Epoch 369/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6172 - val_loss: 150.2618\n",
      "Epoch 370/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6209 - val_loss: 148.6314\n",
      "Epoch 371/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6322 - val_loss: 153.4495\n",
      "Epoch 372/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6248 - val_loss: 151.9724\n",
      "Epoch 373/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6399 - val_loss: 149.4573\n",
      "Epoch 374/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6547 - val_loss: 152.0458\n",
      "Epoch 375/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6251 - val_loss: 149.0788\n",
      "Epoch 376/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 78.6690 - val_loss: 149.0919\n",
      "Epoch 377/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 78.6425 - val_loss: 153.0459\n",
      "Epoch 378/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6548 - val_loss: 147.4761\n",
      "Epoch 379/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6527 - val_loss: 143.7323\n",
      "Epoch 380/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6807 - val_loss: 148.8936\n",
      "Epoch 381/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6475 - val_loss: 144.5678\n",
      "Epoch 382/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6411 - val_loss: 144.8363\n",
      "Epoch 383/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6510 - val_loss: 149.2781\n",
      "Epoch 384/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6634 - val_loss: 151.3648\n",
      "Epoch 385/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6297 - val_loss: 151.9619\n",
      "Epoch 386/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6311 - val_loss: 141.9991\n",
      "Epoch 387/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7040 - val_loss: 145.3783\n",
      "Epoch 388/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6125 - val_loss: 149.6919\n",
      "Epoch 389/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6387 - val_loss: 147.3778\n",
      "Epoch 390/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7069 - val_loss: 144.6191\n",
      "Epoch 391/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6558 - val_loss: 151.7566\n",
      "Epoch 392/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7240 - val_loss: 146.4357\n",
      "Epoch 393/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7670 - val_loss: 144.1399\n",
      "Epoch 394/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6289 - val_loss: 146.8319\n",
      "Epoch 395/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6444 - val_loss: 147.8349\n",
      "Epoch 396/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6722 - val_loss: 150.3885\n",
      "Epoch 397/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6488 - val_loss: 151.2617\n",
      "Epoch 398/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6650 - val_loss: 150.4289\n",
      "Epoch 399/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6034 - val_loss: 147.4830\n",
      "Epoch 400/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6069 - val_loss: 147.2662\n",
      "Epoch 401/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6151 - val_loss: 143.5901\n",
      "Epoch 402/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6057 - val_loss: 148.0078\n",
      "Epoch 403/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6154 - val_loss: 145.8331\n",
      "Epoch 404/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6264 - val_loss: 145.9211\n",
      "Epoch 405/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6143 - val_loss: 148.4534\n",
      "Epoch 406/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6498 - val_loss: 147.3774\n",
      "Epoch 407/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7077 - val_loss: 155.0106\n",
      "Epoch 408/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6394 - val_loss: 137.8496\n",
      "Epoch 409/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6206 - val_loss: 145.0411\n",
      "Epoch 410/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6250 - val_loss: 141.9308\n",
      "Epoch 411/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6250 - val_loss: 145.6322\n",
      "Epoch 412/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6734 - val_loss: 151.1168\n",
      "Epoch 413/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6412 - val_loss: 146.0098\n",
      "Epoch 414/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6352 - val_loss: 147.2966\n",
      "Epoch 415/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6016 - val_loss: 139.2776\n",
      "Epoch 416/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6534 - val_loss: 144.5542\n",
      "Epoch 417/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6478 - val_loss: 145.3773\n",
      "Epoch 418/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6482 - val_loss: 146.3242\n",
      "Epoch 419/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6378 - val_loss: 149.2758\n",
      "Epoch 420/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6357 - val_loss: 147.1329\n",
      "Epoch 421/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.5964 - val_loss: 145.4152\n",
      "Epoch 422/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6246 - val_loss: 147.4760\n",
      "Epoch 423/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6221 - val_loss: 143.3826\n",
      "Epoch 424/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6005 - val_loss: 149.5138\n",
      "Epoch 425/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6452 - val_loss: 150.9819\n",
      "Epoch 426/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.5954 - val_loss: 147.4226\n",
      "Epoch 427/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6515 - val_loss: 148.6994\n",
      "Epoch 428/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6206 - val_loss: 147.5969\n",
      "Epoch 429/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 78.6361 - val_loss: 145.0822\n",
      "Epoch 430/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6391 - val_loss: 142.0947\n",
      "Epoch 431/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6516 - val_loss: 143.2899\n",
      "Epoch 432/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 78.6157 - val_loss: 144.5840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 433/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6208 - val_loss: 148.2871\n",
      "Epoch 434/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6610 - val_loss: 151.9455\n",
      "Epoch 435/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 78.6529 - val_loss: 147.7673\n",
      "Epoch 436/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 78.6536 - val_loss: 143.7624\n",
      "Epoch 437/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 78.6722 - val_loss: 143.0649\n",
      "Epoch 438/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6381 - val_loss: 154.1223\n",
      "Epoch 439/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6485 - val_loss: 147.4778\n",
      "Epoch 440/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7457 - val_loss: 149.3451\n",
      "Epoch 441/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6773 - val_loss: 149.3435\n",
      "Epoch 442/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6709 - val_loss: 141.0410\n",
      "Epoch 443/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6135 - val_loss: 148.0504\n",
      "Epoch 444/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6510 - val_loss: 147.8534\n",
      "Epoch 445/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6468 - val_loss: 150.7792\n",
      "Epoch 446/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6229 - val_loss: 140.0279\n",
      "Epoch 447/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 78.6427 - val_loss: 153.8993\n",
      "Epoch 448/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6504 - val_loss: 142.7152\n",
      "Epoch 449/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6112 - val_loss: 140.1188\n",
      "Epoch 450/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6488 - val_loss: 143.3315\n",
      "Epoch 451/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6257 - val_loss: 145.8682\n",
      "Epoch 452/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6202 - val_loss: 141.4432\n",
      "Epoch 453/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6622 - val_loss: 145.6868\n",
      "Epoch 454/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6370 - val_loss: 146.6990\n",
      "Epoch 455/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.8009 - val_loss: 138.1992\n",
      "Epoch 456/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7533 - val_loss: 151.0594\n",
      "Epoch 457/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6383 - val_loss: 150.7817\n",
      "Epoch 458/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6192 - val_loss: 147.7769\n",
      "Epoch 459/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6181 - val_loss: 148.4522\n",
      "Epoch 460/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6187 - val_loss: 146.6697\n",
      "Epoch 461/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6075 - val_loss: 155.2095\n",
      "Epoch 462/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7134 - val_loss: 141.9143\n",
      "Epoch 463/10000\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 78.6089 - val_loss: 146.9981\n",
      "Epoch 464/10000\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 78.6133 - val_loss: 139.8506\n",
      "Epoch 465/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 78.6524 - val_loss: 148.2872\n",
      "Epoch 466/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 78.6527 - val_loss: 143.3525\n",
      "Epoch 467/10000\n",
      "34280/34280 [==============================] - 0s 13us/sample - loss: 78.6515 - val_loss: 143.2497\n",
      "Epoch 468/10000\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 78.6447 - val_loss: 140.4923\n",
      "Epoch 469/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 78.7462 - val_loss: 143.8930\n",
      "Epoch 470/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 78.6440 - val_loss: 139.8121\n",
      "Epoch 471/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6089 - val_loss: 143.0840\n",
      "Epoch 472/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6339 - val_loss: 141.1581\n",
      "Epoch 473/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6511 - val_loss: 136.8261\n",
      "Epoch 474/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6304 - val_loss: 139.6399\n",
      "Epoch 475/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6344 - val_loss: 140.1937\n",
      "Epoch 476/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6495 - val_loss: 143.5309\n",
      "Epoch 477/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6255 - val_loss: 141.2116\n",
      "Epoch 478/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6024 - val_loss: 143.3580\n",
      "Epoch 479/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6233 - val_loss: 139.6357\n",
      "Epoch 480/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6441 - val_loss: 139.4299\n",
      "Epoch 481/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 78.6198 - val_loss: 155.7747\n",
      "Epoch 482/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 78.6416 - val_loss: 145.5885\n",
      "Epoch 483/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 78.6532 - val_loss: 141.3508\n",
      "Epoch 484/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6701 - val_loss: 147.1258\n",
      "Epoch 485/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6747 - val_loss: 143.9195\n",
      "Epoch 486/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6355 - val_loss: 145.4477\n",
      "Epoch 487/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6043 - val_loss: 143.7019\n",
      "Epoch 488/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6049 - val_loss: 144.3815\n",
      "Epoch 489/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 78.6159 - val_loss: 142.0030\n",
      "Epoch 490/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 78.6100 - val_loss: 141.6787\n",
      "Epoch 491/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 78.6133 - val_loss: 141.8996\n",
      "Epoch 492/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 78.6221 - val_loss: 146.6782\n",
      "Epoch 493/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 78.6193 - val_loss: 139.9101\n",
      "Epoch 494/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 78.5987 - val_loss: 145.5615\n",
      "Epoch 495/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6376 - val_loss: 147.9477\n",
      "Epoch 496/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6295 - val_loss: 141.9264\n",
      "Epoch 497/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6715 - val_loss: 140.7346\n",
      "Epoch 498/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.5919 - val_loss: 144.5779\n",
      "Epoch 499/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6539 - val_loss: 147.0476\n",
      "Epoch 500/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6587 - val_loss: 148.3640\n",
      "Epoch 501/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6646 - val_loss: 145.4835\n",
      "Epoch 502/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6256 - val_loss: 140.0315\n",
      "Epoch 503/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6404 - val_loss: 139.4423\n",
      "Epoch 504/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 78.6312 - val_loss: 144.7055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 505/10000\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 78.6154 - val_loss: 144.8768\n",
      "Epoch 506/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 78.7032 - val_loss: 142.5558\n",
      "Epoch 507/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 78.7170 - val_loss: 146.2817\n",
      "Epoch 508/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6709 - val_loss: 141.0893\n",
      "Epoch 509/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6079 - val_loss: 143.2350\n",
      "Epoch 510/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6183 - val_loss: 140.3882\n",
      "Epoch 511/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7525 - val_loss: 152.1107\n",
      "Epoch 512/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6353 - val_loss: 149.7688\n",
      "Epoch 513/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6308 - val_loss: 142.4916\n",
      "Epoch 514/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 78.6190 - val_loss: 144.5234\n",
      "Epoch 515/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 78.6491 - val_loss: 143.8229\n",
      "Epoch 516/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6379 - val_loss: 142.4160\n",
      "Epoch 517/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6452 - val_loss: 132.5253\n",
      "Epoch 518/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6446 - val_loss: 149.0304\n",
      "Epoch 519/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6275 - val_loss: 142.4481\n",
      "Epoch 520/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6067 - val_loss: 139.4096\n",
      "Epoch 521/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6170 - val_loss: 139.8544\n",
      "Epoch 522/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6035 - val_loss: 135.6803\n",
      "Epoch 523/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6363 - val_loss: 140.9929\n",
      "Epoch 524/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6672 - val_loss: 138.1539\n",
      "Epoch 525/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6276 - val_loss: 138.5671\n",
      "Epoch 526/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6860 - val_loss: 146.7597\n",
      "Epoch 527/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6415 - val_loss: 140.3071\n",
      "Epoch 528/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6553 - val_loss: 143.9619\n",
      "Epoch 529/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6318 - val_loss: 145.1113\n",
      "Epoch 530/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6269 - val_loss: 138.4220\n",
      "Epoch 531/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6555 - val_loss: 145.0943\n",
      "Epoch 532/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6011 - val_loss: 142.2713\n",
      "Epoch 533/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6214 - val_loss: 144.6866\n",
      "Epoch 534/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6245 - val_loss: 143.8626\n",
      "Epoch 535/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6089 - val_loss: 140.6260\n",
      "Epoch 536/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6388 - val_loss: 139.6275\n",
      "Epoch 537/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6169 - val_loss: 138.3607\n",
      "Epoch 538/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6255 - val_loss: 134.9666\n",
      "Epoch 539/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6346 - val_loss: 141.6980\n",
      "Epoch 540/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6072 - val_loss: 140.7345\n",
      "Epoch 541/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6036 - val_loss: 140.4199\n",
      "Epoch 542/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.6003 - val_loss: 144.1821\n",
      "Epoch 543/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.5997 - val_loss: 144.3761\n",
      "Epoch 544/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.7727 - val_loss: 126.7083\n",
      "Epoch 545/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.8649 - val_loss: 143.4147\n",
      "Epoch 546/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.4995 - val_loss: 145.7365\n",
      "Epoch 547/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 78.4188 - val_loss: 139.3367\n",
      "Epoch 548/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 78.3624 - val_loss: 139.1270\n",
      "Epoch 549/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 18.8759 - val_loss: 88.9289\n",
      "Epoch 550/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 1.0813 - val_loss: 101.0154\n",
      "Epoch 551/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.8148 - val_loss: 93.8040\n",
      "Epoch 552/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.7064 - val_loss: 82.2110\n",
      "Epoch 553/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.6463 - val_loss: 93.9079\n",
      "Epoch 554/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.5640 - val_loss: 93.4430\n",
      "Epoch 555/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4806 - val_loss: 88.9986\n",
      "Epoch 556/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4612 - val_loss: 93.0461\n",
      "Epoch 557/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4648 - val_loss: 86.0367\n",
      "Epoch 558/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4889 - val_loss: 87.8981\n",
      "Epoch 559/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.5000 - val_loss: 85.0170\n",
      "Epoch 560/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4416 - val_loss: 88.3481\n",
      "Epoch 561/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3917 - val_loss: 88.6112\n",
      "Epoch 562/10000\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 0.3983 - val_loss: 80.2213\n",
      "Epoch 563/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3974 - val_loss: 86.0030\n",
      "Epoch 564/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4138 - val_loss: 80.8424\n",
      "Epoch 565/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4379 - val_loss: 91.0039\n",
      "Epoch 566/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4187 - val_loss: 77.1777\n",
      "Epoch 567/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3762 - val_loss: 76.5378\n",
      "Epoch 568/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3844 - val_loss: 76.4759\n",
      "Epoch 569/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.3936 - val_loss: 68.8797\n",
      "Epoch 570/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3761 - val_loss: 75.4208\n",
      "Epoch 571/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3552 - val_loss: 75.5780\n",
      "Epoch 572/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4065 - val_loss: 70.4171\n",
      "Epoch 573/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4339 - val_loss: 72.3611\n",
      "Epoch 574/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3600 - val_loss: 79.1615\n",
      "Epoch 575/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.3438 - val_loss: 69.7937\n",
      "Epoch 576/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3747 - val_loss: 78.5938\n",
      "Epoch 577/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3730 - val_loss: 71.7305\n",
      "Epoch 578/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3420 - val_loss: 74.1391\n",
      "Epoch 579/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4236 - val_loss: 66.5342\n",
      "Epoch 580/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.3497 - val_loss: 71.5832\n",
      "Epoch 581/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3349 - val_loss: 73.6886\n",
      "Epoch 582/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3347 - val_loss: 71.6920\n",
      "Epoch 583/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.3560 - val_loss: 68.5075\n",
      "Epoch 584/10000\n",
      "34280/34280 [==============================] - 0s 14us/sample - loss: 0.3506 - val_loss: 66.0650\n",
      "Epoch 585/10000\n",
      "34280/34280 [==============================] - 0s 12us/sample - loss: 0.3178 - val_loss: 66.4657\n",
      "Epoch 586/10000\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 0.3626 - val_loss: 57.5869\n",
      "Epoch 587/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.3648 - val_loss: 61.2303\n",
      "Epoch 588/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.3339 - val_loss: 59.9155\n",
      "Epoch 589/10000\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 0.3345 - val_loss: 53.4613\n",
      "Epoch 590/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.4074 - val_loss: 59.7506\n",
      "Epoch 591/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3383 - val_loss: 64.5943\n",
      "Epoch 592/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.3549 - val_loss: 55.9346\n",
      "Epoch 593/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3364 - val_loss: 58.4490\n",
      "Epoch 594/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.3308 - val_loss: 52.2554\n",
      "Epoch 595/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.3305 - val_loss: 59.3107\n",
      "Epoch 596/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2994 - val_loss: 59.9951\n",
      "Epoch 597/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2993 - val_loss: 61.2358\n",
      "Epoch 598/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.3035 - val_loss: 57.9960\n",
      "Epoch 599/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.3275 - val_loss: 56.1391\n",
      "Epoch 600/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.3250 - val_loss: 61.1549\n",
      "Epoch 601/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.3240 - val_loss: 61.2195\n",
      "Epoch 602/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.3034 - val_loss: 49.9575\n",
      "Epoch 603/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.3316 - val_loss: 62.9535\n",
      "Epoch 604/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.3449 - val_loss: 63.6635\n",
      "Epoch 605/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.3044 - val_loss: 54.0499\n",
      "Epoch 606/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2950 - val_loss: 59.1559\n",
      "Epoch 607/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2888 - val_loss: 65.3260\n",
      "Epoch 608/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3737 - val_loss: 51.0155\n",
      "Epoch 609/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3610 - val_loss: 59.5378\n",
      "Epoch 610/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.3470 - val_loss: 70.9778\n",
      "Epoch 611/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.3648 - val_loss: 54.8996\n",
      "Epoch 612/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3923 - val_loss: 54.5899\n",
      "Epoch 613/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.3420 - val_loss: 50.0727\n",
      "Epoch 614/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2881 - val_loss: 55.7449\n",
      "Epoch 615/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2954 - val_loss: 54.7118\n",
      "Epoch 616/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3570 - val_loss: 60.0832\n",
      "Epoch 617/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3291 - val_loss: 56.4469\n",
      "Epoch 618/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3462 - val_loss: 58.4003\n",
      "Epoch 619/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3475 - val_loss: 59.9983\n",
      "Epoch 620/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3435 - val_loss: 54.9448\n",
      "Epoch 621/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.3468 - val_loss: 55.2120\n",
      "Epoch 622/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.3150 - val_loss: 52.8841\n",
      "Epoch 623/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2961 - val_loss: 56.6168\n",
      "Epoch 624/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2935 - val_loss: 58.6424\n",
      "Epoch 625/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2810 - val_loss: 62.2975\n",
      "Epoch 626/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2916 - val_loss: 53.4047\n",
      "Epoch 627/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2919 - val_loss: 61.4873\n",
      "Epoch 628/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3305 - val_loss: 54.6453\n",
      "Epoch 629/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3273 - val_loss: 63.8787\n",
      "Epoch 630/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3426 - val_loss: 49.5703\n",
      "Epoch 631/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2769 - val_loss: 44.6485\n",
      "Epoch 632/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2823 - val_loss: 56.7828\n",
      "Epoch 633/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2671 - val_loss: 57.9332\n",
      "Epoch 634/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2901 - val_loss: 54.3344\n",
      "Epoch 635/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2626 - val_loss: 60.3873\n",
      "Epoch 636/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2809 - val_loss: 54.9700\n",
      "Epoch 637/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3028 - val_loss: 53.9438\n",
      "Epoch 638/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2743 - val_loss: 54.0637\n",
      "Epoch 639/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2956 - val_loss: 56.8187\n",
      "Epoch 640/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2690 - val_loss: 55.9367\n",
      "Epoch 641/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2915 - val_loss: 61.3984\n",
      "Epoch 642/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2881 - val_loss: 60.7159\n",
      "Epoch 643/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.3443 - val_loss: 54.4263\n",
      "Epoch 644/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.5138 - val_loss: 59.2688\n",
      "Epoch 645/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3097 - val_loss: 47.7276\n",
      "Epoch 646/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2820 - val_loss: 60.2826\n",
      "Epoch 647/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3030 - val_loss: 52.3718\n",
      "Epoch 648/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2738 - val_loss: 58.4456\n",
      "Epoch 649/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3031 - val_loss: 59.7395\n",
      "Epoch 650/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2915 - val_loss: 54.1667\n",
      "Epoch 651/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4395 - val_loss: 39.3786\n",
      "Epoch 652/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2899 - val_loss: 47.4643\n",
      "Epoch 653/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3533 - val_loss: 39.4022\n",
      "Epoch 654/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3039 - val_loss: 48.6870\n",
      "Epoch 655/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2781 - val_loss: 48.0692\n",
      "Epoch 656/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3271 - val_loss: 55.2149\n",
      "Epoch 657/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2740 - val_loss: 51.6007\n",
      "Epoch 658/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2857 - val_loss: 55.1245\n",
      "Epoch 659/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2649 - val_loss: 53.5365\n",
      "Epoch 660/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3614 - val_loss: 58.3087\n",
      "Epoch 661/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3309 - val_loss: 49.7239\n",
      "Epoch 662/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3789 - val_loss: 38.6194\n",
      "Epoch 663/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3481 - val_loss: 53.9792\n",
      "Epoch 664/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2882 - val_loss: 51.4627\n",
      "Epoch 665/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2702 - val_loss: 51.0634\n",
      "Epoch 666/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3343 - val_loss: 52.3355\n",
      "Epoch 667/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2749 - val_loss: 47.4245\n",
      "Epoch 668/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2673 - val_loss: 48.0328\n",
      "Epoch 669/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2630 - val_loss: 45.3856\n",
      "Epoch 670/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2752 - val_loss: 55.8258\n",
      "Epoch 671/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3147 - val_loss: 52.4298\n",
      "Epoch 672/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2805 - val_loss: 45.3816\n",
      "Epoch 673/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2639 - val_loss: 54.4613\n",
      "Epoch 674/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3026 - val_loss: 56.0496\n",
      "Epoch 675/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2847 - val_loss: 51.2315\n",
      "Epoch 676/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2984 - val_loss: 47.4458\n",
      "Epoch 677/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2751 - val_loss: 54.3956\n",
      "Epoch 678/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2701 - val_loss: 54.8467\n",
      "Epoch 679/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3035 - val_loss: 49.2958\n",
      "Epoch 680/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2727 - val_loss: 55.3843\n",
      "Epoch 681/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2973 - val_loss: 55.7403\n",
      "Epoch 682/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2801 - val_loss: 55.6098\n",
      "Epoch 683/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2955 - val_loss: 60.6561\n",
      "Epoch 684/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3355 - val_loss: 46.8421\n",
      "Epoch 685/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3032 - val_loss: 52.6559\n",
      "Epoch 686/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2519 - val_loss: 56.1105\n",
      "Epoch 687/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2425 - val_loss: 50.7745\n",
      "Epoch 688/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2740 - val_loss: 54.8635\n",
      "Epoch 689/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2670 - val_loss: 60.4298\n",
      "Epoch 690/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2777 - val_loss: 49.3049\n",
      "Epoch 691/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3350 - val_loss: 56.4839\n",
      "Epoch 692/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2796 - val_loss: 52.5460\n",
      "Epoch 693/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2789 - val_loss: 49.3590\n",
      "Epoch 694/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2859 - val_loss: 59.0638\n",
      "Epoch 695/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3029 - val_loss: 51.0835\n",
      "Epoch 696/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2985 - val_loss: 54.3001\n",
      "Epoch 697/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3005 - val_loss: 49.3555\n",
      "Epoch 698/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2755 - val_loss: 55.5147\n",
      "Epoch 699/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2463 - val_loss: 54.7863\n",
      "Epoch 700/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2598 - val_loss: 58.8920\n",
      "Epoch 701/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3255 - val_loss: 51.5284\n",
      "Epoch 702/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2657 - val_loss: 58.7679\n",
      "Epoch 703/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2516 - val_loss: 48.3109\n",
      "Epoch 704/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2710 - val_loss: 50.1468\n",
      "Epoch 705/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2759 - val_loss: 53.7134\n",
      "Epoch 706/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2977 - val_loss: 50.8310\n",
      "Epoch 707/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2725 - val_loss: 55.3575\n",
      "Epoch 708/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2523 - val_loss: 54.9401\n",
      "Epoch 709/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2581 - val_loss: 56.5770\n",
      "Epoch 710/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2645 - val_loss: 51.6850\n",
      "Epoch 711/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2511 - val_loss: 56.1153\n",
      "Epoch 712/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3112 - val_loss: 57.4022\n",
      "Epoch 713/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2770 - val_loss: 49.9517\n",
      "Epoch 714/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2624 - val_loss: 51.2248\n",
      "Epoch 715/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2906 - val_loss: 46.0870\n",
      "Epoch 716/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3524 - val_loss: 49.9450\n",
      "Epoch 717/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3055 - val_loss: 57.5498\n",
      "Epoch 718/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2857 - val_loss: 40.7995\n",
      "Epoch 719/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3005 - val_loss: 57.5679\n",
      "Epoch 720/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3043 - val_loss: 49.0069\n",
      "Epoch 721/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2594 - val_loss: 41.1442\n",
      "Epoch 722/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2692 - val_loss: 49.7789\n",
      "Epoch 723/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2651 - val_loss: 54.4961\n",
      "Epoch 724/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2975 - val_loss: 47.6913\n",
      "Epoch 725/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3098 - val_loss: 47.7875\n",
      "Epoch 726/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2669 - val_loss: 52.8854\n",
      "Epoch 727/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2677 - val_loss: 51.7519\n",
      "Epoch 728/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2951 - val_loss: 49.5598\n",
      "Epoch 729/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2816 - val_loss: 50.8904\n",
      "Epoch 730/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2527 - val_loss: 60.5095\n",
      "Epoch 731/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2681 - val_loss: 47.0002\n",
      "Epoch 732/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2928 - val_loss: 50.7573\n",
      "Epoch 733/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2596 - val_loss: 49.6550\n",
      "Epoch 734/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2546 - val_loss: 53.4950\n",
      "Epoch 735/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2570 - val_loss: 49.5909\n",
      "Epoch 736/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2708 - val_loss: 44.5506\n",
      "Epoch 737/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2885 - val_loss: 50.3329\n",
      "Epoch 738/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3305 - val_loss: 40.0681\n",
      "Epoch 739/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3018 - val_loss: 48.3397\n",
      "Epoch 740/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2526 - val_loss: 52.5634\n",
      "Epoch 741/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2521 - val_loss: 49.4411\n",
      "Epoch 742/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2412 - val_loss: 52.1776\n",
      "Epoch 743/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2640 - val_loss: 45.8157\n",
      "Epoch 744/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2626 - val_loss: 62.7896\n",
      "Epoch 745/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3004 - val_loss: 45.5357\n",
      "Epoch 746/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2893 - val_loss: 44.0942\n",
      "Epoch 747/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2997 - val_loss: 50.3686\n",
      "Epoch 748/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2881 - val_loss: 48.1687\n",
      "Epoch 749/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2455 - val_loss: 46.9238\n",
      "Epoch 750/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4160 - val_loss: 41.9400\n",
      "Epoch 751/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2863 - val_loss: 47.5094\n",
      "Epoch 752/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2495 - val_loss: 39.3402\n",
      "Epoch 753/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3131 - val_loss: 42.1451\n",
      "Epoch 754/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2769 - val_loss: 44.8468\n",
      "Epoch 755/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2774 - val_loss: 40.3674\n",
      "Epoch 756/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3320 - val_loss: 45.4037\n",
      "Epoch 757/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3856 - val_loss: 33.3386\n",
      "Epoch 758/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2629 - val_loss: 36.9460\n",
      "Epoch 759/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2711 - val_loss: 33.6659\n",
      "Epoch 760/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2596 - val_loss: 38.6688\n",
      "Epoch 761/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2450 - val_loss: 36.1044\n",
      "Epoch 762/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2629 - val_loss: 45.7502\n",
      "Epoch 763/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2918 - val_loss: 34.6237\n",
      "Epoch 764/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3106 - val_loss: 44.6171\n",
      "Epoch 765/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2849 - val_loss: 41.0412\n",
      "Epoch 766/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3776 - val_loss: 45.0597\n",
      "Epoch 767/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2901 - val_loss: 44.3703\n",
      "Epoch 768/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2730 - val_loss: 37.8125\n",
      "Epoch 769/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2401 - val_loss: 43.0960\n",
      "Epoch 770/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2673 - val_loss: 40.4621\n",
      "Epoch 771/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2703 - val_loss: 36.2647\n",
      "Epoch 772/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2989 - val_loss: 38.8045\n",
      "Epoch 773/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2681 - val_loss: 41.6447\n",
      "Epoch 774/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2616 - val_loss: 46.6150\n",
      "Epoch 775/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2844 - val_loss: 40.4256\n",
      "Epoch 776/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3502 - val_loss: 41.7971\n",
      "Epoch 777/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2745 - val_loss: 42.8947\n",
      "Epoch 778/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2631 - val_loss: 35.0660\n",
      "Epoch 779/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2420 - val_loss: 40.9149\n",
      "Epoch 780/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2925 - val_loss: 39.1259\n",
      "Epoch 781/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2682 - val_loss: 31.2979\n",
      "Epoch 782/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2549 - val_loss: 34.8119\n",
      "Epoch 783/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2515 - val_loss: 32.7134\n",
      "Epoch 784/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2832 - val_loss: 46.7539\n",
      "Epoch 785/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2589 - val_loss: 45.5145\n",
      "Epoch 786/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2642 - val_loss: 37.5181\n",
      "Epoch 787/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2626 - val_loss: 44.8622\n",
      "Epoch 788/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2636 - val_loss: 37.4803\n",
      "Epoch 789/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2575 - val_loss: 41.5802\n",
      "Epoch 790/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2575 - val_loss: 40.7178\n",
      "Epoch 791/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3530 - val_loss: 39.0682\n",
      "Epoch 792/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2593 - val_loss: 39.0153\n",
      "Epoch 793/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2532 - val_loss: 48.0194\n",
      "Epoch 794/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2593 - val_loss: 48.9135\n",
      "Epoch 795/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2452 - val_loss: 42.3462\n",
      "Epoch 796/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2831 - val_loss: 53.7131\n",
      "Epoch 797/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3184 - val_loss: 39.2992\n",
      "Epoch 798/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2989 - val_loss: 36.2420\n",
      "Epoch 799/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2770 - val_loss: 45.1890\n",
      "Epoch 800/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2656 - val_loss: 32.0975\n",
      "Epoch 801/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2869 - val_loss: 37.7596\n",
      "Epoch 802/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2637 - val_loss: 31.9215\n",
      "Epoch 803/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2813 - val_loss: 34.1823\n",
      "Epoch 804/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.3854 - val_loss: 18.7641\n",
      "Epoch 805/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3439 - val_loss: 35.6448\n",
      "Epoch 806/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2683 - val_loss: 36.3507\n",
      "Epoch 807/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2551 - val_loss: 34.5754\n",
      "Epoch 808/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2379 - val_loss: 32.1070\n",
      "Epoch 809/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2639 - val_loss: 41.8935\n",
      "Epoch 810/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2415 - val_loss: 41.1996\n",
      "Epoch 811/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2600 - val_loss: 35.2029\n",
      "Epoch 812/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3044 - val_loss: 38.4816\n",
      "Epoch 813/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2690 - val_loss: 41.2332\n",
      "Epoch 814/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2394 - val_loss: 36.1651\n",
      "Epoch 815/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3457 - val_loss: 27.4197\n",
      "Epoch 816/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3000 - val_loss: 32.9283\n",
      "Epoch 817/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2488 - val_loss: 35.3321\n",
      "Epoch 818/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2967 - val_loss: 35.0854\n",
      "Epoch 819/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2915 - val_loss: 34.2933\n",
      "Epoch 820/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2991 - val_loss: 42.8286\n",
      "Epoch 821/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2721 - val_loss: 34.9270\n",
      "Epoch 822/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2416 - val_loss: 30.4013\n",
      "Epoch 823/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2847 - val_loss: 35.0392\n",
      "Epoch 824/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2893 - val_loss: 29.2009\n",
      "Epoch 825/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2434 - val_loss: 32.2156\n",
      "Epoch 826/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2360 - val_loss: 36.2472\n",
      "Epoch 827/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2998 - val_loss: 27.5122\n",
      "Epoch 828/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2525 - val_loss: 31.0356\n",
      "Epoch 829/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2327 - val_loss: 31.3155\n",
      "Epoch 830/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2460 - val_loss: 32.4559\n",
      "Epoch 831/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2610 - val_loss: 30.0594\n",
      "Epoch 832/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2744 - val_loss: 32.2597\n",
      "Epoch 833/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3035 - val_loss: 25.7091\n",
      "Epoch 834/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3068 - val_loss: 19.0734\n",
      "Epoch 835/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2637 - val_loss: 33.4941\n",
      "Epoch 836/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2727 - val_loss: 30.5016\n",
      "Epoch 837/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2593 - val_loss: 20.7787\n",
      "Epoch 838/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2702 - val_loss: 28.4977\n",
      "Epoch 839/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2632 - val_loss: 28.6616\n",
      "Epoch 840/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2424 - val_loss: 31.2241\n",
      "Epoch 841/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2425 - val_loss: 29.7961\n",
      "Epoch 842/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3538 - val_loss: 17.4827\n",
      "Epoch 843/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2569 - val_loss: 24.6691\n",
      "Epoch 844/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2589 - val_loss: 30.8460\n",
      "Epoch 845/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2606 - val_loss: 26.5055\n",
      "Epoch 846/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2921 - val_loss: 24.0396\n",
      "Epoch 847/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2657 - val_loss: 25.7240\n",
      "Epoch 848/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2542 - val_loss: 18.3184\n",
      "Epoch 849/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2567 - val_loss: 25.1243\n",
      "Epoch 850/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2438 - val_loss: 29.6781\n",
      "Epoch 851/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2804 - val_loss: 28.3845\n",
      "Epoch 852/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2451 - val_loss: 28.6375\n",
      "Epoch 853/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2487 - val_loss: 22.0264\n",
      "Epoch 854/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3194 - val_loss: 25.4222\n",
      "Epoch 855/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2823 - val_loss: 24.6808\n",
      "Epoch 856/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2813 - val_loss: 32.1705\n",
      "Epoch 857/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2775 - val_loss: 30.0571\n",
      "Epoch 858/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2509 - val_loss: 30.9992\n",
      "Epoch 859/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2568 - val_loss: 25.8854\n",
      "Epoch 860/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2684 - val_loss: 26.7025\n",
      "Epoch 861/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2942 - val_loss: 21.3540\n",
      "Epoch 862/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2493 - val_loss: 25.6449\n",
      "Epoch 863/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3107 - val_loss: 24.5382\n",
      "Epoch 864/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2578 - val_loss: 26.6828\n",
      "Epoch 865/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2906 - val_loss: 11.4123\n",
      "Epoch 866/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2625 - val_loss: 24.7447\n",
      "Epoch 867/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2549 - val_loss: 30.0108\n",
      "Epoch 868/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2583 - val_loss: 22.5885\n",
      "Epoch 869/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2940 - val_loss: 21.6070\n",
      "Epoch 870/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2566 - val_loss: 27.1118\n",
      "Epoch 871/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2597 - val_loss: 29.6390\n",
      "Epoch 872/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3583 - val_loss: 24.0797\n",
      "Epoch 873/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2835 - val_loss: 21.4304\n",
      "Epoch 874/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2370 - val_loss: 25.3511\n",
      "Epoch 875/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2325 - val_loss: 26.8101\n",
      "Epoch 876/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2335 - val_loss: 21.1287\n",
      "Epoch 877/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.2672 - val_loss: 22.5937\n",
      "Epoch 878/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2517 - val_loss: 28.3628\n",
      "Epoch 879/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2921 - val_loss: 17.2533\n",
      "Epoch 880/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2874 - val_loss: 26.4361\n",
      "Epoch 881/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2885 - val_loss: 41.0158\n",
      "Epoch 882/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2930 - val_loss: 28.5816\n",
      "Epoch 883/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2584 - val_loss: 19.2519\n",
      "Epoch 884/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2745 - val_loss: 37.4276\n",
      "Epoch 885/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2455 - val_loss: 27.9543\n",
      "Epoch 886/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2437 - val_loss: 31.8284\n",
      "Epoch 887/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2416 - val_loss: 30.6199\n",
      "Epoch 888/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2268 - val_loss: 33.8080\n",
      "Epoch 889/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2627 - val_loss: 31.4558\n",
      "Epoch 890/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2798 - val_loss: 23.7178\n",
      "Epoch 891/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2453 - val_loss: 31.1104\n",
      "Epoch 892/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2996 - val_loss: 17.0010\n",
      "Epoch 893/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3144 - val_loss: 39.0072\n",
      "Epoch 894/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2414 - val_loss: 30.5556\n",
      "Epoch 895/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2572 - val_loss: 26.4063\n",
      "Epoch 896/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2689 - val_loss: 32.2307\n",
      "Epoch 897/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.3033 - val_loss: 27.7985\n",
      "Epoch 898/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2573 - val_loss: 40.8623\n",
      "Epoch 899/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3082 - val_loss: 26.9811\n",
      "Epoch 900/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2614 - val_loss: 29.4085\n",
      "Epoch 901/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2500 - val_loss: 28.8178\n",
      "Epoch 902/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3362 - val_loss: 28.2365\n",
      "Epoch 903/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2578 - val_loss: 26.1106\n",
      "Epoch 904/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2497 - val_loss: 30.5737\n",
      "Epoch 905/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2370 - val_loss: 29.1651\n",
      "Epoch 906/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2335 - val_loss: 31.2320\n",
      "Epoch 907/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2477 - val_loss: 29.9294\n",
      "Epoch 908/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2543 - val_loss: 24.9697\n",
      "Epoch 909/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3410 - val_loss: 30.0137\n",
      "Epoch 910/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2531 - val_loss: 31.9750\n",
      "Epoch 911/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2650 - val_loss: 33.3262\n",
      "Epoch 912/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2657 - val_loss: 30.8701\n",
      "Epoch 913/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2683 - val_loss: 25.5820\n",
      "Epoch 914/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2498 - val_loss: 30.3706\n",
      "Epoch 915/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2617 - val_loss: 19.0793\n",
      "Epoch 916/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2549 - val_loss: 29.1712\n",
      "Epoch 917/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2708 - val_loss: 30.2999\n",
      "Epoch 918/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2240 - val_loss: 27.8926\n",
      "Epoch 919/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2332 - val_loss: 24.6135\n",
      "Epoch 920/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2322 - val_loss: 18.2322\n",
      "Epoch 921/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2755 - val_loss: 25.4949\n",
      "Epoch 922/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2393 - val_loss: 25.9459\n",
      "Epoch 923/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2433 - val_loss: 35.7743\n",
      "Epoch 924/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2579 - val_loss: 28.3802\n",
      "Epoch 925/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2922 - val_loss: 17.3991\n",
      "Epoch 926/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2423 - val_loss: 27.9308\n",
      "Epoch 927/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2538 - val_loss: 24.6973\n",
      "Epoch 928/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2349 - val_loss: 28.6245\n",
      "Epoch 929/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2401 - val_loss: 26.6956\n",
      "Epoch 930/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2972 - val_loss: 14.8310\n",
      "Epoch 931/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2638 - val_loss: 30.9090\n",
      "Epoch 932/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2354 - val_loss: 30.1397\n",
      "Epoch 933/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2401 - val_loss: 25.3992\n",
      "Epoch 934/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2452 - val_loss: 29.3730\n",
      "Epoch 935/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2737 - val_loss: 30.2225\n",
      "Epoch 936/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3141 - val_loss: 25.0932\n",
      "Epoch 937/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2337 - val_loss: 27.5539\n",
      "Epoch 938/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2326 - val_loss: 19.3362\n",
      "Epoch 939/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2732 - val_loss: 24.4464\n",
      "Epoch 940/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2765 - val_loss: 20.4114\n",
      "Epoch 941/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2432 - val_loss: 24.2308\n",
      "Epoch 942/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3262 - val_loss: 20.4109\n",
      "Epoch 943/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2538 - val_loss: 31.2263\n",
      "Epoch 944/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2420 - val_loss: 25.8977\n",
      "Epoch 945/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2659 - val_loss: 29.6966\n",
      "Epoch 946/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2760 - val_loss: 38.3677\n",
      "Epoch 947/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2631 - val_loss: 26.2919\n",
      "Epoch 948/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2506 - val_loss: 27.8315\n",
      "Epoch 949/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2310 - val_loss: 29.9659\n",
      "Epoch 950/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3078 - val_loss: 33.3961\n",
      "Epoch 951/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2898 - val_loss: 25.4189\n",
      "Epoch 952/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3179 - val_loss: 28.9362\n",
      "Epoch 953/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2431 - val_loss: 29.9647\n",
      "Epoch 954/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2692 - val_loss: 35.9237\n",
      "Epoch 955/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2878 - val_loss: 30.0636\n",
      "Epoch 956/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2722 - val_loss: 27.5997\n",
      "Epoch 957/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3232 - val_loss: 37.7206\n",
      "Epoch 958/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2615 - val_loss: 27.9172\n",
      "Epoch 959/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2271 - val_loss: 28.4263\n",
      "Epoch 960/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2789 - val_loss: 33.5391\n",
      "Epoch 961/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2504 - val_loss: 30.9433\n",
      "Epoch 962/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2225 - val_loss: 30.9406\n",
      "Epoch 963/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2656 - val_loss: 32.9475\n",
      "Epoch 964/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2563 - val_loss: 24.9950\n",
      "Epoch 965/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2532 - val_loss: 25.9669\n",
      "Epoch 966/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2259 - val_loss: 28.8500\n",
      "Epoch 967/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2232 - val_loss: 29.0672\n",
      "Epoch 968/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2285 - val_loss: 31.7633\n",
      "Epoch 969/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2841 - val_loss: 20.6109\n",
      "Epoch 970/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2760 - val_loss: 26.2183\n",
      "Epoch 971/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2579 - val_loss: 21.2520\n",
      "Epoch 972/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2331 - val_loss: 34.5909\n",
      "Epoch 973/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3602 - val_loss: 21.5742\n",
      "Epoch 974/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2723 - val_loss: 26.6649\n",
      "Epoch 975/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2287 - val_loss: 25.8330\n",
      "Epoch 976/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2523 - val_loss: 29.3761\n",
      "Epoch 977/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2394 - val_loss: 21.6896\n",
      "Epoch 978/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3070 - val_loss: 26.9078\n",
      "Epoch 979/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2453 - val_loss: 29.4778\n",
      "Epoch 980/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2418 - val_loss: 26.5323\n",
      "Epoch 981/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2440 - val_loss: 26.5298\n",
      "Epoch 982/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2664 - val_loss: 25.4918\n",
      "Epoch 983/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3176 - val_loss: 35.7338\n",
      "Epoch 984/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3188 - val_loss: 25.1512\n",
      "Epoch 985/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2566 - val_loss: 29.4787\n",
      "Epoch 986/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2621 - val_loss: 29.3290\n",
      "Epoch 987/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2246 - val_loss: 34.2020\n",
      "Epoch 988/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2687 - val_loss: 28.6842\n",
      "Epoch 989/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2187 - val_loss: 30.2124\n",
      "Epoch 990/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2332 - val_loss: 32.0807\n",
      "Epoch 991/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2622 - val_loss: 37.7464\n",
      "Epoch 992/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2507 - val_loss: 43.1445\n",
      "Epoch 993/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2556 - val_loss: 33.5933\n",
      "Epoch 994/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2580 - val_loss: 34.1970\n",
      "Epoch 995/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2723 - val_loss: 15.5288\n",
      "Epoch 996/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2974 - val_loss: 24.7997\n",
      "Epoch 997/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2467 - val_loss: 35.5863\n",
      "Epoch 998/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2535 - val_loss: 33.8079\n",
      "Epoch 999/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3046 - val_loss: 25.3784\n",
      "Epoch 1000/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2616 - val_loss: 26.3479\n",
      "Epoch 1001/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2440 - val_loss: 25.6520\n",
      "Epoch 1002/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2387 - val_loss: 31.3758\n",
      "Epoch 1003/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3198 - val_loss: 25.9691\n",
      "Epoch 1004/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2396 - val_loss: 33.2495\n",
      "Epoch 1005/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2385 - val_loss: 27.4570\n",
      "Epoch 1006/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2818 - val_loss: 29.6143\n",
      "Epoch 1007/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2839 - val_loss: 24.9546\n",
      "Epoch 1008/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2363 - val_loss: 35.9654\n",
      "Epoch 1009/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2657 - val_loss: 39.2964\n",
      "Epoch 1010/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3973 - val_loss: 26.8057\n",
      "Epoch 1011/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2390 - val_loss: 30.5231\n",
      "Epoch 1012/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2183 - val_loss: 24.9389\n",
      "Epoch 1013/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2992 - val_loss: 22.1845\n",
      "Epoch 1014/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2459 - val_loss: 28.5448\n",
      "Epoch 1015/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2466 - val_loss: 25.8790\n",
      "Epoch 1016/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2260 - val_loss: 29.9348\n",
      "Epoch 1017/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2374 - val_loss: 28.3451\n",
      "Epoch 1018/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2221 - val_loss: 35.0908\n",
      "Epoch 1019/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2328 - val_loss: 29.6636\n",
      "Epoch 1020/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2632 - val_loss: 26.4744\n",
      "Epoch 1021/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2365 - val_loss: 30.2780\n",
      "Epoch 1022/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2402 - val_loss: 29.7546\n",
      "Epoch 1023/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2225 - val_loss: 29.6747\n",
      "Epoch 1024/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2241 - val_loss: 32.0826\n",
      "Epoch 1025/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2274 - val_loss: 33.1682\n",
      "Epoch 1026/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2326 - val_loss: 36.3673\n",
      "Epoch 1027/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2316 - val_loss: 31.9424\n",
      "Epoch 1028/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3254 - val_loss: 51.0289\n",
      "Epoch 1029/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3184 - val_loss: 27.5016\n",
      "Epoch 1030/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3473 - val_loss: 21.2465\n",
      "Epoch 1031/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2976 - val_loss: 18.0918\n",
      "Epoch 1032/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2413 - val_loss: 29.2048\n",
      "Epoch 1033/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2719 - val_loss: 19.9238\n",
      "Epoch 1034/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2740 - val_loss: 16.3069\n",
      "Epoch 1035/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3010 - val_loss: 20.1600\n",
      "Epoch 1036/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2672 - val_loss: 18.5143\n",
      "Epoch 1037/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2346 - val_loss: 26.0662\n",
      "Epoch 1038/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2539 - val_loss: 22.3690\n",
      "Epoch 1039/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2561 - val_loss: 19.7558\n",
      "Epoch 1040/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2298 - val_loss: 21.7359\n",
      "Epoch 1041/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2168 - val_loss: 20.8600\n",
      "Epoch 1042/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2886 - val_loss: 19.4329\n",
      "Epoch 1043/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2387 - val_loss: 30.0816\n",
      "Epoch 1044/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2400 - val_loss: 13.9598\n",
      "Epoch 1045/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3114 - val_loss: 19.2615\n",
      "Epoch 1046/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2401 - val_loss: 19.2421\n",
      "Epoch 1047/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2201 - val_loss: 21.6890\n",
      "Epoch 1048/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2253 - val_loss: 25.3189\n",
      "Epoch 1049/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2361 - val_loss: 30.5260\n",
      "Epoch 1050/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2172 - val_loss: 28.3868\n",
      "Epoch 1051/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2402 - val_loss: 25.1862\n",
      "Epoch 1052/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2389 - val_loss: 33.9607\n",
      "Epoch 1053/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2330 - val_loss: 26.7014\n",
      "Epoch 1054/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2305 - val_loss: 31.7724\n",
      "Epoch 1055/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3042 - val_loss: 21.0860\n",
      "Epoch 1056/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2803 - val_loss: 31.0173\n",
      "Epoch 1057/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2324 - val_loss: 31.2393\n",
      "Epoch 1058/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2729 - val_loss: 27.3421\n",
      "Epoch 1059/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2690 - val_loss: 40.4484\n",
      "Epoch 1060/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2793 - val_loss: 24.2223\n",
      "Epoch 1061/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2677 - val_loss: 38.9676\n",
      "Epoch 1062/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2707 - val_loss: 39.6714\n",
      "Epoch 1063/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2767 - val_loss: 43.8785\n",
      "Epoch 1064/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2442 - val_loss: 23.1211\n",
      "Epoch 1065/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2288 - val_loss: 33.9675\n",
      "Epoch 1066/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2220 - val_loss: 29.1888\n",
      "Epoch 1067/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2204 - val_loss: 33.2233\n",
      "Epoch 1068/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2688 - val_loss: 36.2467\n",
      "Epoch 1069/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2229 - val_loss: 29.9316\n",
      "Epoch 1070/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2151 - val_loss: 34.2461\n",
      "Epoch 1071/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2497 - val_loss: 10.8611\n",
      "Epoch 1072/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3181 - val_loss: 33.1961\n",
      "Epoch 1073/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2325 - val_loss: 23.8631\n",
      "Epoch 1074/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2721 - val_loss: 27.3785\n",
      "Epoch 1075/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2437 - val_loss: 32.5967\n",
      "Epoch 1076/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2522 - val_loss: 34.1129\n",
      "Epoch 1077/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2351 - val_loss: 27.0521\n",
      "Epoch 1078/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3690 - val_loss: 44.6304\n",
      "Epoch 1079/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2701 - val_loss: 25.8976\n",
      "Epoch 1080/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3171 - val_loss: 17.0601\n",
      "Epoch 1081/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2723 - val_loss: 27.7033\n",
      "Epoch 1082/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3048 - val_loss: 43.1950\n",
      "Epoch 1083/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2717 - val_loss: 25.0372\n",
      "Epoch 1084/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2293 - val_loss: 29.8154\n",
      "Epoch 1085/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.2559 - val_loss: 21.7155\n",
      "Epoch 1086/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2338 - val_loss: 25.2893\n",
      "Epoch 1087/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2712 - val_loss: 29.9831\n",
      "Epoch 1088/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2304 - val_loss: 21.8705\n",
      "Epoch 1089/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2373 - val_loss: 25.1711\n",
      "Epoch 1090/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2500 - val_loss: 32.9104\n",
      "Epoch 1091/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2712 - val_loss: 24.4158\n",
      "Epoch 1092/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2525 - val_loss: 23.0826\n",
      "Epoch 1093/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3063 - val_loss: 42.0942\n",
      "Epoch 1094/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2752 - val_loss: 14.2676\n",
      "Epoch 1095/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2443 - val_loss: 19.7284\n",
      "Epoch 1096/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2391 - val_loss: 25.5171\n",
      "Epoch 1097/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2263 - val_loss: 24.2630\n",
      "Epoch 1098/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2352 - val_loss: 26.0300\n",
      "Epoch 1099/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2126 - val_loss: 25.0340\n",
      "Epoch 1100/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2281 - val_loss: 21.3139\n",
      "Epoch 1101/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2335 - val_loss: 30.9198\n",
      "Epoch 1102/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2387 - val_loss: 22.5403\n",
      "Epoch 1103/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2594 - val_loss: 37.3663\n",
      "Epoch 1104/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2664 - val_loss: 30.1449\n",
      "Epoch 1105/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2228 - val_loss: 31.3627\n",
      "Epoch 1106/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2184 - val_loss: 29.7432\n",
      "Epoch 1107/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.2636 - val_loss: 29.8003\n",
      "Epoch 1108/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2214 - val_loss: 25.8032\n",
      "Epoch 1109/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2269 - val_loss: 38.2093\n",
      "Epoch 1110/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2150 - val_loss: 32.3841\n",
      "Epoch 1111/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2415 - val_loss: 28.7021\n",
      "Epoch 1112/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2231 - val_loss: 33.6290\n",
      "Epoch 1113/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2366 - val_loss: 19.3476\n",
      "Epoch 1114/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2734 - val_loss: 21.2703\n",
      "Epoch 1115/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2700 - val_loss: 23.3568\n",
      "Epoch 1116/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2664 - val_loss: 30.1525\n",
      "Epoch 1117/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2646 - val_loss: 21.8075\n",
      "Epoch 1118/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2409 - val_loss: 24.1299\n",
      "Epoch 1119/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2261 - val_loss: 30.7151\n",
      "Epoch 1120/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2488 - val_loss: 27.1479\n",
      "Epoch 1121/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2496 - val_loss: 21.5195\n",
      "Epoch 1122/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2192 - val_loss: 29.1324\n",
      "Epoch 1123/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2260 - val_loss: 27.9629\n",
      "Epoch 1124/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2911 - val_loss: 17.3923\n",
      "Epoch 1125/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2531 - val_loss: 17.9291\n",
      "Epoch 1126/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2352 - val_loss: 31.3259\n",
      "Epoch 1127/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2184 - val_loss: 26.6578\n",
      "Epoch 1128/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2219 - val_loss: 31.1469\n",
      "Epoch 1129/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2622 - val_loss: 39.5422\n",
      "Epoch 1130/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2510 - val_loss: 32.1318\n",
      "Epoch 1131/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2511 - val_loss: 27.5425\n",
      "Epoch 1132/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2389 - val_loss: 28.3504\n",
      "Epoch 1133/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2552 - val_loss: 35.5469\n",
      "Epoch 1134/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2745 - val_loss: 34.9281\n",
      "Epoch 1135/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2647 - val_loss: 37.0975\n",
      "Epoch 1136/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2380 - val_loss: 27.0668\n",
      "Epoch 1137/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2806 - val_loss: 30.4854\n",
      "Epoch 1138/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2803 - val_loss: 31.7383\n",
      "Epoch 1139/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3093 - val_loss: 35.6308\n",
      "Epoch 1140/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2270 - val_loss: 39.5206\n",
      "Epoch 1141/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2249 - val_loss: 42.8398\n",
      "Epoch 1142/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2459 - val_loss: 40.9785\n",
      "Epoch 1143/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2454 - val_loss: 33.3410\n",
      "Epoch 1144/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2252 - val_loss: 27.4455\n",
      "Epoch 1145/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2360 - val_loss: 40.3815\n",
      "Epoch 1146/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2184 - val_loss: 36.7326\n",
      "Epoch 1147/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2130 - val_loss: 42.2154\n",
      "Epoch 1148/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2180 - val_loss: 24.1048\n",
      "Epoch 1149/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.3325 - val_loss: 30.5395\n",
      "Epoch 1150/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2612 - val_loss: 40.5891\n",
      "Epoch 1151/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2295 - val_loss: 39.1518\n",
      "Epoch 1152/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3668 - val_loss: 43.0932\n",
      "Epoch 1153/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2931 - val_loss: 29.6088\n",
      "Epoch 1154/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2978 - val_loss: 32.7639\n",
      "Epoch 1155/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2697 - val_loss: 31.0420\n",
      "Epoch 1156/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2219 - val_loss: 29.9491\n",
      "Epoch 1157/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2136 - val_loss: 35.6599\n",
      "Epoch 1158/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2176 - val_loss: 26.6484\n",
      "Epoch 1159/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2217 - val_loss: 34.3972\n",
      "Epoch 1160/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2188 - val_loss: 32.3343\n",
      "Epoch 1161/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2437 - val_loss: 32.9843\n",
      "Epoch 1162/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3299 - val_loss: 44.7556\n",
      "Epoch 1163/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2604 - val_loss: 33.5628\n",
      "Epoch 1164/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3396 - val_loss: 35.9981\n",
      "Epoch 1165/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3093 - val_loss: 35.0046\n",
      "Epoch 1166/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2151 - val_loss: 33.8490\n",
      "Epoch 1167/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2062 - val_loss: 38.6448\n",
      "Epoch 1168/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2462 - val_loss: 36.7118\n",
      "Epoch 1169/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2327 - val_loss: 26.5764\n",
      "Epoch 1170/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2300 - val_loss: 38.4632\n",
      "Epoch 1171/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2113 - val_loss: 41.2915\n",
      "Epoch 1172/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2460 - val_loss: 38.9976\n",
      "Epoch 1173/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2537 - val_loss: 27.7012\n",
      "Epoch 1174/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2677 - val_loss: 27.5987\n",
      "Epoch 1175/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2215 - val_loss: 29.6617\n",
      "Epoch 1176/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2502 - val_loss: 36.0894\n",
      "Epoch 1177/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2382 - val_loss: 32.8026\n",
      "Epoch 1178/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2405 - val_loss: 33.7985\n",
      "Epoch 1179/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2643 - val_loss: 22.3240\n",
      "Epoch 1180/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2755 - val_loss: 23.1393\n",
      "Epoch 1181/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2297 - val_loss: 34.3689\n",
      "Epoch 1182/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2253 - val_loss: 38.2166\n",
      "Epoch 1183/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2418 - val_loss: 35.2394\n",
      "Epoch 1184/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3152 - val_loss: 49.9027\n",
      "Epoch 1185/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2842 - val_loss: 18.2865\n",
      "Epoch 1186/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2560 - val_loss: 29.1712\n",
      "Epoch 1187/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2234 - val_loss: 33.0917\n",
      "Epoch 1188/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2107 - val_loss: 28.5814\n",
      "Epoch 1189/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2153 - val_loss: 17.9339\n",
      "Epoch 1190/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3624 - val_loss: 26.4070\n",
      "Epoch 1191/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3559 - val_loss: 10.5091\n",
      "Epoch 1192/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2771 - val_loss: 29.9007\n",
      "Epoch 1193/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2433 - val_loss: 34.1415\n",
      "Epoch 1194/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2574 - val_loss: 37.2718\n",
      "Epoch 1195/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2547 - val_loss: 35.2808\n",
      "Epoch 1196/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2157 - val_loss: 30.5737\n",
      "Epoch 1197/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2489 - val_loss: 43.4261\n",
      "Epoch 1198/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2803 - val_loss: 40.6125\n",
      "Epoch 1199/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2393 - val_loss: 37.8277\n",
      "Epoch 1200/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2165 - val_loss: 36.9321\n",
      "Epoch 1201/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2318 - val_loss: 44.6157\n",
      "Epoch 1202/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2412 - val_loss: 35.1028\n",
      "Epoch 1203/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4473 - val_loss: 24.6652\n",
      "Epoch 1204/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3175 - val_loss: 33.9411\n",
      "Epoch 1205/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2200 - val_loss: 40.9866\n",
      "Epoch 1206/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2389 - val_loss: 33.8240\n",
      "Epoch 1207/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2085 - val_loss: 30.7791\n",
      "Epoch 1208/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2253 - val_loss: 40.8791\n",
      "Epoch 1209/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2204 - val_loss: 36.7201\n",
      "Epoch 1210/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2574 - val_loss: 30.6380\n",
      "Epoch 1211/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2365 - val_loss: 30.8425\n",
      "Epoch 1212/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2165 - val_loss: 35.6687\n",
      "Epoch 1213/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2095 - val_loss: 35.2177\n",
      "Epoch 1214/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2399 - val_loss: 37.4521\n",
      "Epoch 1215/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2522 - val_loss: 32.9969\n",
      "Epoch 1216/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2516 - val_loss: 22.9981\n",
      "Epoch 1217/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2352 - val_loss: 35.9778\n",
      "Epoch 1218/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3055 - val_loss: 37.3122\n",
      "Epoch 1219/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2208 - val_loss: 41.1613\n",
      "Epoch 1220/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2123 - val_loss: 38.0237\n",
      "Epoch 1221/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2343 - val_loss: 39.5933\n",
      "Epoch 1222/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2130 - val_loss: 40.2931\n",
      "Epoch 1223/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2128 - val_loss: 39.1426\n",
      "Epoch 1224/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2043 - val_loss: 44.9851\n",
      "Epoch 1225/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3063 - val_loss: 44.5337\n",
      "Epoch 1226/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2222 - val_loss: 46.2809\n",
      "Epoch 1227/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2041 - val_loss: 46.3261\n",
      "Epoch 1228/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2594 - val_loss: 37.8217\n",
      "Epoch 1229/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2909 - val_loss: 26.3774\n",
      "Epoch 1230/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2632 - val_loss: 50.0374\n",
      "Epoch 1231/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2438 - val_loss: 42.7035\n",
      "Epoch 1232/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2560 - val_loss: 42.2506\n",
      "Epoch 1233/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2289 - val_loss: 42.1688\n",
      "Epoch 1234/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2445 - val_loss: 49.3676\n",
      "Epoch 1235/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3154 - val_loss: 44.0720\n",
      "Epoch 1236/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4079 - val_loss: 37.2651\n",
      "Epoch 1237/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2395 - val_loss: 40.6433\n",
      "Epoch 1238/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2429 - val_loss: 36.4690\n",
      "Epoch 1239/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2606 - val_loss: 33.6905\n",
      "Epoch 1240/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2258 - val_loss: 40.9637\n",
      "Epoch 1241/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2372 - val_loss: 33.6188\n",
      "Epoch 1242/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2342 - val_loss: 40.7980\n",
      "Epoch 1243/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2235 - val_loss: 44.3354\n",
      "Epoch 1244/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2267 - val_loss: 45.8723\n",
      "Epoch 1245/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2229 - val_loss: 44.2525\n",
      "Epoch 1246/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2371 - val_loss: 46.4862\n",
      "Epoch 1247/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2498 - val_loss: 46.4138\n",
      "Epoch 1248/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2824 - val_loss: 38.5194\n",
      "Epoch 1249/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2463 - val_loss: 50.5370\n",
      "Epoch 1250/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2260 - val_loss: 40.2087\n",
      "Epoch 1251/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2956 - val_loss: 33.2004\n",
      "Epoch 1252/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2286 - val_loss: 39.4325\n",
      "Epoch 1253/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2526 - val_loss: 43.5329\n",
      "Epoch 1254/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2289 - val_loss: 46.3424\n",
      "Epoch 1255/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2318 - val_loss: 54.6339\n",
      "Epoch 1256/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2658 - val_loss: 54.3363\n",
      "Epoch 1257/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2424 - val_loss: 54.2100\n",
      "Epoch 1258/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2343 - val_loss: 55.6444\n",
      "Epoch 1259/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2246 - val_loss: 45.7961\n",
      "Epoch 1260/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2153 - val_loss: 44.3629\n",
      "Epoch 1261/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2387 - val_loss: 49.0577\n",
      "Epoch 1262/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2555 - val_loss: 49.0006\n",
      "Epoch 1263/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2366 - val_loss: 40.5747\n",
      "Epoch 1264/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2494 - val_loss: 41.1132\n",
      "Epoch 1265/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2924 - val_loss: 48.7341\n",
      "Epoch 1266/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2917 - val_loss: 52.3060\n",
      "Epoch 1267/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2418 - val_loss: 54.5140\n",
      "Epoch 1268/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2391 - val_loss: 50.7764\n",
      "Epoch 1269/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2502 - val_loss: 50.9939\n",
      "Epoch 1270/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2398 - val_loss: 45.5713\n",
      "Epoch 1271/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2730 - val_loss: 43.1980\n",
      "Epoch 1272/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2318 - val_loss: 43.4612\n",
      "Epoch 1273/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2644 - val_loss: 37.9751\n",
      "Epoch 1274/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2253 - val_loss: 46.7963\n",
      "Epoch 1275/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2309 - val_loss: 42.9599\n",
      "Epoch 1276/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2986 - val_loss: 53.4102\n",
      "Epoch 1277/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2837 - val_loss: 20.4314\n",
      "Epoch 1278/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2586 - val_loss: 51.8076\n",
      "Epoch 1279/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2232 - val_loss: 51.4650\n",
      "Epoch 1280/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2389 - val_loss: 44.2096\n",
      "Epoch 1281/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2206 - val_loss: 49.7111\n",
      "Epoch 1282/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2209 - val_loss: 46.5813\n",
      "Epoch 1283/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2303 - val_loss: 37.4650\n",
      "Epoch 1284/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2671 - val_loss: 33.1873\n",
      "Epoch 1285/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2353 - val_loss: 45.4138\n",
      "Epoch 1286/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2258 - val_loss: 40.9502\n",
      "Epoch 1287/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2084 - val_loss: 46.0230\n",
      "Epoch 1288/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2085 - val_loss: 51.8002\n",
      "Epoch 1289/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2293 - val_loss: 48.6715\n",
      "Epoch 1290/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2305 - val_loss: 47.9328\n",
      "Epoch 1291/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2147 - val_loss: 52.2895\n",
      "Epoch 1292/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2745 - val_loss: 45.7444\n",
      "Epoch 1293/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2495 - val_loss: 51.0899\n",
      "Epoch 1294/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2371 - val_loss: 46.2513\n",
      "Epoch 1295/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2170 - val_loss: 54.5812\n",
      "Epoch 1296/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2743 - val_loss: 51.9748\n",
      "Epoch 1297/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2465 - val_loss: 45.1814\n",
      "Epoch 1298/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2136 - val_loss: 49.0486\n",
      "Epoch 1299/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2060 - val_loss: 43.5428\n",
      "Epoch 1300/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2691 - val_loss: 47.3518\n",
      "Epoch 1301/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2604 - val_loss: 50.9931\n",
      "Epoch 1302/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2422 - val_loss: 40.5454\n",
      "Epoch 1303/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2576 - val_loss: 40.0122\n",
      "Epoch 1304/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2427 - val_loss: 49.6915\n",
      "Epoch 1305/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2177 - val_loss: 45.5843\n",
      "Epoch 1306/10000\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 0.2283 - val_loss: 34.3057\n",
      "Epoch 1307/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2718 - val_loss: 40.6102\n",
      "Epoch 1308/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2182 - val_loss: 52.8088\n",
      "Epoch 1309/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3001 - val_loss: 50.2156\n",
      "Epoch 1310/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2393 - val_loss: 44.2039\n",
      "Epoch 1311/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2212 - val_loss: 46.0832\n",
      "Epoch 1312/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2210 - val_loss: 43.9320\n",
      "Epoch 1313/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2097 - val_loss: 43.7079\n",
      "Epoch 1314/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2386 - val_loss: 40.8636\n",
      "Epoch 1315/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2403 - val_loss: 46.2403\n",
      "Epoch 1316/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2666 - val_loss: 42.0045\n",
      "Epoch 1317/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2202 - val_loss: 39.0000\n",
      "Epoch 1318/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2150 - val_loss: 40.6252\n",
      "Epoch 1319/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2074 - val_loss: 42.1105\n",
      "Epoch 1320/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2113 - val_loss: 44.0319\n",
      "Epoch 1321/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2815 - val_loss: 49.5899\n",
      "Epoch 1322/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.3982 - val_loss: 60.4069\n",
      "Epoch 1323/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.3126 - val_loss: 41.4025\n",
      "Epoch 1324/10000\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 0.2417 - val_loss: 44.5525\n",
      "Epoch 1325/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.2144 - val_loss: 39.9765\n",
      "Epoch 1326/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2258 - val_loss: 33.0268\n",
      "Epoch 1327/10000\n",
      "34280/34280 [==============================] - 0s 12us/sample - loss: 0.2474 - val_loss: 38.4157\n",
      "Epoch 1328/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2330 - val_loss: 32.6812\n",
      "Epoch 1329/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2245 - val_loss: 34.7577\n",
      "Epoch 1330/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2156 - val_loss: 34.8379\n",
      "Epoch 1331/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2227 - val_loss: 43.6613\n",
      "Epoch 1332/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2159 - val_loss: 37.6330\n",
      "Epoch 1333/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2107 - val_loss: 40.0246\n",
      "Epoch 1334/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3548 - val_loss: 21.8350\n",
      "Epoch 1335/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2353 - val_loss: 40.5594\n",
      "Epoch 1336/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2111 - val_loss: 44.6351\n",
      "Epoch 1337/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2656 - val_loss: 41.0346\n",
      "Epoch 1338/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2938 - val_loss: 44.6705\n",
      "Epoch 1339/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2858 - val_loss: 40.0596\n",
      "Epoch 1340/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2542 - val_loss: 51.3710\n",
      "Epoch 1341/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2182 - val_loss: 44.9499\n",
      "Epoch 1342/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2174 - val_loss: 41.0227\n",
      "Epoch 1343/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2168 - val_loss: 40.8092\n",
      "Epoch 1344/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2468 - val_loss: 35.6905\n",
      "Epoch 1345/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2329 - val_loss: 46.0291\n",
      "Epoch 1346/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2050 - val_loss: 44.9795\n",
      "Epoch 1347/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2063 - val_loss: 45.9352\n",
      "Epoch 1348/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2083 - val_loss: 40.2456\n",
      "Epoch 1349/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3285 - val_loss: 51.8452\n",
      "Epoch 1350/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2577 - val_loss: 50.6334\n",
      "Epoch 1351/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2191 - val_loss: 45.4533\n",
      "Epoch 1352/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2103 - val_loss: 48.1802\n",
      "Epoch 1353/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2689 - val_loss: 47.7273\n",
      "Epoch 1354/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2201 - val_loss: 41.4795\n",
      "Epoch 1355/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2181 - val_loss: 49.5806\n",
      "Epoch 1356/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2242 - val_loss: 39.2702\n",
      "Epoch 1357/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2711 - val_loss: 56.6402\n",
      "Epoch 1358/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3062 - val_loss: 20.0629\n",
      "Epoch 1359/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3074 - val_loss: 48.3038\n",
      "Epoch 1360/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2322 - val_loss: 40.7232\n",
      "Epoch 1361/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2286 - val_loss: 44.2346\n",
      "Epoch 1362/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2167 - val_loss: 36.1896\n",
      "Epoch 1363/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.3193 - val_loss: 26.8523\n",
      "Epoch 1364/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2556 - val_loss: 36.6223\n",
      "Epoch 1365/10000\n",
      "34280/34280 [==============================] - ETA: 0s - loss: 0.217 - 0s 9us/sample - loss: 0.2221 - val_loss: 35.9736\n",
      "Epoch 1366/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2199 - val_loss: 32.6329\n",
      "Epoch 1367/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2223 - val_loss: 22.6652\n",
      "Epoch 1368/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2634 - val_loss: 21.9715\n",
      "Epoch 1369/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2844 - val_loss: 33.9496\n",
      "Epoch 1370/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2282 - val_loss: 37.7234\n",
      "Epoch 1371/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2353 - val_loss: 29.7513\n",
      "Epoch 1372/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2536 - val_loss: 32.6344\n",
      "Epoch 1373/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2605 - val_loss: 33.7519\n",
      "Epoch 1374/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2478 - val_loss: 32.8452\n",
      "Epoch 1375/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2138 - val_loss: 28.7215\n",
      "Epoch 1376/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2154 - val_loss: 31.2428\n",
      "Epoch 1377/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2349 - val_loss: 25.7484\n",
      "Epoch 1378/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2423 - val_loss: 32.6252\n",
      "Epoch 1379/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2249 - val_loss: 26.9175\n",
      "Epoch 1380/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2597 - val_loss: 21.0551\n",
      "Epoch 1381/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2176 - val_loss: 31.8657\n",
      "Epoch 1382/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2475 - val_loss: 11.2396\n",
      "Epoch 1383/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2929 - val_loss: 36.1970\n",
      "Epoch 1384/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2670 - val_loss: 26.6754\n",
      "Epoch 1385/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2566 - val_loss: 24.4686\n",
      "Epoch 1386/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2853 - val_loss: 43.3565\n",
      "Epoch 1387/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2297 - val_loss: 37.4049\n",
      "Epoch 1388/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2146 - val_loss: 26.7121\n",
      "Epoch 1389/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2236 - val_loss: 33.7437\n",
      "Epoch 1390/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2175 - val_loss: 33.1064\n",
      "Epoch 1391/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2343 - val_loss: 29.7277\n",
      "Epoch 1392/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2517 - val_loss: 26.3566\n",
      "Epoch 1393/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2442 - val_loss: 27.5128\n",
      "Epoch 1394/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2147 - val_loss: 31.5941\n",
      "Epoch 1395/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2409 - val_loss: 31.7765\n",
      "Epoch 1396/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2919 - val_loss: 34.0917\n",
      "Epoch 1397/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2151 - val_loss: 42.6193\n",
      "Epoch 1398/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2057 - val_loss: 35.0228\n",
      "Epoch 1399/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2163 - val_loss: 40.9957\n",
      "Epoch 1400/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2427 - val_loss: 35.9827\n",
      "Epoch 1401/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2159 - val_loss: 40.6893\n",
      "Epoch 1402/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2368 - val_loss: 28.0094\n",
      "Epoch 1403/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2325 - val_loss: 32.6861\n",
      "Epoch 1404/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2321 - val_loss: 35.5740\n",
      "Epoch 1405/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2422 - val_loss: 38.6546\n",
      "Epoch 1406/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2531 - val_loss: 35.9050\n",
      "Epoch 1407/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2386 - val_loss: 38.7661\n",
      "Epoch 1408/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2603 - val_loss: 30.3709\n",
      "Epoch 1409/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2473 - val_loss: 32.6472\n",
      "Epoch 1410/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2262 - val_loss: 40.3216\n",
      "Epoch 1411/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2117 - val_loss: 38.5133\n",
      "Epoch 1412/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2129 - val_loss: 42.9405\n",
      "Epoch 1413/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2416 - val_loss: 52.6165\n",
      "Epoch 1414/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2154 - val_loss: 41.1932\n",
      "Epoch 1415/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2222 - val_loss: 44.0866\n",
      "Epoch 1416/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2375 - val_loss: 41.5165\n",
      "Epoch 1417/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2530 - val_loss: 48.6711\n",
      "Epoch 1418/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2112 - val_loss: 37.0111\n",
      "Epoch 1419/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2313 - val_loss: 46.5388\n",
      "Epoch 1420/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2030 - val_loss: 48.6015\n",
      "Epoch 1421/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2037 - val_loss: 42.9809\n",
      "Epoch 1422/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2489 - val_loss: 46.8455\n",
      "Epoch 1423/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2375 - val_loss: 30.9126\n",
      "Epoch 1424/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2450 - val_loss: 40.4197\n",
      "Epoch 1425/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2217 - val_loss: 49.8390\n",
      "Epoch 1426/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2055 - val_loss: 45.1958\n",
      "Epoch 1427/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2130 - val_loss: 50.4500\n",
      "Epoch 1428/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2111 - val_loss: 43.1901\n",
      "Epoch 1429/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2675 - val_loss: 36.7989\n",
      "Epoch 1430/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3094 - val_loss: 27.6122\n",
      "Epoch 1431/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3226 - val_loss: 45.6351\n",
      "Epoch 1432/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2161 - val_loss: 45.9435\n",
      "Epoch 1433/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2485 - val_loss: 39.5315\n",
      "Epoch 1434/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2445 - val_loss: 38.4994\n",
      "Epoch 1435/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2496 - val_loss: 41.6916\n",
      "Epoch 1436/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2123 - val_loss: 38.1169\n",
      "Epoch 1437/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2206 - val_loss: 35.1376\n",
      "Epoch 1438/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2810 - val_loss: 40.3761\n",
      "Epoch 1439/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2247 - val_loss: 36.1189\n",
      "Epoch 1440/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2903 - val_loss: 33.2531\n",
      "Epoch 1441/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2229 - val_loss: 43.1083\n",
      "Epoch 1442/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2105 - val_loss: 35.7180\n",
      "Epoch 1443/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2533 - val_loss: 56.5739\n",
      "Epoch 1444/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3620 - val_loss: 13.9895\n",
      "Epoch 1445/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2694 - val_loss: 31.1966\n",
      "Epoch 1446/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2145 - val_loss: 27.3949\n",
      "Epoch 1447/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2876 - val_loss: 38.0446\n",
      "Epoch 1448/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2434 - val_loss: 33.0732\n",
      "Epoch 1449/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2418 - val_loss: 47.6802\n",
      "Epoch 1450/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2118 - val_loss: 36.6240\n",
      "Epoch 1451/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2192 - val_loss: 38.3563\n",
      "Epoch 1452/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2855 - val_loss: 37.2893\n",
      "Epoch 1453/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2375 - val_loss: 42.1465\n",
      "Epoch 1454/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2320 - val_loss: 40.7548\n",
      "Epoch 1455/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2186 - val_loss: 35.5025\n",
      "Epoch 1456/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2276 - val_loss: 31.1103\n",
      "Epoch 1457/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2443 - val_loss: 43.7955\n",
      "Epoch 1458/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2084 - val_loss: 38.4568\n",
      "Epoch 1459/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2358 - val_loss: 28.9988\n",
      "Epoch 1460/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2767 - val_loss: 19.1041\n",
      "Epoch 1461/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2273 - val_loss: 37.9842\n",
      "Epoch 1462/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2602 - val_loss: 27.2502\n",
      "Epoch 1463/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2365 - val_loss: 34.3910\n",
      "Epoch 1464/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2073 - val_loss: 38.1218\n",
      "Epoch 1465/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2242 - val_loss: 41.3004\n",
      "Epoch 1466/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2118 - val_loss: 39.8561\n",
      "Epoch 1467/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2083 - val_loss: 36.7783\n",
      "Epoch 1468/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2253 - val_loss: 24.8036\n",
      "Epoch 1469/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2596 - val_loss: 47.0468\n",
      "Epoch 1470/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2393 - val_loss: 46.2904\n",
      "Epoch 1471/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2086 - val_loss: 40.4732\n",
      "Epoch 1472/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2125 - val_loss: 46.5225\n",
      "Epoch 1473/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3561 - val_loss: 47.5072\n",
      "Epoch 1474/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3142 - val_loss: 21.0135\n",
      "Epoch 1475/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2202 - val_loss: 18.6270\n",
      "Epoch 1476/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2183 - val_loss: 20.3036\n",
      "Epoch 1477/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2305 - val_loss: 27.2883\n",
      "Epoch 1478/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2093 - val_loss: 23.7850\n",
      "Epoch 1479/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2060 - val_loss: 18.4975\n",
      "Epoch 1480/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.2735 - val_loss: 24.1118\n",
      "Epoch 1481/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2186 - val_loss: 29.4860\n",
      "Epoch 1482/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2117 - val_loss: 23.8801\n",
      "Epoch 1483/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2054 - val_loss: 21.4832\n",
      "Epoch 1484/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2166 - val_loss: 35.2065\n",
      "Epoch 1485/10000\n",
      "34280/34280 [==============================] - ETA: 0s - loss: 0.223 - 0s 10us/sample - loss: 0.2244 - val_loss: 17.7851\n",
      "Epoch 1486/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2526 - val_loss: 11.8792\n",
      "Epoch 1487/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2999 - val_loss: 20.4233\n",
      "Epoch 1488/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2355 - val_loss: 32.7782\n",
      "Epoch 1489/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2134 - val_loss: 29.0873\n",
      "Epoch 1490/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2004 - val_loss: 34.2719\n",
      "Epoch 1491/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2528 - val_loss: 9.5932\n",
      "Epoch 1492/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2402 - val_loss: 23.8498\n",
      "Epoch 1493/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2150 - val_loss: 23.3084\n",
      "Epoch 1494/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2162 - val_loss: 41.6340\n",
      "Epoch 1495/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2180 - val_loss: 27.9421\n",
      "Epoch 1496/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2218 - val_loss: 34.4153\n",
      "Epoch 1497/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2359 - val_loss: 27.2524\n",
      "Epoch 1498/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2935 - val_loss: 45.8081\n",
      "Epoch 1499/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2349 - val_loss: 29.4999\n",
      "Epoch 1500/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2297 - val_loss: 11.8013\n",
      "Epoch 1501/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2461 - val_loss: 40.0810\n",
      "Epoch 1502/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2169 - val_loss: 34.9251\n",
      "Epoch 1503/10000\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 0.2278 - val_loss: 41.5687\n",
      "Epoch 1504/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2630 - val_loss: 34.4025\n",
      "Epoch 1505/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2522 - val_loss: 31.8836\n",
      "Epoch 1506/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2340 - val_loss: 20.0881\n",
      "Epoch 1507/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.3204 - val_loss: 48.7862\n",
      "Epoch 1508/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2631 - val_loss: 17.3009\n",
      "Epoch 1509/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2315 - val_loss: 27.7593\n",
      "Epoch 1510/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2156 - val_loss: 29.0021\n",
      "Epoch 1511/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2133 - val_loss: 27.1279\n",
      "Epoch 1512/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2336 - val_loss: 25.5641\n",
      "Epoch 1513/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2487 - val_loss: 22.2479\n",
      "Epoch 1514/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2114 - val_loss: 33.0569\n",
      "Epoch 1515/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2051 - val_loss: 36.4282\n",
      "Epoch 1516/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2142 - val_loss: 28.0963\n",
      "Epoch 1517/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2168 - val_loss: 23.7123\n",
      "Epoch 1518/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.2100 - val_loss: 19.2530\n",
      "Epoch 1519/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 12us/sample - loss: 0.2052 - val_loss: 26.9344\n",
      "Epoch 1520/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2129 - val_loss: 34.6848\n",
      "Epoch 1521/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2273 - val_loss: 33.4332\n",
      "Epoch 1522/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2083 - val_loss: 31.2684\n",
      "Epoch 1523/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2051 - val_loss: 24.0273\n",
      "Epoch 1524/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2650 - val_loss: 24.9238\n",
      "Epoch 1525/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2305 - val_loss: 47.9110\n",
      "Epoch 1526/10000\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 0.3762 - val_loss: 7.7137\n",
      "Epoch 1527/10000\n",
      "34280/34280 [==============================] - 0s 12us/sample - loss: 0.2668 - val_loss: 40.7227\n",
      "Epoch 1528/10000\n",
      "34280/34280 [==============================] - 0s 12us/sample - loss: 0.2430 - val_loss: 37.3334\n",
      "Epoch 1529/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.2111 - val_loss: 41.0402\n",
      "Epoch 1530/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2007 - val_loss: 33.0807\n",
      "Epoch 1531/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2142 - val_loss: 45.9761\n",
      "Epoch 1532/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2645 - val_loss: 34.3677\n",
      "Epoch 1533/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2247 - val_loss: 27.8457\n",
      "Epoch 1534/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2029 - val_loss: 35.5266\n",
      "Epoch 1535/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2086 - val_loss: 42.7412\n",
      "Epoch 1536/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2329 - val_loss: 38.3548\n",
      "Epoch 1537/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2358 - val_loss: 44.9438\n",
      "Epoch 1538/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1984 - val_loss: 39.9555\n",
      "Epoch 1539/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2151 - val_loss: 39.7474\n",
      "Epoch 1540/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2125 - val_loss: 39.8024\n",
      "Epoch 1541/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2754 - val_loss: 39.4833\n",
      "Epoch 1542/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2178 - val_loss: 30.2084\n",
      "Epoch 1543/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2689 - val_loss: 40.0599\n",
      "Epoch 1544/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2262 - val_loss: 39.3421\n",
      "Epoch 1545/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2303 - val_loss: 24.9539\n",
      "Epoch 1546/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2362 - val_loss: 32.1507\n",
      "Epoch 1547/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2571 - val_loss: 30.8333\n",
      "Epoch 1548/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2727 - val_loss: 20.3540\n",
      "Epoch 1549/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2620 - val_loss: 39.2846\n",
      "Epoch 1550/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2126 - val_loss: 51.6775\n",
      "Epoch 1551/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2609 - val_loss: 31.9348\n",
      "Epoch 1552/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2618 - val_loss: 28.1268\n",
      "Epoch 1553/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2137 - val_loss: 27.5664\n",
      "Epoch 1554/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2140 - val_loss: 25.4083\n",
      "Epoch 1555/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2052 - val_loss: 27.6728\n",
      "Epoch 1556/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2160 - val_loss: 25.6903\n",
      "Epoch 1557/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2031 - val_loss: 19.6988\n",
      "Epoch 1558/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2056 - val_loss: 18.1306\n",
      "Epoch 1559/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2121 - val_loss: 28.5418\n",
      "Epoch 1560/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2151 - val_loss: 31.3158\n",
      "Epoch 1561/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2412 - val_loss: 13.2535\n",
      "Epoch 1562/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2578 - val_loss: 37.0417\n",
      "Epoch 1563/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2362 - val_loss: 28.0473\n",
      "Epoch 1564/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2133 - val_loss: 29.5014\n",
      "Epoch 1565/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2068 - val_loss: 22.7368\n",
      "Epoch 1566/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2355 - val_loss: 28.0116\n",
      "Epoch 1567/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2369 - val_loss: 32.3993\n",
      "Epoch 1568/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2962 - val_loss: 19.1122\n",
      "Epoch 1569/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2232 - val_loss: 32.3430\n",
      "Epoch 1570/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2125 - val_loss: 29.2995\n",
      "Epoch 1571/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2366 - val_loss: 26.0852\n",
      "Epoch 1572/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2796 - val_loss: 4.5745\n",
      "Epoch 1573/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2769 - val_loss: 44.6004\n",
      "Epoch 1574/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2404 - val_loss: 16.8653\n",
      "Epoch 1575/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2329 - val_loss: 28.0412\n",
      "Epoch 1576/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2432 - val_loss: 34.6068\n",
      "Epoch 1577/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2958 - val_loss: 31.5401\n",
      "Epoch 1578/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2307 - val_loss: 29.9250\n",
      "Epoch 1579/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2336 - val_loss: 30.6729\n",
      "Epoch 1580/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2771 - val_loss: 33.9035\n",
      "Epoch 1581/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2319 - val_loss: 34.3621\n",
      "Epoch 1582/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2235 - val_loss: 31.8967\n",
      "Epoch 1583/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2597 - val_loss: 20.6290\n",
      "Epoch 1584/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2519 - val_loss: 36.9516\n",
      "Epoch 1585/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2443 - val_loss: 43.5132\n",
      "Epoch 1586/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2319 - val_loss: 27.9940\n",
      "Epoch 1587/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2184 - val_loss: 21.9648\n",
      "Epoch 1588/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2783 - val_loss: 19.0041\n",
      "Epoch 1589/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2330 - val_loss: 16.3652\n",
      "Epoch 1590/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2149 - val_loss: 15.0666\n",
      "Epoch 1591/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2073 - val_loss: 34.0796\n",
      "Epoch 1592/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2223 - val_loss: 43.4061\n",
      "Epoch 1593/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2454 - val_loss: 34.9712\n",
      "Epoch 1594/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2222 - val_loss: 45.8290\n",
      "Epoch 1595/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2238 - val_loss: 32.6746\n",
      "Epoch 1596/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2161 - val_loss: 36.0722\n",
      "Epoch 1597/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2696 - val_loss: 45.6112\n",
      "Epoch 1598/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2594 - val_loss: 44.2512\n",
      "Epoch 1599/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2137 - val_loss: 32.4546\n",
      "Epoch 1600/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2053 - val_loss: 24.0155\n",
      "Epoch 1601/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2597 - val_loss: 30.0600\n",
      "Epoch 1602/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2582 - val_loss: 45.7992\n",
      "Epoch 1603/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2131 - val_loss: 41.8750\n",
      "Epoch 1604/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2169 - val_loss: 35.3725\n",
      "Epoch 1605/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2047 - val_loss: 26.8793\n",
      "Epoch 1606/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2030 - val_loss: 40.9442\n",
      "Epoch 1607/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2022 - val_loss: 36.7672\n",
      "Epoch 1608/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2151 - val_loss: 27.8989\n",
      "Epoch 1609/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2244 - val_loss: 34.2281\n",
      "Epoch 1610/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2095 - val_loss: 33.8829\n",
      "Epoch 1611/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2159 - val_loss: 33.8346\n",
      "Epoch 1612/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2097 - val_loss: 43.2338\n",
      "Epoch 1613/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2092 - val_loss: 32.8418\n",
      "Epoch 1614/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2141 - val_loss: 32.0860\n",
      "Epoch 1615/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2325 - val_loss: 20.7153\n",
      "Epoch 1616/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2713 - val_loss: 7.3547\n",
      "Epoch 1617/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2789 - val_loss: 27.0756\n",
      "Epoch 1618/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2517 - val_loss: 24.1009\n",
      "Epoch 1619/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2942 - val_loss: 35.7141\n",
      "Epoch 1620/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2292 - val_loss: 46.8553\n",
      "Epoch 1621/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4080 - val_loss: 29.7394\n",
      "Epoch 1622/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2664 - val_loss: 25.3483\n",
      "Epoch 1623/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2172 - val_loss: 32.4966\n",
      "Epoch 1624/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2142 - val_loss: 23.7152\n",
      "Epoch 1625/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2929 - val_loss: 47.8703\n",
      "Epoch 1626/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2327 - val_loss: 29.3594\n",
      "Epoch 1627/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2094 - val_loss: 25.9462\n",
      "Epoch 1628/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2405 - val_loss: 32.4178\n",
      "Epoch 1629/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2066 - val_loss: 36.0416\n",
      "Epoch 1630/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3354 - val_loss: 38.1459\n",
      "Epoch 1631/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3235 - val_loss: 8.2638\n",
      "Epoch 1632/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2801 - val_loss: 44.1997\n",
      "Epoch 1633/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3307 - val_loss: 21.8475\n",
      "Epoch 1634/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2082 - val_loss: 20.5929\n",
      "Epoch 1635/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2094 - val_loss: 16.1980\n",
      "Epoch 1636/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2179 - val_loss: 19.0187\n",
      "Epoch 1637/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2052 - val_loss: 20.7053\n",
      "Epoch 1638/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2037 - val_loss: 23.1600\n",
      "Epoch 1639/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2081 - val_loss: 33.8665\n",
      "Epoch 1640/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2130 - val_loss: 21.0229\n",
      "Epoch 1641/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2035 - val_loss: 24.8224\n",
      "Epoch 1642/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2044 - val_loss: 18.4518\n",
      "Epoch 1643/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2075 - val_loss: 16.6558\n",
      "Epoch 1644/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2454 - val_loss: 32.3023\n",
      "Epoch 1645/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2587 - val_loss: 24.2810\n",
      "Epoch 1646/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2262 - val_loss: 24.9189\n",
      "Epoch 1647/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2059 - val_loss: 17.4709\n",
      "Epoch 1648/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2311 - val_loss: 17.2313\n",
      "Epoch 1649/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2214 - val_loss: 21.1459\n",
      "Epoch 1650/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2146 - val_loss: 19.4299\n",
      "Epoch 1651/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2262 - val_loss: 15.3378\n",
      "Epoch 1652/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2197 - val_loss: 22.9145\n",
      "Epoch 1653/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2322 - val_loss: 24.1826\n",
      "Epoch 1654/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2577 - val_loss: 13.8941\n",
      "Epoch 1655/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2008 - val_loss: 11.6298\n",
      "Epoch 1656/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2160 - val_loss: 26.2231\n",
      "Epoch 1657/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2321 - val_loss: 24.6794\n",
      "Epoch 1658/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2287 - val_loss: 15.5175\n",
      "Epoch 1659/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2071 - val_loss: 18.8771\n",
      "Epoch 1660/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2007 - val_loss: 20.4550\n",
      "Epoch 1661/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2220 - val_loss: 41.9032\n",
      "Epoch 1662/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2598 - val_loss: 34.3908\n",
      "Epoch 1663/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2611 - val_loss: 27.8047\n",
      "Epoch 1664/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2437 - val_loss: 30.1722\n",
      "Epoch 1665/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2145 - val_loss: 16.6424\n",
      "Epoch 1666/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2204 - val_loss: 18.1111\n",
      "Epoch 1667/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2559 - val_loss: 28.8937\n",
      "Epoch 1668/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2833 - val_loss: 40.7548\n",
      "Epoch 1669/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2333 - val_loss: 35.8911\n",
      "Epoch 1670/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2318 - val_loss: 33.5612\n",
      "Epoch 1671/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2339 - val_loss: 32.7364\n",
      "Epoch 1672/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2502 - val_loss: 23.8806\n",
      "Epoch 1673/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2436 - val_loss: 29.1377\n",
      "Epoch 1674/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2763 - val_loss: 14.0845\n",
      "Epoch 1675/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2353 - val_loss: 36.9666\n",
      "Epoch 1676/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2244 - val_loss: 26.5531\n",
      "Epoch 1677/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2373 - val_loss: 22.8084\n",
      "Epoch 1678/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2298 - val_loss: 19.9939\n",
      "Epoch 1679/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2436 - val_loss: 34.0861\n",
      "Epoch 1680/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2159 - val_loss: 21.9484\n",
      "Epoch 1681/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2287 - val_loss: 30.0977\n",
      "Epoch 1682/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1989 - val_loss: 27.8949\n",
      "Epoch 1683/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2035 - val_loss: 28.2868\n",
      "Epoch 1684/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2034 - val_loss: 21.0141\n",
      "Epoch 1685/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2914 - val_loss: 57.7635\n",
      "Epoch 1686/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2907 - val_loss: 31.0063\n",
      "Epoch 1687/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2541 - val_loss: 26.0776\n",
      "Epoch 1688/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2132 - val_loss: 13.6755\n",
      "Epoch 1689/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2218 - val_loss: 12.9679\n",
      "Epoch 1690/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2168 - val_loss: 22.7886\n",
      "Epoch 1691/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2017 - val_loss: 18.6553\n",
      "Epoch 1692/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2405 - val_loss: 17.2199\n",
      "Epoch 1693/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2180 - val_loss: 19.5586\n",
      "Epoch 1694/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2327 - val_loss: 16.0671\n",
      "Epoch 1695/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2140 - val_loss: 24.9855\n",
      "Epoch 1696/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2537 - val_loss: 17.9815\n",
      "Epoch 1697/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2384 - val_loss: 24.9649\n",
      "Epoch 1698/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2347 - val_loss: 14.6140\n",
      "Epoch 1699/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2575 - val_loss: 47.2024\n",
      "Epoch 1700/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2545 - val_loss: 23.9371\n",
      "Epoch 1701/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2543 - val_loss: 12.2674\n",
      "Epoch 1702/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3076 - val_loss: 17.6886\n",
      "Epoch 1703/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2279 - val_loss: 32.2552\n",
      "Epoch 1704/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2119 - val_loss: 20.3853\n",
      "Epoch 1705/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1988 - val_loss: 16.2176\n",
      "Epoch 1706/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2099 - val_loss: 18.9292\n",
      "Epoch 1707/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2019 - val_loss: 16.3199\n",
      "Epoch 1708/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2160 - val_loss: 21.7100\n",
      "Epoch 1709/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2373 - val_loss: 34.5499\n",
      "Epoch 1710/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2247 - val_loss: 25.2511\n",
      "Epoch 1711/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2195 - val_loss: 24.0952\n",
      "Epoch 1712/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2113 - val_loss: 13.1144\n",
      "Epoch 1713/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2362 - val_loss: 30.2706\n",
      "Epoch 1714/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2623 - val_loss: 15.8715\n",
      "Epoch 1715/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2388 - val_loss: 18.4781\n",
      "Epoch 1716/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2436 - val_loss: 28.5453\n",
      "Epoch 1717/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2330 - val_loss: 13.0717\n",
      "Epoch 1718/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2077 - val_loss: 13.9976\n",
      "Epoch 1719/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2106 - val_loss: 17.6824\n",
      "Epoch 1720/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2065 - val_loss: 17.6125\n",
      "Epoch 1721/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2020 - val_loss: 20.9487\n",
      "Epoch 1722/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2211 - val_loss: 9.6147\n",
      "Epoch 1723/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2037 - val_loss: 17.5924\n",
      "Epoch 1724/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1942 - val_loss: 19.2115\n",
      "Epoch 1725/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2075 - val_loss: 26.7933\n",
      "Epoch 1726/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2455 - val_loss: 21.5453\n",
      "Epoch 1727/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2339 - val_loss: 26.9221\n",
      "Epoch 1728/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2253 - val_loss: 7.0093\n",
      "Epoch 1729/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3421 - val_loss: 25.0219\n",
      "Epoch 1730/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3244 - val_loss: 11.2083\n",
      "Epoch 1731/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2117 - val_loss: 26.3361\n",
      "Epoch 1732/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2143 - val_loss: 10.9343\n",
      "Epoch 1733/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2521 - val_loss: 18.7423\n",
      "Epoch 1734/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2245 - val_loss: 23.6218\n",
      "Epoch 1735/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2070 - val_loss: 29.2871\n",
      "Epoch 1736/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2247 - val_loss: 32.9376\n",
      "Epoch 1737/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2125 - val_loss: 24.7589\n",
      "Epoch 1738/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2421 - val_loss: 9.6836\n",
      "Epoch 1739/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2084 - val_loss: 29.5617\n",
      "Epoch 1740/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.2516 - val_loss: 31.3689\n",
      "Epoch 1741/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2350 - val_loss: 30.8318\n",
      "Epoch 1742/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2233 - val_loss: 35.2760\n",
      "Epoch 1743/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2152 - val_loss: 24.2784\n",
      "Epoch 1744/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2055 - val_loss: 24.6685\n",
      "Epoch 1745/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2452 - val_loss: 30.9745\n",
      "Epoch 1746/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2369 - val_loss: 20.9823\n",
      "Epoch 1747/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2484 - val_loss: 21.6603\n",
      "Epoch 1748/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2190 - val_loss: 36.0324\n",
      "Epoch 1749/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2520 - val_loss: 6.6532\n",
      "Epoch 1750/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2225 - val_loss: 8.7861\n",
      "Epoch 1751/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2062 - val_loss: 14.3360\n",
      "Epoch 1752/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2181 - val_loss: 13.3598\n",
      "Epoch 1753/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2151 - val_loss: 7.2424\n",
      "Epoch 1754/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2054 - val_loss: 10.7889\n",
      "Epoch 1755/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2100 - val_loss: 24.9239\n",
      "Epoch 1756/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2152 - val_loss: 6.0992\n",
      "Epoch 1757/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2648 - val_loss: 21.8515\n",
      "Epoch 1758/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2551 - val_loss: 25.1245\n",
      "Epoch 1759/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2880 - val_loss: 22.8019\n",
      "Epoch 1760/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2534 - val_loss: 12.2313\n",
      "Epoch 1761/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2185 - val_loss: 12.3917\n",
      "Epoch 1762/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2148 - val_loss: 14.3280\n",
      "Epoch 1763/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2186 - val_loss: 25.2297\n",
      "Epoch 1764/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2777 - val_loss: 14.8261\n",
      "Epoch 1765/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2451 - val_loss: 27.4196\n",
      "Epoch 1766/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2733 - val_loss: 10.5651\n",
      "Epoch 1767/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2393 - val_loss: 7.2116\n",
      "Epoch 1768/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2153 - val_loss: 9.5260\n",
      "Epoch 1769/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2366 - val_loss: 10.4467\n",
      "Epoch 1770/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2477 - val_loss: 15.7464\n",
      "Epoch 1771/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2047 - val_loss: 16.5537\n",
      "Epoch 1772/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1994 - val_loss: 21.2002\n",
      "Epoch 1773/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2171 - val_loss: 24.8638\n",
      "Epoch 1774/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2590 - val_loss: 14.1961\n",
      "Epoch 1775/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2266 - val_loss: 17.4211\n",
      "Epoch 1776/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2235 - val_loss: 25.0160\n",
      "Epoch 1777/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2780 - val_loss: 23.0354\n",
      "Epoch 1778/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2641 - val_loss: 16.3768\n",
      "Epoch 1779/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2142 - val_loss: 13.3315\n",
      "Epoch 1780/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2004 - val_loss: 10.8673\n",
      "Epoch 1781/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2035 - val_loss: 11.4568\n",
      "Epoch 1782/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2185 - val_loss: 12.4145\n",
      "Epoch 1783/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2184 - val_loss: 7.0332\n",
      "Epoch 1784/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2356 - val_loss: 11.8638\n",
      "Epoch 1785/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2059 - val_loss: 13.2338\n",
      "Epoch 1786/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2586 - val_loss: 7.9333\n",
      "Epoch 1787/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2214 - val_loss: 14.0030\n",
      "Epoch 1788/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2229 - val_loss: 16.5010\n",
      "Epoch 1789/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2113 - val_loss: 12.8454\n",
      "Epoch 1790/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2270 - val_loss: 5.2771\n",
      "Epoch 1791/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2131 - val_loss: 22.2878\n",
      "Epoch 1792/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2031 - val_loss: 20.4364\n",
      "Epoch 1793/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2309 - val_loss: 11.6507\n",
      "Epoch 1794/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2335 - val_loss: 4.6804\n",
      "Epoch 1795/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2140 - val_loss: 19.4269\n",
      "Epoch 1796/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2149 - val_loss: 16.4371\n",
      "Epoch 1797/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2227 - val_loss: 18.6070\n",
      "Epoch 1798/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2362 - val_loss: 12.8536\n",
      "Epoch 1799/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2157 - val_loss: 10.8645\n",
      "Epoch 1800/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2293 - val_loss: 22.2764\n",
      "Epoch 1801/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2096 - val_loss: 23.9446\n",
      "Epoch 1802/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2159 - val_loss: 11.7251\n",
      "Epoch 1803/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2277 - val_loss: 11.2394\n",
      "Epoch 1804/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2161 - val_loss: 29.7643\n",
      "Epoch 1805/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2370 - val_loss: 8.0437\n",
      "Epoch 1806/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2169 - val_loss: 5.7778\n",
      "Epoch 1807/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2521 - val_loss: 7.3380\n",
      "Epoch 1808/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2526 - val_loss: 5.3580\n",
      "Epoch 1809/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2468 - val_loss: 8.4787\n",
      "Epoch 1810/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2412 - val_loss: 17.7403\n",
      "Epoch 1811/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2084 - val_loss: 7.0615\n",
      "Epoch 1812/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2104 - val_loss: 18.8249\n",
      "Epoch 1813/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2134 - val_loss: 20.9527\n",
      "Epoch 1814/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2171 - val_loss: 21.1050\n",
      "Epoch 1815/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2535 - val_loss: 4.9856\n",
      "Epoch 1816/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2059 - val_loss: 20.6672\n",
      "Epoch 1817/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2224 - val_loss: 13.6051\n",
      "Epoch 1818/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2317 - val_loss: 23.2538\n",
      "Epoch 1819/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2437 - val_loss: 10.0960\n",
      "Epoch 1820/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2575 - val_loss: 10.1565\n",
      "Epoch 1821/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2495 - val_loss: 4.7809\n",
      "Epoch 1822/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2693 - val_loss: 11.9969\n",
      "Epoch 1823/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2257 - val_loss: 14.9130\n",
      "Epoch 1824/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2283 - val_loss: 15.9615\n",
      "Epoch 1825/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2084 - val_loss: 37.0982\n",
      "Epoch 1826/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2202 - val_loss: 26.7860\n",
      "Epoch 1827/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2299 - val_loss: 29.8884\n",
      "Epoch 1828/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1993 - val_loss: 20.5010\n",
      "Epoch 1829/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2309 - val_loss: 27.2424\n",
      "Epoch 1830/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2279 - val_loss: 28.5265\n",
      "Epoch 1831/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2019 - val_loss: 14.0195\n",
      "Epoch 1832/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2180 - val_loss: 19.3054\n",
      "Epoch 1833/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2173 - val_loss: 18.8445\n",
      "Epoch 1834/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2011 - val_loss: 15.8055\n",
      "Epoch 1835/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2962 - val_loss: 2.8756\n",
      "Epoch 1836/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2675 - val_loss: 9.7155\n",
      "Epoch 1837/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2273 - val_loss: 9.7628\n",
      "Epoch 1838/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2632 - val_loss: 19.1026\n",
      "Epoch 1839/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2585 - val_loss: 11.3745\n",
      "Epoch 1840/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2529 - val_loss: 15.5365\n",
      "Epoch 1841/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2163 - val_loss: 12.4195\n",
      "Epoch 1842/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2126 - val_loss: 15.9314\n",
      "Epoch 1843/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2209 - val_loss: 15.7402\n",
      "Epoch 1844/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2263 - val_loss: 21.0341\n",
      "Epoch 1845/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1993 - val_loss: 29.0082\n",
      "Epoch 1846/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2095 - val_loss: 20.4347\n",
      "Epoch 1847/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2022 - val_loss: 15.9488\n",
      "Epoch 1848/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2682 - val_loss: 22.1631\n",
      "Epoch 1849/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2153 - val_loss: 17.3155\n",
      "Epoch 1850/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2077 - val_loss: 6.7587\n",
      "Epoch 1851/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2221 - val_loss: 4.4478\n",
      "Epoch 1852/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2346 - val_loss: 5.3053\n",
      "Epoch 1853/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2485 - val_loss: 6.7302\n",
      "Epoch 1854/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2093 - val_loss: 10.5640\n",
      "Epoch 1855/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2279 - val_loss: 10.8028\n",
      "Epoch 1856/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2462 - val_loss: 18.8399\n",
      "Epoch 1857/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2135 - val_loss: 13.4890\n",
      "Epoch 1858/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2397 - val_loss: 12.4716\n",
      "Epoch 1859/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2195 - val_loss: 15.8698\n",
      "Epoch 1860/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2097 - val_loss: 13.2952\n",
      "Epoch 1861/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2933 - val_loss: 4.0970\n",
      "Epoch 1862/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2232 - val_loss: 14.0979\n",
      "Epoch 1863/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3169 - val_loss: 20.8878\n",
      "Epoch 1864/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2416 - val_loss: 24.2460\n",
      "Epoch 1865/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2398 - val_loss: 12.0770\n",
      "Epoch 1866/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2231 - val_loss: 7.6935\n",
      "Epoch 1867/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2608 - val_loss: 6.4643\n",
      "Epoch 1868/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2124 - val_loss: 8.6891\n",
      "Epoch 1869/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2307 - val_loss: 10.3425\n",
      "Epoch 1870/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2149 - val_loss: 15.3843\n",
      "Epoch 1871/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2090 - val_loss: 9.1273\n",
      "Epoch 1872/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2113 - val_loss: 10.5723\n",
      "Epoch 1873/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1984 - val_loss: 9.6707\n",
      "Epoch 1874/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1966 - val_loss: 10.4111\n",
      "Epoch 1875/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2047 - val_loss: 11.6950\n",
      "Epoch 1876/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2061 - val_loss: 16.2912\n",
      "Epoch 1877/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2278 - val_loss: 17.3937\n",
      "Epoch 1878/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2340 - val_loss: 13.1877\n",
      "Epoch 1879/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1921 - val_loss: 12.5317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1880/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1958 - val_loss: 14.8594\n",
      "Epoch 1881/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1991 - val_loss: 16.9944\n",
      "Epoch 1882/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2140 - val_loss: 14.4216\n",
      "Epoch 1883/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2632 - val_loss: 6.7707\n",
      "Epoch 1884/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2384 - val_loss: 17.7140\n",
      "Epoch 1885/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2037 - val_loss: 15.6168\n",
      "Epoch 1886/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1990 - val_loss: 14.3687\n",
      "Epoch 1887/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2538 - val_loss: 10.9803\n",
      "Epoch 1888/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2231 - val_loss: 17.9996\n",
      "Epoch 1889/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1975 - val_loss: 18.1595\n",
      "Epoch 1890/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2796 - val_loss: 24.5270\n",
      "Epoch 1891/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2572 - val_loss: 20.1191\n",
      "Epoch 1892/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2518 - val_loss: 11.4945\n",
      "Epoch 1893/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2373 - val_loss: 7.0803\n",
      "Epoch 1894/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2372 - val_loss: 20.9479\n",
      "Epoch 1895/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2199 - val_loss: 12.4152\n",
      "Epoch 1896/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2045 - val_loss: 26.5324\n",
      "Epoch 1897/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2124 - val_loss: 13.7873\n",
      "Epoch 1898/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1944 - val_loss: 14.5523\n",
      "Epoch 1899/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2250 - val_loss: 13.9050\n",
      "Epoch 1900/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2007 - val_loss: 14.6553\n",
      "Epoch 1901/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2804 - val_loss: 38.0309\n",
      "Epoch 1902/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2828 - val_loss: 13.6642\n",
      "Epoch 1903/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2288 - val_loss: 20.7034\n",
      "Epoch 1904/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2151 - val_loss: 8.8002\n",
      "Epoch 1905/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2243 - val_loss: 6.5857\n",
      "Epoch 1906/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2030 - val_loss: 7.2711\n",
      "Epoch 1907/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2029 - val_loss: 6.7359\n",
      "Epoch 1908/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1970 - val_loss: 13.0554\n",
      "Epoch 1909/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2133 - val_loss: 7.1760\n",
      "Epoch 1910/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1985 - val_loss: 6.3810\n",
      "Epoch 1911/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2016 - val_loss: 13.1987\n",
      "Epoch 1912/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1999 - val_loss: 11.7513\n",
      "Epoch 1913/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2618 - val_loss: 3.0261\n",
      "Epoch 1914/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2794 - val_loss: 17.7813\n",
      "Epoch 1915/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2115 - val_loss: 11.1426\n",
      "Epoch 1916/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2114 - val_loss: 11.7885\n",
      "Epoch 1917/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2117 - val_loss: 9.8306\n",
      "Epoch 1918/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1991 - val_loss: 9.3373\n",
      "Epoch 1919/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3039 - val_loss: 7.1213\n",
      "Epoch 1920/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4247 - val_loss: 38.1382\n",
      "Epoch 1921/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2511 - val_loss: 26.9036\n",
      "Epoch 1922/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2437 - val_loss: 26.5182\n",
      "Epoch 1923/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3116 - val_loss: 31.4434\n",
      "Epoch 1924/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2576 - val_loss: 16.2080\n",
      "Epoch 1925/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2152 - val_loss: 7.4694\n",
      "Epoch 1926/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2019 - val_loss: 5.2025\n",
      "Epoch 1927/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2294 - val_loss: 3.0587\n",
      "Epoch 1928/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2361 - val_loss: 3.1698\n",
      "Epoch 1929/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1966 - val_loss: 3.1017\n",
      "Epoch 1930/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1965 - val_loss: 2.4395\n",
      "Epoch 1931/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1937 - val_loss: 2.7223\n",
      "Epoch 1932/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2075 - val_loss: 3.4137\n",
      "Epoch 1933/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2135 - val_loss: 4.9887\n",
      "Epoch 1934/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2068 - val_loss: 2.4063\n",
      "Epoch 1935/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2125 - val_loss: 4.6124\n",
      "Epoch 1936/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3167 - val_loss: 2.3762\n",
      "Epoch 1937/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2793 - val_loss: 3.1363\n",
      "Epoch 1938/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2645 - val_loss: 3.7723\n",
      "Epoch 1939/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2067 - val_loss: 4.6180\n",
      "Epoch 1940/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2151 - val_loss: 2.1976\n",
      "Epoch 1941/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2736 - val_loss: 2.4450\n",
      "Epoch 1942/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2073 - val_loss: 2.7653\n",
      "Epoch 1943/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2262 - val_loss: 2.1947\n",
      "Epoch 1944/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2397 - val_loss: 2.8792\n",
      "Epoch 1945/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2305 - val_loss: 2.1768\n",
      "Epoch 1946/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2429 - val_loss: 2.7874\n",
      "Epoch 1947/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2210 - val_loss: 2.0549\n",
      "Epoch 1948/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1968 - val_loss: 2.6109\n",
      "Epoch 1949/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2026 - val_loss: 2.1563\n",
      "Epoch 1950/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2008 - val_loss: 2.4648\n",
      "Epoch 1951/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2096 - val_loss: 3.3274\n",
      "Epoch 1952/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2087 - val_loss: 3.1844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1953/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1959 - val_loss: 2.9777\n",
      "Epoch 1954/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2260 - val_loss: 2.3282\n",
      "Epoch 1955/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2089 - val_loss: 2.2999\n",
      "Epoch 1956/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2104 - val_loss: 4.0157\n",
      "Epoch 1957/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1950 - val_loss: 3.7029\n",
      "Epoch 1958/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2111 - val_loss: 2.4507\n",
      "Epoch 1959/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2302 - val_loss: 2.8241\n",
      "Epoch 1960/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2012 - val_loss: 5.1247\n",
      "Epoch 1961/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1980 - val_loss: 4.3154\n",
      "Epoch 1962/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1993 - val_loss: 6.4299\n",
      "Epoch 1963/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2094 - val_loss: 2.4087\n",
      "Epoch 1964/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2812 - val_loss: 2.1758\n",
      "Epoch 1965/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2120 - val_loss: 4.9613\n",
      "Epoch 1966/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2320 - val_loss: 2.4178\n",
      "Epoch 1967/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3532 - val_loss: 19.7678\n",
      "Epoch 1968/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4052 - val_loss: 4.4383\n",
      "Epoch 1969/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2762 - val_loss: 1.9695\n",
      "Epoch 1970/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2011 - val_loss: 2.0697\n",
      "Epoch 1971/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2023 - val_loss: 2.0048\n",
      "Epoch 1972/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1953 - val_loss: 3.2502\n",
      "Epoch 1973/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2031 - val_loss: 2.6501\n",
      "Epoch 1974/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1964 - val_loss: 2.3931\n",
      "Epoch 1975/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2540 - val_loss: 2.0625\n",
      "Epoch 1976/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2046 - val_loss: 4.1598\n",
      "Epoch 1977/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1977 - val_loss: 2.3391\n",
      "Epoch 1978/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2043 - val_loss: 3.2282\n",
      "Epoch 1979/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1939 - val_loss: 2.1772\n",
      "Epoch 1980/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2286 - val_loss: 3.0141\n",
      "Epoch 1981/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2072 - val_loss: 9.5595\n",
      "Epoch 1982/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2092 - val_loss: 3.8544\n",
      "Epoch 1983/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1983 - val_loss: 2.1501\n",
      "Epoch 1984/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2013 - val_loss: 2.7692\n",
      "Epoch 1985/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2667 - val_loss: 5.3366\n",
      "Epoch 1986/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2191 - val_loss: 3.0846\n",
      "Epoch 1987/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2309 - val_loss: 2.2373\n",
      "Epoch 1988/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2137 - val_loss: 4.8027\n",
      "Epoch 1989/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2543 - val_loss: 2.3563\n",
      "Epoch 1990/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2069 - val_loss: 2.9847\n",
      "Epoch 1991/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2168 - val_loss: 2.7358\n",
      "Epoch 1992/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2192 - val_loss: 2.9031\n",
      "Epoch 1993/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2128 - val_loss: 3.6338\n",
      "Epoch 1994/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1976 - val_loss: 3.0807\n",
      "Epoch 1995/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1941 - val_loss: 4.1358\n",
      "Epoch 1996/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1915 - val_loss: 2.7604\n",
      "Epoch 1997/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1976 - val_loss: 3.9580\n",
      "Epoch 1998/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1992 - val_loss: 2.4309\n",
      "Epoch 1999/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1975 - val_loss: 2.9340\n",
      "Epoch 2000/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2121 - val_loss: 3.4497\n",
      "Epoch 2001/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1975 - val_loss: 3.3140\n",
      "Epoch 2002/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3022 - val_loss: 12.0939\n",
      "Epoch 2003/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3312 - val_loss: 30.9084\n",
      "Epoch 2004/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2724 - val_loss: 2.8637\n",
      "Epoch 2005/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2239 - val_loss: 3.4851\n",
      "Epoch 2006/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2515 - val_loss: 15.2636\n",
      "Epoch 2007/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2005 - val_loss: 2.5388\n",
      "Epoch 2008/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2137 - val_loss: 3.0502\n",
      "Epoch 2009/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2234 - val_loss: 9.4895\n",
      "Epoch 2010/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2170 - val_loss: 2.8780\n",
      "Epoch 2011/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1928 - val_loss: 3.1403\n",
      "Epoch 2012/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1898 - val_loss: 3.0589\n",
      "Epoch 2013/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1926 - val_loss: 2.7224\n",
      "Epoch 2014/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1926 - val_loss: 2.3267\n",
      "Epoch 2015/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1945 - val_loss: 2.1647\n",
      "Epoch 2016/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2090 - val_loss: 2.3925\n",
      "Epoch 2017/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2259 - val_loss: 2.3939\n",
      "Epoch 2018/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2147 - val_loss: 3.4742\n",
      "Epoch 2019/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2601 - val_loss: 4.2126\n",
      "Epoch 2020/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2373 - val_loss: 8.2653\n",
      "Epoch 2021/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2307 - val_loss: 3.1337\n",
      "Epoch 2022/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2102 - val_loss: 3.5834\n",
      "Epoch 2023/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2186 - val_loss: 2.0566\n",
      "Epoch 2024/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1982 - val_loss: 2.1018\n",
      "Epoch 2025/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2057 - val_loss: 2.2248\n",
      "Epoch 2026/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1966 - val_loss: 2.0892\n",
      "Epoch 2027/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1970 - val_loss: 2.0212\n",
      "Epoch 2028/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2493 - val_loss: 1.8936\n",
      "Epoch 2029/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2029 - val_loss: 2.0905\n",
      "Epoch 2030/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2074 - val_loss: 2.4174\n",
      "Epoch 2031/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1994 - val_loss: 2.3574\n",
      "Epoch 2032/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1981 - val_loss: 1.9546\n",
      "Epoch 2033/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1918 - val_loss: 2.3756\n",
      "Epoch 2034/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1929 - val_loss: 2.4702\n",
      "Epoch 2035/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2085 - val_loss: 2.6058\n",
      "Epoch 2036/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1976 - val_loss: 3.3084\n",
      "Epoch 2037/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1924 - val_loss: 2.4529\n",
      "Epoch 2038/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1938 - val_loss: 2.4264\n",
      "Epoch 2039/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1920 - val_loss: 2.2128\n",
      "Epoch 2040/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2133 - val_loss: 1.9861\n",
      "Epoch 2041/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2061 - val_loss: 1.9941\n",
      "Epoch 2042/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2006 - val_loss: 3.0800\n",
      "Epoch 2043/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2007 - val_loss: 1.9475\n",
      "Epoch 2044/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2007 - val_loss: 4.2469\n",
      "Epoch 2045/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2092 - val_loss: 2.5902\n",
      "Epoch 2046/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2275 - val_loss: 2.6746\n",
      "Epoch 2047/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3741 - val_loss: 11.0010\n",
      "Epoch 2048/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2297 - val_loss: 8.7925\n",
      "Epoch 2049/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2005 - val_loss: 10.7912\n",
      "Epoch 2050/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2141 - val_loss: 3.3089\n",
      "Epoch 2051/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2130 - val_loss: 2.5656\n",
      "Epoch 2052/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2166 - val_loss: 2.3402\n",
      "Epoch 2053/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1979 - val_loss: 2.3561\n",
      "Epoch 2054/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1973 - val_loss: 3.1724\n",
      "Epoch 2055/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1926 - val_loss: 3.4043\n",
      "Epoch 2056/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1916 - val_loss: 3.0082\n",
      "Epoch 2057/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2178 - val_loss: 3.3497\n",
      "Epoch 2058/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2141 - val_loss: 2.7783\n",
      "Epoch 2059/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2317 - val_loss: 2.7500\n",
      "Epoch 2060/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2327 - val_loss: 2.1087\n",
      "Epoch 2061/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2290 - val_loss: 2.3573\n",
      "Epoch 2062/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2169 - val_loss: 2.6985\n",
      "Epoch 2063/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3180 - val_loss: 3.7564\n",
      "Epoch 2064/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2765 - val_loss: 4.7993\n",
      "Epoch 2065/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2131 - val_loss: 6.7990\n",
      "Epoch 2066/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2051 - val_loss: 2.5303\n",
      "Epoch 2067/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2449 - val_loss: 2.0562\n",
      "Epoch 2068/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2653 - val_loss: 5.5853\n",
      "Epoch 2069/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2663 - val_loss: 1.9550\n",
      "Epoch 2070/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2059 - val_loss: 2.2997\n",
      "Epoch 2071/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2050 - val_loss: 2.2342\n",
      "Epoch 2072/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2255 - val_loss: 2.4068\n",
      "Epoch 2073/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2293 - val_loss: 2.2559\n",
      "Epoch 2074/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2181 - val_loss: 1.9797\n",
      "Epoch 2075/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2250 - val_loss: 2.0584\n",
      "Epoch 2076/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2660 - val_loss: 15.9326\n",
      "Epoch 2077/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2592 - val_loss: 3.6113\n",
      "Epoch 2078/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2154 - val_loss: 2.1655\n",
      "Epoch 2079/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1955 - val_loss: 2.1169\n",
      "Epoch 2080/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1914 - val_loss: 2.1282\n",
      "Epoch 2081/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1911 - val_loss: 2.1636\n",
      "Epoch 2082/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1872 - val_loss: 5.3612\n",
      "Epoch 2083/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2025 - val_loss: 2.0726\n",
      "Epoch 2084/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2745 - val_loss: 12.9467\n",
      "Epoch 2085/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3515 - val_loss: 2.1155\n",
      "Epoch 2086/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2399 - val_loss: 1.8828\n",
      "Epoch 2087/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2242 - val_loss: 1.9306\n",
      "Epoch 2088/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2249 - val_loss: 2.2387\n",
      "Epoch 2089/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2164 - val_loss: 2.2272\n",
      "Epoch 2090/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1952 - val_loss: 2.1876\n",
      "Epoch 2091/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1985 - val_loss: 2.1636\n",
      "Epoch 2092/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1941 - val_loss: 2.1831\n",
      "Epoch 2093/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.2100 - val_loss: 2.5680\n",
      "Epoch 2094/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2284 - val_loss: 2.4679\n",
      "Epoch 2095/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2134 - val_loss: 2.7406\n",
      "Epoch 2096/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2089 - val_loss: 2.1666\n",
      "Epoch 2097/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1944 - val_loss: 2.0609\n",
      "Epoch 2098/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2233 - val_loss: 2.0980\n",
      "Epoch 2099/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2434 - val_loss: 1.7575\n",
      "Epoch 2100/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2423 - val_loss: 2.0695\n",
      "Epoch 2101/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1959 - val_loss: 2.4627\n",
      "Epoch 2102/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1888 - val_loss: 2.5727\n",
      "Epoch 2103/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1899 - val_loss: 2.2146\n",
      "Epoch 2104/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2070 - val_loss: 2.1076\n",
      "Epoch 2105/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2081 - val_loss: 2.6108\n",
      "Epoch 2106/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2048 - val_loss: 2.1366\n",
      "Epoch 2107/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1903 - val_loss: 2.0113\n",
      "Epoch 2108/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2062 - val_loss: 2.0180\n",
      "Epoch 2109/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1911 - val_loss: 2.1499\n",
      "Epoch 2110/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1995 - val_loss: 2.3617\n",
      "Epoch 2111/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2605 - val_loss: 1.9437\n",
      "Epoch 2112/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1990 - val_loss: 1.9645\n",
      "Epoch 2113/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2064 - val_loss: 1.8983\n",
      "Epoch 2114/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2116 - val_loss: 1.9814\n",
      "Epoch 2115/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2133 - val_loss: 1.7881\n",
      "Epoch 2116/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1972 - val_loss: 1.9132\n",
      "Epoch 2117/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1924 - val_loss: 1.9654\n",
      "Epoch 2118/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1999 - val_loss: 2.0281\n",
      "Epoch 2119/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2124 - val_loss: 2.1238\n",
      "Epoch 2120/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3582 - val_loss: 2.3212\n",
      "Epoch 2121/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3194 - val_loss: 1.9010\n",
      "Epoch 2122/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2147 - val_loss: 2.2147\n",
      "Epoch 2123/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2028 - val_loss: 2.7378\n",
      "Epoch 2124/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1909 - val_loss: 2.2113\n",
      "Epoch 2125/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1932 - val_loss: 1.9301\n",
      "Epoch 2126/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2337 - val_loss: 6.1744\n",
      "Epoch 2127/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2593 - val_loss: 2.0196\n",
      "Epoch 2128/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2202 - val_loss: 1.8822\n",
      "Epoch 2129/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2287 - val_loss: 1.8603\n",
      "Epoch 2130/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2140 - val_loss: 2.0326\n",
      "Epoch 2131/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2223 - val_loss: 1.8760\n",
      "Epoch 2132/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2063 - val_loss: 1.9889\n",
      "Epoch 2133/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2065 - val_loss: 1.9484\n",
      "Epoch 2134/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2129 - val_loss: 1.8484\n",
      "Epoch 2135/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2121 - val_loss: 1.9296\n",
      "Epoch 2136/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1896 - val_loss: 1.8830\n",
      "Epoch 2137/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1884 - val_loss: 1.9218\n",
      "Epoch 2138/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2486 - val_loss: 1.9441\n",
      "Epoch 2139/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2110 - val_loss: 1.9131\n",
      "Epoch 2140/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2031 - val_loss: 1.9157\n",
      "Epoch 2141/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2124 - val_loss: 1.7443\n",
      "Epoch 2142/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2266 - val_loss: 1.9149\n",
      "Epoch 2143/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2510 - val_loss: 2.1392\n",
      "Epoch 2144/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2165 - val_loss: 2.1488\n",
      "Epoch 2145/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2040 - val_loss: 3.2065\n",
      "Epoch 2146/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1879 - val_loss: 2.3084\n",
      "Epoch 2147/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2018 - val_loss: 5.0768\n",
      "Epoch 2148/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1956 - val_loss: 4.1624\n",
      "Epoch 2149/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2738 - val_loss: 2.0308\n",
      "Epoch 2150/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2414 - val_loss: 3.5051\n",
      "Epoch 2151/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2516 - val_loss: 4.0518\n",
      "Epoch 2152/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3216 - val_loss: 2.0835\n",
      "Epoch 2153/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2508 - val_loss: 2.8419\n",
      "Epoch 2154/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1989 - val_loss: 1.9453\n",
      "Epoch 2155/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1940 - val_loss: 1.9484\n",
      "Epoch 2156/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1992 - val_loss: 2.0480\n",
      "Epoch 2157/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2631 - val_loss: 7.6355\n",
      "Epoch 2158/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2391 - val_loss: 2.3326\n",
      "Epoch 2159/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2033 - val_loss: 3.0825\n",
      "Epoch 2160/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2018 - val_loss: 2.1739\n",
      "Epoch 2161/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1940 - val_loss: 1.9445\n",
      "Epoch 2162/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1928 - val_loss: 1.7862\n",
      "Epoch 2163/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1949 - val_loss: 1.9875\n",
      "Epoch 2164/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3126 - val_loss: 1.8153\n",
      "Epoch 2165/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2411 - val_loss: 2.0245\n",
      "Epoch 2166/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2082 - val_loss: 2.2717\n",
      "Epoch 2167/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1953 - val_loss: 2.5325\n",
      "Epoch 2168/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2020 - val_loss: 3.5722\n",
      "Epoch 2169/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2805 - val_loss: 2.8944\n",
      "Epoch 2170/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2211 - val_loss: 1.8774\n",
      "Epoch 2171/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2148 - val_loss: 1.9020\n",
      "Epoch 2172/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2000 - val_loss: 2.1002\n",
      "Epoch 2173/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2199 - val_loss: 2.0336\n",
      "Epoch 2174/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2896 - val_loss: 2.1876\n",
      "Epoch 2175/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1972 - val_loss: 2.2620\n",
      "Epoch 2176/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1988 - val_loss: 2.0654\n",
      "Epoch 2177/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2093 - val_loss: 2.1294\n",
      "Epoch 2178/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1891 - val_loss: 2.2377\n",
      "Epoch 2179/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2101 - val_loss: 2.7076\n",
      "Epoch 2180/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2640 - val_loss: 1.7684\n",
      "Epoch 2181/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2054 - val_loss: 2.6130\n",
      "Epoch 2182/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1901 - val_loss: 2.3733\n",
      "Epoch 2183/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1864 - val_loss: 2.4307\n",
      "Epoch 2184/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2366 - val_loss: 2.1875\n",
      "Epoch 2185/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2353 - val_loss: 2.9849\n",
      "Epoch 2186/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2298 - val_loss: 2.0709\n",
      "Epoch 2187/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2163 - val_loss: 1.9583\n",
      "Epoch 2188/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2010 - val_loss: 1.8389\n",
      "Epoch 2189/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1992 - val_loss: 2.2181\n",
      "Epoch 2190/10000\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 0.2176 - val_loss: 1.9295\n",
      "Epoch 2191/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1984 - val_loss: 1.9698\n",
      "Epoch 2192/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2710 - val_loss: 2.0130\n",
      "Epoch 2193/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2995 - val_loss: 5.3133\n",
      "Epoch 2194/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2070 - val_loss: 3.2559\n",
      "Epoch 2195/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1990 - val_loss: 3.3625\n",
      "Epoch 2196/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2002 - val_loss: 3.4138\n",
      "Epoch 2197/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1919 - val_loss: 2.4436\n",
      "Epoch 2198/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1925 - val_loss: 2.3356\n",
      "Epoch 2199/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1894 - val_loss: 2.6616\n",
      "Epoch 2200/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1924 - val_loss: 2.2534\n",
      "Epoch 2201/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2143 - val_loss: 2.0582\n",
      "Epoch 2202/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1954 - val_loss: 2.1844\n",
      "Epoch 2203/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2115 - val_loss: 2.1696\n",
      "Epoch 2204/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1909 - val_loss: 2.1843\n",
      "Epoch 2205/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1961 - val_loss: 2.8513\n",
      "Epoch 2206/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1996 - val_loss: 2.1963\n",
      "Epoch 2207/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1947 - val_loss: 2.4673\n",
      "Epoch 2208/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1942 - val_loss: 2.9093\n",
      "Epoch 2209/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2405 - val_loss: 4.0489\n",
      "Epoch 2210/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2133 - val_loss: 2.2025\n",
      "Epoch 2211/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2101 - val_loss: 2.2955\n",
      "Epoch 2212/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2012 - val_loss: 3.0766\n",
      "Epoch 2213/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1950 - val_loss: 2.0907\n",
      "Epoch 2214/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2539 - val_loss: 3.0411\n",
      "Epoch 2215/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2259 - val_loss: 2.3152\n",
      "Epoch 2216/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3227 - val_loss: 2.9110\n",
      "Epoch 2217/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2214 - val_loss: 2.3758\n",
      "Epoch 2218/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2058 - val_loss: 1.7934\n",
      "Epoch 2219/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1938 - val_loss: 2.4989\n",
      "Epoch 2220/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1943 - val_loss: 2.6196\n",
      "Epoch 2221/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1968 - val_loss: 2.6236\n",
      "Epoch 2222/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1970 - val_loss: 2.1942\n",
      "Epoch 2223/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2271 - val_loss: 2.8180\n",
      "Epoch 2224/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1962 - val_loss: 2.0585\n",
      "Epoch 2225/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1907 - val_loss: 2.1641\n",
      "Epoch 2226/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1885 - val_loss: 2.6164\n",
      "Epoch 2227/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2024 - val_loss: 2.8412\n",
      "Epoch 2228/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2006 - val_loss: 2.9678\n",
      "Epoch 2229/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2085 - val_loss: 2.4508\n",
      "Epoch 2230/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2161 - val_loss: 3.0739\n",
      "Epoch 2231/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1958 - val_loss: 2.2375\n",
      "Epoch 2232/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2116 - val_loss: 2.1901\n",
      "Epoch 2233/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2270 - val_loss: 2.0050\n",
      "Epoch 2234/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2756 - val_loss: 2.0604\n",
      "Epoch 2235/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4048 - val_loss: 10.9081\n",
      "Epoch 2236/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2593 - val_loss: 3.1917\n",
      "Epoch 2237/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2039 - val_loss: 3.0078\n",
      "Epoch 2238/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2235 - val_loss: 1.7625\n",
      "Epoch 2239/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2153 - val_loss: 1.6660\n",
      "Epoch 2240/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1980 - val_loss: 2.3488\n",
      "Epoch 2241/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1966 - val_loss: 1.8455\n",
      "Epoch 2242/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2075 - val_loss: 2.6288\n",
      "Epoch 2243/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2075 - val_loss: 1.8010\n",
      "Epoch 2244/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2184 - val_loss: 2.3533\n",
      "Epoch 2245/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2136 - val_loss: 1.8485\n",
      "Epoch 2246/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1949 - val_loss: 1.9107\n",
      "Epoch 2247/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2069 - val_loss: 2.0207\n",
      "Epoch 2248/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2166 - val_loss: 2.2284\n",
      "Epoch 2249/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2051 - val_loss: 1.9591\n",
      "Epoch 2250/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2004 - val_loss: 1.8685\n",
      "Epoch 2251/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2023 - val_loss: 2.0481\n",
      "Epoch 2252/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1992 - val_loss: 1.9375\n",
      "Epoch 2253/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.2001 - val_loss: 2.3755\n",
      "Epoch 2254/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2050 - val_loss: 1.8559\n",
      "Epoch 2255/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1912 - val_loss: 1.8836\n",
      "Epoch 2256/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1914 - val_loss: 1.9343\n",
      "Epoch 2257/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1926 - val_loss: 1.9151\n",
      "Epoch 2258/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2106 - val_loss: 2.0263\n",
      "Epoch 2259/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2320 - val_loss: 2.2614\n",
      "Epoch 2260/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2828 - val_loss: 2.2017\n",
      "Epoch 2261/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2314 - val_loss: 3.1737\n",
      "Epoch 2262/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2202 - val_loss: 2.2030\n",
      "Epoch 2263/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1944 - val_loss: 2.3437\n",
      "Epoch 2264/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2177 - val_loss: 2.5680\n",
      "Epoch 2265/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2046 - val_loss: 4.4535\n",
      "Epoch 2266/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2047 - val_loss: 2.6041\n",
      "Epoch 2267/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1969 - val_loss: 2.2530\n",
      "Epoch 2268/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2396 - val_loss: 1.9792\n",
      "Epoch 2269/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2038 - val_loss: 1.8048\n",
      "Epoch 2270/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2447 - val_loss: 2.4437\n",
      "Epoch 2271/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2839 - val_loss: 2.0483\n",
      "Epoch 2272/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2051 - val_loss: 1.9986\n",
      "Epoch 2273/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2018 - val_loss: 2.3144\n",
      "Epoch 2274/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2113 - val_loss: 1.8629\n",
      "Epoch 2275/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2161 - val_loss: 1.9765\n",
      "Epoch 2276/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2037 - val_loss: 1.8993\n",
      "Epoch 2277/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1952 - val_loss: 2.1982\n",
      "Epoch 2278/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2058 - val_loss: 2.1696\n",
      "Epoch 2279/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1904 - val_loss: 2.1623\n",
      "Epoch 2280/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1911 - val_loss: 2.2613\n",
      "Epoch 2281/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2205 - val_loss: 2.1043\n",
      "Epoch 2282/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2030 - val_loss: 2.6791\n",
      "Epoch 2283/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1861 - val_loss: 2.1781\n",
      "Epoch 2284/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1956 - val_loss: 3.2454\n",
      "Epoch 2285/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2297 - val_loss: 2.3695\n",
      "Epoch 2286/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2243 - val_loss: 2.0509\n",
      "Epoch 2287/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2097 - val_loss: 2.8499\n",
      "Epoch 2288/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1964 - val_loss: 3.7299\n",
      "Epoch 2289/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2378 - val_loss: 2.2195\n",
      "Epoch 2290/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2200 - val_loss: 2.1028\n",
      "Epoch 2291/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2593 - val_loss: 4.6003\n",
      "Epoch 2292/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3246 - val_loss: 2.1895\n",
      "Epoch 2293/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2320 - val_loss: 1.8474\n",
      "Epoch 2294/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1981 - val_loss: 1.8143\n",
      "Epoch 2295/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1964 - val_loss: 1.7623\n",
      "Epoch 2296/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2408 - val_loss: 2.1863\n",
      "Epoch 2297/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.5251 - val_loss: 4.1555\n",
      "Epoch 2298/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2409 - val_loss: 12.2513\n",
      "Epoch 2299/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2123 - val_loss: 16.4993\n",
      "Epoch 2300/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2073 - val_loss: 3.6381\n",
      "Epoch 2301/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2254 - val_loss: 7.2190\n",
      "Epoch 2302/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2257 - val_loss: 8.5368\n",
      "Epoch 2303/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2490 - val_loss: 8.3437\n",
      "Epoch 2304/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2045 - val_loss: 4.6613\n",
      "Epoch 2305/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1957 - val_loss: 2.9068\n",
      "Epoch 2306/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2045 - val_loss: 3.1996\n",
      "Epoch 2307/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2107 - val_loss: 2.7562\n",
      "Epoch 2308/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1907 - val_loss: 3.4745\n",
      "Epoch 2309/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1878 - val_loss: 2.8543\n",
      "Epoch 2310/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1886 - val_loss: 2.5830\n",
      "Epoch 2311/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1891 - val_loss: 2.7814\n",
      "Epoch 2312/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1875 - val_loss: 3.6089\n",
      "Epoch 2313/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1926 - val_loss: 3.2546\n",
      "Epoch 2314/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2032 - val_loss: 1.8388\n",
      "Epoch 2315/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1962 - val_loss: 2.0191\n",
      "Epoch 2316/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1934 - val_loss: 2.1092\n",
      "Epoch 2317/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1954 - val_loss: 2.3446\n",
      "Epoch 2318/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1898 - val_loss: 2.2586\n",
      "Epoch 2319/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1927 - val_loss: 2.4154\n",
      "Epoch 2320/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2035 - val_loss: 2.8221\n",
      "Epoch 2321/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1991 - val_loss: 1.9500\n",
      "Epoch 2322/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1942 - val_loss: 2.2531\n",
      "Epoch 2323/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1901 - val_loss: 2.2757\n",
      "Epoch 2324/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1901 - val_loss: 2.5185\n",
      "Epoch 2325/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2177 - val_loss: 1.8661\n",
      "Epoch 2326/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2114 - val_loss: 2.9701\n",
      "Epoch 2327/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2039 - val_loss: 1.9095\n",
      "Epoch 2328/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2302 - val_loss: 3.5538\n",
      "Epoch 2329/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2003 - val_loss: 3.1588\n",
      "Epoch 2330/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1896 - val_loss: 4.3596\n",
      "Epoch 2331/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1866 - val_loss: 2.4199\n",
      "Epoch 2332/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1894 - val_loss: 3.1040\n",
      "Epoch 2333/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2073 - val_loss: 2.7721\n",
      "Epoch 2334/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1988 - val_loss: 8.4650\n",
      "Epoch 2335/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2097 - val_loss: 8.7233\n",
      "Epoch 2336/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1915 - val_loss: 6.9220\n",
      "Epoch 2337/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1879 - val_loss: 8.1190\n",
      "Epoch 2338/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2220 - val_loss: 11.8665\n",
      "Epoch 2339/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2468 - val_loss: 4.2688\n",
      "Epoch 2340/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1934 - val_loss: 2.6754\n",
      "Epoch 2341/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1932 - val_loss: 2.5150\n",
      "Epoch 2342/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2443 - val_loss: 11.8144\n",
      "Epoch 2343/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3322 - val_loss: 1.8008\n",
      "Epoch 2344/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2172 - val_loss: 1.9655\n",
      "Epoch 2345/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1984 - val_loss: 1.9460\n",
      "Epoch 2346/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2005 - val_loss: 2.0956\n",
      "Epoch 2347/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1907 - val_loss: 1.9110\n",
      "Epoch 2348/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1844 - val_loss: 2.0632\n",
      "Epoch 2349/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1862 - val_loss: 2.2331\n",
      "Epoch 2350/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2198 - val_loss: 4.5173\n",
      "Epoch 2351/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2765 - val_loss: 2.3651\n",
      "Epoch 2352/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2401 - val_loss: 5.3808\n",
      "Epoch 2353/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2118 - val_loss: 4.1015\n",
      "Epoch 2354/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2012 - val_loss: 3.4660\n",
      "Epoch 2355/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3096 - val_loss: 1.8117\n",
      "Epoch 2356/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3436 - val_loss: 3.9273\n",
      "Epoch 2357/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2950 - val_loss: 2.0564\n",
      "Epoch 2358/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2142 - val_loss: 1.8126\n",
      "Epoch 2359/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2058 - val_loss: 2.1319\n",
      "Epoch 2360/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2170 - val_loss: 4.1465\n",
      "Epoch 2361/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1942 - val_loss: 3.4340\n",
      "Epoch 2362/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1989 - val_loss: 3.5345\n",
      "Epoch 2363/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1883 - val_loss: 4.1113\n",
      "Epoch 2364/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1864 - val_loss: 2.7717\n",
      "Epoch 2365/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2046 - val_loss: 1.7800\n",
      "Epoch 2366/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2293 - val_loss: 2.0862\n",
      "Epoch 2367/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2222 - val_loss: 5.7561\n",
      "Epoch 2368/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2240 - val_loss: 2.2519\n",
      "Epoch 2369/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2367 - val_loss: 2.3375\n",
      "Epoch 2370/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2286 - val_loss: 3.8541\n",
      "Epoch 2371/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2307 - val_loss: 5.5433\n",
      "Epoch 2372/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2608 - val_loss: 2.1845\n",
      "Epoch 2373/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2133 - val_loss: 2.2475\n",
      "Epoch 2374/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1877 - val_loss: 2.1560\n",
      "Epoch 2375/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1895 - val_loss: 2.5265\n",
      "Epoch 2376/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1931 - val_loss: 2.6766\n",
      "Epoch 2377/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2124 - val_loss: 1.8272\n",
      "Epoch 2378/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2018 - val_loss: 1.8969\n",
      "Epoch 2379/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1929 - val_loss: 2.1052\n",
      "Epoch 2380/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1911 - val_loss: 2.0972\n",
      "Epoch 2381/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2033 - val_loss: 1.9270\n",
      "Epoch 2382/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1907 - val_loss: 2.3047\n",
      "Epoch 2383/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1899 - val_loss: 1.9111\n",
      "Epoch 2384/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2098 - val_loss: 2.0653\n",
      "Epoch 2385/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2587 - val_loss: 2.2018\n",
      "Epoch 2386/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2665 - val_loss: 2.8012\n",
      "Epoch 2387/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2441 - val_loss: 2.4931\n",
      "Epoch 2388/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2187 - val_loss: 5.1121\n",
      "Epoch 2389/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1977 - val_loss: 6.0775\n",
      "Epoch 2390/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1891 - val_loss: 6.7179\n",
      "Epoch 2391/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1883 - val_loss: 3.0826\n",
      "Epoch 2392/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2029 - val_loss: 2.7507\n",
      "Epoch 2393/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2383 - val_loss: 2.6475\n",
      "Epoch 2394/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2122 - val_loss: 3.5088\n",
      "Epoch 2395/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2153 - val_loss: 3.7164\n",
      "Epoch 2396/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2067 - val_loss: 2.3441\n",
      "Epoch 2397/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2029 - val_loss: 2.5434\n",
      "Epoch 2398/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2155 - val_loss: 2.3500\n",
      "Epoch 2399/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1977 - val_loss: 3.2580\n",
      "Epoch 2400/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1973 - val_loss: 2.2251\n",
      "Epoch 2401/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2110 - val_loss: 5.0774\n",
      "Epoch 2402/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2481 - val_loss: 3.4847\n",
      "Epoch 2403/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2267 - val_loss: 2.2803\n",
      "Epoch 2404/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2053 - val_loss: 1.9316\n",
      "Epoch 2405/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2223 - val_loss: 9.6916\n",
      "Epoch 2406/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1954 - val_loss: 7.8842\n",
      "Epoch 2407/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1912 - val_loss: 2.9412\n",
      "Epoch 2408/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1895 - val_loss: 3.0399\n",
      "Epoch 2409/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1949 - val_loss: 2.8809\n",
      "Epoch 2410/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1921 - val_loss: 3.1997\n",
      "Epoch 2411/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1905 - val_loss: 2.2705\n",
      "Epoch 2412/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1896 - val_loss: 3.2263\n",
      "Epoch 2413/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2104 - val_loss: 3.8033\n",
      "Epoch 2414/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2232 - val_loss: 10.2185\n",
      "Epoch 2415/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2337 - val_loss: 3.5831\n",
      "Epoch 2416/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2161 - val_loss: 1.9976\n",
      "Epoch 2417/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2347 - val_loss: 2.3755\n",
      "Epoch 2418/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2289 - val_loss: 2.3334\n",
      "Epoch 2419/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2007 - val_loss: 2.0091\n",
      "Epoch 2420/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1905 - val_loss: 2.8441\n",
      "Epoch 2421/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1868 - val_loss: 5.0678\n",
      "Epoch 2422/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1946 - val_loss: 3.0174\n",
      "Epoch 2423/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2081 - val_loss: 5.6815\n",
      "Epoch 2424/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1926 - val_loss: 3.5530\n",
      "Epoch 2425/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2254 - val_loss: 2.0875\n",
      "Epoch 2426/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2269 - val_loss: 4.3595\n",
      "Epoch 2427/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2212 - val_loss: 3.7322\n",
      "Epoch 2428/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2315 - val_loss: 2.1233\n",
      "Epoch 2429/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2101 - val_loss: 2.2360\n",
      "Epoch 2430/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1947 - val_loss: 2.2784\n",
      "Epoch 2431/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2056 - val_loss: 5.0403\n",
      "Epoch 2432/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2920 - val_loss: 2.9268\n",
      "Epoch 2433/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2155 - val_loss: 6.6436\n",
      "Epoch 2434/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2050 - val_loss: 5.8099\n",
      "Epoch 2435/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1977 - val_loss: 2.5368\n",
      "Epoch 2436/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2278 - val_loss: 2.3462\n",
      "Epoch 2437/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1909 - val_loss: 2.4281\n",
      "Epoch 2438/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2035 - val_loss: 2.4876\n",
      "Epoch 2439/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2444 - val_loss: 3.3722\n",
      "Epoch 2440/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3429 - val_loss: 20.8788\n",
      "Epoch 2441/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2891 - val_loss: 15.8620\n",
      "Epoch 2442/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2387 - val_loss: 17.8088\n",
      "Epoch 2443/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2293 - val_loss: 17.8346\n",
      "Epoch 2444/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1957 - val_loss: 17.6175\n",
      "Epoch 2445/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1867 - val_loss: 10.2630\n",
      "Epoch 2446/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2209 - val_loss: 10.3101\n",
      "Epoch 2447/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3177 - val_loss: 4.0422\n",
      "Epoch 2448/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2588 - val_loss: 22.2396\n",
      "Epoch 2449/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2551 - val_loss: 15.2423\n",
      "Epoch 2450/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2032 - val_loss: 18.5311\n",
      "Epoch 2451/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2081 - val_loss: 17.3749\n",
      "Epoch 2452/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1892 - val_loss: 19.4375\n",
      "Epoch 2453/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2009 - val_loss: 31.6962\n",
      "Epoch 2454/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2049 - val_loss: 22.5536\n",
      "Epoch 2455/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2313 - val_loss: 38.1976\n",
      "Epoch 2456/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2204 - val_loss: 15.2269\n",
      "Epoch 2457/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1987 - val_loss: 24.1865\n",
      "Epoch 2458/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2006 - val_loss: 25.7345\n",
      "Epoch 2459/10000\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 0.2098 - val_loss: 34.3920\n",
      "Epoch 2460/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.2052 - val_loss: 30.3579\n",
      "Epoch 2461/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2751 - val_loss: 12.7981\n",
      "Epoch 2462/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2266 - val_loss: 17.3325\n",
      "Epoch 2463/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1964 - val_loss: 17.2391\n",
      "Epoch 2464/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1896 - val_loss: 15.1559\n",
      "Epoch 2465/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1856 - val_loss: 17.2238\n",
      "Epoch 2466/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1996 - val_loss: 26.5757\n",
      "Epoch 2467/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2352 - val_loss: 35.9417\n",
      "Epoch 2468/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2008 - val_loss: 22.8734\n",
      "Epoch 2469/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2183 - val_loss: 28.5263\n",
      "Epoch 2470/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2314 - val_loss: 13.3330\n",
      "Epoch 2471/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1890 - val_loss: 19.4738\n",
      "Epoch 2472/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1885 - val_loss: 18.5529\n",
      "Epoch 2473/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2109 - val_loss: 6.4697\n",
      "Epoch 2474/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4026 - val_loss: 4.9602\n",
      "Epoch 2475/10000\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 0.3134 - val_loss: 6.8837\n",
      "Epoch 2476/10000\n",
      "34280/34280 [==============================] - 0s 13us/sample - loss: 0.2192 - val_loss: 5.0170\n",
      "Epoch 2477/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1996 - val_loss: 4.8207\n",
      "Epoch 2478/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1921 - val_loss: 7.2864\n",
      "Epoch 2479/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1937 - val_loss: 22.0414\n",
      "Epoch 2480/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1995 - val_loss: 17.5204\n",
      "Epoch 2481/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1925 - val_loss: 18.8993\n",
      "Epoch 2482/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1968 - val_loss: 10.7912\n",
      "Epoch 2483/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1954 - val_loss: 13.0158\n",
      "Epoch 2484/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1901 - val_loss: 2.7948\n",
      "Epoch 2485/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2206 - val_loss: 12.7723\n",
      "Epoch 2486/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2019 - val_loss: 17.6370\n",
      "Epoch 2487/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1967 - val_loss: 13.7195\n",
      "Epoch 2488/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3303 - val_loss: 2.4250\n",
      "Epoch 2489/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2917 - val_loss: 2.8734\n",
      "Epoch 2490/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2540 - val_loss: 33.6039\n",
      "Epoch 2491/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2362 - val_loss: 8.1021\n",
      "Epoch 2492/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1944 - val_loss: 4.9116\n",
      "Epoch 2493/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2002 - val_loss: 3.0658\n",
      "Epoch 2494/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1919 - val_loss: 8.8371\n",
      "Epoch 2495/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1941 - val_loss: 5.9036\n",
      "Epoch 2496/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2002 - val_loss: 8.3142\n",
      "Epoch 2497/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2253 - val_loss: 2.9103\n",
      "Epoch 2498/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2488 - val_loss: 8.1300\n",
      "Epoch 2499/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2076 - val_loss: 16.3641\n",
      "Epoch 2500/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1930 - val_loss: 7.0736\n",
      "Epoch 2501/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2805 - val_loss: 26.9113\n",
      "Epoch 2502/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2414 - val_loss: 9.7899\n",
      "Epoch 2503/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2033 - val_loss: 3.8107\n",
      "Epoch 2504/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2290 - val_loss: 10.6068\n",
      "Epoch 2505/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2036 - val_loss: 16.1045\n",
      "Epoch 2506/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1878 - val_loss: 10.8415\n",
      "Epoch 2507/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1852 - val_loss: 4.1822\n",
      "Epoch 2508/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2020 - val_loss: 6.3275\n",
      "Epoch 2509/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1973 - val_loss: 9.9386\n",
      "Epoch 2510/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1924 - val_loss: 12.0173\n",
      "Epoch 2511/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2217 - val_loss: 6.6318\n",
      "Epoch 2512/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1902 - val_loss: 13.0336\n",
      "Epoch 2513/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2021 - val_loss: 6.2202\n",
      "Epoch 2514/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2268 - val_loss: 41.7401\n",
      "Epoch 2515/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2180 - val_loss: 10.9001\n",
      "Epoch 2516/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2200 - val_loss: 3.7455\n",
      "Epoch 2517/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1952 - val_loss: 4.3410\n",
      "Epoch 2518/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2062 - val_loss: 14.0830\n",
      "Epoch 2519/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2293 - val_loss: 8.3202\n",
      "Epoch 2520/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1930 - val_loss: 8.5552\n",
      "Epoch 2521/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1956 - val_loss: 14.3755\n",
      "Epoch 2522/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1880 - val_loss: 7.2571\n",
      "Epoch 2523/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1865 - val_loss: 7.5644\n",
      "Epoch 2524/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1904 - val_loss: 14.3031\n",
      "Epoch 2525/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1863 - val_loss: 11.4009\n",
      "Epoch 2526/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1906 - val_loss: 6.8330\n",
      "Epoch 2527/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2075 - val_loss: 7.5573\n",
      "Epoch 2528/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2318 - val_loss: 9.8545\n",
      "Epoch 2529/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2181 - val_loss: 3.7785\n",
      "Epoch 2530/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2055 - val_loss: 5.0311\n",
      "Epoch 2531/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1982 - val_loss: 5.5422\n",
      "Epoch 2532/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2003 - val_loss: 5.2388\n",
      "Epoch 2533/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2082 - val_loss: 2.2041\n",
      "Epoch 2534/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2245 - val_loss: 15.2661\n",
      "Epoch 2535/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1981 - val_loss: 20.4901\n",
      "Epoch 2536/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1918 - val_loss: 15.3638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2537/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2163 - val_loss: 24.4573\n",
      "Epoch 2538/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2161 - val_loss: 8.3166\n",
      "Epoch 2539/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2032 - val_loss: 9.6479\n",
      "Epoch 2540/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1915 - val_loss: 14.3700\n",
      "Epoch 2541/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2031 - val_loss: 9.3651\n",
      "Epoch 2542/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2573 - val_loss: 25.7614\n",
      "Epoch 2543/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2630 - val_loss: 6.0755\n",
      "Epoch 2544/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2086 - val_loss: 14.8985\n",
      "Epoch 2545/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2018 - val_loss: 13.2268\n",
      "Epoch 2546/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1928 - val_loss: 9.4961\n",
      "Epoch 2547/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1851 - val_loss: 8.9803\n",
      "Epoch 2548/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1890 - val_loss: 4.9565\n",
      "Epoch 2549/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2167 - val_loss: 8.0803\n",
      "Epoch 2550/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2072 - val_loss: 13.8549\n",
      "Epoch 2551/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1895 - val_loss: 7.2545\n",
      "Epoch 2552/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1900 - val_loss: 6.1377\n",
      "Epoch 2553/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1916 - val_loss: 7.5638\n",
      "Epoch 2554/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1996 - val_loss: 14.5004\n",
      "Epoch 2555/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1998 - val_loss: 9.4355\n",
      "Epoch 2556/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2077 - val_loss: 11.6445\n",
      "Epoch 2557/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2367 - val_loss: 22.8372\n",
      "Epoch 2558/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.2368 - val_loss: 12.9444\n",
      "Epoch 2559/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2094 - val_loss: 17.8169\n",
      "Epoch 2560/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1909 - val_loss: 15.6013\n",
      "Epoch 2561/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1927 - val_loss: 27.9267\n",
      "Epoch 2562/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2182 - val_loss: 15.8140\n",
      "Epoch 2563/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1996 - val_loss: 8.7662\n",
      "Epoch 2564/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1976 - val_loss: 7.2011\n",
      "Epoch 2565/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2503 - val_loss: 23.6920\n",
      "Epoch 2566/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.3111 - val_loss: 35.2426\n",
      "Epoch 2567/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2713 - val_loss: 8.6284\n",
      "Epoch 2568/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1978 - val_loss: 8.1344\n",
      "Epoch 2569/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2006 - val_loss: 5.9642\n",
      "Epoch 2570/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2314 - val_loss: 16.0190\n",
      "Epoch 2571/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2056 - val_loss: 11.2100\n",
      "Epoch 2572/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1891 - val_loss: 12.3438\n",
      "Epoch 2573/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1952 - val_loss: 17.0890\n",
      "Epoch 2574/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1925 - val_loss: 14.2762\n",
      "Epoch 2575/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1900 - val_loss: 11.5251\n",
      "Epoch 2576/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1881 - val_loss: 9.2506\n",
      "Epoch 2577/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1954 - val_loss: 14.1231\n",
      "Epoch 2578/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2093 - val_loss: 8.5639\n",
      "Epoch 2579/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1892 - val_loss: 10.9457\n",
      "Epoch 2580/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1907 - val_loss: 11.6203\n",
      "Epoch 2581/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1854 - val_loss: 5.6929\n",
      "Epoch 2582/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2352 - val_loss: 9.8255\n",
      "Epoch 2583/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1948 - val_loss: 9.0315\n",
      "Epoch 2584/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1937 - val_loss: 9.4525\n",
      "Epoch 2585/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1919 - val_loss: 6.7436\n",
      "Epoch 2586/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1925 - val_loss: 6.7315\n",
      "Epoch 2587/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1987 - val_loss: 6.8869\n",
      "Epoch 2588/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2241 - val_loss: 5.6479\n",
      "Epoch 2589/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.3415 - val_loss: 14.5291\n",
      "Epoch 2590/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2101 - val_loss: 5.5980\n",
      "Epoch 2591/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2190 - val_loss: 19.3318\n",
      "Epoch 2592/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1948 - val_loss: 14.6505\n",
      "Epoch 2593/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1873 - val_loss: 7.4847\n",
      "Epoch 2594/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1877 - val_loss: 5.6757\n",
      "Epoch 2595/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1918 - val_loss: 10.8489\n",
      "Epoch 2596/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2030 - val_loss: 7.3572\n",
      "Epoch 2597/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1865 - val_loss: 5.8628\n",
      "Epoch 2598/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1866 - val_loss: 5.4922\n",
      "Epoch 2599/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2222 - val_loss: 7.1877\n",
      "Epoch 2600/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2039 - val_loss: 11.8428\n",
      "Epoch 2601/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1929 - val_loss: 8.7638\n",
      "Epoch 2602/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1931 - val_loss: 12.2348\n",
      "Epoch 2603/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1925 - val_loss: 11.7981\n",
      "Epoch 2604/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1927 - val_loss: 9.3845\n",
      "Epoch 2605/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1827 - val_loss: 11.1693\n",
      "Epoch 2606/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2116 - val_loss: 14.4036\n",
      "Epoch 2607/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2476 - val_loss: 9.7953\n",
      "Epoch 2608/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1926 - val_loss: 9.2919\n",
      "Epoch 2609/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1932 - val_loss: 14.7040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2610/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2357 - val_loss: 19.7299\n",
      "Epoch 2611/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2375 - val_loss: 14.2785\n",
      "Epoch 2612/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2126 - val_loss: 4.4059\n",
      "Epoch 2613/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1913 - val_loss: 6.0411\n",
      "Epoch 2614/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1953 - val_loss: 5.7780\n",
      "Epoch 2615/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1956 - val_loss: 4.8056\n",
      "Epoch 2616/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1930 - val_loss: 8.9379\n",
      "Epoch 2617/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2304 - val_loss: 6.4172\n",
      "Epoch 2618/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1965 - val_loss: 9.4414\n",
      "Epoch 2619/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1922 - val_loss: 7.7886\n",
      "Epoch 2620/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2121 - val_loss: 4.7094\n",
      "Epoch 2621/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2288 - val_loss: 15.6315\n",
      "Epoch 2622/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2204 - val_loss: 12.7722\n",
      "Epoch 2623/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2077 - val_loss: 9.7391\n",
      "Epoch 2624/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1843 - val_loss: 6.7290\n",
      "Epoch 2625/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1942 - val_loss: 13.2425\n",
      "Epoch 2626/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2061 - val_loss: 10.9045\n",
      "Epoch 2627/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1891 - val_loss: 15.0272\n",
      "Epoch 2628/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1843 - val_loss: 6.2320\n",
      "Epoch 2629/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2686 - val_loss: 5.7736\n",
      "Epoch 2630/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2334 - val_loss: 9.5798\n",
      "Epoch 2631/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1947 - val_loss: 9.3277\n",
      "Epoch 2632/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1895 - val_loss: 9.9174\n",
      "Epoch 2633/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1843 - val_loss: 7.6552\n",
      "Epoch 2634/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1834 - val_loss: 6.9029\n",
      "Epoch 2635/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1967 - val_loss: 12.4368\n",
      "Epoch 2636/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2517 - val_loss: 15.2929\n",
      "Epoch 2637/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.3614 - val_loss: 7.1917\n",
      "Epoch 2638/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2888 - val_loss: 14.0179\n",
      "Epoch 2639/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2207 - val_loss: 10.5366\n",
      "Epoch 2640/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2425 - val_loss: 22.4273\n",
      "Epoch 2641/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2112 - val_loss: 14.9637\n",
      "Epoch 2642/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2085 - val_loss: 10.0554\n",
      "Epoch 2643/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1936 - val_loss: 6.2287\n",
      "Epoch 2644/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2047 - val_loss: 14.7514\n",
      "Epoch 2645/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2303 - val_loss: 3.4524\n",
      "Epoch 2646/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1907 - val_loss: 17.6393\n",
      "Epoch 2647/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1902 - val_loss: 19.3227\n",
      "Epoch 2648/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1893 - val_loss: 14.8455\n",
      "Epoch 2649/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2305 - val_loss: 8.8633\n",
      "Epoch 2650/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2355 - val_loss: 24.8889\n",
      "Epoch 2651/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2008 - val_loss: 20.6817\n",
      "Epoch 2652/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1936 - val_loss: 18.4648\n",
      "Epoch 2653/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2049 - val_loss: 19.1845\n",
      "Epoch 2654/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2363 - val_loss: 7.7624\n",
      "Epoch 2655/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2271 - val_loss: 23.0833\n",
      "Epoch 2656/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1974 - val_loss: 18.1140\n",
      "Epoch 2657/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1951 - val_loss: 29.6730\n",
      "Epoch 2658/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2081 - val_loss: 15.7451\n",
      "Epoch 2659/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1993 - val_loss: 21.7862\n",
      "Epoch 2660/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1932 - val_loss: 16.6094\n",
      "Epoch 2661/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1893 - val_loss: 18.7439\n",
      "Epoch 2662/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1865 - val_loss: 20.5713\n",
      "Epoch 2663/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1971 - val_loss: 23.2869\n",
      "Epoch 2664/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1872 - val_loss: 15.6580\n",
      "Epoch 2665/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1884 - val_loss: 10.5322\n",
      "Epoch 2666/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1906 - val_loss: 22.8080\n",
      "Epoch 2667/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1947 - val_loss: 23.5021\n",
      "Epoch 2668/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1863 - val_loss: 16.6576\n",
      "Epoch 2669/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1857 - val_loss: 19.9523\n",
      "Epoch 2670/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1854 - val_loss: 17.1379\n",
      "Epoch 2671/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1864 - val_loss: 17.8684\n",
      "Epoch 2672/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2815 - val_loss: 35.9170\n",
      "Epoch 2673/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.3070 - val_loss: 20.1375\n",
      "Epoch 2674/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2019 - val_loss: 29.8568\n",
      "Epoch 2675/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1948 - val_loss: 34.8184\n",
      "Epoch 2676/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1958 - val_loss: 39.7046\n",
      "Epoch 2677/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2002 - val_loss: 35.6274\n",
      "Epoch 2678/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1882 - val_loss: 27.3286\n",
      "Epoch 2679/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2073 - val_loss: 24.1398\n",
      "Epoch 2680/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2302 - val_loss: 24.0172\n",
      "Epoch 2681/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1968 - val_loss: 18.3439\n",
      "Epoch 2682/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1922 - val_loss: 32.2331\n",
      "Epoch 2683/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2025 - val_loss: 23.6903\n",
      "Epoch 2684/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1971 - val_loss: 32.0594\n",
      "Epoch 2685/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2582 - val_loss: 23.4653\n",
      "Epoch 2686/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2134 - val_loss: 22.2295\n",
      "Epoch 2687/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1916 - val_loss: 17.1501\n",
      "Epoch 2688/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2059 - val_loss: 17.3156\n",
      "Epoch 2689/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2269 - val_loss: 20.6363\n",
      "Epoch 2690/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2046 - val_loss: 15.9740\n",
      "Epoch 2691/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2421 - val_loss: 16.4481\n",
      "Epoch 2692/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2648 - val_loss: 14.9040\n",
      "Epoch 2693/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2199 - val_loss: 16.9519\n",
      "Epoch 2694/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2091 - val_loss: 21.3662\n",
      "Epoch 2695/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2327 - val_loss: 17.8273\n",
      "Epoch 2696/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1928 - val_loss: 14.5912\n",
      "Epoch 2697/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1946 - val_loss: 16.8197\n",
      "Epoch 2698/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1911 - val_loss: 10.6419\n",
      "Epoch 2699/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1959 - val_loss: 6.8888\n",
      "Epoch 2700/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.3096 - val_loss: 11.7130\n",
      "Epoch 2701/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2504 - val_loss: 5.0860\n",
      "Epoch 2702/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2514 - val_loss: 14.7165\n",
      "Epoch 2703/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1921 - val_loss: 8.3781\n",
      "Epoch 2704/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2068 - val_loss: 7.2952\n",
      "Epoch 2705/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1943 - val_loss: 8.8550\n",
      "Epoch 2706/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1875 - val_loss: 8.5475\n",
      "Epoch 2707/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1891 - val_loss: 8.6451\n",
      "Epoch 2708/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1933 - val_loss: 4.5317\n",
      "Epoch 2709/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1989 - val_loss: 6.8493\n",
      "Epoch 2710/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1934 - val_loss: 4.7535\n",
      "Epoch 2711/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2001 - val_loss: 5.3252\n",
      "Epoch 2712/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1843 - val_loss: 10.4315\n",
      "Epoch 2713/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1891 - val_loss: 11.1535\n",
      "Epoch 2714/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1879 - val_loss: 6.9842\n",
      "Epoch 2715/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1961 - val_loss: 7.3170\n",
      "Epoch 2716/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1928 - val_loss: 13.7487\n",
      "Epoch 2717/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1832 - val_loss: 9.7847\n",
      "Epoch 2718/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1894 - val_loss: 7.4734\n",
      "Epoch 2719/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1886 - val_loss: 8.0326\n",
      "Epoch 2720/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1818 - val_loss: 8.5758\n",
      "Epoch 2721/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1811 - val_loss: 10.4450\n",
      "Epoch 2722/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1866 - val_loss: 5.3413\n",
      "Epoch 2723/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2029 - val_loss: 11.5981\n",
      "Epoch 2724/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1839 - val_loss: 7.4681\n",
      "Epoch 2725/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1863 - val_loss: 8.0308\n",
      "Epoch 2726/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2130 - val_loss: 8.9103\n",
      "Epoch 2727/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2335 - val_loss: 2.1566\n",
      "Epoch 2728/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2403 - val_loss: 5.0856\n",
      "Epoch 2729/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1987 - val_loss: 6.1703\n",
      "Epoch 2730/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2031 - val_loss: 9.6509\n",
      "Epoch 2731/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2015 - val_loss: 6.5240\n",
      "Epoch 2732/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2078 - val_loss: 4.8639\n",
      "Epoch 2733/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2149 - val_loss: 10.1336\n",
      "Epoch 2734/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2059 - val_loss: 6.4700\n",
      "Epoch 2735/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1854 - val_loss: 5.1866\n",
      "Epoch 2736/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2024 - val_loss: 7.0645\n",
      "Epoch 2737/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1985 - val_loss: 4.8602\n",
      "Epoch 2738/10000\n",
      "34280/34280 [==============================] - 0s 12us/sample - loss: 0.2172 - val_loss: 5.1504\n",
      "Epoch 2739/10000\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 0.2076 - val_loss: 2.7147\n",
      "Epoch 2740/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.2422 - val_loss: 2.1290\n",
      "Epoch 2741/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2200 - val_loss: 2.0097\n",
      "Epoch 2742/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2402 - val_loss: 1.9107\n",
      "Epoch 2743/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3877 - val_loss: 5.6447\n",
      "Epoch 2744/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3595 - val_loss: 5.8054\n",
      "Epoch 2745/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3028 - val_loss: 2.6666\n",
      "Epoch 2746/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2200 - val_loss: 2.0564\n",
      "Epoch 2747/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2005 - val_loss: 3.9697\n",
      "Epoch 2748/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1972 - val_loss: 2.1542\n",
      "Epoch 2749/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2561 - val_loss: 4.4092\n",
      "Epoch 2750/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1953 - val_loss: 4.7016\n",
      "Epoch 2751/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1853 - val_loss: 6.7793\n",
      "Epoch 2752/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1886 - val_loss: 4.4266\n",
      "Epoch 2753/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2000 - val_loss: 3.6085\n",
      "Epoch 2754/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1866 - val_loss: 3.0140\n",
      "Epoch 2755/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2118 - val_loss: 2.8880\n",
      "Epoch 2756/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1958 - val_loss: 2.4702\n",
      "Epoch 2757/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1833 - val_loss: 3.6551\n",
      "Epoch 2758/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1829 - val_loss: 3.0101\n",
      "Epoch 2759/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1863 - val_loss: 2.6063\n",
      "Epoch 2760/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1825 - val_loss: 2.8572\n",
      "Epoch 2761/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1960 - val_loss: 3.7039\n",
      "Epoch 2762/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2055 - val_loss: 4.0261\n",
      "Epoch 2763/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2048 - val_loss: 6.3615\n",
      "Epoch 2764/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1974 - val_loss: 2.2494\n",
      "Epoch 2765/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1947 - val_loss: 1.9707\n",
      "Epoch 2766/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2755 - val_loss: 14.0209\n",
      "Epoch 2767/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2844 - val_loss: 16.1920\n",
      "Epoch 2768/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2866 - val_loss: 17.7231\n",
      "Epoch 2769/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2178 - val_loss: 13.0022\n",
      "Epoch 2770/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1900 - val_loss: 9.1114\n",
      "Epoch 2771/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1869 - val_loss: 6.4557\n",
      "Epoch 2772/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2064 - val_loss: 6.2749\n",
      "Epoch 2773/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2063 - val_loss: 4.1673\n",
      "Epoch 2774/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1946 - val_loss: 6.6562\n",
      "Epoch 2775/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2121 - val_loss: 8.5983\n",
      "Epoch 2776/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2303 - val_loss: 4.1261\n",
      "Epoch 2777/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2019 - val_loss: 4.0203\n",
      "Epoch 2778/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1927 - val_loss: 4.6347\n",
      "Epoch 2779/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1895 - val_loss: 4.2546\n",
      "Epoch 2780/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1860 - val_loss: 4.1964\n",
      "Epoch 2781/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1851 - val_loss: 4.3606\n",
      "Epoch 2782/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2092 - val_loss: 7.9577\n",
      "Epoch 2783/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2038 - val_loss: 3.5938\n",
      "Epoch 2784/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1853 - val_loss: 2.1116\n",
      "Epoch 2785/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1867 - val_loss: 2.7369\n",
      "Epoch 2786/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1883 - val_loss: 6.4505\n",
      "Epoch 2787/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1856 - val_loss: 4.2974\n",
      "Epoch 2788/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1958 - val_loss: 3.6074\n",
      "Epoch 2789/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1891 - val_loss: 2.6207\n",
      "Epoch 2790/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1929 - val_loss: 4.1471\n",
      "Epoch 2791/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2119 - val_loss: 4.4223\n",
      "Epoch 2792/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2313 - val_loss: 11.4147\n",
      "Epoch 2793/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2061 - val_loss: 2.5836\n",
      "Epoch 2794/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1930 - val_loss: 3.4372\n",
      "Epoch 2795/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1848 - val_loss: 5.3286\n",
      "Epoch 2796/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2036 - val_loss: 3.6234\n",
      "Epoch 2797/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2137 - val_loss: 4.4061\n",
      "Epoch 2798/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1906 - val_loss: 3.7367\n",
      "Epoch 2799/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1837 - val_loss: 3.8227\n",
      "Epoch 2800/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1984 - val_loss: 2.4540\n",
      "Epoch 2801/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2639 - val_loss: 5.8970\n",
      "Epoch 2802/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1922 - val_loss: 3.1240\n",
      "Epoch 2803/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1857 - val_loss: 2.6070\n",
      "Epoch 2804/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1822 - val_loss: 2.2388\n",
      "Epoch 2805/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1835 - val_loss: 1.9724\n",
      "Epoch 2806/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1877 - val_loss: 1.7149\n",
      "Epoch 2807/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2755 - val_loss: 1.6814\n",
      "Epoch 2808/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2812 - val_loss: 2.7003\n",
      "Epoch 2809/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2629 - val_loss: 29.0158\n",
      "Epoch 2810/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2355 - val_loss: 6.4932\n",
      "Epoch 2811/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1917 - val_loss: 2.9659\n",
      "Epoch 2812/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1991 - val_loss: 3.6037\n",
      "Epoch 2813/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2469 - val_loss: 3.3561\n",
      "Epoch 2814/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2352 - val_loss: 2.0114\n",
      "Epoch 2815/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2006 - val_loss: 1.7706\n",
      "Epoch 2816/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2155 - val_loss: 2.9570\n",
      "Epoch 2817/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1929 - val_loss: 4.4697\n",
      "Epoch 2818/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1985 - val_loss: 7.1641\n",
      "Epoch 2819/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1889 - val_loss: 3.2763\n",
      "Epoch 2820/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1938 - val_loss: 5.2758\n",
      "Epoch 2821/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1918 - val_loss: 5.5636\n",
      "Epoch 2822/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1873 - val_loss: 2.7640\n",
      "Epoch 2823/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1898 - val_loss: 3.2848\n",
      "Epoch 2824/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1864 - val_loss: 6.1103\n",
      "Epoch 2825/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1852 - val_loss: 4.1153\n",
      "Epoch 2826/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1848 - val_loss: 3.1599\n",
      "Epoch 2827/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1852 - val_loss: 8.4132\n",
      "Epoch 2828/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1840 - val_loss: 7.5980\n",
      "Epoch 2829/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1808 - val_loss: 6.6803\n",
      "Epoch 2830/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1950 - val_loss: 5.3790\n",
      "Epoch 2831/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4002 - val_loss: 14.8717\n",
      "Epoch 2832/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2735 - val_loss: 3.5176\n",
      "Epoch 2833/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3393 - val_loss: 15.3691\n",
      "Epoch 2834/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2247 - val_loss: 15.1993\n",
      "Epoch 2835/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2238 - val_loss: 37.2723\n",
      "Epoch 2836/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2019 - val_loss: 27.3932\n",
      "Epoch 2837/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1886 - val_loss: 23.3921\n",
      "Epoch 2838/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1988 - val_loss: 40.6307\n",
      "Epoch 2839/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2070 - val_loss: 22.8325\n",
      "Epoch 2840/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1869 - val_loss: 21.9546\n",
      "Epoch 2841/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1946 - val_loss: 23.4900\n",
      "Epoch 2842/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2029 - val_loss: 22.6908\n",
      "Epoch 2843/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1956 - val_loss: 26.9502\n",
      "Epoch 2844/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2039 - val_loss: 31.8703\n",
      "Epoch 2845/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1954 - val_loss: 24.6474\n",
      "Epoch 2846/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1927 - val_loss: 27.3821\n",
      "Epoch 2847/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2034 - val_loss: 22.0697\n",
      "Epoch 2848/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1898 - val_loss: 22.0830\n",
      "Epoch 2849/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1875 - val_loss: 14.5829\n",
      "Epoch 2850/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2397 - val_loss: 23.0960\n",
      "Epoch 2851/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2014 - val_loss: 25.9962\n",
      "Epoch 2852/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1882 - val_loss: 11.5210\n",
      "Epoch 2853/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1901 - val_loss: 18.4398\n",
      "Epoch 2854/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2160 - val_loss: 9.7431\n",
      "Epoch 2855/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2380 - val_loss: 18.1699\n",
      "Epoch 2856/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2380 - val_loss: 7.5662\n",
      "Epoch 2857/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2025 - val_loss: 20.6352\n",
      "Epoch 2858/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1917 - val_loss: 15.8647\n",
      "Epoch 2859/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1911 - val_loss: 20.0633\n",
      "Epoch 2860/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1842 - val_loss: 10.3600\n",
      "Epoch 2861/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3195 - val_loss: 8.0237\n",
      "Epoch 2862/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4107 - val_loss: 57.3257\n",
      "Epoch 2863/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.2928 - val_loss: 65.3818\n",
      "Epoch 2864/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2135 - val_loss: 64.1880\n",
      "Epoch 2865/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1874 - val_loss: 65.8073\n",
      "Epoch 2866/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1949 - val_loss: 53.4636\n",
      "Epoch 2867/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2078 - val_loss: 56.5870\n",
      "Epoch 2868/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1999 - val_loss: 50.2273\n",
      "Epoch 2869/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1910 - val_loss: 44.0300\n",
      "Epoch 2870/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1849 - val_loss: 51.2644\n",
      "Epoch 2871/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1856 - val_loss: 52.0220\n",
      "Epoch 2872/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1882 - val_loss: 52.8890\n",
      "Epoch 2873/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1804 - val_loss: 51.8983\n",
      "Epoch 2874/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1846 - val_loss: 46.3518\n",
      "Epoch 2875/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1839 - val_loss: 46.7811\n",
      "Epoch 2876/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1851 - val_loss: 50.9907\n",
      "Epoch 2877/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1862 - val_loss: 49.7993\n",
      "Epoch 2878/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1866 - val_loss: 56.1845\n",
      "Epoch 2879/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1899 - val_loss: 50.9145\n",
      "Epoch 2880/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2002 - val_loss: 53.3202\n",
      "Epoch 2881/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1898 - val_loss: 52.4355\n",
      "Epoch 2882/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2394 - val_loss: 51.1609\n",
      "Epoch 2883/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1956 - val_loss: 55.1493\n",
      "Epoch 2884/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2170 - val_loss: 51.3452\n",
      "Epoch 2885/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2179 - val_loss: 45.7129\n",
      "Epoch 2886/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1937 - val_loss: 48.6582\n",
      "Epoch 2887/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2156 - val_loss: 43.9342\n",
      "Epoch 2888/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1931 - val_loss: 45.8735\n",
      "Epoch 2889/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1991 - val_loss: 41.4764\n",
      "Epoch 2890/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2232 - val_loss: 51.9392\n",
      "Epoch 2891/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2039 - val_loss: 42.3321\n",
      "Epoch 2892/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2289 - val_loss: 24.5040\n",
      "Epoch 2893/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2112 - val_loss: 36.1796\n",
      "Epoch 2894/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1925 - val_loss: 34.9148\n",
      "Epoch 2895/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1874 - val_loss: 36.7039\n",
      "Epoch 2896/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1838 - val_loss: 36.8839\n",
      "Epoch 2897/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1913 - val_loss: 37.1770\n",
      "Epoch 2898/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1848 - val_loss: 39.1526\n",
      "Epoch 2899/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1863 - val_loss: 40.6627\n",
      "Epoch 2900/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1825 - val_loss: 40.4711\n",
      "Epoch 2901/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1839 - val_loss: 38.4662\n",
      "Epoch 2902/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1845 - val_loss: 41.8485\n",
      "Epoch 2903/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1861 - val_loss: 36.1093\n",
      "Epoch 2904/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1963 - val_loss: 39.4381\n",
      "Epoch 2905/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2586 - val_loss: 51.3331\n",
      "Epoch 2906/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2685 - val_loss: 39.8666\n",
      "Epoch 2907/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2567 - val_loss: 35.9846\n",
      "Epoch 2908/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1919 - val_loss: 34.7269\n",
      "Epoch 2909/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1886 - val_loss: 39.9518\n",
      "Epoch 2910/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1904 - val_loss: 38.2626\n",
      "Epoch 2911/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2027 - val_loss: 47.7859\n",
      "Epoch 2912/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2311 - val_loss: 48.4672\n",
      "Epoch 2913/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2416 - val_loss: 26.6728\n",
      "Epoch 2914/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2022 - val_loss: 31.1921\n",
      "Epoch 2915/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2285 - val_loss: 24.6251\n",
      "Epoch 2916/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2029 - val_loss: 42.5782\n",
      "Epoch 2917/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1848 - val_loss: 32.7342\n",
      "Epoch 2918/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1865 - val_loss: 36.0237\n",
      "Epoch 2919/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1808 - val_loss: 36.3604\n",
      "Epoch 2920/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1803 - val_loss: 43.7801\n",
      "Epoch 2921/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1817 - val_loss: 46.8342\n",
      "Epoch 2922/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1866 - val_loss: 36.7618\n",
      "Epoch 2923/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1834 - val_loss: 39.1929\n",
      "Epoch 2924/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1916 - val_loss: 31.7333\n",
      "Epoch 2925/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2189 - val_loss: 35.7865\n",
      "Epoch 2926/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1863 - val_loss: 39.5890\n",
      "Epoch 2927/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1868 - val_loss: 27.8748\n",
      "Epoch 2928/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2065 - val_loss: 36.2572\n",
      "Epoch 2929/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2094 - val_loss: 32.4005\n",
      "Epoch 2930/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2296 - val_loss: 34.5937\n",
      "Epoch 2931/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2414 - val_loss: 28.7940\n",
      "Epoch 2932/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2499 - val_loss: 35.4569\n",
      "Epoch 2933/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2852 - val_loss: 36.5230\n",
      "Epoch 2934/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2158 - val_loss: 41.1170\n",
      "Epoch 2935/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1998 - val_loss: 36.9793\n",
      "Epoch 2936/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2126 - val_loss: 33.4483\n",
      "Epoch 2937/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1985 - val_loss: 51.2855\n",
      "Epoch 2938/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1927 - val_loss: 46.6500\n",
      "Epoch 2939/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1952 - val_loss: 50.3058\n",
      "Epoch 2940/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1850 - val_loss: 47.1110\n",
      "Epoch 2941/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1855 - val_loss: 47.3641\n",
      "Epoch 2942/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1910 - val_loss: 44.1205\n",
      "Epoch 2943/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1875 - val_loss: 44.1063\n",
      "Epoch 2944/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1907 - val_loss: 43.2568\n",
      "Epoch 2945/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1876 - val_loss: 38.2734\n",
      "Epoch 2946/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1877 - val_loss: 32.5241\n",
      "Epoch 2947/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1841 - val_loss: 33.1596\n",
      "Epoch 2948/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1850 - val_loss: 37.8897\n",
      "Epoch 2949/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1984 - val_loss: 37.0394\n",
      "Epoch 2950/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2194 - val_loss: 50.0993\n",
      "Epoch 2951/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1895 - val_loss: 44.5432\n",
      "Epoch 2952/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1911 - val_loss: 35.8146\n",
      "Epoch 2953/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1841 - val_loss: 42.2581\n",
      "Epoch 2954/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1833 - val_loss: 37.9502\n",
      "Epoch 2955/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2073 - val_loss: 42.8408\n",
      "Epoch 2956/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1853 - val_loss: 43.4059\n",
      "Epoch 2957/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1886 - val_loss: 37.3544\n",
      "Epoch 2958/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1824 - val_loss: 37.9576\n",
      "Epoch 2959/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1821 - val_loss: 36.9196\n",
      "Epoch 2960/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1840 - val_loss: 41.1086\n",
      "Epoch 2961/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1859 - val_loss: 39.9393\n",
      "Epoch 2962/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1815 - val_loss: 39.2709\n",
      "Epoch 2963/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1901 - val_loss: 37.8253\n",
      "Epoch 2964/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2045 - val_loss: 31.0845\n",
      "Epoch 2965/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2676 - val_loss: 33.3190\n",
      "Epoch 2966/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.3358 - val_loss: 51.2877\n",
      "Epoch 2967/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.4488 - val_loss: 30.7041\n",
      "Epoch 2968/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3101 - val_loss: 5.5465\n",
      "Epoch 2969/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2770 - val_loss: 15.6983\n",
      "Epoch 2970/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2223 - val_loss: 24.0709\n",
      "Epoch 2971/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3526 - val_loss: 65.3680\n",
      "Epoch 2972/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4592 - val_loss: 6.5933\n",
      "Epoch 2973/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2558 - val_loss: 6.3973\n",
      "Epoch 2974/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2236 - val_loss: 5.2839\n",
      "Epoch 2975/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2176 - val_loss: 2.1564\n",
      "Epoch 2976/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2779 - val_loss: 16.4210\n",
      "Epoch 2977/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2175 - val_loss: 4.9456\n",
      "Epoch 2978/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2161 - val_loss: 5.9297\n",
      "Epoch 2979/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1879 - val_loss: 12.4397\n",
      "Epoch 2980/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1959 - val_loss: 10.8504\n",
      "Epoch 2981/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1871 - val_loss: 10.7024\n",
      "Epoch 2982/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1848 - val_loss: 9.0674\n",
      "Epoch 2983/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1886 - val_loss: 11.1613\n",
      "Epoch 2984/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1836 - val_loss: 12.4824\n",
      "Epoch 2985/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1904 - val_loss: 18.4644\n",
      "Epoch 2986/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1939 - val_loss: 12.1180\n",
      "Epoch 2987/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1852 - val_loss: 11.0957\n",
      "Epoch 2988/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1869 - val_loss: 20.9669\n",
      "Epoch 2989/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1904 - val_loss: 11.0009\n",
      "Epoch 2990/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1837 - val_loss: 11.9712\n",
      "Epoch 2991/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1830 - val_loss: 8.5658\n",
      "Epoch 2992/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1808 - val_loss: 12.5878\n",
      "Epoch 2993/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1929 - val_loss: 17.8367\n",
      "Epoch 2994/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1925 - val_loss: 8.4977\n",
      "Epoch 2995/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1849 - val_loss: 15.3457\n",
      "Epoch 2996/10000\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 0.1821 - val_loss: 16.0242\n",
      "Epoch 2997/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1812 - val_loss: 19.3009\n",
      "Epoch 2998/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1802 - val_loss: 16.3661\n",
      "Epoch 2999/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1901 - val_loss: 19.7652\n",
      "Epoch 3000/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.2134 - val_loss: 26.2285\n",
      "Epoch 3001/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1920 - val_loss: 17.0162\n",
      "Epoch 3002/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1835 - val_loss: 23.3383\n",
      "Epoch 3003/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2003 - val_loss: 28.4099\n",
      "Epoch 3004/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1914 - val_loss: 14.2190\n",
      "Epoch 3005/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1915 - val_loss: 13.6175\n",
      "Epoch 3006/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1876 - val_loss: 21.9701\n",
      "Epoch 3007/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1908 - val_loss: 20.0287\n",
      "Epoch 3008/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1825 - val_loss: 22.2146\n",
      "Epoch 3009/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1928 - val_loss: 8.9198\n",
      "Epoch 3010/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.2348 - val_loss: 15.6450\n",
      "Epoch 3011/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1913 - val_loss: 27.8341\n",
      "Epoch 3012/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1816 - val_loss: 18.9220\n",
      "Epoch 3013/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1864 - val_loss: 17.2232\n",
      "Epoch 3014/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1841 - val_loss: 16.0406\n",
      "Epoch 3015/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1860 - val_loss: 22.8679\n",
      "Epoch 3016/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1830 - val_loss: 21.4414\n",
      "Epoch 3017/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1838 - val_loss: 22.4344\n",
      "Epoch 3018/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1809 - val_loss: 22.6446\n",
      "Epoch 3019/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1838 - val_loss: 18.9518\n",
      "Epoch 3020/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1860 - val_loss: 30.9055\n",
      "Epoch 3021/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.2537 - val_loss: 13.9986\n",
      "Epoch 3022/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2382 - val_loss: 3.8334\n",
      "Epoch 3023/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.2739 - val_loss: 13.1171\n",
      "Epoch 3024/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2331 - val_loss: 35.6457\n",
      "Epoch 3025/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2465 - val_loss: 26.2646\n",
      "Epoch 3026/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.3556 - val_loss: 20.1949\n",
      "Epoch 3027/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2607 - val_loss: 41.0428\n",
      "Epoch 3028/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2348 - val_loss: 23.0895\n",
      "Epoch 3029/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2074 - val_loss: 26.3995\n",
      "Epoch 3030/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1865 - val_loss: 18.6755\n",
      "Epoch 3031/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1851 - val_loss: 18.5403\n",
      "Epoch 3032/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1812 - val_loss: 18.1652\n",
      "Epoch 3033/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1864 - val_loss: 12.5758\n",
      "Epoch 3034/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1818 - val_loss: 12.5898\n",
      "Epoch 3035/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1788 - val_loss: 12.1531\n",
      "Epoch 3036/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1809 - val_loss: 14.8815\n",
      "Epoch 3037/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1809 - val_loss: 18.1301\n",
      "Epoch 3038/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1806 - val_loss: 15.1794\n",
      "Epoch 3039/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1820 - val_loss: 20.4900\n",
      "Epoch 3040/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1817 - val_loss: 15.5696\n",
      "Epoch 3041/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1854 - val_loss: 31.8537\n",
      "Epoch 3042/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2052 - val_loss: 13.9143\n",
      "Epoch 3043/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1977 - val_loss: 31.6899\n",
      "Epoch 3044/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1856 - val_loss: 13.1442\n",
      "Epoch 3045/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2619 - val_loss: 23.2453\n",
      "Epoch 3046/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.2114 - val_loss: 16.4981\n",
      "Epoch 3047/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1901 - val_loss: 16.9871\n",
      "Epoch 3048/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1832 - val_loss: 12.9337\n",
      "Epoch 3049/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1814 - val_loss: 15.8919\n",
      "Epoch 3050/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1832 - val_loss: 17.6361\n",
      "Epoch 3051/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1933 - val_loss: 14.0262\n",
      "Epoch 3052/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1896 - val_loss: 9.4042\n",
      "Epoch 3053/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1829 - val_loss: 3.3030\n",
      "Epoch 3054/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2386 - val_loss: 5.2084\n",
      "Epoch 3055/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4727 - val_loss: 3.8082\n",
      "Epoch 3056/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2798 - val_loss: 2.6694\n",
      "Epoch 3057/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2611 - val_loss: 20.5092\n",
      "Epoch 3058/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2204 - val_loss: 18.5699\n",
      "Epoch 3059/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2048 - val_loss: 22.5647\n",
      "Epoch 3060/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2084 - val_loss: 20.1331\n",
      "Epoch 3061/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1933 - val_loss: 12.3001\n",
      "Epoch 3062/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2065 - val_loss: 5.5595\n",
      "Epoch 3063/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1952 - val_loss: 6.1375\n",
      "Epoch 3064/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1918 - val_loss: 12.7304\n",
      "Epoch 3065/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1870 - val_loss: 9.7223\n",
      "Epoch 3066/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1910 - val_loss: 11.9017\n",
      "Epoch 3067/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1888 - val_loss: 8.9270\n",
      "Epoch 3068/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1839 - val_loss: 13.2135\n",
      "Epoch 3069/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1820 - val_loss: 12.5102\n",
      "Epoch 3070/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1811 - val_loss: 14.0593\n",
      "Epoch 3071/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1798 - val_loss: 10.4759\n",
      "Epoch 3072/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1823 - val_loss: 9.2843\n",
      "Epoch 3073/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1852 - val_loss: 10.2497\n",
      "Epoch 3074/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3530 - val_loss: 13.9924\n",
      "Epoch 3075/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.3367 - val_loss: 4.0524\n",
      "Epoch 3076/10000\n",
      "34280/34280 [==============================] - 0s 12us/sample - loss: 0.3027 - val_loss: 30.4610\n",
      "Epoch 3077/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2463 - val_loss: 19.9782\n",
      "Epoch 3078/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2184 - val_loss: 15.2841\n",
      "Epoch 3079/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1997 - val_loss: 16.8056\n",
      "Epoch 3080/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1947 - val_loss: 13.7711\n",
      "Epoch 3081/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1954 - val_loss: 19.1393\n",
      "Epoch 3082/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1964 - val_loss: 10.5610\n",
      "Epoch 3083/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1955 - val_loss: 21.3234\n",
      "Epoch 3084/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1927 - val_loss: 2.9081\n",
      "Epoch 3085/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1893 - val_loss: 3.9549\n",
      "Epoch 3086/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2167 - val_loss: 11.1894\n",
      "Epoch 3087/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2001 - val_loss: 12.0979\n",
      "Epoch 3088/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2036 - val_loss: 13.4961\n",
      "Epoch 3089/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1836 - val_loss: 17.9390\n",
      "Epoch 3090/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1846 - val_loss: 9.2511\n",
      "Epoch 3091/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1897 - val_loss: 9.8820\n",
      "Epoch 3092/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1849 - val_loss: 9.7474\n",
      "Epoch 3093/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1900 - val_loss: 7.4626\n",
      "Epoch 3094/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1874 - val_loss: 7.2861\n",
      "Epoch 3095/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1890 - val_loss: 4.8309\n",
      "Epoch 3096/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1829 - val_loss: 15.2900\n",
      "Epoch 3097/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1968 - val_loss: 10.7591\n",
      "Epoch 3098/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1911 - val_loss: 8.2252\n",
      "Epoch 3099/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1833 - val_loss: 5.1811\n",
      "Epoch 3100/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1811 - val_loss: 6.4305\n",
      "Epoch 3101/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1866 - val_loss: 3.4006\n",
      "Epoch 3102/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2089 - val_loss: 11.2941\n",
      "Epoch 3103/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1973 - val_loss: 5.4584\n",
      "Epoch 3104/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1858 - val_loss: 5.6891\n",
      "Epoch 3105/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1859 - val_loss: 3.2640\n",
      "Epoch 3106/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1793 - val_loss: 4.4104\n",
      "Epoch 3107/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1802 - val_loss: 4.4929\n",
      "Epoch 3108/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1818 - val_loss: 4.2480\n",
      "Epoch 3109/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1808 - val_loss: 7.3428\n",
      "Epoch 3110/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1826 - val_loss: 5.5769\n",
      "Epoch 3111/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1808 - val_loss: 6.5286\n",
      "Epoch 3112/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1882 - val_loss: 4.5830\n",
      "Epoch 3113/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1833 - val_loss: 5.9518\n",
      "Epoch 3114/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1908 - val_loss: 4.4920\n",
      "Epoch 3115/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2038 - val_loss: 26.9320\n",
      "Epoch 3116/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2345 - val_loss: 11.2600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3117/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3591 - val_loss: 13.8617\n",
      "Epoch 3118/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3790 - val_loss: 23.7085\n",
      "Epoch 3119/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4092 - val_loss: 66.2642\n",
      "Epoch 3120/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4257 - val_loss: 11.4302\n",
      "Epoch 3121/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2768 - val_loss: 14.1055\n",
      "Epoch 3122/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2019 - val_loss: 30.8697\n",
      "Epoch 3123/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1936 - val_loss: 24.1877\n",
      "Epoch 3124/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1891 - val_loss: 31.5422\n",
      "Epoch 3125/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1926 - val_loss: 27.8487\n",
      "Epoch 3126/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1971 - val_loss: 42.2027\n",
      "Epoch 3127/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1977 - val_loss: 37.9742\n",
      "Epoch 3128/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1835 - val_loss: 29.0432\n",
      "Epoch 3129/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1911 - val_loss: 26.8307\n",
      "Epoch 3130/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1853 - val_loss: 32.4859\n",
      "Epoch 3131/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1827 - val_loss: 31.9788\n",
      "Epoch 3132/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1831 - val_loss: 16.5193\n",
      "Epoch 3133/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1885 - val_loss: 28.1360\n",
      "Epoch 3134/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1819 - val_loss: 28.7604\n",
      "Epoch 3135/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1818 - val_loss: 33.7854\n",
      "Epoch 3136/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1888 - val_loss: 37.1532\n",
      "Epoch 3137/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1859 - val_loss: 28.9925\n",
      "Epoch 3138/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1829 - val_loss: 28.0615\n",
      "Epoch 3139/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1837 - val_loss: 26.1931\n",
      "Epoch 3140/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1801 - val_loss: 27.4235\n",
      "Epoch 3141/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1810 - val_loss: 32.3079\n",
      "Epoch 3142/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1893 - val_loss: 35.2480\n",
      "Epoch 3143/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1842 - val_loss: 24.0287\n",
      "Epoch 3144/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2198 - val_loss: 42.5356\n",
      "Epoch 3145/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1921 - val_loss: 29.6290\n",
      "Epoch 3146/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2011 - val_loss: 43.9760\n",
      "Epoch 3147/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2523 - val_loss: 38.4864\n",
      "Epoch 3148/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2082 - val_loss: 25.1561\n",
      "Epoch 3149/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1825 - val_loss: 35.0333\n",
      "Epoch 3150/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1860 - val_loss: 27.7630\n",
      "Epoch 3151/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2771 - val_loss: 46.9849\n",
      "Epoch 3152/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2560 - val_loss: 15.6509\n",
      "Epoch 3153/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2879 - val_loss: 40.9096\n",
      "Epoch 3154/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1912 - val_loss: 34.9926\n",
      "Epoch 3155/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1822 - val_loss: 34.0253\n",
      "Epoch 3156/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1828 - val_loss: 33.9455\n",
      "Epoch 3157/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1778 - val_loss: 36.3457\n",
      "Epoch 3158/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1788 - val_loss: 30.7333\n",
      "Epoch 3159/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1810 - val_loss: 33.0517\n",
      "Epoch 3160/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1801 - val_loss: 30.8055\n",
      "Epoch 3161/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1772 - val_loss: 36.7555\n",
      "Epoch 3162/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1809 - val_loss: 31.5197\n",
      "Epoch 3163/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1837 - val_loss: 35.0058\n",
      "Epoch 3164/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1818 - val_loss: 33.3569\n",
      "Epoch 3165/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1787 - val_loss: 29.6928\n",
      "Epoch 3166/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1805 - val_loss: 38.8438\n",
      "Epoch 3167/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1870 - val_loss: 33.9258\n",
      "Epoch 3168/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1809 - val_loss: 33.6189\n",
      "Epoch 3169/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1842 - val_loss: 27.0314\n",
      "Epoch 3170/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1834 - val_loss: 29.4378\n",
      "Epoch 3171/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1899 - val_loss: 28.0026\n",
      "Epoch 3172/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1863 - val_loss: 36.0670\n",
      "Epoch 3173/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1918 - val_loss: 30.9192\n",
      "Epoch 3174/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2339 - val_loss: 27.9188\n",
      "Epoch 3175/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3485 - val_loss: 43.7695\n",
      "Epoch 3176/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3414 - val_loss: 14.0454\n",
      "Epoch 3177/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2462 - val_loss: 24.9331\n",
      "Epoch 3178/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1908 - val_loss: 24.3108\n",
      "Epoch 3179/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1827 - val_loss: 25.2051\n",
      "Epoch 3180/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1827 - val_loss: 23.8628\n",
      "Epoch 3181/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1807 - val_loss: 24.9919\n",
      "Epoch 3182/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1803 - val_loss: 17.5542\n",
      "Epoch 3183/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1993 - val_loss: 26.9474\n",
      "Epoch 3184/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3564 - val_loss: 19.5751\n",
      "Epoch 3185/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3426 - val_loss: 28.0282\n",
      "Epoch 3186/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2252 - val_loss: 17.9409\n",
      "Epoch 3187/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1916 - val_loss: 32.6524\n",
      "Epoch 3188/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1955 - val_loss: 27.2562\n",
      "Epoch 3189/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1880 - val_loss: 22.0111\n",
      "Epoch 3190/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1866 - val_loss: 20.1751\n",
      "Epoch 3191/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1825 - val_loss: 19.0286\n",
      "Epoch 3192/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1782 - val_loss: 18.5732\n",
      "Epoch 3193/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1796 - val_loss: 19.0088\n",
      "Epoch 3194/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1805 - val_loss: 24.8560\n",
      "Epoch 3195/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1794 - val_loss: 17.2025\n",
      "Epoch 3196/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1794 - val_loss: 16.4084\n",
      "Epoch 3197/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1804 - val_loss: 20.1949\n",
      "Epoch 3198/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1809 - val_loss: 13.4914\n",
      "Epoch 3199/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1875 - val_loss: 19.6013\n",
      "Epoch 3200/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2008 - val_loss: 21.1613\n",
      "Epoch 3201/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2019 - val_loss: 15.4792\n",
      "Epoch 3202/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1851 - val_loss: 16.1669\n",
      "Epoch 3203/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1992 - val_loss: 22.0498\n",
      "Epoch 3204/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2338 - val_loss: 18.4531\n",
      "Epoch 3205/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1905 - val_loss: 7.2728\n",
      "Epoch 3206/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1832 - val_loss: 12.8998\n",
      "Epoch 3207/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1845 - val_loss: 14.1797\n",
      "Epoch 3208/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1795 - val_loss: 15.2336\n",
      "Epoch 3209/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1810 - val_loss: 11.2191\n",
      "Epoch 3210/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1801 - val_loss: 9.0638\n",
      "Epoch 3211/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1855 - val_loss: 4.1062\n",
      "Epoch 3212/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3219 - val_loss: 36.1089\n",
      "Epoch 3213/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2813 - val_loss: 25.9342\n",
      "Epoch 3214/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2356 - val_loss: 5.5392\n",
      "Epoch 3215/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2330 - val_loss: 10.8558\n",
      "Epoch 3216/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2457 - val_loss: 13.4224\n",
      "Epoch 3217/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1975 - val_loss: 24.7884\n",
      "Epoch 3218/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1810 - val_loss: 17.0437\n",
      "Epoch 3219/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1945 - val_loss: 32.2651\n",
      "Epoch 3220/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2247 - val_loss: 15.5837\n",
      "Epoch 3221/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2036 - val_loss: 12.7843\n",
      "Epoch 3222/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2260 - val_loss: 33.9105\n",
      "Epoch 3223/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2077 - val_loss: 20.6402\n",
      "Epoch 3224/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1927 - val_loss: 19.0057\n",
      "Epoch 3225/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1853 - val_loss: 19.8131\n",
      "Epoch 3226/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1823 - val_loss: 32.9434\n",
      "Epoch 3227/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1841 - val_loss: 27.8067\n",
      "Epoch 3228/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1803 - val_loss: 21.6255\n",
      "Epoch 3229/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1808 - val_loss: 12.8416\n",
      "Epoch 3230/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1818 - val_loss: 17.3226\n",
      "Epoch 3231/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1844 - val_loss: 20.5575\n",
      "Epoch 3232/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1837 - val_loss: 21.8148\n",
      "Epoch 3233/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1837 - val_loss: 22.8109\n",
      "Epoch 3234/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1792 - val_loss: 20.0577\n",
      "Epoch 3235/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1802 - val_loss: 26.3082\n",
      "Epoch 3236/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2026 - val_loss: 23.8149\n",
      "Epoch 3237/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1933 - val_loss: 23.6901\n",
      "Epoch 3238/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1915 - val_loss: 12.2941\n",
      "Epoch 3239/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2045 - val_loss: 25.2326\n",
      "Epoch 3240/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3210 - val_loss: 59.9300\n",
      "Epoch 3241/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2826 - val_loss: 37.5937\n",
      "Epoch 3242/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1971 - val_loss: 23.8653\n",
      "Epoch 3243/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1905 - val_loss: 27.2052\n",
      "Epoch 3244/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1785 - val_loss: 25.6389\n",
      "Epoch 3245/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1806 - val_loss: 29.4170\n",
      "Epoch 3246/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1780 - val_loss: 24.6572\n",
      "Epoch 3247/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1795 - val_loss: 25.5352\n",
      "Epoch 3248/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1838 - val_loss: 25.3992\n",
      "Epoch 3249/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1872 - val_loss: 26.2674\n",
      "Epoch 3250/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1794 - val_loss: 24.0503\n",
      "Epoch 3251/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1802 - val_loss: 34.1212\n",
      "Epoch 3252/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1914 - val_loss: 16.3084\n",
      "Epoch 3253/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2054 - val_loss: 4.8403\n",
      "Epoch 3254/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2181 - val_loss: 28.8425\n",
      "Epoch 3255/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2034 - val_loss: 22.7526\n",
      "Epoch 3256/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1854 - val_loss: 20.5361\n",
      "Epoch 3257/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1874 - val_loss: 25.5271\n",
      "Epoch 3258/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1794 - val_loss: 20.7293\n",
      "Epoch 3259/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1789 - val_loss: 24.9509\n",
      "Epoch 3260/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1835 - val_loss: 23.4838\n",
      "Epoch 3261/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1918 - val_loss: 27.8589\n",
      "Epoch 3262/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1825 - val_loss: 14.5587\n",
      "Epoch 3263/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1806 - val_loss: 27.0457\n",
      "Epoch 3264/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1825 - val_loss: 15.8413\n",
      "Epoch 3265/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2138 - val_loss: 7.0863\n",
      "Epoch 3266/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3356 - val_loss: 19.0522\n",
      "Epoch 3267/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2942 - val_loss: 36.8544\n",
      "Epoch 3268/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2166 - val_loss: 27.3089\n",
      "Epoch 3269/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1894 - val_loss: 28.5074\n",
      "Epoch 3270/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1864 - val_loss: 26.8262\n",
      "Epoch 3271/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1837 - val_loss: 25.0814\n",
      "Epoch 3272/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1796 - val_loss: 25.0019\n",
      "Epoch 3273/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1806 - val_loss: 26.8023\n",
      "Epoch 3274/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1823 - val_loss: 33.5553\n",
      "Epoch 3275/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2128 - val_loss: 43.2037\n",
      "Epoch 3276/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1945 - val_loss: 31.6657\n",
      "Epoch 3277/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1897 - val_loss: 29.1664\n",
      "Epoch 3278/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2037 - val_loss: 23.0196\n",
      "Epoch 3279/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1962 - val_loss: 11.8026\n",
      "Epoch 3280/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1800 - val_loss: 8.8760\n",
      "Epoch 3281/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1867 - val_loss: 14.6791\n",
      "Epoch 3282/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2263 - val_loss: 10.0483\n",
      "Epoch 3283/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2073 - val_loss: 26.6888\n",
      "Epoch 3284/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1856 - val_loss: 27.3929\n",
      "Epoch 3285/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2025 - val_loss: 15.4683\n",
      "Epoch 3286/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1946 - val_loss: 17.9826\n",
      "Epoch 3287/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2263 - val_loss: 32.2227\n",
      "Epoch 3288/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2220 - val_loss: 49.1834\n",
      "Epoch 3289/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1901 - val_loss: 47.9236\n",
      "Epoch 3290/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1999 - val_loss: 39.9397\n",
      "Epoch 3291/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1861 - val_loss: 28.5294\n",
      "Epoch 3292/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1902 - val_loss: 16.8838\n",
      "Epoch 3293/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1910 - val_loss: 2.6336\n",
      "Epoch 3294/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2095 - val_loss: 16.2464\n",
      "Epoch 3295/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1834 - val_loss: 10.1530\n",
      "Epoch 3296/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1882 - val_loss: 12.3240\n",
      "Epoch 3297/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1796 - val_loss: 13.3982\n",
      "Epoch 3298/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1794 - val_loss: 15.1508\n",
      "Epoch 3299/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1825 - val_loss: 16.4667\n",
      "Epoch 3300/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1956 - val_loss: 20.0677\n",
      "Epoch 3301/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1887 - val_loss: 25.1320\n",
      "Epoch 3302/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1905 - val_loss: 29.6098\n",
      "Epoch 3303/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1919 - val_loss: 23.0497\n",
      "Epoch 3304/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1989 - val_loss: 50.1803\n",
      "Epoch 3305/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3970 - val_loss: 26.1771\n",
      "Epoch 3306/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3280 - val_loss: 29.7379\n",
      "Epoch 3307/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3166 - val_loss: 26.6495\n",
      "Epoch 3308/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2747 - val_loss: 16.2786\n",
      "Epoch 3309/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2920 - val_loss: 8.4532\n",
      "Epoch 3310/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2801 - val_loss: 15.9078\n",
      "Epoch 3311/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2360 - val_loss: 19.9688\n",
      "Epoch 3312/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2621 - val_loss: 7.0503\n",
      "Epoch 3313/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2384 - val_loss: 8.5042\n",
      "Epoch 3314/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1991 - val_loss: 7.5324\n",
      "Epoch 3315/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1975 - val_loss: 7.1431\n",
      "Epoch 3316/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2305 - val_loss: 9.7485\n",
      "Epoch 3317/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1944 - val_loss: 14.0556\n",
      "Epoch 3318/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1926 - val_loss: 12.3399\n",
      "Epoch 3319/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1901 - val_loss: 8.5412\n",
      "Epoch 3320/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1973 - val_loss: 15.8303\n",
      "Epoch 3321/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1944 - val_loss: 10.2691\n",
      "Epoch 3322/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1973 - val_loss: 11.3588\n",
      "Epoch 3323/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1969 - val_loss: 16.7977\n",
      "Epoch 3324/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2166 - val_loss: 17.1710\n",
      "Epoch 3325/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1933 - val_loss: 19.7610\n",
      "Epoch 3326/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1849 - val_loss: 16.3026\n",
      "Epoch 3327/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1818 - val_loss: 18.1376\n",
      "Epoch 3328/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1919 - val_loss: 19.6287\n",
      "Epoch 3329/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1829 - val_loss: 18.5811\n",
      "Epoch 3330/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1911 - val_loss: 14.1664\n",
      "Epoch 3331/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1843 - val_loss: 17.3774\n",
      "Epoch 3332/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1782 - val_loss: 19.7607\n",
      "Epoch 3333/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1845 - val_loss: 18.3772\n",
      "Epoch 3334/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1941 - val_loss: 14.0301\n",
      "Epoch 3335/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1844 - val_loss: 12.8231\n",
      "Epoch 3336/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1805 - val_loss: 20.2086\n",
      "Epoch 3337/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1804 - val_loss: 15.9402\n",
      "Epoch 3338/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1792 - val_loss: 14.9423\n",
      "Epoch 3339/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1796 - val_loss: 18.7990\n",
      "Epoch 3340/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1813 - val_loss: 11.8995\n",
      "Epoch 3341/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1801 - val_loss: 10.3258\n",
      "Epoch 3342/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1818 - val_loss: 14.6091\n",
      "Epoch 3343/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1803 - val_loss: 12.5226\n",
      "Epoch 3344/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1779 - val_loss: 11.4261\n",
      "Epoch 3345/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1793 - val_loss: 16.0996\n",
      "Epoch 3346/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1806 - val_loss: 11.7740\n",
      "Epoch 3347/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1819 - val_loss: 18.2917\n",
      "Epoch 3348/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1791 - val_loss: 14.2032\n",
      "Epoch 3349/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1823 - val_loss: 15.3111\n",
      "Epoch 3350/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1812 - val_loss: 10.6334\n",
      "Epoch 3351/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1928 - val_loss: 12.3957\n",
      "Epoch 3352/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1968 - val_loss: 15.2662\n",
      "Epoch 3353/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1868 - val_loss: 15.3629\n",
      "Epoch 3354/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2137 - val_loss: 16.1436\n",
      "Epoch 3355/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2008 - val_loss: 14.9963\n",
      "Epoch 3356/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1862 - val_loss: 14.8437\n",
      "Epoch 3357/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1822 - val_loss: 21.4649\n",
      "Epoch 3358/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2947 - val_loss: 25.2671\n",
      "Epoch 3359/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.5022 - val_loss: 11.3660\n",
      "Epoch 3360/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2878 - val_loss: 7.9119\n",
      "Epoch 3361/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2483 - val_loss: 16.5718\n",
      "Epoch 3362/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2690 - val_loss: 12.4290\n",
      "Epoch 3363/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2867 - val_loss: 36.2017\n",
      "Epoch 3364/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2071 - val_loss: 24.8851\n",
      "Epoch 3365/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1910 - val_loss: 31.5417\n",
      "Epoch 3366/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1865 - val_loss: 28.3883\n",
      "Epoch 3367/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1936 - val_loss: 33.3884\n",
      "Epoch 3368/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1888 - val_loss: 33.8204\n",
      "Epoch 3369/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2161 - val_loss: 53.8884\n",
      "Epoch 3370/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2404 - val_loss: 37.2082\n",
      "Epoch 3371/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1949 - val_loss: 30.9595\n",
      "Epoch 3372/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1927 - val_loss: 32.9262\n",
      "Epoch 3373/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1904 - val_loss: 30.9987\n",
      "Epoch 3374/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1985 - val_loss: 20.7820\n",
      "Epoch 3375/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1879 - val_loss: 25.9977\n",
      "Epoch 3376/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1809 - val_loss: 26.6462\n",
      "Epoch 3377/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1866 - val_loss: 30.4355\n",
      "Epoch 3378/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1814 - val_loss: 23.3511\n",
      "Epoch 3379/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1804 - val_loss: 22.1864\n",
      "Epoch 3380/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1801 - val_loss: 16.9390\n",
      "Epoch 3381/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1934 - val_loss: 19.4640\n",
      "Epoch 3382/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1897 - val_loss: 22.9814\n",
      "Epoch 3383/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1960 - val_loss: 13.5158\n",
      "Epoch 3384/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2199 - val_loss: 25.6508\n",
      "Epoch 3385/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1966 - val_loss: 23.3146\n",
      "Epoch 3386/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1853 - val_loss: 19.0860\n",
      "Epoch 3387/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1840 - val_loss: 25.1306\n",
      "Epoch 3388/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1801 - val_loss: 21.7357\n",
      "Epoch 3389/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1795 - val_loss: 20.7456\n",
      "Epoch 3390/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1819 - val_loss: 23.1364\n",
      "Epoch 3391/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1789 - val_loss: 26.8630\n",
      "Epoch 3392/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1787 - val_loss: 18.8970\n",
      "Epoch 3393/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1815 - val_loss: 20.8626\n",
      "Epoch 3394/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1818 - val_loss: 18.7537\n",
      "Epoch 3395/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1846 - val_loss: 23.7142\n",
      "Epoch 3396/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2158 - val_loss: 12.5425\n",
      "Epoch 3397/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3417 - val_loss: 10.4431\n",
      "Epoch 3398/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4543 - val_loss: 17.7994\n",
      "Epoch 3399/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1996 - val_loss: 21.6793\n",
      "Epoch 3400/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2225 - val_loss: 36.3845\n",
      "Epoch 3401/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2125 - val_loss: 22.3391\n",
      "Epoch 3402/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1879 - val_loss: 15.1124\n",
      "Epoch 3403/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1819 - val_loss: 20.5622\n",
      "Epoch 3404/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1810 - val_loss: 19.4080\n",
      "Epoch 3405/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1799 - val_loss: 26.3342\n",
      "Epoch 3406/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1793 - val_loss: 21.6124\n",
      "Epoch 3407/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1794 - val_loss: 22.0416\n",
      "Epoch 3408/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1778 - val_loss: 18.0280\n",
      "Epoch 3409/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1796 - val_loss: 16.4270\n",
      "Epoch 3410/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1802 - val_loss: 23.8495\n",
      "Epoch 3411/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1793 - val_loss: 21.2099\n",
      "Epoch 3412/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1787 - val_loss: 17.2605\n",
      "Epoch 3413/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1788 - val_loss: 19.4290\n",
      "Epoch 3414/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1788 - val_loss: 15.8554\n",
      "Epoch 3415/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1852 - val_loss: 16.3792\n",
      "Epoch 3416/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1847 - val_loss: 17.7275\n",
      "Epoch 3417/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1814 - val_loss: 16.3936\n",
      "Epoch 3418/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1825 - val_loss: 8.6706\n",
      "Epoch 3419/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1888 - val_loss: 23.0412\n",
      "Epoch 3420/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1800 - val_loss: 19.8636\n",
      "Epoch 3421/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1767 - val_loss: 20.6721\n",
      "Epoch 3422/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1831 - val_loss: 23.4480\n",
      "Epoch 3423/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1869 - val_loss: 10.5105\n",
      "Epoch 3424/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3408 - val_loss: 17.6697\n",
      "Epoch 3425/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3007 - val_loss: 10.3274\n",
      "Epoch 3426/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2050 - val_loss: 35.0964\n",
      "Epoch 3427/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2048 - val_loss: 25.6328\n",
      "Epoch 3428/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1916 - val_loss: 21.4173\n",
      "Epoch 3429/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3330 - val_loss: 21.5998\n",
      "Epoch 3430/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3505 - val_loss: 68.3632\n",
      "Epoch 3431/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3554 - val_loss: 14.8039\n",
      "Epoch 3432/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2793 - val_loss: 28.5718\n",
      "Epoch 3433/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2364 - val_loss: 22.6135\n",
      "Epoch 3434/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2891 - val_loss: 26.5000\n",
      "Epoch 3435/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2377 - val_loss: 18.3762\n",
      "Epoch 3436/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2228 - val_loss: 10.6097\n",
      "Epoch 3437/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2494 - val_loss: 13.5245\n",
      "Epoch 3438/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2507 - val_loss: 9.9769\n",
      "Epoch 3439/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2296 - val_loss: 8.7685\n",
      "Epoch 3440/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2831 - val_loss: 14.2679\n",
      "Epoch 3441/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2143 - val_loss: 7.1801\n",
      "Epoch 3442/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2005 - val_loss: 6.6334\n",
      "Epoch 3443/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1898 - val_loss: 6.8829\n",
      "Epoch 3444/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1848 - val_loss: 7.4210\n",
      "Epoch 3445/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1822 - val_loss: 7.0285\n",
      "Epoch 3446/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1894 - val_loss: 5.0150\n",
      "Epoch 3447/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1896 - val_loss: 5.5225\n",
      "Epoch 3448/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2006 - val_loss: 7.0950\n",
      "Epoch 3449/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1853 - val_loss: 5.1921\n",
      "Epoch 3450/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1815 - val_loss: 5.1813\n",
      "Epoch 3451/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1864 - val_loss: 4.8521\n",
      "Epoch 3452/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1788 - val_loss: 5.3362\n",
      "Epoch 3453/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1829 - val_loss: 4.3309\n",
      "Epoch 3454/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1796 - val_loss: 4.9303\n",
      "Epoch 3455/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1810 - val_loss: 7.3646\n",
      "Epoch 3456/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1802 - val_loss: 5.9172\n",
      "Epoch 3457/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1789 - val_loss: 3.0201\n",
      "Epoch 3458/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1844 - val_loss: 4.2575\n",
      "Epoch 3459/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1809 - val_loss: 6.0386\n",
      "Epoch 3460/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1797 - val_loss: 7.7830\n",
      "Epoch 3461/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1784 - val_loss: 6.2359\n",
      "Epoch 3462/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1769 - val_loss: 5.4842\n",
      "Epoch 3463/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1832 - val_loss: 7.3634\n",
      "Epoch 3464/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1972 - val_loss: 5.3957\n",
      "Epoch 3465/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2148 - val_loss: 5.8361\n",
      "Epoch 3466/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1824 - val_loss: 3.6866\n",
      "Epoch 3467/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1838 - val_loss: 4.0595\n",
      "Epoch 3468/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1799 - val_loss: 4.5931\n",
      "Epoch 3469/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1783 - val_loss: 4.4114\n",
      "Epoch 3470/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1800 - val_loss: 3.7314\n",
      "Epoch 3471/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1790 - val_loss: 4.7317\n",
      "Epoch 3472/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1801 - val_loss: 5.1950\n",
      "Epoch 3473/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1814 - val_loss: 2.6822\n",
      "Epoch 3474/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1882 - val_loss: 6.3248\n",
      "Epoch 3475/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1975 - val_loss: 29.6364\n",
      "Epoch 3476/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2947 - val_loss: 11.4825\n",
      "Epoch 3477/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2050 - val_loss: 4.6346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3478/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2388 - val_loss: 16.1079\n",
      "Epoch 3479/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1951 - val_loss: 12.3650\n",
      "Epoch 3480/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2113 - val_loss: 6.4298\n",
      "Epoch 3481/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1946 - val_loss: 5.2024\n",
      "Epoch 3482/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1835 - val_loss: 3.4482\n",
      "Epoch 3483/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1870 - val_loss: 6.7521\n",
      "Epoch 3484/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1950 - val_loss: 3.2969\n",
      "Epoch 3485/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2279 - val_loss: 19.1664\n",
      "Epoch 3486/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2810 - val_loss: 14.4349\n",
      "Epoch 3487/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2147 - val_loss: 6.7195\n",
      "Epoch 3488/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2293 - val_loss: 3.0568\n",
      "Epoch 3489/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1920 - val_loss: 2.5213\n",
      "Epoch 3490/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1856 - val_loss: 2.5559\n",
      "Epoch 3491/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1859 - val_loss: 4.1094\n",
      "Epoch 3492/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1828 - val_loss: 5.5206\n",
      "Epoch 3493/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2067 - val_loss: 10.4327\n",
      "Epoch 3494/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2240 - val_loss: 1.9584\n",
      "Epoch 3495/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2723 - val_loss: 3.6888\n",
      "Epoch 3496/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2114 - val_loss: 3.7246\n",
      "Epoch 3497/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1882 - val_loss: 5.7624\n",
      "Epoch 3498/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1833 - val_loss: 7.0326\n",
      "Epoch 3499/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1858 - val_loss: 4.9724\n",
      "Epoch 3500/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1810 - val_loss: 5.0233\n",
      "Epoch 3501/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1787 - val_loss: 5.3931\n",
      "Epoch 3502/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1761 - val_loss: 4.9251\n",
      "Epoch 3503/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1793 - val_loss: 6.9370\n",
      "Epoch 3504/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1887 - val_loss: 5.0858\n",
      "Epoch 3505/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1823 - val_loss: 9.6020\n",
      "Epoch 3506/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2468 - val_loss: 15.2808\n",
      "Epoch 3507/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2313 - val_loss: 2.7097\n",
      "Epoch 3508/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2172 - val_loss: 7.3913\n",
      "Epoch 3509/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1876 - val_loss: 7.4752\n",
      "Epoch 3510/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1907 - val_loss: 5.9167\n",
      "Epoch 3511/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1805 - val_loss: 8.7475\n",
      "Epoch 3512/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1786 - val_loss: 8.3627\n",
      "Epoch 3513/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1771 - val_loss: 8.6013\n",
      "Epoch 3514/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1788 - val_loss: 6.2162\n",
      "Epoch 3515/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1789 - val_loss: 7.8516\n",
      "Epoch 3516/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1806 - val_loss: 7.0061\n",
      "Epoch 3517/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1803 - val_loss: 10.3369\n",
      "Epoch 3518/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1840 - val_loss: 8.2142\n",
      "Epoch 3519/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1913 - val_loss: 12.6692\n",
      "Epoch 3520/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1913 - val_loss: 15.4028\n",
      "Epoch 3521/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1977 - val_loss: 5.5080\n",
      "Epoch 3522/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4443 - val_loss: 14.9059\n",
      "Epoch 3523/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3138 - val_loss: 13.8498\n",
      "Epoch 3524/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3214 - val_loss: 22.9118\n",
      "Epoch 3525/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2784 - val_loss: 25.2803\n",
      "Epoch 3526/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2571 - val_loss: 19.4666\n",
      "Epoch 3527/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2140 - val_loss: 23.9781\n",
      "Epoch 3528/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2003 - val_loss: 22.9520\n",
      "Epoch 3529/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1877 - val_loss: 19.1680\n",
      "Epoch 3530/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2030 - val_loss: 23.1668\n",
      "Epoch 3531/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1915 - val_loss: 22.6717\n",
      "Epoch 3532/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2116 - val_loss: 33.9085\n",
      "Epoch 3533/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3558 - val_loss: 15.3283\n",
      "Epoch 3534/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2234 - val_loss: 18.5840\n",
      "Epoch 3535/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1892 - val_loss: 17.6222\n",
      "Epoch 3536/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1863 - val_loss: 18.2882\n",
      "Epoch 3537/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1964 - val_loss: 12.7466\n",
      "Epoch 3538/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1944 - val_loss: 13.3163\n",
      "Epoch 3539/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1929 - val_loss: 9.2816\n",
      "Epoch 3540/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2407 - val_loss: 12.3148\n",
      "Epoch 3541/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2043 - val_loss: 16.8613\n",
      "Epoch 3542/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1927 - val_loss: 19.2391\n",
      "Epoch 3543/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1959 - val_loss: 15.7770\n",
      "Epoch 3544/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1878 - val_loss: 9.3905\n",
      "Epoch 3545/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1952 - val_loss: 13.7731\n",
      "Epoch 3546/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1908 - val_loss: 15.3753\n",
      "Epoch 3547/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1797 - val_loss: 20.7652\n",
      "Epoch 3548/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1803 - val_loss: 22.8306\n",
      "Epoch 3549/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1786 - val_loss: 21.1234\n",
      "Epoch 3550/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1764 - val_loss: 23.0676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3551/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1805 - val_loss: 16.8425\n",
      "Epoch 3552/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1813 - val_loss: 17.6383\n",
      "Epoch 3553/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1768 - val_loss: 18.5404\n",
      "Epoch 3554/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1773 - val_loss: 18.7745\n",
      "Epoch 3555/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1776 - val_loss: 23.3806\n",
      "Epoch 3556/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1808 - val_loss: 19.9156\n",
      "Epoch 3557/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1898 - val_loss: 15.1902\n",
      "Epoch 3558/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1958 - val_loss: 12.8201\n",
      "Epoch 3559/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3471 - val_loss: 41.0577\n",
      "Epoch 3560/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2454 - val_loss: 25.7949\n",
      "Epoch 3561/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1907 - val_loss: 22.9104\n",
      "Epoch 3562/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1854 - val_loss: 22.4212\n",
      "Epoch 3563/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1823 - val_loss: 24.0722\n",
      "Epoch 3564/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1860 - val_loss: 20.5936\n",
      "Epoch 3565/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1820 - val_loss: 20.8588\n",
      "Epoch 3566/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1791 - val_loss: 22.5525\n",
      "Epoch 3567/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1800 - val_loss: 27.4741\n",
      "Epoch 3568/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1787 - val_loss: 20.8087\n",
      "Epoch 3569/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1828 - val_loss: 31.3895\n",
      "Epoch 3570/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2019 - val_loss: 21.0997\n",
      "Epoch 3571/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2433 - val_loss: 13.9432\n",
      "Epoch 3572/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2437 - val_loss: 29.8517\n",
      "Epoch 3573/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1901 - val_loss: 32.4111\n",
      "Epoch 3574/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1823 - val_loss: 31.7733\n",
      "Epoch 3575/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1835 - val_loss: 27.1497\n",
      "Epoch 3576/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1829 - val_loss: 17.4204\n",
      "Epoch 3577/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2928 - val_loss: 6.8526\n",
      "Epoch 3578/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3709 - val_loss: 46.4753\n",
      "Epoch 3579/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2633 - val_loss: 36.0644\n",
      "Epoch 3580/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2123 - val_loss: 44.9757\n",
      "Epoch 3581/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1966 - val_loss: 36.0114\n",
      "Epoch 3582/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1832 - val_loss: 32.8869\n",
      "Epoch 3583/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1816 - val_loss: 28.2464\n",
      "Epoch 3584/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1778 - val_loss: 34.1785\n",
      "Epoch 3585/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1803 - val_loss: 34.6793\n",
      "Epoch 3586/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1799 - val_loss: 33.8600\n",
      "Epoch 3587/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1786 - val_loss: 31.3868\n",
      "Epoch 3588/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1812 - val_loss: 30.9102\n",
      "Epoch 3589/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1763 - val_loss: 30.4420\n",
      "Epoch 3590/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1807 - val_loss: 32.8026\n",
      "Epoch 3591/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1766 - val_loss: 30.7713\n",
      "Epoch 3592/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1794 - val_loss: 28.2890\n",
      "Epoch 3593/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1801 - val_loss: 25.7238\n",
      "Epoch 3594/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2126 - val_loss: 32.7990\n",
      "Epoch 3595/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1848 - val_loss: 29.2550\n",
      "Epoch 3596/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1788 - val_loss: 28.2366\n",
      "Epoch 3597/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1776 - val_loss: 32.5428\n",
      "Epoch 3598/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1981 - val_loss: 34.4315\n",
      "Epoch 3599/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1986 - val_loss: 16.7491\n",
      "Epoch 3600/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1894 - val_loss: 20.1650\n",
      "Epoch 3601/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1812 - val_loss: 26.3646\n",
      "Epoch 3602/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1844 - val_loss: 26.3442\n",
      "Epoch 3603/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1766 - val_loss: 26.9579\n",
      "Epoch 3604/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1782 - val_loss: 20.1365\n",
      "Epoch 3605/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1850 - val_loss: 7.6002\n",
      "Epoch 3606/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2154 - val_loss: 11.7833\n",
      "Epoch 3607/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1901 - val_loss: 22.0735\n",
      "Epoch 3608/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1828 - val_loss: 37.7977\n",
      "Epoch 3609/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2058 - val_loss: 13.0132\n",
      "Epoch 3610/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1972 - val_loss: 19.9764\n",
      "Epoch 3611/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3073 - val_loss: 23.5220\n",
      "Epoch 3612/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2564 - val_loss: 25.3625\n",
      "Epoch 3613/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2092 - val_loss: 27.0412\n",
      "Epoch 3614/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2000 - val_loss: 28.4863\n",
      "Epoch 3615/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2384 - val_loss: 19.7838\n",
      "Epoch 3616/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2806 - val_loss: 30.0205\n",
      "Epoch 3617/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2051 - val_loss: 32.8102\n",
      "Epoch 3618/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1994 - val_loss: 31.9171\n",
      "Epoch 3619/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2181 - val_loss: 19.2172\n",
      "Epoch 3620/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1864 - val_loss: 27.1113\n",
      "Epoch 3621/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1808 - val_loss: 34.5766\n",
      "Epoch 3622/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1801 - val_loss: 40.9190\n",
      "Epoch 3623/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1775 - val_loss: 37.0906\n",
      "Epoch 3624/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1780 - val_loss: 37.4071\n",
      "Epoch 3625/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1772 - val_loss: 35.4138\n",
      "Epoch 3626/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1788 - val_loss: 38.8316\n",
      "Epoch 3627/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1785 - val_loss: 27.9976\n",
      "Epoch 3628/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2007 - val_loss: 35.5871\n",
      "Epoch 3629/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1873 - val_loss: 38.9759\n",
      "Epoch 3630/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2778 - val_loss: 26.6523\n",
      "Epoch 3631/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3341 - val_loss: 45.8751\n",
      "Epoch 3632/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1865 - val_loss: 39.5013\n",
      "Epoch 3633/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1803 - val_loss: 41.0458\n",
      "Epoch 3634/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1803 - val_loss: 38.2966\n",
      "Epoch 3635/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1880 - val_loss: 30.3776\n",
      "Epoch 3636/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1865 - val_loss: 31.5546\n",
      "Epoch 3637/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1788 - val_loss: 40.0668\n",
      "Epoch 3638/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1769 - val_loss: 37.3806\n",
      "Epoch 3639/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1775 - val_loss: 27.5940\n",
      "Epoch 3640/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1818 - val_loss: 33.4635\n",
      "Epoch 3641/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1805 - val_loss: 33.5808\n",
      "Epoch 3642/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1799 - val_loss: 32.3502\n",
      "Epoch 3643/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2096 - val_loss: 32.1926\n",
      "Epoch 3644/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2520 - val_loss: 27.7127\n",
      "Epoch 3645/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2077 - val_loss: 17.3228\n",
      "Epoch 3646/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2024 - val_loss: 16.8320\n",
      "Epoch 3647/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2263 - val_loss: 12.0784\n",
      "Epoch 3648/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1948 - val_loss: 37.9265\n",
      "Epoch 3649/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1974 - val_loss: 14.6510\n",
      "Epoch 3650/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1831 - val_loss: 17.4724\n",
      "Epoch 3651/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1836 - val_loss: 25.2579\n",
      "Epoch 3652/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1769 - val_loss: 29.9886\n",
      "Epoch 3653/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1781 - val_loss: 31.7397\n",
      "Epoch 3654/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1773 - val_loss: 24.0965\n",
      "Epoch 3655/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1774 - val_loss: 33.0962\n",
      "Epoch 3656/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1782 - val_loss: 26.1340\n",
      "Epoch 3657/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1780 - val_loss: 30.9057\n",
      "Epoch 3658/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1776 - val_loss: 24.7633\n",
      "Epoch 3659/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1771 - val_loss: 27.3885\n",
      "Epoch 3660/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1781 - val_loss: 22.8326\n",
      "Epoch 3661/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1809 - val_loss: 32.4687\n",
      "Epoch 3662/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1800 - val_loss: 26.5983\n",
      "Epoch 3663/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1781 - val_loss: 25.2065\n",
      "Epoch 3664/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1782 - val_loss: 30.4420\n",
      "Epoch 3665/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1785 - val_loss: 22.2930\n",
      "Epoch 3666/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1790 - val_loss: 30.4760\n",
      "Epoch 3667/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1775 - val_loss: 26.8544\n",
      "Epoch 3668/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1765 - val_loss: 28.5674\n",
      "Epoch 3669/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1852 - val_loss: 22.4286\n",
      "Epoch 3670/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1785 - val_loss: 21.0817\n",
      "Epoch 3671/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1808 - val_loss: 28.7462\n",
      "Epoch 3672/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1800 - val_loss: 23.8378\n",
      "Epoch 3673/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1809 - val_loss: 35.5703\n",
      "Epoch 3674/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1928 - val_loss: 26.7044\n",
      "Epoch 3675/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3534 - val_loss: 25.8263\n",
      "Epoch 3676/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3088 - val_loss: 21.2560\n",
      "Epoch 3677/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2267 - val_loss: 31.2034\n",
      "Epoch 3678/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3695 - val_loss: 40.2869\n",
      "Epoch 3679/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2773 - val_loss: 31.6919\n",
      "Epoch 3680/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1972 - val_loss: 13.4486\n",
      "Epoch 3681/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1886 - val_loss: 14.0747\n",
      "Epoch 3682/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1774 - val_loss: 14.0799\n",
      "Epoch 3683/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1804 - val_loss: 14.0572\n",
      "Epoch 3684/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1813 - val_loss: 19.9044\n",
      "Epoch 3685/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1869 - val_loss: 13.0702\n",
      "Epoch 3686/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1880 - val_loss: 16.4135\n",
      "Epoch 3687/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1818 - val_loss: 13.2187\n",
      "Epoch 3688/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1817 - val_loss: 11.7277\n",
      "Epoch 3689/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1912 - val_loss: 14.1557\n",
      "Epoch 3690/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1775 - val_loss: 13.1391\n",
      "Epoch 3691/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1778 - val_loss: 15.3076\n",
      "Epoch 3692/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1785 - val_loss: 16.2771\n",
      "Epoch 3693/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1783 - val_loss: 17.7144\n",
      "Epoch 3694/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1796 - val_loss: 10.6587\n",
      "Epoch 3695/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1895 - val_loss: 13.6341\n",
      "Epoch 3696/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2103 - val_loss: 11.9303\n",
      "Epoch 3697/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3245 - val_loss: 15.2118\n",
      "Epoch 3698/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3966 - val_loss: 22.5027\n",
      "Epoch 3699/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2659 - val_loss: 23.4173\n",
      "Epoch 3700/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2130 - val_loss: 18.1864\n",
      "Epoch 3701/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1938 - val_loss: 30.2077\n",
      "Epoch 3702/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1812 - val_loss: 19.1098\n",
      "Epoch 3703/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1793 - val_loss: 21.2948\n",
      "Epoch 3704/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1815 - val_loss: 21.1419\n",
      "Epoch 3705/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1790 - val_loss: 20.8456\n",
      "Epoch 3706/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1833 - val_loss: 24.6741\n",
      "Epoch 3707/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1785 - val_loss: 23.5914\n",
      "Epoch 3708/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1891 - val_loss: 24.9421\n",
      "Epoch 3709/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2132 - val_loss: 47.4531\n",
      "Epoch 3710/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2656 - val_loss: 36.5725\n",
      "Epoch 3711/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2053 - val_loss: 40.0292\n",
      "Epoch 3712/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1854 - val_loss: 32.6895\n",
      "Epoch 3713/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1805 - val_loss: 30.5228\n",
      "Epoch 3714/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1835 - val_loss: 26.6365\n",
      "Epoch 3715/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1781 - val_loss: 33.9121\n",
      "Epoch 3716/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1777 - val_loss: 35.0574\n",
      "Epoch 3717/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1757 - val_loss: 32.5612\n",
      "Epoch 3718/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1771 - val_loss: 36.7959\n",
      "Epoch 3719/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1776 - val_loss: 32.3800\n",
      "Epoch 3720/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1907 - val_loss: 37.6653\n",
      "Epoch 3721/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1785 - val_loss: 38.4747\n",
      "Epoch 3722/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1793 - val_loss: 33.2399\n",
      "Epoch 3723/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1782 - val_loss: 38.8222\n",
      "Epoch 3724/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1777 - val_loss: 35.9262\n",
      "Epoch 3725/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2916 - val_loss: 39.6841\n",
      "Epoch 3726/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2345 - val_loss: 15.7265\n",
      "Epoch 3727/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1910 - val_loss: 18.2731\n",
      "Epoch 3728/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1845 - val_loss: 16.7236\n",
      "Epoch 3729/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1990 - val_loss: 34.2403\n",
      "Epoch 3730/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2046 - val_loss: 20.3928\n",
      "Epoch 3731/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2087 - val_loss: 35.8835\n",
      "Epoch 3732/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2457 - val_loss: 38.1684\n",
      "Epoch 3733/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2956 - val_loss: 36.0896\n",
      "Epoch 3734/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2388 - val_loss: 14.8845\n",
      "Epoch 3735/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2336 - val_loss: 26.2598\n",
      "Epoch 3736/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1981 - val_loss: 25.6982\n",
      "Epoch 3737/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2783 - val_loss: 12.3032\n",
      "Epoch 3738/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.6177 - val_loss: 2.3490\n",
      "Epoch 3739/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3200 - val_loss: 2.9219\n",
      "Epoch 3740/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2886 - val_loss: 7.8565\n",
      "Epoch 3741/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2534 - val_loss: 11.8751\n",
      "Epoch 3742/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2369 - val_loss: 11.6132\n",
      "Epoch 3743/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2401 - val_loss: 11.8810\n",
      "Epoch 3744/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2192 - val_loss: 13.0496\n",
      "Epoch 3745/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2137 - val_loss: 10.6364\n",
      "Epoch 3746/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2004 - val_loss: 12.6644\n",
      "Epoch 3747/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1958 - val_loss: 11.3113\n",
      "Epoch 3748/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1945 - val_loss: 10.8816\n",
      "Epoch 3749/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1938 - val_loss: 12.2433\n",
      "Epoch 3750/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1923 - val_loss: 12.0781\n",
      "Epoch 3751/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1905 - val_loss: 10.9338\n",
      "Epoch 3752/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1901 - val_loss: 8.6872\n",
      "Epoch 3753/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1929 - val_loss: 11.2154\n",
      "Epoch 3754/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1957 - val_loss: 14.1393\n",
      "Epoch 3755/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1983 - val_loss: 16.5627\n",
      "Epoch 3756/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1937 - val_loss: 13.2668\n",
      "Epoch 3757/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1862 - val_loss: 11.8623\n",
      "Epoch 3758/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1860 - val_loss: 12.5189\n",
      "Epoch 3759/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1872 - val_loss: 11.7871\n",
      "Epoch 3760/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1858 - val_loss: 11.9401\n",
      "Epoch 3761/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1860 - val_loss: 11.2335\n",
      "Epoch 3762/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1886 - val_loss: 13.3625\n",
      "Epoch 3763/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1865 - val_loss: 10.8195\n",
      "Epoch 3764/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1865 - val_loss: 11.1823\n",
      "Epoch 3765/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1817 - val_loss: 15.5795\n",
      "Epoch 3766/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1876 - val_loss: 17.3637\n",
      "Epoch 3767/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1878 - val_loss: 14.3350\n",
      "Epoch 3768/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1877 - val_loss: 10.0555\n",
      "Epoch 3769/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2240 - val_loss: 8.9992\n",
      "Epoch 3770/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2251 - val_loss: 21.2701\n",
      "Epoch 3771/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2027 - val_loss: 21.3360\n",
      "Epoch 3772/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1871 - val_loss: 15.2710\n",
      "Epoch 3773/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1962 - val_loss: 25.7044\n",
      "Epoch 3774/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1935 - val_loss: 24.9078\n",
      "Epoch 3775/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1927 - val_loss: 24.2801\n",
      "Epoch 3776/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1879 - val_loss: 21.9125\n",
      "Epoch 3777/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1839 - val_loss: 26.8824\n",
      "Epoch 3778/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1862 - val_loss: 18.8974\n",
      "Epoch 3779/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1845 - val_loss: 18.4109\n",
      "Epoch 3780/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1806 - val_loss: 14.7949\n",
      "Epoch 3781/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1948 - val_loss: 21.2466\n",
      "Epoch 3782/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1859 - val_loss: 16.7757\n",
      "Epoch 3783/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1817 - val_loss: 15.5875\n",
      "Epoch 3784/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1831 - val_loss: 15.9352\n",
      "Epoch 3785/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1923 - val_loss: 8.9071\n",
      "Epoch 3786/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.3298 - val_loss: 31.3594\n",
      "Epoch 3787/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3237 - val_loss: 18.4276\n",
      "Epoch 3788/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2477 - val_loss: 17.4985\n",
      "Epoch 3789/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2463 - val_loss: 12.7411\n",
      "Epoch 3790/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2244 - val_loss: 11.1452\n",
      "Epoch 3791/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1994 - val_loss: 6.2897\n",
      "Epoch 3792/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1955 - val_loss: 7.6964\n",
      "Epoch 3793/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2067 - val_loss: 15.7612\n",
      "Epoch 3794/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2022 - val_loss: 9.4185\n",
      "Epoch 3795/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1855 - val_loss: 8.7934\n",
      "Epoch 3796/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2158 - val_loss: 21.4152\n",
      "Epoch 3797/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.7779 - val_loss: 4.6089\n",
      "Epoch 3798/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.5597 - val_loss: 14.0620\n",
      "Epoch 3799/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3238 - val_loss: 10.0105\n",
      "Epoch 3800/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2664 - val_loss: 14.1748\n",
      "Epoch 3801/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2308 - val_loss: 15.7487\n",
      "Epoch 3802/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2159 - val_loss: 17.1439\n",
      "Epoch 3803/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2391 - val_loss: 20.6750\n",
      "Epoch 3804/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2840 - val_loss: 14.5228\n",
      "Epoch 3805/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2324 - val_loss: 11.5132\n",
      "Epoch 3806/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2178 - val_loss: 16.5077\n",
      "Epoch 3807/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2122 - val_loss: 15.0809\n",
      "Epoch 3808/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1937 - val_loss: 13.9127\n",
      "Epoch 3809/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1894 - val_loss: 11.1556\n",
      "Epoch 3810/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1863 - val_loss: 8.5153\n",
      "Epoch 3811/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1904 - val_loss: 9.3982\n",
      "Epoch 3812/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1868 - val_loss: 6.0319\n",
      "Epoch 3813/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1975 - val_loss: 8.0730\n",
      "Epoch 3814/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1973 - val_loss: 8.6897\n",
      "Epoch 3815/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2008 - val_loss: 10.3111\n",
      "Epoch 3816/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1967 - val_loss: 13.9644\n",
      "Epoch 3817/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1876 - val_loss: 14.3515\n",
      "Epoch 3818/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1825 - val_loss: 12.7921\n",
      "Epoch 3819/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1838 - val_loss: 13.4740\n",
      "Epoch 3820/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1845 - val_loss: 14.7472\n",
      "Epoch 3821/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2335 - val_loss: 14.0760\n",
      "Epoch 3822/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2036 - val_loss: 14.5313\n",
      "Epoch 3823/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1973 - val_loss: 16.0682\n",
      "Epoch 3824/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1881 - val_loss: 13.5542\n",
      "Epoch 3825/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1839 - val_loss: 12.7773\n",
      "Epoch 3826/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1810 - val_loss: 15.6454\n",
      "Epoch 3827/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1927 - val_loss: 10.9565\n",
      "Epoch 3828/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2149 - val_loss: 14.0361\n",
      "Epoch 3829/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1888 - val_loss: 16.0390\n",
      "Epoch 3830/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1833 - val_loss: 16.7593\n",
      "Epoch 3831/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1829 - val_loss: 16.4172\n",
      "Epoch 3832/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1860 - val_loss: 14.1168\n",
      "Epoch 3833/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1816 - val_loss: 15.3096\n",
      "Epoch 3834/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1918 - val_loss: 4.7833\n",
      "Epoch 3835/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2942 - val_loss: 23.7805\n",
      "Epoch 3836/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2370 - val_loss: 18.2734\n",
      "Epoch 3837/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2305 - val_loss: 18.3925\n",
      "Epoch 3838/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1910 - val_loss: 14.7673\n",
      "Epoch 3839/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1807 - val_loss: 11.1658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3840/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1823 - val_loss: 15.3232\n",
      "Epoch 3841/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1801 - val_loss: 11.1257\n",
      "Epoch 3842/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1816 - val_loss: 15.3494\n",
      "Epoch 3843/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1842 - val_loss: 15.0270\n",
      "Epoch 3844/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1894 - val_loss: 16.6855\n",
      "Epoch 3845/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1966 - val_loss: 15.9010\n",
      "Epoch 3846/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2130 - val_loss: 12.6918\n",
      "Epoch 3847/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1899 - val_loss: 13.0372\n",
      "Epoch 3848/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1835 - val_loss: 10.8373\n",
      "Epoch 3849/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1825 - val_loss: 17.9105\n",
      "Epoch 3850/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1799 - val_loss: 15.7566\n",
      "Epoch 3851/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1811 - val_loss: 15.5711\n",
      "Epoch 3852/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1807 - val_loss: 15.3902\n",
      "Epoch 3853/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1806 - val_loss: 15.3292\n",
      "Epoch 3854/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1824 - val_loss: 14.5780\n",
      "Epoch 3855/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1846 - val_loss: 11.3614\n",
      "Epoch 3856/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1853 - val_loss: 14.5094\n",
      "Epoch 3857/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1808 - val_loss: 13.2449\n",
      "Epoch 3858/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1801 - val_loss: 13.2793\n",
      "Epoch 3859/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1791 - val_loss: 14.2195\n",
      "Epoch 3860/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1804 - val_loss: 12.7065\n",
      "Epoch 3861/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1795 - val_loss: 16.5853\n",
      "Epoch 3862/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1782 - val_loss: 12.2949\n",
      "Epoch 3863/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1816 - val_loss: 14.3307\n",
      "Epoch 3864/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1884 - val_loss: 10.7039\n",
      "Epoch 3865/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3658 - val_loss: 12.8373\n",
      "Epoch 3866/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3816 - val_loss: 8.1378\n",
      "Epoch 3867/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2546 - val_loss: 22.3599\n",
      "Epoch 3868/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2243 - val_loss: 19.6354\n",
      "Epoch 3869/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2038 - val_loss: 24.4805\n",
      "Epoch 3870/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1894 - val_loss: 22.1996\n",
      "Epoch 3871/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1854 - val_loss: 21.8988\n",
      "Epoch 3872/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1834 - val_loss: 29.6300\n",
      "Epoch 3873/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1879 - val_loss: 26.7358\n",
      "Epoch 3874/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1904 - val_loss: 30.4763\n",
      "Epoch 3875/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1833 - val_loss: 21.1351\n",
      "Epoch 3876/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1816 - val_loss: 19.7306\n",
      "Epoch 3877/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1887 - val_loss: 21.6501\n",
      "Epoch 3878/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1819 - val_loss: 23.0751\n",
      "Epoch 3879/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1817 - val_loss: 25.7453\n",
      "Epoch 3880/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1841 - val_loss: 28.0054\n",
      "Epoch 3881/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1828 - val_loss: 27.2116\n",
      "Epoch 3882/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1838 - val_loss: 24.6436\n",
      "Epoch 3883/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1807 - val_loss: 26.5093\n",
      "Epoch 3884/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1834 - val_loss: 19.1972\n",
      "Epoch 3885/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1801 - val_loss: 26.4011\n",
      "Epoch 3886/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1820 - val_loss: 22.2754\n",
      "Epoch 3887/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1861 - val_loss: 24.9714\n",
      "Epoch 3888/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1823 - val_loss: 22.0617\n",
      "Epoch 3889/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1802 - val_loss: 20.3021\n",
      "Epoch 3890/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1844 - val_loss: 23.8115\n",
      "Epoch 3891/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2082 - val_loss: 18.7636\n",
      "Epoch 3892/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3257 - val_loss: 17.5772\n",
      "Epoch 3893/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2815 - val_loss: 19.6376\n",
      "Epoch 3894/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2923 - val_loss: 20.3245\n",
      "Epoch 3895/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2480 - val_loss: 24.9034\n",
      "Epoch 3896/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2327 - val_loss: 18.9561\n",
      "Epoch 3897/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2477 - val_loss: 21.7906\n",
      "Epoch 3898/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2498 - val_loss: 34.1716\n",
      "Epoch 3899/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2825 - val_loss: 33.0626\n",
      "Epoch 3900/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2792 - val_loss: 26.0214\n",
      "Epoch 3901/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2718 - val_loss: 10.4101\n",
      "Epoch 3902/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2659 - val_loss: 35.9433\n",
      "Epoch 3903/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3068 - val_loss: 23.7544\n",
      "Epoch 3904/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3016 - val_loss: 17.1265\n",
      "Epoch 3905/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2156 - val_loss: 17.2369\n",
      "Epoch 3906/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2126 - val_loss: 18.9312\n",
      "Epoch 3907/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2302 - val_loss: 19.1409\n",
      "Epoch 3908/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2085 - val_loss: 14.1126\n",
      "Epoch 3909/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1991 - val_loss: 14.0519\n",
      "Epoch 3910/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1952 - val_loss: 20.2581\n",
      "Epoch 3911/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2210 - val_loss: 26.8545\n",
      "Epoch 3912/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2186 - val_loss: 11.5247\n",
      "Epoch 3913/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1908 - val_loss: 15.6970\n",
      "Epoch 3914/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1878 - val_loss: 16.0346\n",
      "Epoch 3915/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1857 - val_loss: 18.6809\n",
      "Epoch 3916/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2044 - val_loss: 11.2521\n",
      "Epoch 3917/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1902 - val_loss: 23.8429\n",
      "Epoch 3918/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1846 - val_loss: 20.5419\n",
      "Epoch 3919/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1923 - val_loss: 26.4235\n",
      "Epoch 3920/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1827 - val_loss: 22.6692\n",
      "Epoch 3921/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1832 - val_loss: 17.1923\n",
      "Epoch 3922/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1860 - val_loss: 18.4820\n",
      "Epoch 3923/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1857 - val_loss: 27.9386\n",
      "Epoch 3924/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1888 - val_loss: 20.4385\n",
      "Epoch 3925/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1819 - val_loss: 19.7471\n",
      "Epoch 3926/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1807 - val_loss: 23.2623\n",
      "Epoch 3927/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1824 - val_loss: 22.2324\n",
      "Epoch 3928/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1872 - val_loss: 17.6670\n",
      "Epoch 3929/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2882 - val_loss: 27.9727\n",
      "Epoch 3930/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3047 - val_loss: 19.9554\n",
      "Epoch 3931/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2565 - val_loss: 9.6421\n",
      "Epoch 3932/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3080 - val_loss: 23.5341\n",
      "Epoch 3933/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2062 - val_loss: 24.7511\n",
      "Epoch 3934/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1884 - val_loss: 17.9875\n",
      "Epoch 3935/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1852 - val_loss: 22.3241\n",
      "Epoch 3936/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1812 - val_loss: 21.7051\n",
      "Epoch 3937/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1819 - val_loss: 18.8627\n",
      "Epoch 3938/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2118 - val_loss: 9.2151\n",
      "Epoch 3939/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1999 - val_loss: 10.1661\n",
      "Epoch 3940/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1873 - val_loss: 17.1348\n",
      "Epoch 3941/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1893 - val_loss: 28.6149\n",
      "Epoch 3942/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2155 - val_loss: 6.8704\n",
      "Epoch 3943/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2175 - val_loss: 13.0493\n",
      "Epoch 3944/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1915 - val_loss: 22.5397\n",
      "Epoch 3945/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1984 - val_loss: 20.4507\n",
      "Epoch 3946/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2128 - val_loss: 15.7655\n",
      "Epoch 3947/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1975 - val_loss: 14.3775\n",
      "Epoch 3948/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1842 - val_loss: 18.7972\n",
      "Epoch 3949/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1843 - val_loss: 20.5536\n",
      "Epoch 3950/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1886 - val_loss: 23.7106\n",
      "Epoch 3951/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2484 - val_loss: 34.0292\n",
      "Epoch 3952/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2456 - val_loss: 34.4874\n",
      "Epoch 3953/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2081 - val_loss: 35.2662\n",
      "Epoch 3954/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1868 - val_loss: 46.8630\n",
      "Epoch 3955/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2287 - val_loss: 44.7474\n",
      "Epoch 3956/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2020 - val_loss: 47.2673\n",
      "Epoch 3957/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1907 - val_loss: 42.3196\n",
      "Epoch 3958/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1840 - val_loss: 39.8043\n",
      "Epoch 3959/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1809 - val_loss: 40.2644\n",
      "Epoch 3960/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1835 - val_loss: 42.2986\n",
      "Epoch 3961/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1824 - val_loss: 41.7836\n",
      "Epoch 3962/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1866 - val_loss: 44.0980\n",
      "Epoch 3963/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2299 - val_loss: 37.5130\n",
      "Epoch 3964/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2067 - val_loss: 37.1017\n",
      "Epoch 3965/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1920 - val_loss: 43.5382\n",
      "Epoch 3966/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1878 - val_loss: 38.2532\n",
      "Epoch 3967/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1881 - val_loss: 40.3489\n",
      "Epoch 3968/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1877 - val_loss: 38.5847\n",
      "Epoch 3969/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1854 - val_loss: 37.7822\n",
      "Epoch 3970/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1805 - val_loss: 40.7262\n",
      "Epoch 3971/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1803 - val_loss: 41.3799\n",
      "Epoch 3972/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1813 - val_loss: 42.3700\n",
      "Epoch 3973/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1785 - val_loss: 39.6833\n",
      "Epoch 3974/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1820 - val_loss: 36.6797\n",
      "Epoch 3975/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1830 - val_loss: 39.2290\n",
      "Epoch 3976/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1965 - val_loss: 43.8120\n",
      "Epoch 3977/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2778 - val_loss: 35.4691\n",
      "Epoch 3978/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3101 - val_loss: 40.9068\n",
      "Epoch 3979/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2676 - val_loss: 42.1392\n",
      "Epoch 3980/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2020 - val_loss: 38.1373\n",
      "Epoch 3981/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1835 - val_loss: 35.3533\n",
      "Epoch 3982/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1837 - val_loss: 37.4207\n",
      "Epoch 3983/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1804 - val_loss: 38.8977\n",
      "Epoch 3984/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1849 - val_loss: 42.6355\n",
      "Epoch 3985/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2632 - val_loss: 41.5975\n",
      "Epoch 3986/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2308 - val_loss: 37.6437\n",
      "Epoch 3987/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1846 - val_loss: 40.5969\n",
      "Epoch 3988/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1798 - val_loss: 36.5324\n",
      "Epoch 3989/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1799 - val_loss: 37.6082\n",
      "Epoch 3990/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1794 - val_loss: 36.6321\n",
      "Epoch 3991/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1801 - val_loss: 37.2083\n",
      "Epoch 3992/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1850 - val_loss: 38.5334\n",
      "Epoch 3993/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2467 - val_loss: 37.7971\n",
      "Epoch 3994/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1861 - val_loss: 33.7477\n",
      "Epoch 3995/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1796 - val_loss: 33.5276\n",
      "Epoch 3996/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1790 - val_loss: 39.3449\n",
      "Epoch 3997/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1853 - val_loss: 35.2126\n",
      "Epoch 3998/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1853 - val_loss: 36.9152\n",
      "Epoch 3999/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1841 - val_loss: 33.7763\n",
      "Epoch 4000/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1806 - val_loss: 36.8406\n",
      "Epoch 4001/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1985 - val_loss: 34.1314\n",
      "Epoch 4002/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1845 - val_loss: 36.2797\n",
      "Epoch 4003/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1903 - val_loss: 35.8660\n",
      "Epoch 4004/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1786 - val_loss: 34.3186\n",
      "Epoch 4005/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1790 - val_loss: 29.8491\n",
      "Epoch 4006/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1863 - val_loss: 35.0039\n",
      "Epoch 4007/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1811 - val_loss: 28.0082\n",
      "Epoch 4008/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1988 - val_loss: 41.2268\n",
      "Epoch 4009/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2398 - val_loss: 34.8742\n",
      "Epoch 4010/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2004 - val_loss: 38.1688\n",
      "Epoch 4011/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1904 - val_loss: 36.3587\n",
      "Epoch 4012/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1827 - val_loss: 34.6375\n",
      "Epoch 4013/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2027 - val_loss: 26.2982\n",
      "Epoch 4014/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4910 - val_loss: 3.5990\n",
      "Epoch 4015/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.6919 - val_loss: 19.5091\n",
      "Epoch 4016/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3558 - val_loss: 18.8830\n",
      "Epoch 4017/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2814 - val_loss: 17.4673\n",
      "Epoch 4018/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2567 - val_loss: 19.7175\n",
      "Epoch 4019/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2674 - val_loss: 29.0879\n",
      "Epoch 4020/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2722 - val_loss: 19.3794\n",
      "Epoch 4021/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2345 - val_loss: 16.9698\n",
      "Epoch 4022/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2549 - val_loss: 23.9548\n",
      "Epoch 4023/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2202 - val_loss: 22.3006\n",
      "Epoch 4024/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2099 - val_loss: 19.2819\n",
      "Epoch 4025/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2153 - val_loss: 18.5213\n",
      "Epoch 4026/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2166 - val_loss: 22.2206\n",
      "Epoch 4027/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3158 - val_loss: 16.7449\n",
      "Epoch 4028/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2573 - val_loss: 17.6354\n",
      "Epoch 4029/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2449 - val_loss: 21.7091\n",
      "Epoch 4030/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2148 - val_loss: 16.9451\n",
      "Epoch 4031/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2175 - val_loss: 17.4815\n",
      "Epoch 4032/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2250 - val_loss: 24.6128\n",
      "Epoch 4033/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2186 - val_loss: 18.3692\n",
      "Epoch 4034/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2243 - val_loss: 21.0316\n",
      "Epoch 4035/10000\n",
      "34280/34280 [==============================] - ETA: 0s - loss: 0.209 - 0s 8us/sample - loss: 0.1998 - val_loss: 21.3345\n",
      "Epoch 4036/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1928 - val_loss: 20.0843\n",
      "Epoch 4037/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2021 - val_loss: 20.5184\n",
      "Epoch 4038/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2023 - val_loss: 25.1017\n",
      "Epoch 4039/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1962 - val_loss: 23.8443\n",
      "Epoch 4040/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.2089 - val_loss: 23.6492\n",
      "Epoch 4041/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1947 - val_loss: 26.4815\n",
      "Epoch 4042/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2327 - val_loss: 8.0579\n",
      "Epoch 4043/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2172 - val_loss: 18.6309\n",
      "Epoch 4044/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2125 - val_loss: 16.1058\n",
      "Epoch 4045/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2051 - val_loss: 10.7306\n",
      "Epoch 4046/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2314 - val_loss: 21.2427\n",
      "Epoch 4047/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2097 - val_loss: 21.1322\n",
      "Epoch 4048/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1891 - val_loss: 21.8565\n",
      "Epoch 4049/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1936 - val_loss: 19.6261\n",
      "Epoch 4050/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2061 - val_loss: 17.7484\n",
      "Epoch 4051/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2155 - val_loss: 21.7584\n",
      "Epoch 4052/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2022 - val_loss: 22.8117\n",
      "Epoch 4053/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1909 - val_loss: 22.8020\n",
      "Epoch 4054/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2014 - val_loss: 24.8667\n",
      "Epoch 4055/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1944 - val_loss: 24.7672\n",
      "Epoch 4056/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1973 - val_loss: 24.1479\n",
      "Epoch 4057/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1919 - val_loss: 22.6418\n",
      "Epoch 4058/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1834 - val_loss: 22.4406\n",
      "Epoch 4059/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1863 - val_loss: 22.4823\n",
      "Epoch 4060/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1853 - val_loss: 23.1486\n",
      "Epoch 4061/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1931 - val_loss: 20.9447\n",
      "Epoch 4062/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2084 - val_loss: 24.3427\n",
      "Epoch 4063/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2701 - val_loss: 25.1576\n",
      "Epoch 4064/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2204 - val_loss: 29.0422\n",
      "Epoch 4065/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2376 - val_loss: 20.5252\n",
      "Epoch 4066/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1956 - val_loss: 23.0268\n",
      "Epoch 4067/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1908 - val_loss: 24.9521\n",
      "Epoch 4068/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1933 - val_loss: 25.3956\n",
      "Epoch 4069/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2247 - val_loss: 29.1562\n",
      "Epoch 4070/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2525 - val_loss: 27.0035\n",
      "Epoch 4071/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2038 - val_loss: 24.9042\n",
      "Epoch 4072/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1865 - val_loss: 26.0414\n",
      "Epoch 4073/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1887 - val_loss: 18.7676\n",
      "Epoch 4074/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1975 - val_loss: 25.4780\n",
      "Epoch 4075/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1909 - val_loss: 24.1892\n",
      "Epoch 4076/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1818 - val_loss: 26.7837\n",
      "Epoch 4077/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1876 - val_loss: 26.0035\n",
      "Epoch 4078/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1840 - val_loss: 21.5721\n",
      "Epoch 4079/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2178 - val_loss: 16.6790\n",
      "Epoch 4080/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1987 - val_loss: 20.5333\n",
      "Epoch 4081/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1849 - val_loss: 22.3388\n",
      "Epoch 4082/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1819 - val_loss: 23.8671\n",
      "Epoch 4083/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1845 - val_loss: 20.7131\n",
      "Epoch 4084/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1909 - val_loss: 23.7609\n",
      "Epoch 4085/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1907 - val_loss: 28.5597\n",
      "Epoch 4086/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2274 - val_loss: 12.0887\n",
      "Epoch 4087/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1935 - val_loss: 14.6174\n",
      "Epoch 4088/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1923 - val_loss: 23.2758\n",
      "Epoch 4089/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1875 - val_loss: 27.4903\n",
      "Epoch 4090/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1861 - val_loss: 27.8575\n",
      "Epoch 4091/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1837 - val_loss: 23.5798\n",
      "Epoch 4092/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1810 - val_loss: 25.4506\n",
      "Epoch 4093/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1794 - val_loss: 20.4191\n",
      "Epoch 4094/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1835 - val_loss: 26.0370\n",
      "Epoch 4095/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1813 - val_loss: 24.4405\n",
      "Epoch 4096/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1887 - val_loss: 25.0432\n",
      "Epoch 4097/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1814 - val_loss: 22.0181\n",
      "Epoch 4098/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1869 - val_loss: 21.9041\n",
      "Epoch 4099/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1820 - val_loss: 19.8456\n",
      "Epoch 4100/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1881 - val_loss: 22.1555\n",
      "Epoch 4101/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2151 - val_loss: 21.8502\n",
      "Epoch 4102/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2127 - val_loss: 21.9043\n",
      "Epoch 4103/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2235 - val_loss: 24.8898\n",
      "Epoch 4104/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2010 - val_loss: 26.1269\n",
      "Epoch 4105/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1843 - val_loss: 22.8645\n",
      "Epoch 4106/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1913 - val_loss: 28.4467\n",
      "Epoch 4107/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1891 - val_loss: 24.3016\n",
      "Epoch 4108/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1847 - val_loss: 25.6440\n",
      "Epoch 4109/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1793 - val_loss: 20.1742\n",
      "Epoch 4110/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1818 - val_loss: 24.3410\n",
      "Epoch 4111/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1811 - val_loss: 20.9875\n",
      "Epoch 4112/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1877 - val_loss: 21.2254\n",
      "Epoch 4113/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1994 - val_loss: 16.9505\n",
      "Epoch 4114/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3011 - val_loss: 11.0403\n",
      "Epoch 4115/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3181 - val_loss: 27.3830\n",
      "Epoch 4116/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2949 - val_loss: 17.6400\n",
      "Epoch 4117/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2051 - val_loss: 20.9461\n",
      "Epoch 4118/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2123 - val_loss: 24.8132\n",
      "Epoch 4119/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3200 - val_loss: 5.9176\n",
      "Epoch 4120/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2406 - val_loss: 31.0896\n",
      "Epoch 4121/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1905 - val_loss: 28.9656\n",
      "Epoch 4122/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1869 - val_loss: 29.9514\n",
      "Epoch 4123/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1838 - val_loss: 30.1239\n",
      "Epoch 4124/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1821 - val_loss: 30.7170\n",
      "Epoch 4125/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1766 - val_loss: 30.4121\n",
      "Epoch 4126/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1861 - val_loss: 30.5180\n",
      "Epoch 4127/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1774 - val_loss: 29.3342\n",
      "Epoch 4128/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1831 - val_loss: 29.0728\n",
      "Epoch 4129/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1872 - val_loss: 25.4249\n",
      "Epoch 4130/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1986 - val_loss: 27.5260\n",
      "Epoch 4131/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1820 - val_loss: 27.5687\n",
      "Epoch 4132/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1779 - val_loss: 26.4160\n",
      "Epoch 4133/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1818 - val_loss: 30.2238\n",
      "Epoch 4134/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1804 - val_loss: 29.4819\n",
      "Epoch 4135/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1814 - val_loss: 23.7261\n",
      "Epoch 4136/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2252 - val_loss: 24.9307\n",
      "Epoch 4137/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2246 - val_loss: 31.5657\n",
      "Epoch 4138/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1965 - val_loss: 31.1381\n",
      "Epoch 4139/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1805 - val_loss: 31.4047\n",
      "Epoch 4140/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1905 - val_loss: 32.4081\n",
      "Epoch 4141/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1844 - val_loss: 35.1315\n",
      "Epoch 4142/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1812 - val_loss: 29.6359\n",
      "Epoch 4143/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1796 - val_loss: 27.3322\n",
      "Epoch 4144/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1840 - val_loss: 29.4829\n",
      "Epoch 4145/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1792 - val_loss: 32.5667\n",
      "Epoch 4146/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1809 - val_loss: 33.6462\n",
      "Epoch 4147/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1843 - val_loss: 30.0355\n",
      "Epoch 4148/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1783 - val_loss: 29.9888\n",
      "Epoch 4149/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1773 - val_loss: 30.0578\n",
      "Epoch 4150/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1768 - val_loss: 30.2894\n",
      "Epoch 4151/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1826 - val_loss: 28.1051\n",
      "Epoch 4152/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1856 - val_loss: 29.3288\n",
      "Epoch 4153/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1802 - val_loss: 31.0780\n",
      "Epoch 4154/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1796 - val_loss: 32.7428\n",
      "Epoch 4155/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1869 - val_loss: 27.8404\n",
      "Epoch 4156/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1792 - val_loss: 29.7727\n",
      "Epoch 4157/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1809 - val_loss: 24.8977\n",
      "Epoch 4158/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1909 - val_loss: 29.6213\n",
      "Epoch 4159/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1815 - val_loss: 31.1347\n",
      "Epoch 4160/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1928 - val_loss: 28.2016\n",
      "Epoch 4161/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1898 - val_loss: 25.6534\n",
      "Epoch 4162/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1823 - val_loss: 25.0060\n",
      "Epoch 4163/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1824 - val_loss: 29.7290\n",
      "Epoch 4164/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1806 - val_loss: 23.7131\n",
      "Epoch 4165/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1872 - val_loss: 26.7461\n",
      "Epoch 4166/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1810 - val_loss: 27.3042\n",
      "Epoch 4167/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2182 - val_loss: 31.0869\n",
      "Epoch 4168/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2291 - val_loss: 30.3605\n",
      "Epoch 4169/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2069 - val_loss: 21.0033\n",
      "Epoch 4170/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1850 - val_loss: 23.8170\n",
      "Epoch 4171/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1856 - val_loss: 25.9159\n",
      "Epoch 4172/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1795 - val_loss: 27.2591\n",
      "Epoch 4173/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1794 - val_loss: 23.9625\n",
      "Epoch 4174/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1806 - val_loss: 25.8044\n",
      "Epoch 4175/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2385 - val_loss: 25.4092\n",
      "Epoch 4176/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2454 - val_loss: 16.4184\n",
      "Epoch 4177/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2174 - val_loss: 20.7170\n",
      "Epoch 4178/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2393 - val_loss: 29.9368\n",
      "Epoch 4179/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2827 - val_loss: 8.7817\n",
      "Epoch 4180/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2102 - val_loss: 21.3940\n",
      "Epoch 4181/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1863 - val_loss: 18.4803\n",
      "Epoch 4182/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1851 - val_loss: 26.3966\n",
      "Epoch 4183/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1801 - val_loss: 29.5645\n",
      "Epoch 4184/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1844 - val_loss: 31.5251\n",
      "Epoch 4185/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1840 - val_loss: 32.9122\n",
      "Epoch 4186/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1792 - val_loss: 29.2131\n",
      "Epoch 4187/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1773 - val_loss: 29.8210\n",
      "Epoch 4188/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1770 - val_loss: 32.7125\n",
      "Epoch 4189/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2067 - val_loss: 18.0092\n",
      "Epoch 4190/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2281 - val_loss: 20.1554\n",
      "Epoch 4191/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1948 - val_loss: 22.7409\n",
      "Epoch 4192/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1976 - val_loss: 30.0388\n",
      "Epoch 4193/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2130 - val_loss: 25.1249\n",
      "Epoch 4194/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2489 - val_loss: 31.4660\n",
      "Epoch 4195/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.2000 - val_loss: 25.0146\n",
      "Epoch 4196/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1789 - val_loss: 25.2872\n",
      "Epoch 4197/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1789 - val_loss: 24.9815\n",
      "Epoch 4198/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1784 - val_loss: 25.7321\n",
      "Epoch 4199/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1798 - val_loss: 24.9768\n",
      "Epoch 4200/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1879 - val_loss: 27.2906\n",
      "Epoch 4201/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1832 - val_loss: 27.8196\n",
      "Epoch 4202/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1919 - val_loss: 28.3524\n",
      "Epoch 4203/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1887 - val_loss: 26.3063\n",
      "Epoch 4204/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1845 - val_loss: 29.0051\n",
      "Epoch 4205/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1853 - val_loss: 26.9305\n",
      "Epoch 4206/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1792 - val_loss: 26.4923\n",
      "Epoch 4207/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1800 - val_loss: 27.2878\n",
      "Epoch 4208/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1774 - val_loss: 29.5104\n",
      "Epoch 4209/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1778 - val_loss: 28.9199\n",
      "Epoch 4210/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1881 - val_loss: 19.1341\n",
      "Epoch 4211/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1944 - val_loss: 26.6735\n",
      "Epoch 4212/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1807 - val_loss: 26.5637\n",
      "Epoch 4213/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1828 - val_loss: 25.1291\n",
      "Epoch 4214/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1814 - val_loss: 28.6413\n",
      "Epoch 4215/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1775 - val_loss: 26.8005\n",
      "Epoch 4216/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1757 - val_loss: 27.5207\n",
      "Epoch 4217/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1796 - val_loss: 25.0011\n",
      "Epoch 4218/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2056 - val_loss: 21.5041\n",
      "Epoch 4219/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3656 - val_loss: 34.1830\n",
      "Epoch 4220/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2774 - val_loss: 24.4649\n",
      "Epoch 4221/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2096 - val_loss: 21.6009\n",
      "Epoch 4222/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2601 - val_loss: 24.4769\n",
      "Epoch 4223/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3408 - val_loss: 19.7174\n",
      "Epoch 4224/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2669 - val_loss: 22.4451\n",
      "Epoch 4225/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2400 - val_loss: 23.1536\n",
      "Epoch 4226/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1869 - val_loss: 22.6539\n",
      "Epoch 4227/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1804 - val_loss: 23.3612\n",
      "Epoch 4228/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1780 - val_loss: 22.0036\n",
      "Epoch 4229/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1803 - val_loss: 26.1545\n",
      "Epoch 4230/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1802 - val_loss: 23.5838\n",
      "Epoch 4231/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1875 - val_loss: 25.2075\n",
      "Epoch 4232/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1912 - val_loss: 27.2762\n",
      "Epoch 4233/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1814 - val_loss: 25.5860\n",
      "Epoch 4234/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1779 - val_loss: 24.9757\n",
      "Epoch 4235/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1779 - val_loss: 25.0559\n",
      "Epoch 4236/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1783 - val_loss: 26.3827\n",
      "Epoch 4237/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1783 - val_loss: 24.5230\n",
      "Epoch 4238/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1786 - val_loss: 25.3929\n",
      "Epoch 4239/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1873 - val_loss: 26.0931\n",
      "Epoch 4240/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2092 - val_loss: 22.4481\n",
      "Epoch 4241/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1822 - val_loss: 20.7364\n",
      "Epoch 4242/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2073 - val_loss: 25.0309\n",
      "Epoch 4243/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1859 - val_loss: 23.8458\n",
      "Epoch 4244/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2617 - val_loss: 32.3163\n",
      "Epoch 4245/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2234 - val_loss: 24.4544\n",
      "Epoch 4246/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1966 - val_loss: 23.4390\n",
      "Epoch 4247/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2067 - val_loss: 22.2574\n",
      "Epoch 4248/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1823 - val_loss: 21.5813\n",
      "Epoch 4249/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1811 - val_loss: 23.5880\n",
      "Epoch 4250/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1757 - val_loss: 22.6527\n",
      "Epoch 4251/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1783 - val_loss: 25.5936\n",
      "Epoch 4252/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1978 - val_loss: 22.2115\n",
      "Epoch 4253/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2187 - val_loss: 25.6719\n",
      "Epoch 4254/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1845 - val_loss: 24.1236\n",
      "Epoch 4255/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1784 - val_loss: 25.0184\n",
      "Epoch 4256/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1778 - val_loss: 25.5068\n",
      "Epoch 4257/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1766 - val_loss: 25.0328\n",
      "Epoch 4258/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1759 - val_loss: 25.8413\n",
      "Epoch 4259/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1769 - val_loss: 27.6724\n",
      "Epoch 4260/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1830 - val_loss: 24.6446\n",
      "Epoch 4261/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1793 - val_loss: 24.1564\n",
      "Epoch 4262/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1775 - val_loss: 23.7010\n",
      "Epoch 4263/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1786 - val_loss: 22.7462\n",
      "Epoch 4264/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1774 - val_loss: 23.8616\n",
      "Epoch 4265/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1780 - val_loss: 23.3367\n",
      "Epoch 4266/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1771 - val_loss: 22.6245\n",
      "Epoch 4267/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1757 - val_loss: 24.4905\n",
      "Epoch 4268/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1763 - val_loss: 24.0014\n",
      "Epoch 4269/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1774 - val_loss: 22.9366\n",
      "Epoch 4270/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1787 - val_loss: 22.2257\n",
      "Epoch 4271/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1772 - val_loss: 23.7968\n",
      "Epoch 4272/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1770 - val_loss: 21.8138\n",
      "Epoch 4273/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1768 - val_loss: 22.8317\n",
      "Epoch 4274/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1773 - val_loss: 24.3933\n",
      "Epoch 4275/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2233 - val_loss: 14.4830\n",
      "Epoch 4276/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2747 - val_loss: 20.1457\n",
      "Epoch 4277/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1872 - val_loss: 21.1779\n",
      "Epoch 4278/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1941 - val_loss: 18.7142\n",
      "Epoch 4279/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2267 - val_loss: 18.1930\n",
      "Epoch 4280/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2813 - val_loss: 26.6370\n",
      "Epoch 4281/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2396 - val_loss: 19.2964\n",
      "Epoch 4282/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1977 - val_loss: 19.2164\n",
      "Epoch 4283/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1812 - val_loss: 21.8605\n",
      "Epoch 4284/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1780 - val_loss: 22.8601\n",
      "Epoch 4285/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1774 - val_loss: 23.6732\n",
      "Epoch 4286/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1779 - val_loss: 23.2048\n",
      "Epoch 4287/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1778 - val_loss: 23.8723\n",
      "Epoch 4288/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1773 - val_loss: 23.4812\n",
      "Epoch 4289/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1761 - val_loss: 22.0440\n",
      "Epoch 4290/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1763 - val_loss: 22.8688\n",
      "Epoch 4291/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1758 - val_loss: 23.1330\n",
      "Epoch 4292/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1779 - val_loss: 23.4995\n",
      "Epoch 4293/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1830 - val_loss: 22.4317\n",
      "Epoch 4294/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1859 - val_loss: 22.6796\n",
      "Epoch 4295/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1781 - val_loss: 21.4754\n",
      "Epoch 4296/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1754 - val_loss: 22.8438\n",
      "Epoch 4297/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1765 - val_loss: 24.3916\n",
      "Epoch 4298/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1747 - val_loss: 22.8305\n",
      "Epoch 4299/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1746 - val_loss: 21.5871\n",
      "Epoch 4300/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1773 - val_loss: 22.8953\n",
      "Epoch 4301/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1778 - val_loss: 23.0249\n",
      "Epoch 4302/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1865 - val_loss: 18.3436\n",
      "Epoch 4303/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1857 - val_loss: 20.9352\n",
      "Epoch 4304/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.5230 - val_loss: 8.0758\n",
      "Epoch 4305/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3682 - val_loss: 14.7152\n",
      "Epoch 4306/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3021 - val_loss: 25.3703\n",
      "Epoch 4307/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2445 - val_loss: 25.6164\n",
      "Epoch 4308/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2341 - val_loss: 15.9239\n",
      "Epoch 4309/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2232 - val_loss: 18.6317\n",
      "Epoch 4310/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2090 - val_loss: 22.8874\n",
      "Epoch 4311/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2168 - val_loss: 19.9528\n",
      "Epoch 4312/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1937 - val_loss: 19.1584\n",
      "Epoch 4313/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1906 - val_loss: 22.8542\n",
      "Epoch 4314/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1918 - val_loss: 18.0782\n",
      "Epoch 4315/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2013 - val_loss: 18.8793\n",
      "Epoch 4316/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2360 - val_loss: 22.2832\n",
      "Epoch 4317/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2457 - val_loss: 25.7468\n",
      "Epoch 4318/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2261 - val_loss: 33.5436\n",
      "Epoch 4319/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3136 - val_loss: 33.4801\n",
      "Epoch 4320/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2363 - val_loss: 36.8226\n",
      "Epoch 4321/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2104 - val_loss: 24.9686\n",
      "Epoch 4322/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2029 - val_loss: 28.9804\n",
      "Epoch 4323/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1821 - val_loss: 29.1935\n",
      "Epoch 4324/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1920 - val_loss: 31.7928\n",
      "Epoch 4325/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1850 - val_loss: 28.9082\n",
      "Epoch 4326/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1841 - val_loss: 32.3737\n",
      "Epoch 4327/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1852 - val_loss: 32.4497\n",
      "Epoch 4328/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1787 - val_loss: 31.2019\n",
      "Epoch 4329/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1770 - val_loss: 28.8571\n",
      "Epoch 4330/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1788 - val_loss: 31.7646\n",
      "Epoch 4331/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1777 - val_loss: 30.1225\n",
      "Epoch 4332/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1755 - val_loss: 29.1090\n",
      "Epoch 4333/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1770 - val_loss: 28.3336\n",
      "Epoch 4334/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1768 - val_loss: 28.1125\n",
      "Epoch 4335/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1789 - val_loss: 29.3607\n",
      "Epoch 4336/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1794 - val_loss: 29.2866\n",
      "Epoch 4337/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1772 - val_loss: 28.0468\n",
      "Epoch 4338/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1761 - val_loss: 30.6566\n",
      "Epoch 4339/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1777 - val_loss: 30.6638\n",
      "Epoch 4340/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1779 - val_loss: 27.3679\n",
      "Epoch 4341/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1780 - val_loss: 30.2965\n",
      "Epoch 4342/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1780 - val_loss: 30.7590\n",
      "Epoch 4343/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1747 - val_loss: 29.9997\n",
      "Epoch 4344/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1767 - val_loss: 31.7142\n",
      "Epoch 4345/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1778 - val_loss: 28.8546\n",
      "Epoch 4346/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1773 - val_loss: 31.6749\n",
      "Epoch 4347/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1779 - val_loss: 30.3922\n",
      "Epoch 4348/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1775 - val_loss: 30.6483\n",
      "Epoch 4349/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1753 - val_loss: 29.5915\n",
      "Epoch 4350/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1770 - val_loss: 29.9476\n",
      "Epoch 4351/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1768 - val_loss: 32.6242\n",
      "Epoch 4352/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1795 - val_loss: 28.4257\n",
      "Epoch 4353/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1748 - val_loss: 28.1305\n",
      "Epoch 4354/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1781 - val_loss: 32.1859\n",
      "Epoch 4355/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1808 - val_loss: 32.1312\n",
      "Epoch 4356/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1827 - val_loss: 30.5251\n",
      "Epoch 4357/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1905 - val_loss: 31.8239\n",
      "Epoch 4358/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2430 - val_loss: 27.5067\n",
      "Epoch 4359/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3096 - val_loss: 28.9681\n",
      "Epoch 4360/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2655 - val_loss: 29.7567\n",
      "Epoch 4361/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2158 - val_loss: 24.9365\n",
      "Epoch 4362/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2617 - val_loss: 40.6940\n",
      "Epoch 4363/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.5314 - val_loss: 32.4227\n",
      "Epoch 4364/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2189 - val_loss: 29.2963\n",
      "Epoch 4365/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1906 - val_loss: 28.6077\n",
      "Epoch 4366/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1811 - val_loss: 28.6604\n",
      "Epoch 4367/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1884 - val_loss: 30.8011\n",
      "Epoch 4368/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2332 - val_loss: 16.5641\n",
      "Epoch 4369/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2957 - val_loss: 20.6765\n",
      "Epoch 4370/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1952 - val_loss: 19.2197\n",
      "Epoch 4371/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1835 - val_loss: 20.8105\n",
      "Epoch 4372/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1812 - val_loss: 22.2169\n",
      "Epoch 4373/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1781 - val_loss: 21.6828\n",
      "Epoch 4374/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1790 - val_loss: 26.9794\n",
      "Epoch 4375/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1861 - val_loss: 24.7594\n",
      "Epoch 4376/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1803 - val_loss: 24.4993\n",
      "Epoch 4377/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1779 - val_loss: 23.9084\n",
      "Epoch 4378/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1838 - val_loss: 28.1296\n",
      "Epoch 4379/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1838 - val_loss: 27.0241\n",
      "Epoch 4380/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1765 - val_loss: 26.4517\n",
      "Epoch 4381/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1765 - val_loss: 24.4993\n",
      "Epoch 4382/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1775 - val_loss: 27.1107\n",
      "Epoch 4383/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1766 - val_loss: 25.1781\n",
      "Epoch 4384/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1758 - val_loss: 26.4526\n",
      "Epoch 4385/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1769 - val_loss: 26.6899\n",
      "Epoch 4386/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1761 - val_loss: 26.6284\n",
      "Epoch 4387/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1759 - val_loss: 26.6287\n",
      "Epoch 4388/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1773 - val_loss: 21.9426\n",
      "Epoch 4389/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2010 - val_loss: 26.1291\n",
      "Epoch 4390/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1792 - val_loss: 23.9672\n",
      "Epoch 4391/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1802 - val_loss: 26.2282\n",
      "Epoch 4392/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1775 - val_loss: 26.7232\n",
      "Epoch 4393/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1790 - val_loss: 26.1896\n",
      "Epoch 4394/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1790 - val_loss: 25.0410\n",
      "Epoch 4395/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2272 - val_loss: 30.2914\n",
      "Epoch 4396/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3385 - val_loss: 22.0833\n",
      "Epoch 4397/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3170 - val_loss: 31.0922\n",
      "Epoch 4398/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2392 - val_loss: 31.5026\n",
      "Epoch 4399/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2273 - val_loss: 34.9341\n",
      "Epoch 4400/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2263 - val_loss: 25.0060\n",
      "Epoch 4401/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1873 - val_loss: 27.2269\n",
      "Epoch 4402/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1823 - val_loss: 27.2054\n",
      "Epoch 4403/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2126 - val_loss: 23.1788\n",
      "Epoch 4404/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1858 - val_loss: 27.0098\n",
      "Epoch 4405/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1785 - val_loss: 27.4857\n",
      "Epoch 4406/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1795 - val_loss: 28.4927\n",
      "Epoch 4407/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2010 - val_loss: 25.6154\n",
      "Epoch 4408/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1825 - val_loss: 28.8192\n",
      "Epoch 4409/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1757 - val_loss: 26.8086\n",
      "Epoch 4410/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1782 - val_loss: 28.5853\n",
      "Epoch 4411/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1782 - val_loss: 26.9180\n",
      "Epoch 4412/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1780 - val_loss: 26.8802\n",
      "Epoch 4413/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1891 - val_loss: 27.7843\n",
      "Epoch 4414/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1789 - val_loss: 27.0584\n",
      "Epoch 4415/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1755 - val_loss: 27.1804\n",
      "Epoch 4416/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1776 - val_loss: 27.2094\n",
      "Epoch 4417/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1787 - val_loss: 27.4623\n",
      "Epoch 4418/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1780 - val_loss: 27.1272\n",
      "Epoch 4419/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1771 - val_loss: 29.2789\n",
      "Epoch 4420/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1755 - val_loss: 29.8564\n",
      "Epoch 4421/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1764 - val_loss: 27.4137\n",
      "Epoch 4422/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1759 - val_loss: 28.2014\n",
      "Epoch 4423/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1767 - val_loss: 29.6101\n",
      "Epoch 4424/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1779 - val_loss: 25.9131\n",
      "Epoch 4425/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2091 - val_loss: 26.2901\n",
      "Epoch 4426/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1842 - val_loss: 29.7778\n",
      "Epoch 4427/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2173 - val_loss: 21.7351\n",
      "Epoch 4428/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1880 - val_loss: 26.1564\n",
      "Epoch 4429/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1791 - val_loss: 26.9358\n",
      "Epoch 4430/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1804 - val_loss: 29.5617\n",
      "Epoch 4431/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1810 - val_loss: 29.8621\n",
      "Epoch 4432/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1774 - val_loss: 28.0031\n",
      "Epoch 4433/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1758 - val_loss: 26.6059\n",
      "Epoch 4434/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1951 - val_loss: 31.1770\n",
      "Epoch 4435/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1981 - val_loss: 26.7410\n",
      "Epoch 4436/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2021 - val_loss: 23.9299\n",
      "Epoch 4437/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2150 - val_loss: 26.2214\n",
      "Epoch 4438/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2000 - val_loss: 29.8156\n",
      "Epoch 4439/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3398 - val_loss: 14.6092\n",
      "Epoch 4440/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2755 - val_loss: 22.6920\n",
      "Epoch 4441/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2233 - val_loss: 21.7610\n",
      "Epoch 4442/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2723 - val_loss: 26.1413\n",
      "Epoch 4443/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2517 - val_loss: 36.1412\n",
      "Epoch 4444/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2271 - val_loss: 25.7259\n",
      "Epoch 4445/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2268 - val_loss: 28.1280\n",
      "Epoch 4446/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2211 - val_loss: 24.1026\n",
      "Epoch 4447/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1933 - val_loss: 21.1653\n",
      "Epoch 4448/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1842 - val_loss: 16.9531\n",
      "Epoch 4449/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1787 - val_loss: 19.5763\n",
      "Epoch 4450/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2249 - val_loss: 24.0899\n",
      "Epoch 4451/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2649 - val_loss: 13.8268\n",
      "Epoch 4452/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2269 - val_loss: 24.3256\n",
      "Epoch 4453/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1892 - val_loss: 21.9012\n",
      "Epoch 4454/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1812 - val_loss: 24.5565\n",
      "Epoch 4455/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1854 - val_loss: 24.5442\n",
      "Epoch 4456/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1776 - val_loss: 24.3695\n",
      "Epoch 4457/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1787 - val_loss: 26.6845\n",
      "Epoch 4458/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1776 - val_loss: 25.2266\n",
      "Epoch 4459/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1777 - val_loss: 25.2769\n",
      "Epoch 4460/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1774 - val_loss: 24.7772\n",
      "Epoch 4461/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1779 - val_loss: 23.3870\n",
      "Epoch 4462/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1754 - val_loss: 25.8696\n",
      "Epoch 4463/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1768 - val_loss: 24.4198\n",
      "Epoch 4464/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1763 - val_loss: 25.1891\n",
      "Epoch 4465/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1777 - val_loss: 25.4469\n",
      "Epoch 4466/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1850 - val_loss: 23.9530\n",
      "Epoch 4467/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1814 - val_loss: 25.0121\n",
      "Epoch 4468/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1790 - val_loss: 26.0462\n",
      "Epoch 4469/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1769 - val_loss: 24.0105\n",
      "Epoch 4470/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1739 - val_loss: 26.0956\n",
      "Epoch 4471/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1768 - val_loss: 25.9611\n",
      "Epoch 4472/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1763 - val_loss: 26.7802\n",
      "Epoch 4473/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1748 - val_loss: 26.0384\n",
      "Epoch 4474/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1757 - val_loss: 27.0500\n",
      "Epoch 4475/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1746 - val_loss: 25.2884\n",
      "Epoch 4476/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1792 - val_loss: 23.2290\n",
      "Epoch 4477/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1756 - val_loss: 24.0249\n",
      "Epoch 4478/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1748 - val_loss: 25.7733\n",
      "Epoch 4479/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1770 - val_loss: 23.6107\n",
      "Epoch 4480/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1807 - val_loss: 22.5910\n",
      "Epoch 4481/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2423 - val_loss: 22.3553\n",
      "Epoch 4482/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3249 - val_loss: 19.7456\n",
      "Epoch 4483/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2787 - val_loss: 23.2752\n",
      "Epoch 4484/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1879 - val_loss: 27.6398\n",
      "Epoch 4485/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2152 - val_loss: 25.1608\n",
      "Epoch 4486/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1961 - val_loss: 28.8491\n",
      "Epoch 4487/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1931 - val_loss: 31.3580\n",
      "Epoch 4488/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1794 - val_loss: 30.5118\n",
      "Epoch 4489/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1772 - val_loss: 31.9173\n",
      "Epoch 4490/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1757 - val_loss: 32.3395\n",
      "Epoch 4491/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1808 - val_loss: 32.1988\n",
      "Epoch 4492/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1754 - val_loss: 29.7317\n",
      "Epoch 4493/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1761 - val_loss: 27.1358\n",
      "Epoch 4494/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1801 - val_loss: 31.7912\n",
      "Epoch 4495/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1779 - val_loss: 32.5933\n",
      "Epoch 4496/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1755 - val_loss: 32.6527\n",
      "Epoch 4497/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1775 - val_loss: 29.8905\n",
      "Epoch 4498/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 30.8714\n",
      "Epoch 4499/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1755 - val_loss: 32.5399\n",
      "Epoch 4500/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1784 - val_loss: 28.2005\n",
      "Epoch 4501/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1815 - val_loss: 27.7363\n",
      "Epoch 4502/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1767 - val_loss: 30.7493\n",
      "Epoch 4503/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1767 - val_loss: 30.3606\n",
      "Epoch 4504/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1764 - val_loss: 30.8523\n",
      "Epoch 4505/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1771 - val_loss: 29.0961\n",
      "Epoch 4506/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1779 - val_loss: 29.7633\n",
      "Epoch 4507/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1757 - val_loss: 28.4972\n",
      "Epoch 4508/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2005 - val_loss: 28.2549\n",
      "Epoch 4509/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3161 - val_loss: 22.1020\n",
      "Epoch 4510/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2085 - val_loss: 25.0021\n",
      "Epoch 4511/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1941 - val_loss: 25.0155\n",
      "Epoch 4512/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1816 - val_loss: 29.6446\n",
      "Epoch 4513/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1963 - val_loss: 26.7639\n",
      "Epoch 4514/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1824 - val_loss: 27.9627\n",
      "Epoch 4515/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1773 - val_loss: 28.5216\n",
      "Epoch 4516/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 27.8861\n",
      "Epoch 4517/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1781 - val_loss: 29.8939\n",
      "Epoch 4518/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1880 - val_loss: 28.6284\n",
      "Epoch 4519/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1778 - val_loss: 28.3625\n",
      "Epoch 4520/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1765 - val_loss: 28.4924\n",
      "Epoch 4521/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1758 - val_loss: 28.1940\n",
      "Epoch 4522/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1760 - val_loss: 28.2012\n",
      "Epoch 4523/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1764 - val_loss: 28.8046\n",
      "Epoch 4524/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1750 - val_loss: 30.0949\n",
      "Epoch 4525/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1771 - val_loss: 27.7700\n",
      "Epoch 4526/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1772 - val_loss: 32.2396\n",
      "Epoch 4527/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1992 - val_loss: 29.0778\n",
      "Epoch 4528/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1974 - val_loss: 23.4202\n",
      "Epoch 4529/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1914 - val_loss: 24.1673\n",
      "Epoch 4530/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1793 - val_loss: 26.6431\n",
      "Epoch 4531/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1787 - val_loss: 26.2966\n",
      "Epoch 4532/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1762 - val_loss: 27.8359\n",
      "Epoch 4533/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1780 - val_loss: 23.8648\n",
      "Epoch 4534/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1786 - val_loss: 26.7201\n",
      "Epoch 4535/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1815 - val_loss: 26.9994\n",
      "Epoch 4536/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2143 - val_loss: 26.8107\n",
      "Epoch 4537/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3196 - val_loss: 31.9221\n",
      "Epoch 4538/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2669 - val_loss: 27.0634\n",
      "Epoch 4539/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2023 - val_loss: 17.9260\n",
      "Epoch 4540/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2153 - val_loss: 23.9889\n",
      "Epoch 4541/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1844 - val_loss: 26.3937\n",
      "Epoch 4542/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1792 - val_loss: 21.3487\n",
      "Epoch 4543/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1910 - val_loss: 25.4971\n",
      "Epoch 4544/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1799 - val_loss: 25.5003\n",
      "Epoch 4545/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1774 - val_loss: 27.6690\n",
      "Epoch 4546/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1762 - val_loss: 25.9200\n",
      "Epoch 4547/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1761 - val_loss: 29.0768\n",
      "Epoch 4548/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1781 - val_loss: 28.5317\n",
      "Epoch 4549/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1769 - val_loss: 28.4692\n",
      "Epoch 4550/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1763 - val_loss: 27.6754\n",
      "Epoch 4551/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1742 - val_loss: 26.7023\n",
      "Epoch 4552/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1766 - val_loss: 27.7597\n",
      "Epoch 4553/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1771 - val_loss: 25.8896\n",
      "Epoch 4554/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1779 - val_loss: 24.6141\n",
      "Epoch 4555/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1842 - val_loss: 26.5278\n",
      "Epoch 4556/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1805 - val_loss: 23.9856\n",
      "Epoch 4557/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1772 - val_loss: 26.3452\n",
      "Epoch 4558/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1777 - val_loss: 25.8285\n",
      "Epoch 4559/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1742 - val_loss: 26.2393\n",
      "Epoch 4560/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1769 - val_loss: 25.1261\n",
      "Epoch 4561/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1753 - val_loss: 27.0241\n",
      "Epoch 4562/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1749 - val_loss: 26.0587\n",
      "Epoch 4563/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 26.8888\n",
      "Epoch 4564/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1762 - val_loss: 28.2144\n",
      "Epoch 4565/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1940 - val_loss: 18.2459\n",
      "Epoch 4566/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1984 - val_loss: 25.6431\n",
      "Epoch 4567/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3006 - val_loss: 32.3764\n",
      "Epoch 4568/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2214 - val_loss: 25.6038\n",
      "Epoch 4569/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2240 - val_loss: 35.3169\n",
      "Epoch 4570/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3916 - val_loss: 24.0779\n",
      "Epoch 4571/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3308 - val_loss: 27.5746\n",
      "Epoch 4572/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3385 - val_loss: 42.7208\n",
      "Epoch 4573/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2324 - val_loss: 33.7276\n",
      "Epoch 4574/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2302 - val_loss: 26.9649\n",
      "Epoch 4575/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1820 - val_loss: 28.0196\n",
      "Epoch 4576/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2217 - val_loss: 26.1482\n",
      "Epoch 4577/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2136 - val_loss: 22.8880\n",
      "Epoch 4578/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2125 - val_loss: 23.3441\n",
      "Epoch 4579/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1833 - val_loss: 22.9870\n",
      "Epoch 4580/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1779 - val_loss: 24.2128\n",
      "Epoch 4581/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1771 - val_loss: 23.3499\n",
      "Epoch 4582/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1742 - val_loss: 24.9404\n",
      "Epoch 4583/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1768 - val_loss: 23.0751\n",
      "Epoch 4584/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1771 - val_loss: 23.5911\n",
      "Epoch 4585/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1756 - val_loss: 23.7304\n",
      "Epoch 4586/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1740 - val_loss: 22.6694\n",
      "Epoch 4587/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1767 - val_loss: 23.5049\n",
      "Epoch 4588/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1755 - val_loss: 24.9619\n",
      "Epoch 4589/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1759 - val_loss: 23.8092\n",
      "Epoch 4590/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1754 - val_loss: 24.0017\n",
      "Epoch 4591/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1765 - val_loss: 23.0040\n",
      "Epoch 4592/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1740 - val_loss: 23.5160\n",
      "Epoch 4593/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1755 - val_loss: 26.4515\n",
      "Epoch 4594/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1756 - val_loss: 22.4202\n",
      "Epoch 4595/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1764 - val_loss: 25.6745\n",
      "Epoch 4596/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1758 - val_loss: 24.0388\n",
      "Epoch 4597/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1877 - val_loss: 18.9759\n",
      "Epoch 4598/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2460 - val_loss: 21.2176\n",
      "Epoch 4599/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3157 - val_loss: 41.6533\n",
      "Epoch 4600/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2991 - val_loss: 41.1799\n",
      "Epoch 4601/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2910 - val_loss: 30.4646\n",
      "Epoch 4602/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2175 - val_loss: 29.1605\n",
      "Epoch 4603/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2875 - val_loss: 26.3274\n",
      "Epoch 4604/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2247 - val_loss: 33.8648\n",
      "Epoch 4605/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1901 - val_loss: 27.3942\n",
      "Epoch 4606/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1776 - val_loss: 27.4758\n",
      "Epoch 4607/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1772 - val_loss: 26.1809\n",
      "Epoch 4608/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1803 - val_loss: 24.5013\n",
      "Epoch 4609/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1934 - val_loss: 29.8845\n",
      "Epoch 4610/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1796 - val_loss: 29.4630\n",
      "Epoch 4611/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1818 - val_loss: 28.6902\n",
      "Epoch 4612/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1794 - val_loss: 27.5407\n",
      "Epoch 4613/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1787 - val_loss: 22.4438\n",
      "Epoch 4614/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1777 - val_loss: 27.7414\n",
      "Epoch 4615/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1770 - val_loss: 27.8635\n",
      "Epoch 4616/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1747 - val_loss: 25.9536\n",
      "Epoch 4617/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1753 - val_loss: 26.6737\n",
      "Epoch 4618/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1797 - val_loss: 20.7859\n",
      "Epoch 4619/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1801 - val_loss: 26.3558\n",
      "Epoch 4620/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1761 - val_loss: 24.4796\n",
      "Epoch 4621/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1766 - val_loss: 26.0641\n",
      "Epoch 4622/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 25.5515\n",
      "Epoch 4623/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1758 - val_loss: 25.0990\n",
      "Epoch 4624/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1752 - val_loss: 27.2320\n",
      "Epoch 4625/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 28.5923\n",
      "Epoch 4626/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1761 - val_loss: 26.6309\n",
      "Epoch 4627/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1761 - val_loss: 25.9406\n",
      "Epoch 4628/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1768 - val_loss: 27.4420\n",
      "Epoch 4629/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1769 - val_loss: 27.5002\n",
      "Epoch 4630/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1752 - val_loss: 24.8170\n",
      "Epoch 4631/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1757 - val_loss: 27.7514\n",
      "Epoch 4632/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1791 - val_loss: 28.2808\n",
      "Epoch 4633/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2047 - val_loss: 30.2356\n",
      "Epoch 4634/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2458 - val_loss: 30.7229\n",
      "Epoch 4635/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2275 - val_loss: 31.2585\n",
      "Epoch 4636/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1981 - val_loss: 28.0405\n",
      "Epoch 4637/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2402 - val_loss: 12.4163\n",
      "Epoch 4638/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1998 - val_loss: 12.1464\n",
      "Epoch 4639/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1904 - val_loss: 11.5858\n",
      "Epoch 4640/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1916 - val_loss: 17.9736\n",
      "Epoch 4641/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1835 - val_loss: 17.1772\n",
      "Epoch 4642/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1778 - val_loss: 17.2457\n",
      "Epoch 4643/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1802 - val_loss: 19.5196\n",
      "Epoch 4644/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1792 - val_loss: 20.5298\n",
      "Epoch 4645/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1777 - val_loss: 18.4357\n",
      "Epoch 4646/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1758 - val_loss: 20.2936\n",
      "Epoch 4647/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1830 - val_loss: 19.3795\n",
      "Epoch 4648/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1789 - val_loss: 17.6718\n",
      "Epoch 4649/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2181 - val_loss: 32.7656\n",
      "Epoch 4650/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3775 - val_loss: 34.6275\n",
      "Epoch 4651/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2172 - val_loss: 25.4812\n",
      "Epoch 4652/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1821 - val_loss: 27.8631\n",
      "Epoch 4653/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1754 - val_loss: 26.7907\n",
      "Epoch 4654/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1769 - val_loss: 27.4749\n",
      "Epoch 4655/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1771 - val_loss: 27.7609\n",
      "Epoch 4656/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1760 - val_loss: 26.1227\n",
      "Epoch 4657/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1892 - val_loss: 26.4719\n",
      "Epoch 4658/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1790 - val_loss: 26.3678\n",
      "Epoch 4659/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1772 - val_loss: 25.6279\n",
      "Epoch 4660/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1761 - val_loss: 27.7826\n",
      "Epoch 4661/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1741 - val_loss: 27.5211\n",
      "Epoch 4662/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 29.1576\n",
      "Epoch 4663/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 28.6223\n",
      "Epoch 4664/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1751 - val_loss: 23.9033\n",
      "Epoch 4665/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1762 - val_loss: 24.4284\n",
      "Epoch 4666/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2071 - val_loss: 29.9155\n",
      "Epoch 4667/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2344 - val_loss: 14.1498\n",
      "Epoch 4668/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2596 - val_loss: 27.9935\n",
      "Epoch 4669/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2663 - val_loss: 22.5421\n",
      "Epoch 4670/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2504 - val_loss: 33.6821\n",
      "Epoch 4671/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2240 - val_loss: 33.9177\n",
      "Epoch 4672/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2080 - val_loss: 21.0301\n",
      "Epoch 4673/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1947 - val_loss: 23.0361\n",
      "Epoch 4674/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4323 - val_loss: 30.3403\n",
      "Epoch 4675/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2978 - val_loss: 33.1650\n",
      "Epoch 4676/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1890 - val_loss: 35.7805\n",
      "Epoch 4677/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1816 - val_loss: 33.2514\n",
      "Epoch 4678/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1797 - val_loss: 32.9819\n",
      "Epoch 4679/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1762 - val_loss: 33.1966\n",
      "Epoch 4680/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1766 - val_loss: 31.0589\n",
      "Epoch 4681/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1774 - val_loss: 31.5374\n",
      "Epoch 4682/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1760 - val_loss: 31.7030\n",
      "Epoch 4683/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1765 - val_loss: 28.7268\n",
      "Epoch 4684/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1820 - val_loss: 29.8156\n",
      "Epoch 4685/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1794 - val_loss: 35.2396\n",
      "Epoch 4686/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1860 - val_loss: 28.4751\n",
      "Epoch 4687/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2041 - val_loss: 27.2353\n",
      "Epoch 4688/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1854 - val_loss: 30.3047\n",
      "Epoch 4689/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1823 - val_loss: 31.0798\n",
      "Epoch 4690/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1791 - val_loss: 29.3687\n",
      "Epoch 4691/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1744 - val_loss: 28.5520\n",
      "Epoch 4692/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1749 - val_loss: 31.2440\n",
      "Epoch 4693/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1746 - val_loss: 28.8382\n",
      "Epoch 4694/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1740 - val_loss: 30.4865\n",
      "Epoch 4695/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1762 - val_loss: 30.5272\n",
      "Epoch 4696/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1778 - val_loss: 30.3858\n",
      "Epoch 4697/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1779 - val_loss: 30.4008\n",
      "Epoch 4698/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 29.0689\n",
      "Epoch 4699/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1756 - val_loss: 30.6246\n",
      "Epoch 4700/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1763 - val_loss: 28.4301\n",
      "Epoch 4701/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1758 - val_loss: 29.0879\n",
      "Epoch 4702/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1767 - val_loss: 27.5695\n",
      "Epoch 4703/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1845 - val_loss: 31.4136\n",
      "Epoch 4704/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1969 - val_loss: 33.1306\n",
      "Epoch 4705/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1974 - val_loss: 25.6703\n",
      "Epoch 4706/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2009 - val_loss: 33.9602\n",
      "Epoch 4707/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2036 - val_loss: 24.8713\n",
      "Epoch 4708/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2080 - val_loss: 34.1033\n",
      "Epoch 4709/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2006 - val_loss: 38.7236\n",
      "Epoch 4710/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1891 - val_loss: 31.7114\n",
      "Epoch 4711/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1833 - val_loss: 33.5520\n",
      "Epoch 4712/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1815 - val_loss: 31.5575\n",
      "Epoch 4713/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1755 - val_loss: 30.0078\n",
      "Epoch 4714/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1762 - val_loss: 30.9610\n",
      "Epoch 4715/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1755 - val_loss: 29.5794\n",
      "Epoch 4716/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1763 - val_loss: 27.7301\n",
      "Epoch 4717/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1764 - val_loss: 31.0854\n",
      "Epoch 4718/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1754 - val_loss: 27.9672\n",
      "Epoch 4719/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1754 - val_loss: 28.4410\n",
      "Epoch 4720/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1741 - val_loss: 29.3540\n",
      "Epoch 4721/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1742 - val_loss: 31.6229\n",
      "Epoch 4722/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1743 - val_loss: 31.5398\n",
      "Epoch 4723/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1743 - val_loss: 32.0524\n",
      "Epoch 4724/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1796 - val_loss: 29.9715\n",
      "Epoch 4725/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1782 - val_loss: 27.5714\n",
      "Epoch 4726/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1806 - val_loss: 31.3912\n",
      "Epoch 4727/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1832 - val_loss: 31.3031\n",
      "Epoch 4728/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1759 - val_loss: 30.3597\n",
      "Epoch 4729/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 27.5685\n",
      "Epoch 4730/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1742 - val_loss: 31.6055\n",
      "Epoch 4731/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1881 - val_loss: 30.9034\n",
      "Epoch 4732/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4190 - val_loss: 44.1861\n",
      "Epoch 4733/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.6545 - val_loss: 20.4649\n",
      "Epoch 4734/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4124 - val_loss: 16.1753\n",
      "Epoch 4735/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3322 - val_loss: 28.5363\n",
      "Epoch 4736/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3469 - val_loss: 29.3507\n",
      "Epoch 4737/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3162 - val_loss: 35.8200\n",
      "Epoch 4738/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2523 - val_loss: 35.3440\n",
      "Epoch 4739/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2419 - val_loss: 31.9771\n",
      "Epoch 4740/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2174 - val_loss: 35.1183\n",
      "Epoch 4741/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2158 - val_loss: 32.7646\n",
      "Epoch 4742/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2290 - val_loss: 29.7469\n",
      "Epoch 4743/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2294 - val_loss: 29.9838\n",
      "Epoch 4744/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2612 - val_loss: 24.2193\n",
      "Epoch 4745/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3435 - val_loss: 39.4908\n",
      "Epoch 4746/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2532 - val_loss: 42.9061\n",
      "Epoch 4747/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.2297 - val_loss: 34.8757\n",
      "Epoch 4748/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2269 - val_loss: 35.6652\n",
      "Epoch 4749/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2021 - val_loss: 35.9636\n",
      "Epoch 4750/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2006 - val_loss: 38.9976\n",
      "Epoch 4751/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2016 - val_loss: 35.3231\n",
      "Epoch 4752/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2064 - val_loss: 34.2351\n",
      "Epoch 4753/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2019 - val_loss: 35.4406\n",
      "Epoch 4754/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2322 - val_loss: 36.8722\n",
      "Epoch 4755/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2374 - val_loss: 36.0263\n",
      "Epoch 4756/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2538 - val_loss: 33.4758\n",
      "Epoch 4757/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2194 - val_loss: 34.8954\n",
      "Epoch 4758/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2016 - val_loss: 34.4926\n",
      "Epoch 4759/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1960 - val_loss: 35.1016\n",
      "Epoch 4760/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1902 - val_loss: 36.8259\n",
      "Epoch 4761/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1891 - val_loss: 36.5797\n",
      "Epoch 4762/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1896 - val_loss: 35.3799\n",
      "Epoch 4763/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1903 - val_loss: 35.4704\n",
      "Epoch 4764/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1905 - val_loss: 36.1998\n",
      "Epoch 4765/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1860 - val_loss: 35.7540\n",
      "Epoch 4766/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1834 - val_loss: 35.3348\n",
      "Epoch 4767/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1872 - val_loss: 35.8243\n",
      "Epoch 4768/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1989 - val_loss: 35.3618\n",
      "Epoch 4769/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1968 - val_loss: 32.8365\n",
      "Epoch 4770/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2165 - val_loss: 31.4931\n",
      "Epoch 4771/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2041 - val_loss: 34.2651\n",
      "Epoch 4772/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1959 - val_loss: 34.7659\n",
      "Epoch 4773/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1917 - val_loss: 35.4951\n",
      "Epoch 4774/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1925 - val_loss: 35.8568\n",
      "Epoch 4775/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1989 - val_loss: 35.2884\n",
      "Epoch 4776/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1886 - val_loss: 36.2630\n",
      "Epoch 4777/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1834 - val_loss: 35.8380\n",
      "Epoch 4778/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1909 - val_loss: 35.0136\n",
      "Epoch 4779/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1882 - val_loss: 36.9955\n",
      "Epoch 4780/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1868 - val_loss: 37.2811\n",
      "Epoch 4781/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1842 - val_loss: 36.0174\n",
      "Epoch 4782/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1872 - val_loss: 36.2311\n",
      "Epoch 4783/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1988 - val_loss: 28.4085\n",
      "Epoch 4784/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2709 - val_loss: 36.4022\n",
      "Epoch 4785/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2013 - val_loss: 38.0629\n",
      "Epoch 4786/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1981 - val_loss: 32.8760\n",
      "Epoch 4787/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2108 - val_loss: 30.1416\n",
      "Epoch 4788/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2094 - val_loss: 38.9475\n",
      "Epoch 4789/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1950 - val_loss: 34.6410\n",
      "Epoch 4790/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1896 - val_loss: 34.0220\n",
      "Epoch 4791/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1952 - val_loss: 35.6667\n",
      "Epoch 4792/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1914 - val_loss: 35.4695\n",
      "Epoch 4793/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1838 - val_loss: 37.9979\n",
      "Epoch 4794/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2393 - val_loss: 38.8938\n",
      "Epoch 4795/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2278 - val_loss: 33.9377\n",
      "Epoch 4796/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2440 - val_loss: 36.0087\n",
      "Epoch 4797/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1853 - val_loss: 35.7640\n",
      "Epoch 4798/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1905 - val_loss: 36.0613\n",
      "Epoch 4799/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1839 - val_loss: 37.0641\n",
      "Epoch 4800/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1850 - val_loss: 36.0277\n",
      "Epoch 4801/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1864 - val_loss: 36.6426\n",
      "Epoch 4802/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1871 - val_loss: 34.8820\n",
      "Epoch 4803/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1829 - val_loss: 36.4856\n",
      "Epoch 4804/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1829 - val_loss: 37.4778\n",
      "Epoch 4805/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2092 - val_loss: 34.2503\n",
      "Epoch 4806/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2135 - val_loss: 34.0814\n",
      "Epoch 4807/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1966 - val_loss: 35.3821\n",
      "Epoch 4808/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1957 - val_loss: 34.9773\n",
      "Epoch 4809/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1919 - val_loss: 37.2286\n",
      "Epoch 4810/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1864 - val_loss: 36.1901\n",
      "Epoch 4811/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1896 - val_loss: 36.9972\n",
      "Epoch 4812/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2773 - val_loss: 35.4831\n",
      "Epoch 4813/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.3238 - val_loss: 29.3603\n",
      "Epoch 4814/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2603 - val_loss: 36.7582\n",
      "Epoch 4815/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2068 - val_loss: 35.9696\n",
      "Epoch 4816/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2007 - val_loss: 36.1521\n",
      "Epoch 4817/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1929 - val_loss: 35.2257\n",
      "Epoch 4818/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1848 - val_loss: 34.1998\n",
      "Epoch 4819/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1886 - val_loss: 34.1874\n",
      "Epoch 4820/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1859 - val_loss: 35.2053\n",
      "Epoch 4821/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1835 - val_loss: 35.0960\n",
      "Epoch 4822/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1845 - val_loss: 36.1387\n",
      "Epoch 4823/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1821 - val_loss: 35.1893\n",
      "Epoch 4824/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1861 - val_loss: 33.6535\n",
      "Epoch 4825/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1813 - val_loss: 32.4022\n",
      "Epoch 4826/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1795 - val_loss: 31.5952\n",
      "Epoch 4827/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2040 - val_loss: 34.8210\n",
      "Epoch 4828/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1912 - val_loss: 33.9010\n",
      "Epoch 4829/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1835 - val_loss: 34.9108\n",
      "Epoch 4830/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1858 - val_loss: 32.7216\n",
      "Epoch 4831/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1883 - val_loss: 35.4713\n",
      "Epoch 4832/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1822 - val_loss: 33.6708\n",
      "Epoch 4833/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1805 - val_loss: 33.5248\n",
      "Epoch 4834/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1859 - val_loss: 35.2197\n",
      "Epoch 4835/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2564 - val_loss: 32.6783\n",
      "Epoch 4836/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1922 - val_loss: 30.3836\n",
      "Epoch 4837/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1793 - val_loss: 31.8494\n",
      "Epoch 4838/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1783 - val_loss: 30.9037\n",
      "Epoch 4839/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1795 - val_loss: 32.5370\n",
      "Epoch 4840/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1814 - val_loss: 32.8065\n",
      "Epoch 4841/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1831 - val_loss: 30.7015\n",
      "Epoch 4842/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1877 - val_loss: 31.0468\n",
      "Epoch 4843/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1825 - val_loss: 30.4141\n",
      "Epoch 4844/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1791 - val_loss: 31.4616\n",
      "Epoch 4845/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1763 - val_loss: 30.4780\n",
      "Epoch 4846/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1783 - val_loss: 30.7312\n",
      "Epoch 4847/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1802 - val_loss: 32.1969\n",
      "Epoch 4848/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1841 - val_loss: 28.4697\n",
      "Epoch 4849/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1982 - val_loss: 32.3949\n",
      "Epoch 4850/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1999 - val_loss: 30.2856\n",
      "Epoch 4851/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2633 - val_loss: 30.5313\n",
      "Epoch 4852/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2491 - val_loss: 29.4299\n",
      "Epoch 4853/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1947 - val_loss: 28.1200\n",
      "Epoch 4854/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1868 - val_loss: 31.2417\n",
      "Epoch 4855/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1813 - val_loss: 27.1603\n",
      "Epoch 4856/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1866 - val_loss: 30.2761\n",
      "Epoch 4857/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1784 - val_loss: 29.3863\n",
      "Epoch 4858/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1792 - val_loss: 31.9034\n",
      "Epoch 4859/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1881 - val_loss: 29.1593\n",
      "Epoch 4860/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1955 - val_loss: 30.0829\n",
      "Epoch 4861/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2443 - val_loss: 26.4260\n",
      "Epoch 4862/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2105 - val_loss: 30.4316\n",
      "Epoch 4863/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1900 - val_loss: 31.3304\n",
      "Epoch 4864/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2245 - val_loss: 27.7741\n",
      "Epoch 4865/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1885 - val_loss: 29.0105\n",
      "Epoch 4866/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1790 - val_loss: 29.4296\n",
      "Epoch 4867/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1781 - val_loss: 30.6487\n",
      "Epoch 4868/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1773 - val_loss: 26.7863\n",
      "Epoch 4869/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1783 - val_loss: 27.5377\n",
      "Epoch 4870/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1763 - val_loss: 30.1097\n",
      "Epoch 4871/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1767 - val_loss: 29.7787\n",
      "Epoch 4872/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1775 - val_loss: 29.0017\n",
      "Epoch 4873/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1752 - val_loss: 28.4555\n",
      "Epoch 4874/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1759 - val_loss: 27.2133\n",
      "Epoch 4875/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1755 - val_loss: 28.3790\n",
      "Epoch 4876/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1771 - val_loss: 28.1914\n",
      "Epoch 4877/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1781 - val_loss: 27.0311\n",
      "Epoch 4878/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1756 - val_loss: 27.7627\n",
      "Epoch 4879/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1887 - val_loss: 28.8749\n",
      "Epoch 4880/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1806 - val_loss: 27.4416\n",
      "Epoch 4881/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1803 - val_loss: 29.2433\n",
      "Epoch 4882/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1794 - val_loss: 29.4764\n",
      "Epoch 4883/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1760 - val_loss: 29.0305\n",
      "Epoch 4884/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1776 - val_loss: 28.9122\n",
      "Epoch 4885/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1793 - val_loss: 31.6919\n",
      "Epoch 4886/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1879 - val_loss: 30.6624\n",
      "Epoch 4887/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1841 - val_loss: 29.4242\n",
      "Epoch 4888/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1778 - val_loss: 30.3807\n",
      "Epoch 4889/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1769 - val_loss: 30.3080\n",
      "Epoch 4890/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1764 - val_loss: 28.6960\n",
      "Epoch 4891/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1839 - val_loss: 31.5329\n",
      "Epoch 4892/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1851 - val_loss: 31.0543\n",
      "Epoch 4893/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1972 - val_loss: 30.0087\n",
      "Epoch 4894/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2698 - val_loss: 27.9967\n",
      "Epoch 4895/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2442 - val_loss: 29.2297\n",
      "Epoch 4896/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2208 - val_loss: 27.9840\n",
      "Epoch 4897/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1953 - val_loss: 33.4558\n",
      "Epoch 4898/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1838 - val_loss: 32.9360\n",
      "Epoch 4899/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1869 - val_loss: 30.8942\n",
      "Epoch 4900/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1797 - val_loss: 36.2358\n",
      "Epoch 4901/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1784 - val_loss: 33.2901\n",
      "Epoch 4902/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1966 - val_loss: 28.7504\n",
      "Epoch 4903/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2332 - val_loss: 33.8105\n",
      "Epoch 4904/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2730 - val_loss: 31.4794\n",
      "Epoch 4905/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1970 - val_loss: 34.1915\n",
      "Epoch 4906/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1834 - val_loss: 31.6645\n",
      "Epoch 4907/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1776 - val_loss: 33.0468\n",
      "Epoch 4908/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1765 - val_loss: 32.7300\n",
      "Epoch 4909/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1778 - val_loss: 33.9665\n",
      "Epoch 4910/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2302 - val_loss: 34.4973\n",
      "Epoch 4911/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.3586 - val_loss: 37.2284\n",
      "Epoch 4912/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2181 - val_loss: 35.8354\n",
      "Epoch 4913/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1864 - val_loss: 36.4972\n",
      "Epoch 4914/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1833 - val_loss: 36.1302\n",
      "Epoch 4915/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1775 - val_loss: 34.7594\n",
      "Epoch 4916/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1782 - val_loss: 36.6068\n",
      "Epoch 4917/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1787 - val_loss: 35.3613\n",
      "Epoch 4918/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1770 - val_loss: 34.2797\n",
      "Epoch 4919/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1776 - val_loss: 36.5547\n",
      "Epoch 4920/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1778 - val_loss: 36.2870\n",
      "Epoch 4921/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1786 - val_loss: 34.0503\n",
      "Epoch 4922/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1805 - val_loss: 34.6842\n",
      "Epoch 4923/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1765 - val_loss: 35.6662\n",
      "Epoch 4924/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1764 - val_loss: 34.5393\n",
      "Epoch 4925/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1942 - val_loss: 31.8993\n",
      "Epoch 4926/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1900 - val_loss: 35.6611\n",
      "Epoch 4927/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1784 - val_loss: 33.9251\n",
      "Epoch 4928/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1888 - val_loss: 31.2256\n",
      "Epoch 4929/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1788 - val_loss: 33.9479\n",
      "Epoch 4930/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1767 - val_loss: 35.8732\n",
      "Epoch 4931/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1761 - val_loss: 36.1211\n",
      "Epoch 4932/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1811 - val_loss: 34.3982\n",
      "Epoch 4933/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1791 - val_loss: 36.6746\n",
      "Epoch 4934/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1825 - val_loss: 32.7222\n",
      "Epoch 4935/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1755 - val_loss: 35.2015\n",
      "Epoch 4936/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1753 - val_loss: 35.8935\n",
      "Epoch 4937/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1766 - val_loss: 35.3079\n",
      "Epoch 4938/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1772 - val_loss: 34.6049\n",
      "Epoch 4939/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1748 - val_loss: 33.2888\n",
      "Epoch 4940/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 35.1577\n",
      "Epoch 4941/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1760 - val_loss: 36.0610\n",
      "Epoch 4942/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1872 - val_loss: 36.5883\n",
      "Epoch 4943/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2637 - val_loss: 28.2130\n",
      "Epoch 4944/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2585 - val_loss: 29.1984\n",
      "Epoch 4945/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2043 - val_loss: 33.7070\n",
      "Epoch 4946/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2538 - val_loss: 36.4078\n",
      "Epoch 4947/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2094 - val_loss: 34.7170\n",
      "Epoch 4948/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1922 - val_loss: 34.1925\n",
      "Epoch 4949/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2226 - val_loss: 34.5179\n",
      "Epoch 4950/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1802 - val_loss: 32.9048\n",
      "Epoch 4951/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1770 - val_loss: 32.6596\n",
      "Epoch 4952/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 33.3133\n",
      "Epoch 4953/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1774 - val_loss: 34.6811\n",
      "Epoch 4954/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1767 - val_loss: 32.0884\n",
      "Epoch 4955/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1817 - val_loss: 32.6465\n",
      "Epoch 4956/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1802 - val_loss: 36.1814\n",
      "Epoch 4957/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1776 - val_loss: 34.5767\n",
      "Epoch 4958/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1783 - val_loss: 35.7879\n",
      "Epoch 4959/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1817 - val_loss: 33.9092\n",
      "Epoch 4960/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1771 - val_loss: 34.7883\n",
      "Epoch 4961/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1764 - val_loss: 35.2071\n",
      "Epoch 4962/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1742 - val_loss: 36.2279\n",
      "Epoch 4963/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1792 - val_loss: 34.3261\n",
      "Epoch 4964/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1778 - val_loss: 35.3177\n",
      "Epoch 4965/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1802 - val_loss: 37.1960\n",
      "Epoch 4966/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1772 - val_loss: 35.1745\n",
      "Epoch 4967/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1752 - val_loss: 35.6706\n",
      "Epoch 4968/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1799 - val_loss: 35.6132\n",
      "Epoch 4969/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1776 - val_loss: 35.6740\n",
      "Epoch 4970/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1779 - val_loss: 33.8069\n",
      "Epoch 4971/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1791 - val_loss: 35.5468\n",
      "Epoch 4972/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1792 - val_loss: 34.8853\n",
      "Epoch 4973/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1825 - val_loss: 32.1455\n",
      "Epoch 4974/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1852 - val_loss: 33.5382\n",
      "Epoch 4975/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1765 - val_loss: 32.7591\n",
      "Epoch 4976/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1739 - val_loss: 36.4018\n",
      "Epoch 4977/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1778 - val_loss: 33.0155\n",
      "Epoch 4978/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2860 - val_loss: 24.9319\n",
      "Epoch 4979/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.5952 - val_loss: 26.6950\n",
      "Epoch 4980/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3073 - val_loss: 22.3014\n",
      "Epoch 4981/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2215 - val_loss: 20.1296\n",
      "Epoch 4982/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1946 - val_loss: 23.0896\n",
      "Epoch 4983/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2282 - val_loss: 28.7080\n",
      "Epoch 4984/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.5919 - val_loss: 33.4781\n",
      "Epoch 4985/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3094 - val_loss: 35.9346\n",
      "Epoch 4986/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2401 - val_loss: 34.1485\n",
      "Epoch 4987/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2170 - val_loss: 33.3541\n",
      "Epoch 4988/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2009 - val_loss: 35.3127\n",
      "Epoch 4989/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2434 - val_loss: 18.1625\n",
      "Epoch 4990/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2710 - val_loss: 34.1268\n",
      "Epoch 4991/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2293 - val_loss: 37.2432\n",
      "Epoch 4992/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2037 - val_loss: 36.4333\n",
      "Epoch 4993/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1916 - val_loss: 34.8029\n",
      "Epoch 4994/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1820 - val_loss: 35.5100\n",
      "Epoch 4995/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1792 - val_loss: 34.1216\n",
      "Epoch 4996/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1811 - val_loss: 33.3420\n",
      "Epoch 4997/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1786 - val_loss: 33.3947\n",
      "Epoch 4998/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1778 - val_loss: 33.9539\n",
      "Epoch 4999/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1797 - val_loss: 33.7386\n",
      "Epoch 5000/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1797 - val_loss: 34.0457\n",
      "Epoch 5001/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1786 - val_loss: 34.5492\n",
      "Epoch 5002/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1764 - val_loss: 33.8029\n",
      "Epoch 5003/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1756 - val_loss: 33.0097\n",
      "Epoch 5004/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1770 - val_loss: 32.7008\n",
      "Epoch 5005/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1770 - val_loss: 32.8401\n",
      "Epoch 5006/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1777 - val_loss: 32.9739\n",
      "Epoch 5007/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1790 - val_loss: 32.8318\n",
      "Epoch 5008/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1773 - val_loss: 31.3218\n",
      "Epoch 5009/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1763 - val_loss: 32.9964\n",
      "Epoch 5010/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1805 - val_loss: 35.0353\n",
      "Epoch 5011/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1799 - val_loss: 35.8674\n",
      "Epoch 5012/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2267 - val_loss: 33.0751\n",
      "Epoch 5013/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2031 - val_loss: 32.6586\n",
      "Epoch 5014/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2099 - val_loss: 30.1101\n",
      "Epoch 5015/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2086 - val_loss: 31.2001\n",
      "Epoch 5016/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1814 - val_loss: 32.3113\n",
      "Epoch 5017/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1823 - val_loss: 33.1471\n",
      "Epoch 5018/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1758 - val_loss: 32.8928\n",
      "Epoch 5019/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1765 - val_loss: 33.2058\n",
      "Epoch 5020/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1756 - val_loss: 32.3053\n",
      "Epoch 5021/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1740 - val_loss: 32.7750\n",
      "Epoch 5022/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1741 - val_loss: 33.1269\n",
      "Epoch 5023/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1762 - val_loss: 32.7176\n",
      "Epoch 5024/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1746 - val_loss: 32.2571\n",
      "Epoch 5025/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1750 - val_loss: 32.1226\n",
      "Epoch 5026/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1763 - val_loss: 30.5475\n",
      "Epoch 5027/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1758 - val_loss: 31.5883\n",
      "Epoch 5028/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1772 - val_loss: 30.9072\n",
      "Epoch 5029/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1772 - val_loss: 31.5670\n",
      "Epoch 5030/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1742 - val_loss: 31.5402\n",
      "Epoch 5031/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1754 - val_loss: 32.1069\n",
      "Epoch 5032/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 30.8217\n",
      "Epoch 5033/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1869 - val_loss: 34.2552\n",
      "Epoch 5034/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1776 - val_loss: 32.3463\n",
      "Epoch 5035/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1798 - val_loss: 35.5755\n",
      "Epoch 5036/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2151 - val_loss: 30.6767\n",
      "Epoch 5037/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3731 - val_loss: 39.3166\n",
      "Epoch 5038/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3149 - val_loss: 34.6219\n",
      "Epoch 5039/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2042 - val_loss: 31.7737\n",
      "Epoch 5040/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2238 - val_loss: 37.1166\n",
      "Epoch 5041/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1859 - val_loss: 33.0745\n",
      "Epoch 5042/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1812 - val_loss: 35.3819\n",
      "Epoch 5043/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1783 - val_loss: 37.2064\n",
      "Epoch 5044/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1832 - val_loss: 33.5049\n",
      "Epoch 5045/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1771 - val_loss: 36.3263\n",
      "Epoch 5046/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1761 - val_loss: 33.9566\n",
      "Epoch 5047/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1751 - val_loss: 35.1231\n",
      "Epoch 5048/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1753 - val_loss: 35.6332\n",
      "Epoch 5049/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1744 - val_loss: 33.9451\n",
      "Epoch 5050/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1754 - val_loss: 35.2446\n",
      "Epoch 5051/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1751 - val_loss: 34.7142\n",
      "Epoch 5052/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 35.4812\n",
      "Epoch 5053/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1755 - val_loss: 34.5674\n",
      "Epoch 5054/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1741 - val_loss: 35.5203\n",
      "Epoch 5055/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 35.8309\n",
      "Epoch 5056/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1759 - val_loss: 35.8571\n",
      "Epoch 5057/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1757 - val_loss: 36.2226\n",
      "Epoch 5058/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 34.8568\n",
      "Epoch 5059/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1752 - val_loss: 35.8245\n",
      "Epoch 5060/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1756 - val_loss: 36.2280\n",
      "Epoch 5061/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1740 - val_loss: 35.3994\n",
      "Epoch 5062/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1752 - val_loss: 36.0369\n",
      "Epoch 5063/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1749 - val_loss: 36.2289\n",
      "Epoch 5064/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1760 - val_loss: 34.9034\n",
      "Epoch 5065/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1745 - val_loss: 35.1365\n",
      "Epoch 5066/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1742 - val_loss: 36.5222\n",
      "Epoch 5067/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1792 - val_loss: 36.3950\n",
      "Epoch 5068/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1740 - val_loss: 37.9456\n",
      "Epoch 5069/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1774 - val_loss: 38.4120\n",
      "Epoch 5070/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2629 - val_loss: 41.0102\n",
      "Epoch 5071/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4248 - val_loss: 27.5838\n",
      "Epoch 5072/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2428 - val_loss: 32.0024\n",
      "Epoch 5073/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2258 - val_loss: 31.3094\n",
      "Epoch 5074/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2383 - val_loss: 31.7520\n",
      "Epoch 5075/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2270 - val_loss: 21.0403\n",
      "Epoch 5076/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2293 - val_loss: 21.8000\n",
      "Epoch 5077/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2871 - val_loss: 26.5176\n",
      "Epoch 5078/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2154 - val_loss: 22.3014\n",
      "Epoch 5079/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1916 - val_loss: 24.0774\n",
      "Epoch 5080/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1823 - val_loss: 23.1923\n",
      "Epoch 5081/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1824 - val_loss: 26.0846\n",
      "Epoch 5082/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1823 - val_loss: 22.6645\n",
      "Epoch 5083/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1761 - val_loss: 21.8161\n",
      "Epoch 5084/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1843 - val_loss: 27.3927\n",
      "Epoch 5085/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2611 - val_loss: 27.6874\n",
      "Epoch 5086/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3229 - val_loss: 27.9324\n",
      "Epoch 5087/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2634 - val_loss: 26.3935\n",
      "Epoch 5088/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2341 - val_loss: 20.9298\n",
      "Epoch 5089/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2049 - val_loss: 27.7767\n",
      "Epoch 5090/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1936 - val_loss: 27.7074\n",
      "Epoch 5091/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1826 - val_loss: 25.5012\n",
      "Epoch 5092/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1773 - val_loss: 24.9758\n",
      "Epoch 5093/10000\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 0.1749 - val_loss: 27.5544\n",
      "Epoch 5094/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1755 - val_loss: 26.6867\n",
      "Epoch 5095/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1760 - val_loss: 26.8340\n",
      "Epoch 5096/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1763 - val_loss: 26.2625\n",
      "Epoch 5097/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1750 - val_loss: 26.1714\n",
      "Epoch 5098/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1753 - val_loss: 26.2460\n",
      "Epoch 5099/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1764 - val_loss: 27.1779\n",
      "Epoch 5100/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1763 - val_loss: 27.7541\n",
      "Epoch 5101/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1771 - val_loss: 28.5391\n",
      "Epoch 5102/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1770 - val_loss: 26.9695\n",
      "Epoch 5103/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1749 - val_loss: 28.7650\n",
      "Epoch 5104/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1747 - val_loss: 26.7607\n",
      "Epoch 5105/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1836 - val_loss: 25.0363\n",
      "Epoch 5106/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1775 - val_loss: 28.0761\n",
      "Epoch 5107/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1769 - val_loss: 26.8709\n",
      "Epoch 5108/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1762 - val_loss: 23.4104\n",
      "Epoch 5109/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1785 - val_loss: 27.7040\n",
      "Epoch 5110/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1771 - val_loss: 25.0511\n",
      "Epoch 5111/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1738 - val_loss: 26.5497\n",
      "Epoch 5112/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1765 - val_loss: 27.6824\n",
      "Epoch 5113/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1761 - val_loss: 28.3719\n",
      "Epoch 5114/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1742 - val_loss: 29.5231\n",
      "Epoch 5115/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1794 - val_loss: 29.6274\n",
      "Epoch 5116/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1756 - val_loss: 27.1529\n",
      "Epoch 5117/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1750 - val_loss: 26.9994\n",
      "Epoch 5118/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1786 - val_loss: 25.4467\n",
      "Epoch 5119/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1943 - val_loss: 25.8922\n",
      "Epoch 5120/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1858 - val_loss: 32.7533\n",
      "Epoch 5121/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2144 - val_loss: 28.3796\n",
      "Epoch 5122/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2438 - val_loss: 36.4995\n",
      "Epoch 5123/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2213 - val_loss: 37.7652\n",
      "Epoch 5124/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2250 - val_loss: 38.3949\n",
      "Epoch 5125/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2179 - val_loss: 31.1153\n",
      "Epoch 5126/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1954 - val_loss: 30.8974\n",
      "Epoch 5127/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1933 - val_loss: 30.4956\n",
      "Epoch 5128/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1910 - val_loss: 30.8663\n",
      "Epoch 5129/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1915 - val_loss: 36.8366\n",
      "Epoch 5130/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1869 - val_loss: 32.4286\n",
      "Epoch 5131/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2221 - val_loss: 30.5533\n",
      "Epoch 5132/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2409 - val_loss: 39.7087\n",
      "Epoch 5133/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2952 - val_loss: 35.0541\n",
      "Epoch 5134/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2519 - val_loss: 29.4440\n",
      "Epoch 5135/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2249 - val_loss: 28.9618\n",
      "Epoch 5136/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2014 - val_loss: 38.8829\n",
      "Epoch 5137/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2018 - val_loss: 33.2527\n",
      "Epoch 5138/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1851 - val_loss: 34.3951\n",
      "Epoch 5139/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1800 - val_loss: 32.6592\n",
      "Epoch 5140/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1790 - val_loss: 33.7120\n",
      "Epoch 5141/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1757 - val_loss: 32.4450\n",
      "Epoch 5142/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1764 - val_loss: 31.3924\n",
      "Epoch 5143/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1741 - val_loss: 33.5634\n",
      "Epoch 5144/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1743 - val_loss: 33.7353\n",
      "Epoch 5145/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1746 - val_loss: 33.7943\n",
      "Epoch 5146/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1752 - val_loss: 34.2435\n",
      "Epoch 5147/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1750 - val_loss: 33.8086\n",
      "Epoch 5148/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1744 - val_loss: 32.8624\n",
      "Epoch 5149/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 32.1967\n",
      "Epoch 5150/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1746 - val_loss: 32.6663\n",
      "Epoch 5151/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 33.9621\n",
      "Epoch 5152/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1756 - val_loss: 32.2398\n",
      "Epoch 5153/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1739 - val_loss: 34.5870\n",
      "Epoch 5154/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1755 - val_loss: 33.0858\n",
      "Epoch 5155/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1776 - val_loss: 33.3601\n",
      "Epoch 5156/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1768 - val_loss: 31.0131\n",
      "Epoch 5157/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1883 - val_loss: 29.3283\n",
      "Epoch 5158/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2311 - val_loss: 30.8986\n",
      "Epoch 5159/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2027 - val_loss: 34.8402\n",
      "Epoch 5160/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2451 - val_loss: 24.2153\n",
      "Epoch 5161/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2479 - val_loss: 29.8271\n",
      "Epoch 5162/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2063 - val_loss: 25.9559\n",
      "Epoch 5163/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1815 - val_loss: 32.1089\n",
      "Epoch 5164/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1799 - val_loss: 30.2355\n",
      "Epoch 5165/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1810 - val_loss: 30.5695\n",
      "Epoch 5166/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1848 - val_loss: 31.1582\n",
      "Epoch 5167/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1884 - val_loss: 31.3046\n",
      "Epoch 5168/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1804 - val_loss: 32.0143\n",
      "Epoch 5169/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1790 - val_loss: 29.5488\n",
      "Epoch 5170/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1781 - val_loss: 29.6707\n",
      "Epoch 5171/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1751 - val_loss: 31.5536\n",
      "Epoch 5172/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1746 - val_loss: 31.2956\n",
      "Epoch 5173/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1743 - val_loss: 30.4541\n",
      "Epoch 5174/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1758 - val_loss: 30.5592\n",
      "Epoch 5175/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1763 - val_loss: 30.6713\n",
      "Epoch 5176/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1771 - val_loss: 33.7596\n",
      "Epoch 5177/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1800 - val_loss: 27.4395\n",
      "Epoch 5178/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2070 - val_loss: 39.0105\n",
      "Epoch 5179/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2346 - val_loss: 27.5497\n",
      "Epoch 5180/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2206 - val_loss: 26.3378\n",
      "Epoch 5181/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1813 - val_loss: 28.8003\n",
      "Epoch 5182/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1788 - val_loss: 29.3379\n",
      "Epoch 5183/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1750 - val_loss: 28.7458\n",
      "Epoch 5184/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1753 - val_loss: 28.9760\n",
      "Epoch 5185/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 28.7801\n",
      "Epoch 5186/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1751 - val_loss: 28.4991\n",
      "Epoch 5187/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1771 - val_loss: 28.8773\n",
      "Epoch 5188/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1771 - val_loss: 29.1409\n",
      "Epoch 5189/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1764 - val_loss: 29.0467\n",
      "Epoch 5190/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1859 - val_loss: 24.1693\n",
      "Epoch 5191/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1847 - val_loss: 27.2861\n",
      "Epoch 5192/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1780 - val_loss: 27.9475\n",
      "Epoch 5193/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1920 - val_loss: 35.2787\n",
      "Epoch 5194/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2050 - val_loss: 31.3519\n",
      "Epoch 5195/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1872 - val_loss: 30.5751\n",
      "Epoch 5196/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1820 - val_loss: 30.4579\n",
      "Epoch 5197/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1834 - val_loss: 34.1470\n",
      "Epoch 5198/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1877 - val_loss: 33.5682\n",
      "Epoch 5199/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1814 - val_loss: 30.6546\n",
      "Epoch 5200/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1761 - val_loss: 31.7333\n",
      "Epoch 5201/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 30.4637\n",
      "Epoch 5202/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 31.2928\n",
      "Epoch 5203/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1753 - val_loss: 29.9643\n",
      "Epoch 5204/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1755 - val_loss: 30.4943\n",
      "Epoch 5205/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 30.5084\n",
      "Epoch 5206/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1763 - val_loss: 32.9907\n",
      "Epoch 5207/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1882 - val_loss: 22.5589\n",
      "Epoch 5208/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1994 - val_loss: 31.0414\n",
      "Epoch 5209/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2178 - val_loss: 31.1760\n",
      "Epoch 5210/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2263 - val_loss: 23.8103\n",
      "Epoch 5211/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1893 - val_loss: 29.5364\n",
      "Epoch 5212/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1774 - val_loss: 28.2045\n",
      "Epoch 5213/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 27.8394\n",
      "Epoch 5214/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1744 - val_loss: 28.0242\n",
      "Epoch 5215/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1739 - val_loss: 27.5815\n",
      "Epoch 5216/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 27.9735\n",
      "Epoch 5217/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1742 - val_loss: 29.0258\n",
      "Epoch 5218/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1814 - val_loss: 30.5221\n",
      "Epoch 5219/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3723 - val_loss: 44.9588\n",
      "Epoch 5220/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.6547 - val_loss: 35.8611\n",
      "Epoch 5221/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2572 - val_loss: 41.5889\n",
      "Epoch 5222/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1918 - val_loss: 43.3959\n",
      "Epoch 5223/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1818 - val_loss: 42.6487\n",
      "Epoch 5224/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1782 - val_loss: 42.5362\n",
      "Epoch 5225/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1745 - val_loss: 42.8390\n",
      "Epoch 5226/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1759 - val_loss: 42.1267\n",
      "Epoch 5227/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1766 - val_loss: 42.8662\n",
      "Epoch 5228/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1775 - val_loss: 42.2871\n",
      "Epoch 5229/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1752 - val_loss: 40.1740\n",
      "Epoch 5230/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1767 - val_loss: 40.9630\n",
      "Epoch 5231/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1760 - val_loss: 40.0456\n",
      "Epoch 5232/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 41.4611\n",
      "Epoch 5233/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 40.5664\n",
      "Epoch 5234/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1747 - val_loss: 41.2391\n",
      "Epoch 5235/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1764 - val_loss: 39.2404\n",
      "Epoch 5236/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1749 - val_loss: 41.0061\n",
      "Epoch 5237/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1740 - val_loss: 39.6904\n",
      "Epoch 5238/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1746 - val_loss: 40.8238\n",
      "Epoch 5239/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1743 - val_loss: 39.5728\n",
      "Epoch 5240/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1750 - val_loss: 40.5797\n",
      "Epoch 5241/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 40.6634\n",
      "Epoch 5242/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1743 - val_loss: 39.0305\n",
      "Epoch 5243/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1753 - val_loss: 40.0857\n",
      "Epoch 5244/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1746 - val_loss: 40.5253\n",
      "Epoch 5245/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 41.1758\n",
      "Epoch 5246/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1750 - val_loss: 37.7220\n",
      "Epoch 5247/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1803 - val_loss: 39.2844\n",
      "Epoch 5248/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1754 - val_loss: 41.5330\n",
      "Epoch 5249/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1743 - val_loss: 40.1705\n",
      "Epoch 5250/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1742 - val_loss: 39.0980\n",
      "Epoch 5251/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1769 - val_loss: 41.7190\n",
      "Epoch 5252/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1919 - val_loss: 38.7058\n",
      "Epoch 5253/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1862 - val_loss: 35.4640\n",
      "Epoch 5254/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1856 - val_loss: 36.2064\n",
      "Epoch 5255/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1934 - val_loss: 41.2785\n",
      "Epoch 5256/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2076 - val_loss: 40.2625\n",
      "Epoch 5257/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2087 - val_loss: 36.5061\n",
      "Epoch 5258/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2102 - val_loss: 35.6128\n",
      "Epoch 5259/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2162 - val_loss: 39.2201\n",
      "Epoch 5260/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2218 - val_loss: 42.0806\n",
      "Epoch 5261/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3084 - val_loss: 38.4974\n",
      "Epoch 5262/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2202 - val_loss: 37.8907\n",
      "Epoch 5263/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1959 - val_loss: 37.3805\n",
      "Epoch 5264/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1809 - val_loss: 38.2118\n",
      "Epoch 5265/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1789 - val_loss: 38.4239\n",
      "Epoch 5266/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1770 - val_loss: 38.2384\n",
      "Epoch 5267/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1749 - val_loss: 38.3629\n",
      "Epoch 5268/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 37.8329\n",
      "Epoch 5269/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1747 - val_loss: 38.4482\n",
      "Epoch 5270/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 38.2269\n",
      "Epoch 5271/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1747 - val_loss: 38.0058\n",
      "Epoch 5272/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1771 - val_loss: 38.2997\n",
      "Epoch 5273/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1761 - val_loss: 39.0950\n",
      "Epoch 5274/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1743 - val_loss: 39.8768\n",
      "Epoch 5275/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 39.1363\n",
      "Epoch 5276/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1744 - val_loss: 39.4116\n",
      "Epoch 5277/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1744 - val_loss: 39.4530\n",
      "Epoch 5278/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 38.2127\n",
      "Epoch 5279/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 37.3981\n",
      "Epoch 5280/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1768 - val_loss: 26.1768\n",
      "Epoch 5281/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2827 - val_loss: 34.1696\n",
      "Epoch 5282/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2323 - val_loss: 38.6845\n",
      "Epoch 5283/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1898 - val_loss: 36.7639\n",
      "Epoch 5284/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1793 - val_loss: 37.5043\n",
      "Epoch 5285/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 37.2554\n",
      "Epoch 5286/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1747 - val_loss: 38.4274\n",
      "Epoch 5287/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1745 - val_loss: 37.6913\n",
      "Epoch 5288/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 38.7009\n",
      "Epoch 5289/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1763 - val_loss: 37.0333\n",
      "Epoch 5290/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1780 - val_loss: 35.1640\n",
      "Epoch 5291/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1786 - val_loss: 37.5414\n",
      "Epoch 5292/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1748 - val_loss: 37.8075\n",
      "Epoch 5293/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1750 - val_loss: 38.0874\n",
      "Epoch 5294/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1746 - val_loss: 40.0014\n",
      "Epoch 5295/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1867 - val_loss: 38.2059\n",
      "Epoch 5296/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1863 - val_loss: 38.4882\n",
      "Epoch 5297/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3516 - val_loss: 37.4044\n",
      "Epoch 5298/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3658 - val_loss: 36.2162\n",
      "Epoch 5299/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2765 - val_loss: 42.2752\n",
      "Epoch 5300/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2342 - val_loss: 40.2847\n",
      "Epoch 5301/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1799 - val_loss: 41.5977\n",
      "Epoch 5302/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1830 - val_loss: 39.1241\n",
      "Epoch 5303/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1803 - val_loss: 39.8203\n",
      "Epoch 5304/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1748 - val_loss: 40.0039\n",
      "Epoch 5305/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1752 - val_loss: 38.7293\n",
      "Epoch 5306/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1745 - val_loss: 39.8190\n",
      "Epoch 5307/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1744 - val_loss: 38.3682\n",
      "Epoch 5308/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 36.0110\n",
      "Epoch 5309/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1747 - val_loss: 39.1087\n",
      "Epoch 5310/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1746 - val_loss: 38.0820\n",
      "Epoch 5311/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 38.6938\n",
      "Epoch 5312/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1741 - val_loss: 37.5329\n",
      "Epoch 5313/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 37.5614\n",
      "Epoch 5314/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 36.9687\n",
      "Epoch 5315/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1739 - val_loss: 37.3679\n",
      "Epoch 5316/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 37.2397\n",
      "Epoch 5317/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 36.9608\n",
      "Epoch 5318/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1742 - val_loss: 36.7758\n",
      "Epoch 5319/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1748 - val_loss: 37.3759\n",
      "Epoch 5320/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 37.5720\n",
      "Epoch 5321/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 37.7245\n",
      "Epoch 5322/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1743 - val_loss: 38.9455\n",
      "Epoch 5323/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1749 - val_loss: 38.2958\n",
      "Epoch 5324/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1775 - val_loss: 35.6802\n",
      "Epoch 5325/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 37.0523\n",
      "Epoch 5326/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 36.5551\n",
      "Epoch 5327/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1745 - val_loss: 37.3425\n",
      "Epoch 5328/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 36.7097\n",
      "Epoch 5329/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 37.5657\n",
      "Epoch 5330/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 36.2504\n",
      "Epoch 5331/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 35.9655\n",
      "Epoch 5332/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 36.8264\n",
      "Epoch 5333/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1746 - val_loss: 34.7393\n",
      "Epoch 5334/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1755 - val_loss: 36.0695\n",
      "Epoch 5335/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1743 - val_loss: 37.1266\n",
      "Epoch 5336/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1750 - val_loss: 37.2919\n",
      "Epoch 5337/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2498 - val_loss: 38.5667\n",
      "Epoch 5338/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2646 - val_loss: 40.3210\n",
      "Epoch 5339/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2549 - val_loss: 36.1549\n",
      "Epoch 5340/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2499 - val_loss: 45.8977\n",
      "Epoch 5341/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2116 - val_loss: 40.1834\n",
      "Epoch 5342/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2080 - val_loss: 44.1986\n",
      "Epoch 5343/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2208 - val_loss: 38.5087\n",
      "Epoch 5344/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2018 - val_loss: 36.2787\n",
      "Epoch 5345/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1827 - val_loss: 33.2290\n",
      "Epoch 5346/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1917 - val_loss: 36.5520\n",
      "Epoch 5347/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1810 - val_loss: 34.6680\n",
      "Epoch 5348/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1763 - val_loss: 34.2980\n",
      "Epoch 5349/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 31.9896\n",
      "Epoch 5350/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 32.3065\n",
      "Epoch 5351/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 31.9223\n",
      "Epoch 5352/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1743 - val_loss: 32.8950\n",
      "Epoch 5353/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1745 - val_loss: 33.9698\n",
      "Epoch 5354/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1742 - val_loss: 33.1710\n",
      "Epoch 5355/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1741 - val_loss: 34.4804\n",
      "Epoch 5356/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1739 - val_loss: 32.6348\n",
      "Epoch 5357/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1740 - val_loss: 32.8321\n",
      "Epoch 5358/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1751 - val_loss: 33.8092\n",
      "Epoch 5359/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1791 - val_loss: 26.0865\n",
      "Epoch 5360/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2053 - val_loss: 29.6238\n",
      "Epoch 5361/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3132 - val_loss: 37.9508\n",
      "Epoch 5362/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2619 - val_loss: 34.1427\n",
      "Epoch 5363/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3324 - val_loss: 27.8885\n",
      "Epoch 5364/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2205 - val_loss: 34.6754\n",
      "Epoch 5365/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2083 - val_loss: 34.0748\n",
      "Epoch 5366/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2468 - val_loss: 26.3077\n",
      "Epoch 5367/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2238 - val_loss: 32.7382\n",
      "Epoch 5368/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2248 - val_loss: 34.3841\n",
      "Epoch 5369/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1946 - val_loss: 35.7000\n",
      "Epoch 5370/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1817 - val_loss: 33.0884\n",
      "Epoch 5371/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1885 - val_loss: 32.7547\n",
      "Epoch 5372/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1766 - val_loss: 31.9588\n",
      "Epoch 5373/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1755 - val_loss: 32.5046\n",
      "Epoch 5374/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1748 - val_loss: 31.4196\n",
      "Epoch 5375/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1745 - val_loss: 31.2389\n",
      "Epoch 5376/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 32.2787\n",
      "Epoch 5377/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1754 - val_loss: 32.0306\n",
      "Epoch 5378/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1757 - val_loss: 30.5966\n",
      "Epoch 5379/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 30.4672\n",
      "Epoch 5380/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1743 - val_loss: 31.9538\n",
      "Epoch 5381/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 29.9553\n",
      "Epoch 5382/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1744 - val_loss: 30.4188\n",
      "Epoch 5383/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 30.4696\n",
      "Epoch 5384/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 31.6354\n",
      "Epoch 5385/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1739 - val_loss: 30.6057\n",
      "Epoch 5386/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 31.5191\n",
      "Epoch 5387/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1711 - val_loss: 32.1967\n",
      "Epoch 5388/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 31.3191\n",
      "Epoch 5389/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 31.1053\n",
      "Epoch 5390/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 29.5888\n",
      "Epoch 5391/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 29.0287\n",
      "Epoch 5392/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 31.9190\n",
      "Epoch 5393/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1711 - val_loss: 32.1328\n",
      "Epoch 5394/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 30.1744\n",
      "Epoch 5395/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 30.0734\n",
      "Epoch 5396/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 30.8549\n",
      "Epoch 5397/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 31.7213\n",
      "Epoch 5398/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1751 - val_loss: 30.8842\n",
      "Epoch 5399/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1777 - val_loss: 33.8212\n",
      "Epoch 5400/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1798 - val_loss: 28.7838\n",
      "Epoch 5401/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1809 - val_loss: 31.2622\n",
      "Epoch 5402/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1878 - val_loss: 31.7375\n",
      "Epoch 5403/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1868 - val_loss: 31.3269\n",
      "Epoch 5404/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 30.4990\n",
      "Epoch 5405/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1758 - val_loss: 32.4354\n",
      "Epoch 5406/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1764 - val_loss: 31.4698\n",
      "Epoch 5407/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1874 - val_loss: 29.9591\n",
      "Epoch 5408/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1998 - val_loss: 24.5429\n",
      "Epoch 5409/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2063 - val_loss: 33.7411\n",
      "Epoch 5410/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1871 - val_loss: 31.2115\n",
      "Epoch 5411/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2021 - val_loss: 29.3895\n",
      "Epoch 5412/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2412 - val_loss: 37.4798\n",
      "Epoch 5413/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2043 - val_loss: 30.6966\n",
      "Epoch 5414/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2136 - val_loss: 35.8531\n",
      "Epoch 5415/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1979 - val_loss: 36.2343\n",
      "Epoch 5416/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2763 - val_loss: 38.2525\n",
      "Epoch 5417/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2190 - val_loss: 40.8226\n",
      "Epoch 5418/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2122 - val_loss: 23.3002\n",
      "Epoch 5419/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2720 - val_loss: 27.7332\n",
      "Epoch 5420/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2205 - val_loss: 36.1017\n",
      "Epoch 5421/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2037 - val_loss: 25.5048\n",
      "Epoch 5422/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2189 - val_loss: 29.5379\n",
      "Epoch 5423/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1812 - val_loss: 37.5601\n",
      "Epoch 5424/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1774 - val_loss: 36.6439\n",
      "Epoch 5425/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1740 - val_loss: 34.8682\n",
      "Epoch 5426/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 34.1921\n",
      "Epoch 5427/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1748 - val_loss: 32.7980\n",
      "Epoch 5428/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1745 - val_loss: 33.7630\n",
      "Epoch 5429/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1741 - val_loss: 35.2135\n",
      "Epoch 5430/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 33.2788\n",
      "Epoch 5431/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1742 - val_loss: 33.7536\n",
      "Epoch 5432/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 34.2172\n",
      "Epoch 5433/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 33.0230\n",
      "Epoch 5434/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 35.3685\n",
      "Epoch 5435/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 34.0376\n",
      "Epoch 5436/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 32.5499\n",
      "Epoch 5437/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1747 - val_loss: 35.2212\n",
      "Epoch 5438/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1745 - val_loss: 35.2346\n",
      "Epoch 5439/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1764 - val_loss: 32.2527\n",
      "Epoch 5440/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 33.4557\n",
      "Epoch 5441/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1725 - val_loss: 34.4084\n",
      "Epoch 5442/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1745 - val_loss: 34.6473\n",
      "Epoch 5443/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1747 - val_loss: 36.2019\n",
      "Epoch 5444/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1927 - val_loss: 34.4098\n",
      "Epoch 5445/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1907 - val_loss: 32.7591\n",
      "Epoch 5446/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1775 - val_loss: 32.3291\n",
      "Epoch 5447/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1777 - val_loss: 31.8563\n",
      "Epoch 5448/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1786 - val_loss: 31.8891\n",
      "Epoch 5449/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1742 - val_loss: 35.7496\n",
      "Epoch 5450/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 34.8203\n",
      "Epoch 5451/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 33.0948\n",
      "Epoch 5452/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1746 - val_loss: 35.5829\n",
      "Epoch 5453/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 34.0013\n",
      "Epoch 5454/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1766 - val_loss: 27.1199\n",
      "Epoch 5455/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2191 - val_loss: 27.1769\n",
      "Epoch 5456/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2721 - val_loss: 46.3118\n",
      "Epoch 5457/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3583 - val_loss: 43.5547\n",
      "Epoch 5458/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3844 - val_loss: 35.0718\n",
      "Epoch 5459/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3075 - val_loss: 36.0975\n",
      "Epoch 5460/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.2485 - val_loss: 35.0397\n",
      "Epoch 5461/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2067 - val_loss: 40.1613\n",
      "Epoch 5462/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1887 - val_loss: 39.7896\n",
      "Epoch 5463/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1813 - val_loss: 39.2346\n",
      "Epoch 5464/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1771 - val_loss: 37.1799\n",
      "Epoch 5465/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1750 - val_loss: 37.3113\n",
      "Epoch 5466/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1748 - val_loss: 35.1052\n",
      "Epoch 5467/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1763 - val_loss: 35.4311\n",
      "Epoch 5468/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 36.0570\n",
      "Epoch 5469/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1740 - val_loss: 36.0172\n",
      "Epoch 5470/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1755 - val_loss: 36.4669\n",
      "Epoch 5471/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1775 - val_loss: 34.0028\n",
      "Epoch 5472/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1776 - val_loss: 33.4443\n",
      "Epoch 5473/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1745 - val_loss: 37.6276\n",
      "Epoch 5474/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1735 - val_loss: 35.6984\n",
      "Epoch 5475/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 36.6159\n",
      "Epoch 5476/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1739 - val_loss: 37.2604\n",
      "Epoch 5477/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1757 - val_loss: 37.2265\n",
      "Epoch 5478/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 35.4467\n",
      "Epoch 5479/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1760 - val_loss: 38.2199\n",
      "Epoch 5480/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1876 - val_loss: 38.3324\n",
      "Epoch 5481/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2115 - val_loss: 34.7891\n",
      "Epoch 5482/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1921 - val_loss: 37.5398\n",
      "Epoch 5483/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2148 - val_loss: 35.1056\n",
      "Epoch 5484/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2588 - val_loss: 35.0372\n",
      "Epoch 5485/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2229 - val_loss: 35.4999\n",
      "Epoch 5486/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1831 - val_loss: 34.3579\n",
      "Epoch 5487/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1755 - val_loss: 36.8730\n",
      "Epoch 5488/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1767 - val_loss: 33.3608\n",
      "Epoch 5489/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1744 - val_loss: 36.3210\n",
      "Epoch 5490/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1758 - val_loss: 36.4218\n",
      "Epoch 5491/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 34.7175\n",
      "Epoch 5492/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1739 - val_loss: 34.1274\n",
      "Epoch 5493/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1754 - val_loss: 35.0271\n",
      "Epoch 5494/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 35.7278\n",
      "Epoch 5495/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 36.3545\n",
      "Epoch 5496/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 36.3071\n",
      "Epoch 5497/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 35.7977\n",
      "Epoch 5498/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 34.2196\n",
      "Epoch 5499/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 36.3379\n",
      "Epoch 5500/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1745 - val_loss: 34.0304\n",
      "Epoch 5501/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 34.2659\n",
      "Epoch 5502/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1739 - val_loss: 35.7686\n",
      "Epoch 5503/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2012 - val_loss: 32.1243\n",
      "Epoch 5504/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3173 - val_loss: 38.5189\n",
      "Epoch 5505/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2002 - val_loss: 35.7339\n",
      "Epoch 5506/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1788 - val_loss: 37.7846\n",
      "Epoch 5507/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1754 - val_loss: 38.4308\n",
      "Epoch 5508/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1740 - val_loss: 37.4596\n",
      "Epoch 5509/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 36.0627\n",
      "Epoch 5510/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 35.6952\n",
      "Epoch 5511/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 35.8598\n",
      "Epoch 5512/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 35.5158\n",
      "Epoch 5513/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 35.2230\n",
      "Epoch 5514/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 33.9521\n",
      "Epoch 5515/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 35.7346\n",
      "Epoch 5516/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1744 - val_loss: 35.6536\n",
      "Epoch 5517/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1745 - val_loss: 37.3621\n",
      "Epoch 5518/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 35.0689\n",
      "Epoch 5519/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 34.8660\n",
      "Epoch 5520/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 35.6659\n",
      "Epoch 5521/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1718 - val_loss: 34.1368\n",
      "Epoch 5522/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1709 - val_loss: 34.1383\n",
      "Epoch 5523/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 33.8578\n",
      "Epoch 5524/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 34.7164\n",
      "Epoch 5525/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 35.7522\n",
      "Epoch 5526/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 36.1194\n",
      "Epoch 5527/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 34.5760\n",
      "Epoch 5528/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 34.9307\n",
      "Epoch 5529/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 34.9030\n",
      "Epoch 5530/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1748 - val_loss: 36.4900\n",
      "Epoch 5531/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1745 - val_loss: 36.0931\n",
      "Epoch 5532/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1820 - val_loss: 32.3482\n",
      "Epoch 5533/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2396 - val_loss: 37.6806\n",
      "Epoch 5534/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2172 - val_loss: 36.9573\n",
      "Epoch 5535/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2272 - val_loss: 41.0036\n",
      "Epoch 5536/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3432 - val_loss: 31.3140\n",
      "Epoch 5537/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2500 - val_loss: 31.9426\n",
      "Epoch 5538/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2229 - val_loss: 30.3705\n",
      "Epoch 5539/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2010 - val_loss: 33.2985\n",
      "Epoch 5540/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2010 - val_loss: 29.3693\n",
      "Epoch 5541/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1944 - val_loss: 28.3210\n",
      "Epoch 5542/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1837 - val_loss: 27.0974\n",
      "Epoch 5543/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1827 - val_loss: 30.6809\n",
      "Epoch 5544/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1785 - val_loss: 27.9145\n",
      "Epoch 5545/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1769 - val_loss: 27.3278\n",
      "Epoch 5546/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1790 - val_loss: 25.9384\n",
      "Epoch 5547/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1820 - val_loss: 27.8612\n",
      "Epoch 5548/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1886 - val_loss: 26.6328\n",
      "Epoch 5549/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1792 - val_loss: 25.5422\n",
      "Epoch 5550/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1759 - val_loss: 26.3286\n",
      "Epoch 5551/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1740 - val_loss: 29.6548\n",
      "Epoch 5552/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1756 - val_loss: 25.8375\n",
      "Epoch 5553/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1763 - val_loss: 26.3034\n",
      "Epoch 5554/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1745 - val_loss: 26.1806\n",
      "Epoch 5555/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1745 - val_loss: 31.4629\n",
      "Epoch 5556/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1759 - val_loss: 31.6229\n",
      "Epoch 5557/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2108 - val_loss: 25.2314\n",
      "Epoch 5558/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1933 - val_loss: 30.4996\n",
      "Epoch 5559/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2160 - val_loss: 25.1130\n",
      "Epoch 5560/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2298 - val_loss: 33.7607\n",
      "Epoch 5561/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2037 - val_loss: 31.0403\n",
      "Epoch 5562/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1823 - val_loss: 32.3911\n",
      "Epoch 5563/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1748 - val_loss: 30.5973\n",
      "Epoch 5564/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 31.2786\n",
      "Epoch 5565/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1704 - val_loss: 30.6802\n",
      "Epoch 5566/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 31.1367\n",
      "Epoch 5567/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 31.5350\n",
      "Epoch 5568/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 30.9456\n",
      "Epoch 5569/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 30.4773\n",
      "Epoch 5570/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 30.9251\n",
      "Epoch 5571/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1750 - val_loss: 29.9426\n",
      "Epoch 5572/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1741 - val_loss: 31.7464\n",
      "Epoch 5573/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 33.0699\n",
      "Epoch 5574/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1750 - val_loss: 33.0870\n",
      "Epoch 5575/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 32.5741\n",
      "Epoch 5576/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 30.5311\n",
      "Epoch 5577/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 31.8161\n",
      "Epoch 5578/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 32.9168\n",
      "Epoch 5579/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 29.8842\n",
      "Epoch 5580/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1771 - val_loss: 34.0876\n",
      "Epoch 5581/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3573 - val_loss: 29.3436\n",
      "Epoch 5582/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2523 - val_loss: 38.2091\n",
      "Epoch 5583/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1904 - val_loss: 32.6568\n",
      "Epoch 5584/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1776 - val_loss: 35.1220\n",
      "Epoch 5585/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1764 - val_loss: 34.8758\n",
      "Epoch 5586/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1758 - val_loss: 34.4294\n",
      "Epoch 5587/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1752 - val_loss: 33.1959\n",
      "Epoch 5588/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1744 - val_loss: 34.7788\n",
      "Epoch 5589/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1750 - val_loss: 35.2771\n",
      "Epoch 5590/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1749 - val_loss: 31.2458\n",
      "Epoch 5591/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 35.1566\n",
      "Epoch 5592/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 34.4551\n",
      "Epoch 5593/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1739 - val_loss: 33.6522\n",
      "Epoch 5594/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 34.1817\n",
      "Epoch 5595/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 33.3366\n",
      "Epoch 5596/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 34.0968\n",
      "Epoch 5597/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 32.4996\n",
      "Epoch 5598/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 34.1456\n",
      "Epoch 5599/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 33.0869\n",
      "Epoch 5600/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1739 - val_loss: 33.6595\n",
      "Epoch 5601/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 32.9579\n",
      "Epoch 5602/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1708 - val_loss: 33.3011\n",
      "Epoch 5603/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 32.7603\n",
      "Epoch 5604/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1738 - val_loss: 34.0994\n",
      "Epoch 5605/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 33.6418\n",
      "Epoch 5606/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1748 - val_loss: 32.2655\n",
      "Epoch 5607/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2389 - val_loss: 30.8715\n",
      "Epoch 5608/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2823 - val_loss: 40.5887\n",
      "Epoch 5609/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2431 - val_loss: 40.0921\n",
      "Epoch 5610/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3421 - val_loss: 11.4268\n",
      "Epoch 5611/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3321 - val_loss: 41.9931\n",
      "Epoch 5612/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2013 - val_loss: 35.1306\n",
      "Epoch 5613/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2061 - val_loss: 39.4093\n",
      "Epoch 5614/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2081 - val_loss: 29.9143\n",
      "Epoch 5615/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1961 - val_loss: 35.6331\n",
      "Epoch 5616/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1895 - val_loss: 36.1045\n",
      "Epoch 5617/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1769 - val_loss: 34.7441\n",
      "Epoch 5618/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 35.7956\n",
      "Epoch 5619/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1745 - val_loss: 35.6505\n",
      "Epoch 5620/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1743 - val_loss: 34.7004\n",
      "Epoch 5621/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 35.5558\n",
      "Epoch 5622/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1712 - val_loss: 34.3696\n",
      "Epoch 5623/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 34.7304\n",
      "Epoch 5624/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 33.8443\n",
      "Epoch 5625/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 33.3680\n",
      "Epoch 5626/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1742 - val_loss: 33.5545\n",
      "Epoch 5627/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 34.3638\n",
      "Epoch 5628/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 33.0368\n",
      "Epoch 5629/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1814 - val_loss: 31.2173\n",
      "Epoch 5630/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1871 - val_loss: 30.6521\n",
      "Epoch 5631/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1920 - val_loss: 38.6408\n",
      "Epoch 5632/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1742 - val_loss: 37.0437\n",
      "Epoch 5633/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 35.0187\n",
      "Epoch 5634/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 34.2984\n",
      "Epoch 5635/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 34.9765\n",
      "Epoch 5636/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 34.8223\n",
      "Epoch 5637/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1759 - val_loss: 33.3846\n",
      "Epoch 5638/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1746 - val_loss: 34.7693\n",
      "Epoch 5639/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 34.3775\n",
      "Epoch 5640/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 32.4364\n",
      "Epoch 5641/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 34.3518\n",
      "Epoch 5642/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 34.8403\n",
      "Epoch 5643/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 34.4836\n",
      "Epoch 5644/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 34.3149\n",
      "Epoch 5645/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1771 - val_loss: 31.0788\n",
      "Epoch 5646/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1760 - val_loss: 31.8736\n",
      "Epoch 5647/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2049 - val_loss: 42.7361\n",
      "Epoch 5648/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2126 - val_loss: 47.2990\n",
      "Epoch 5649/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3087 - val_loss: 37.4266\n",
      "Epoch 5650/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2268 - val_loss: 42.2373\n",
      "Epoch 5651/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1871 - val_loss: 37.7611\n",
      "Epoch 5652/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1926 - val_loss: 35.6476\n",
      "Epoch 5653/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1787 - val_loss: 34.0874\n",
      "Epoch 5654/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1748 - val_loss: 34.4055\n",
      "Epoch 5655/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 34.7199\n",
      "Epoch 5656/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1703 - val_loss: 33.9508\n",
      "Epoch 5657/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1739 - val_loss: 34.4231\n",
      "Epoch 5658/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 33.2961\n",
      "Epoch 5659/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 34.9030\n",
      "Epoch 5660/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 33.4340\n",
      "Epoch 5661/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1709 - val_loss: 33.7289\n",
      "Epoch 5662/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 33.6488\n",
      "Epoch 5663/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 33.5269\n",
      "Epoch 5664/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 32.9157\n",
      "Epoch 5665/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 34.2235\n",
      "Epoch 5666/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 33.3257\n",
      "Epoch 5667/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 34.1953\n",
      "Epoch 5668/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 35.2444\n",
      "Epoch 5669/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1699 - val_loss: 35.6927\n",
      "Epoch 5670/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 35.3897\n",
      "Epoch 5671/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1739 - val_loss: 32.0818\n",
      "Epoch 5672/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1749 - val_loss: 35.7507\n",
      "Epoch 5673/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1750 - val_loss: 33.0377\n",
      "Epoch 5674/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1752 - val_loss: 38.4612\n",
      "Epoch 5675/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1777 - val_loss: 37.6924\n",
      "Epoch 5676/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1775 - val_loss: 38.4799\n",
      "Epoch 5677/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1749 - val_loss: 36.7147\n",
      "Epoch 5678/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1809 - val_loss: 33.1165\n",
      "Epoch 5679/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1844 - val_loss: 36.3416\n",
      "Epoch 5680/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2344 - val_loss: 27.6029\n",
      "Epoch 5681/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2961 - val_loss: 54.9823\n",
      "Epoch 5682/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.7362 - val_loss: 70.3441\n",
      "Epoch 5683/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3200 - val_loss: 65.6356\n",
      "Epoch 5684/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2451 - val_loss: 69.1322\n",
      "Epoch 5685/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2556 - val_loss: 58.3504\n",
      "Epoch 5686/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3444 - val_loss: 60.3122\n",
      "Epoch 5687/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2520 - val_loss: 58.3376\n",
      "Epoch 5688/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2255 - val_loss: 52.8400\n",
      "Epoch 5689/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2141 - val_loss: 51.4157\n",
      "Epoch 5690/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2069 - val_loss: 49.4515\n",
      "Epoch 5691/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2105 - val_loss: 49.6554\n",
      "Epoch 5692/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2037 - val_loss: 50.0297\n",
      "Epoch 5693/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2043 - val_loss: 52.5767\n",
      "Epoch 5694/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1938 - val_loss: 50.1574\n",
      "Epoch 5695/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2084 - val_loss: 53.4900\n",
      "Epoch 5696/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2515 - val_loss: 49.1749\n",
      "Epoch 5697/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2149 - val_loss: 46.1335\n",
      "Epoch 5698/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1970 - val_loss: 45.1582\n",
      "Epoch 5699/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2018 - val_loss: 46.5773\n",
      "Epoch 5700/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2054 - val_loss: 46.9782\n",
      "Epoch 5701/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2211 - val_loss: 44.2067\n",
      "Epoch 5702/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2328 - val_loss: 44.6874\n",
      "Epoch 5703/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1966 - val_loss: 45.3924\n",
      "Epoch 5704/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1929 - val_loss: 44.2743\n",
      "Epoch 5705/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2012 - val_loss: 45.2340\n",
      "Epoch 5706/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2030 - val_loss: 39.3576\n",
      "Epoch 5707/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1948 - val_loss: 40.4446\n",
      "Epoch 5708/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1975 - val_loss: 41.9089\n",
      "Epoch 5709/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2212 - val_loss: 40.4355\n",
      "Epoch 5710/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1925 - val_loss: 40.8538\n",
      "Epoch 5711/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1892 - val_loss: 34.7720\n",
      "Epoch 5712/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1924 - val_loss: 36.8248\n",
      "Epoch 5713/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2056 - val_loss: 39.1699\n",
      "Epoch 5714/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2186 - val_loss: 37.8172\n",
      "Epoch 5715/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1918 - val_loss: 36.8680\n",
      "Epoch 5716/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1897 - val_loss: 35.0108\n",
      "Epoch 5717/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1850 - val_loss: 33.9775\n",
      "Epoch 5718/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1845 - val_loss: 32.8774\n",
      "Epoch 5719/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1827 - val_loss: 34.4457\n",
      "Epoch 5720/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1806 - val_loss: 33.0433\n",
      "Epoch 5721/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1840 - val_loss: 34.0537\n",
      "Epoch 5722/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1851 - val_loss: 34.8728\n",
      "Epoch 5723/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1932 - val_loss: 34.1419\n",
      "Epoch 5724/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2669 - val_loss: 28.0557\n",
      "Epoch 5725/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2223 - val_loss: 30.2337\n",
      "Epoch 5726/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1926 - val_loss: 31.8833\n",
      "Epoch 5727/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1833 - val_loss: 29.1827\n",
      "Epoch 5728/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1883 - val_loss: 29.7934\n",
      "Epoch 5729/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1870 - val_loss: 30.6228\n",
      "Epoch 5730/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1856 - val_loss: 28.3059\n",
      "Epoch 5731/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2708 - val_loss: 20.8739\n",
      "Epoch 5732/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3102 - val_loss: 15.7037\n",
      "Epoch 5733/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2409 - val_loss: 25.2648\n",
      "Epoch 5734/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2005 - val_loss: 19.7036\n",
      "Epoch 5735/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2188 - val_loss: 28.7357\n",
      "Epoch 5736/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2130 - val_loss: 22.3111\n",
      "Epoch 5737/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1935 - val_loss: 22.1810\n",
      "Epoch 5738/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1863 - val_loss: 20.3552\n",
      "Epoch 5739/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1817 - val_loss: 20.4349\n",
      "Epoch 5740/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1844 - val_loss: 21.6808\n",
      "Epoch 5741/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1826 - val_loss: 16.7809\n",
      "Epoch 5742/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1842 - val_loss: 17.7799\n",
      "Epoch 5743/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1810 - val_loss: 14.6951\n",
      "Epoch 5744/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1775 - val_loss: 16.4722\n",
      "Epoch 5745/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1807 - val_loss: 18.7718\n",
      "Epoch 5746/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1829 - val_loss: 13.9393\n",
      "Epoch 5747/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1765 - val_loss: 15.1725\n",
      "Epoch 5748/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1767 - val_loss: 17.8436\n",
      "Epoch 5749/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1874 - val_loss: 21.1082\n",
      "Epoch 5750/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1930 - val_loss: 20.6806\n",
      "Epoch 5751/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1801 - val_loss: 19.7916\n",
      "Epoch 5752/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1804 - val_loss: 13.5096\n",
      "Epoch 5753/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1768 - val_loss: 17.3200\n",
      "Epoch 5754/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1748 - val_loss: 17.0426\n",
      "Epoch 5755/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1774 - val_loss: 19.1286\n",
      "Epoch 5756/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1772 - val_loss: 16.7418\n",
      "Epoch 5757/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1754 - val_loss: 15.5737\n",
      "Epoch 5758/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1772 - val_loss: 16.2754\n",
      "Epoch 5759/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1824 - val_loss: 25.0675\n",
      "Epoch 5760/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1831 - val_loss: 20.2635\n",
      "Epoch 5761/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1787 - val_loss: 15.3438\n",
      "Epoch 5762/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1752 - val_loss: 16.3845\n",
      "Epoch 5763/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1755 - val_loss: 16.5685\n",
      "Epoch 5764/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1753 - val_loss: 19.0474\n",
      "Epoch 5765/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1826 - val_loss: 22.8224\n",
      "Epoch 5766/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3011 - val_loss: 9.4772\n",
      "Epoch 5767/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2172 - val_loss: 5.4872\n",
      "Epoch 5768/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1922 - val_loss: 20.0373\n",
      "Epoch 5769/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1914 - val_loss: 17.4735\n",
      "Epoch 5770/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1859 - val_loss: 19.9288\n",
      "Epoch 5771/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1802 - val_loss: 19.2931\n",
      "Epoch 5772/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1769 - val_loss: 14.9718\n",
      "Epoch 5773/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1787 - val_loss: 16.1097\n",
      "Epoch 5774/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1740 - val_loss: 17.9527\n",
      "Epoch 5775/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1760 - val_loss: 17.6378\n",
      "Epoch 5776/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1755 - val_loss: 21.1072\n",
      "Epoch 5777/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1751 - val_loss: 21.3249\n",
      "Epoch 5778/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1766 - val_loss: 25.6007\n",
      "Epoch 5779/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1903 - val_loss: 28.0422\n",
      "Epoch 5780/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3593 - val_loss: 32.1029\n",
      "Epoch 5781/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2396 - val_loss: 16.4478\n",
      "Epoch 5782/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1903 - val_loss: 16.2474\n",
      "Epoch 5783/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1919 - val_loss: 24.2476\n",
      "Epoch 5784/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2002 - val_loss: 10.7244\n",
      "Epoch 5785/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1898 - val_loss: 17.7315\n",
      "Epoch 5786/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1907 - val_loss: 27.2365\n",
      "Epoch 5787/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2334 - val_loss: 10.4437\n",
      "Epoch 5788/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2204 - val_loss: 18.7371\n",
      "Epoch 5789/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1864 - val_loss: 13.5577\n",
      "Epoch 5790/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1768 - val_loss: 15.1701\n",
      "Epoch 5791/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1749 - val_loss: 14.5340\n",
      "Epoch 5792/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1745 - val_loss: 16.7563\n",
      "Epoch 5793/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1751 - val_loss: 17.6619\n",
      "Epoch 5794/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1744 - val_loss: 14.0565\n",
      "Epoch 5795/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 17.4165\n",
      "Epoch 5796/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1743 - val_loss: 15.0410\n",
      "Epoch 5797/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1764 - val_loss: 13.4635\n",
      "Epoch 5798/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 18.2678\n",
      "Epoch 5799/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 14.4090\n",
      "Epoch 5800/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1744 - val_loss: 13.2122\n",
      "Epoch 5801/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 13.5976\n",
      "Epoch 5802/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 14.5671\n",
      "Epoch 5803/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 15.3567\n",
      "Epoch 5804/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 15.2626\n",
      "Epoch 5805/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1710 - val_loss: 16.5798\n",
      "Epoch 5806/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 16.8362\n",
      "Epoch 5807/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 15.3576\n",
      "Epoch 5808/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1748 - val_loss: 13.5409\n",
      "Epoch 5809/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 17.2876\n",
      "Epoch 5810/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 14.7228\n",
      "Epoch 5811/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1985 - val_loss: 14.7222\n",
      "Epoch 5812/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4181 - val_loss: 16.1588\n",
      "Epoch 5813/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2221 - val_loss: 16.2335\n",
      "Epoch 5814/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1998 - val_loss: 8.5616\n",
      "Epoch 5815/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1911 - val_loss: 12.0927\n",
      "Epoch 5816/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1991 - val_loss: 6.3750\n",
      "Epoch 5817/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1817 - val_loss: 15.6772\n",
      "Epoch 5818/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1828 - val_loss: 11.5734\n",
      "Epoch 5819/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2004 - val_loss: 11.9916\n",
      "Epoch 5820/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1848 - val_loss: 10.8761\n",
      "Epoch 5821/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1798 - val_loss: 16.5711\n",
      "Epoch 5822/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1775 - val_loss: 14.6821\n",
      "Epoch 5823/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1745 - val_loss: 16.5823\n",
      "Epoch 5824/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1760 - val_loss: 10.9402\n",
      "Epoch 5825/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1755 - val_loss: 15.7797\n",
      "Epoch 5826/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1765 - val_loss: 22.3472\n",
      "Epoch 5827/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1843 - val_loss: 8.8898\n",
      "Epoch 5828/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2009 - val_loss: 6.5586\n",
      "Epoch 5829/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2273 - val_loss: 6.1116\n",
      "Epoch 5830/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2814 - val_loss: 16.9112\n",
      "Epoch 5831/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2444 - val_loss: 30.0532\n",
      "Epoch 5832/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2073 - val_loss: 24.4890\n",
      "Epoch 5833/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1976 - val_loss: 6.2365\n",
      "Epoch 5834/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1825 - val_loss: 8.5941\n",
      "Epoch 5835/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1751 - val_loss: 12.5355\n",
      "Epoch 5836/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1755 - val_loss: 13.6098\n",
      "Epoch 5837/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 12.0685\n",
      "Epoch 5838/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 10.7329\n",
      "Epoch 5839/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1734 - val_loss: 12.7205\n",
      "Epoch 5840/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 13.2929\n",
      "Epoch 5841/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 12.8935\n",
      "Epoch 5842/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 13.6523\n",
      "Epoch 5843/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1742 - val_loss: 11.5669\n",
      "Epoch 5844/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1739 - val_loss: 14.0949\n",
      "Epoch 5845/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 12.2755\n",
      "Epoch 5846/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 13.0574\n",
      "Epoch 5847/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 12.0042\n",
      "Epoch 5848/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 15.0599\n",
      "Epoch 5849/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1740 - val_loss: 12.1912\n",
      "Epoch 5850/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1743 - val_loss: 12.1437\n",
      "Epoch 5851/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1741 - val_loss: 14.3070\n",
      "Epoch 5852/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 13.4784\n",
      "Epoch 5853/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 12.7536\n",
      "Epoch 5854/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 16.6518\n",
      "Epoch 5855/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 18.4679\n",
      "Epoch 5856/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1751 - val_loss: 11.1198\n",
      "Epoch 5857/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1746 - val_loss: 14.6991\n",
      "Epoch 5858/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1774 - val_loss: 9.4005\n",
      "Epoch 5859/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3508 - val_loss: 10.6147\n",
      "Epoch 5860/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3954 - val_loss: 33.4478\n",
      "Epoch 5861/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2097 - val_loss: 27.7660\n",
      "Epoch 5862/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1941 - val_loss: 33.2779\n",
      "Epoch 5863/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1821 - val_loss: 29.6948\n",
      "Epoch 5864/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1809 - val_loss: 30.8124\n",
      "Epoch 5865/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1764 - val_loss: 26.0838\n",
      "Epoch 5866/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1775 - val_loss: 28.5829\n",
      "Epoch 5867/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 24.0264\n",
      "Epoch 5868/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1739 - val_loss: 26.9016\n",
      "Epoch 5869/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 25.2880\n",
      "Epoch 5870/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 23.6020\n",
      "Epoch 5871/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 25.6920\n",
      "Epoch 5872/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1717 - val_loss: 26.2760\n",
      "Epoch 5873/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 23.1701\n",
      "Epoch 5874/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 21.5115\n",
      "Epoch 5875/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1770 - val_loss: 27.1420\n",
      "Epoch 5876/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1762 - val_loss: 27.0036\n",
      "Epoch 5877/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 24.8503\n",
      "Epoch 5878/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1741 - val_loss: 25.4361\n",
      "Epoch 5879/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 23.8038\n",
      "Epoch 5880/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1752 - val_loss: 25.1391\n",
      "Epoch 5881/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1744 - val_loss: 22.2620\n",
      "Epoch 5882/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1708 - val_loss: 20.3298\n",
      "Epoch 5883/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 22.5258\n",
      "Epoch 5884/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 23.8424\n",
      "Epoch 5885/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 25.7995\n",
      "Epoch 5886/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1750 - val_loss: 21.8736\n",
      "Epoch 5887/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1739 - val_loss: 20.9407\n",
      "Epoch 5888/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 24.3546\n",
      "Epoch 5889/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 22.3183\n",
      "Epoch 5890/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 20.1708\n",
      "Epoch 5891/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 21.4960\n",
      "Epoch 5892/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2310 - val_loss: 39.5084\n",
      "Epoch 5893/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.5383 - val_loss: 9.0480\n",
      "Epoch 5894/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3681 - val_loss: 32.7238\n",
      "Epoch 5895/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2164 - val_loss: 30.3049\n",
      "Epoch 5896/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1883 - val_loss: 33.8440\n",
      "Epoch 5897/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1807 - val_loss: 31.7784\n",
      "Epoch 5898/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1815 - val_loss: 33.7972\n",
      "Epoch 5899/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1789 - val_loss: 30.8746\n",
      "Epoch 5900/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1767 - val_loss: 32.7891\n",
      "Epoch 5901/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1758 - val_loss: 31.7202\n",
      "Epoch 5902/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1781 - val_loss: 32.4476\n",
      "Epoch 5903/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1767 - val_loss: 30.6365\n",
      "Epoch 5904/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1752 - val_loss: 29.2073\n",
      "Epoch 5905/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1778 - val_loss: 32.9602\n",
      "Epoch 5906/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 31.0180\n",
      "Epoch 5907/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1747 - val_loss: 32.0428\n",
      "Epoch 5908/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1753 - val_loss: 31.2446\n",
      "Epoch 5909/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1753 - val_loss: 30.0345\n",
      "Epoch 5910/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 31.5806\n",
      "Epoch 5911/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 30.3561\n",
      "Epoch 5912/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 31.0277\n",
      "Epoch 5913/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 32.0855\n",
      "Epoch 5914/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1742 - val_loss: 31.8181\n",
      "Epoch 5915/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1743 - val_loss: 29.0066\n",
      "Epoch 5916/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1743 - val_loss: 28.6203\n",
      "Epoch 5917/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1751 - val_loss: 28.9037\n",
      "Epoch 5918/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1764 - val_loss: 30.1466\n",
      "Epoch 5919/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 30.2465\n",
      "Epoch 5920/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 30.2498\n",
      "Epoch 5921/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1739 - val_loss: 30.6611\n",
      "Epoch 5922/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1747 - val_loss: 29.3257\n",
      "Epoch 5923/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2275 - val_loss: 7.6567\n",
      "Epoch 5924/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2841 - val_loss: 26.5976\n",
      "Epoch 5925/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1983 - val_loss: 32.9815\n",
      "Epoch 5926/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2184 - val_loss: 12.4065\n",
      "Epoch 5927/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2690 - val_loss: 27.2072\n",
      "Epoch 5928/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2209 - val_loss: 33.4846\n",
      "Epoch 5929/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2209 - val_loss: 34.2497\n",
      "Epoch 5930/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1919 - val_loss: 30.9952\n",
      "Epoch 5931/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3946 - val_loss: 29.1447\n",
      "Epoch 5932/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3254 - val_loss: 32.9648\n",
      "Epoch 5933/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1989 - val_loss: 36.0914\n",
      "Epoch 5934/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2200 - val_loss: 29.9912\n",
      "Epoch 5935/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2029 - val_loss: 30.8597\n",
      "Epoch 5936/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1816 - val_loss: 33.6908\n",
      "Epoch 5937/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1773 - val_loss: 29.9105\n",
      "Epoch 5938/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1752 - val_loss: 32.6925\n",
      "Epoch 5939/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1761 - val_loss: 30.5086\n",
      "Epoch 5940/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1739 - val_loss: 31.0676\n",
      "Epoch 5941/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1745 - val_loss: 31.4826\n",
      "Epoch 5942/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 29.4102\n",
      "Epoch 5943/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 30.6418\n",
      "Epoch 5944/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 29.6046\n",
      "Epoch 5945/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1743 - val_loss: 31.4746\n",
      "Epoch 5946/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1746 - val_loss: 29.4502\n",
      "Epoch 5947/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 32.6476\n",
      "Epoch 5948/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1742 - val_loss: 28.5145\n",
      "Epoch 5949/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 31.0258\n",
      "Epoch 5950/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1745 - val_loss: 31.7259\n",
      "Epoch 5951/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 30.8875\n",
      "Epoch 5952/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 30.3233\n",
      "Epoch 5953/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 29.4948\n",
      "Epoch 5954/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 30.9116\n",
      "Epoch 5955/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 28.0057\n",
      "Epoch 5956/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 29.7469\n",
      "Epoch 5957/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 30.0365\n",
      "Epoch 5958/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 30.1896\n",
      "Epoch 5959/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 31.4259\n",
      "Epoch 5960/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 31.3046\n",
      "Epoch 5961/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1702 - val_loss: 29.5367\n",
      "Epoch 5962/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1708 - val_loss: 30.8992\n",
      "Epoch 5963/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 30.4312\n",
      "Epoch 5964/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 31.2266\n",
      "Epoch 5965/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 29.9532\n",
      "Epoch 5966/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 29.3800\n",
      "Epoch 5967/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 27.4481\n",
      "Epoch 5968/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 29.7212\n",
      "Epoch 5969/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 30.0569\n",
      "Epoch 5970/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 29.1733\n",
      "Epoch 5971/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1741 - val_loss: 31.0110\n",
      "Epoch 5972/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 27.9788\n",
      "Epoch 5973/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1747 - val_loss: 30.7758\n",
      "Epoch 5974/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 27.7457\n",
      "Epoch 5975/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 31.1172\n",
      "Epoch 5976/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1968 - val_loss: 2.4810\n",
      "Epoch 5977/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3092 - val_loss: 27.9191\n",
      "Epoch 5978/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4035 - val_loss: 37.5413\n",
      "Epoch 5979/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2002 - val_loss: 35.8916\n",
      "Epoch 5980/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1842 - val_loss: 35.8966\n",
      "Epoch 5981/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1775 - val_loss: 39.0236\n",
      "Epoch 5982/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1805 - val_loss: 38.7805\n",
      "Epoch 5983/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2046 - val_loss: 14.7692\n",
      "Epoch 5984/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2116 - val_loss: 22.3628\n",
      "Epoch 5985/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1990 - val_loss: 31.3900\n",
      "Epoch 5986/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1795 - val_loss: 30.0636\n",
      "Epoch 5987/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1757 - val_loss: 30.3962\n",
      "Epoch 5988/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1746 - val_loss: 30.7159\n",
      "Epoch 5989/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 32.6687\n",
      "Epoch 5990/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 32.3821\n",
      "Epoch 5991/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1730 - val_loss: 34.0507\n",
      "Epoch 5992/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1726 - val_loss: 31.2785\n",
      "Epoch 5993/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 32.6990\n",
      "Epoch 5994/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 30.2629\n",
      "Epoch 5995/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 32.3899\n",
      "Epoch 5996/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 32.9989\n",
      "Epoch 5997/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 31.7829\n",
      "Epoch 5998/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 31.8540\n",
      "Epoch 5999/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 32.3681\n",
      "Epoch 6000/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 30.4549\n",
      "Epoch 6001/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 31.9606\n",
      "Epoch 6002/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1744 - val_loss: 32.7241\n",
      "Epoch 6003/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 34.6973\n",
      "Epoch 6004/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 32.7985\n",
      "Epoch 6005/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 31.0583\n",
      "Epoch 6006/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1743 - val_loss: 34.2530\n",
      "Epoch 6007/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1738 - val_loss: 33.0602\n",
      "Epoch 6008/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1733 - val_loss: 33.1175\n",
      "Epoch 6009/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1726 - val_loss: 33.9920\n",
      "Epoch 6010/10000\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 0.1718 - val_loss: 33.6468\n",
      "Epoch 6011/10000\n",
      "34280/34280 [==============================] - 0s 12us/sample - loss: 0.1724 - val_loss: 32.8921\n",
      "Epoch 6012/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1738 - val_loss: 35.1996\n",
      "Epoch 6013/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1773 - val_loss: 32.6123\n",
      "Epoch 6014/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2075 - val_loss: 33.5651\n",
      "Epoch 6015/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3813 - val_loss: 47.5254\n",
      "Epoch 6016/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4121 - val_loss: 32.9918\n",
      "Epoch 6017/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2202 - val_loss: 36.0050\n",
      "Epoch 6018/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1951 - val_loss: 29.5249\n",
      "Epoch 6019/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2067 - val_loss: 30.5144\n",
      "Epoch 6020/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1813 - val_loss: 29.9175\n",
      "Epoch 6021/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1755 - val_loss: 28.2928\n",
      "Epoch 6022/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1762 - val_loss: 33.8179\n",
      "Epoch 6023/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1790 - val_loss: 31.8743\n",
      "Epoch 6024/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1741 - val_loss: 32.6348\n",
      "Epoch 6025/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1744 - val_loss: 33.1626\n",
      "Epoch 6026/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1741 - val_loss: 33.4149\n",
      "Epoch 6027/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1741 - val_loss: 33.1775\n",
      "Epoch 6028/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1741 - val_loss: 31.6443\n",
      "Epoch 6029/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 33.6086\n",
      "Epoch 6030/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1743 - val_loss: 34.1701\n",
      "Epoch 6031/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 32.0326\n",
      "Epoch 6032/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1744 - val_loss: 35.2901\n",
      "Epoch 6033/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1746 - val_loss: 36.6516\n",
      "Epoch 6034/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2085 - val_loss: 31.4194\n",
      "Epoch 6035/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3087 - val_loss: 22.5574\n",
      "Epoch 6036/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3065 - val_loss: 23.8069\n",
      "Epoch 6037/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2809 - val_loss: 27.9719\n",
      "Epoch 6038/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2054 - val_loss: 30.4196\n",
      "Epoch 6039/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1974 - val_loss: 28.4651\n",
      "Epoch 6040/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1864 - val_loss: 24.6232\n",
      "Epoch 6041/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1863 - val_loss: 30.2645\n",
      "Epoch 6042/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1954 - val_loss: 31.5870\n",
      "Epoch 6043/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1871 - val_loss: 32.2838\n",
      "Epoch 6044/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1794 - val_loss: 29.1041\n",
      "Epoch 6045/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1897 - val_loss: 31.8460\n",
      "Epoch 6046/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1776 - val_loss: 30.3555\n",
      "Epoch 6047/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1748 - val_loss: 31.5694\n",
      "Epoch 6048/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1739 - val_loss: 33.5951\n",
      "Epoch 6049/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 32.2430\n",
      "Epoch 6050/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 32.0275\n",
      "Epoch 6051/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 33.1531\n",
      "Epoch 6052/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 31.1998\n",
      "Epoch 6053/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1739 - val_loss: 33.4367\n",
      "Epoch 6054/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1749 - val_loss: 34.7463\n",
      "Epoch 6055/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 30.9998\n",
      "Epoch 6056/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 32.3067\n",
      "Epoch 6057/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 33.7127\n",
      "Epoch 6058/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 29.4116\n",
      "Epoch 6059/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1769 - val_loss: 31.5662\n",
      "Epoch 6060/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 30.9012\n",
      "Epoch 6061/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 32.5064\n",
      "Epoch 6062/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 32.9441\n",
      "Epoch 6063/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1741 - val_loss: 31.1381\n",
      "Epoch 6064/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 31.5217\n",
      "Epoch 6065/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1807 - val_loss: 29.4396\n",
      "Epoch 6066/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1751 - val_loss: 33.7521\n",
      "Epoch 6067/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1740 - val_loss: 32.3954\n",
      "Epoch 6068/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1741 - val_loss: 33.3367\n",
      "Epoch 6069/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1746 - val_loss: 32.9568\n",
      "Epoch 6070/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1745 - val_loss: 31.3928\n",
      "Epoch 6071/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 33.4688\n",
      "Epoch 6072/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2324 - val_loss: 24.6415\n",
      "Epoch 6073/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2701 - val_loss: 13.8487\n",
      "Epoch 6074/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2664 - val_loss: 28.1177\n",
      "Epoch 6075/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2326 - val_loss: 29.3903\n",
      "Epoch 6076/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1849 - val_loss: 25.9381\n",
      "Epoch 6077/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1880 - val_loss: 28.2972\n",
      "Epoch 6078/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1966 - val_loss: 32.3918\n",
      "Epoch 6079/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2800 - val_loss: 27.6120\n",
      "Epoch 6080/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2344 - val_loss: 33.8045\n",
      "Epoch 6081/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1926 - val_loss: 33.2068\n",
      "Epoch 6082/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1785 - val_loss: 33.3765\n",
      "Epoch 6083/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 34.8068\n",
      "Epoch 6084/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 33.5909\n",
      "Epoch 6085/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 34.5565\n",
      "Epoch 6086/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1740 - val_loss: 32.8096\n",
      "Epoch 6087/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 33.6938\n",
      "Epoch 6088/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1735 - val_loss: 33.2723\n",
      "Epoch 6089/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 34.0291\n",
      "Epoch 6090/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 34.6407\n",
      "Epoch 6091/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1752 - val_loss: 32.2659\n",
      "Epoch 6092/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 31.5668\n",
      "Epoch 6093/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 30.8269\n",
      "Epoch 6094/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 31.9297\n",
      "Epoch 6095/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1734 - val_loss: 32.9774\n",
      "Epoch 6096/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 29.8351\n",
      "Epoch 6097/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 33.0961\n",
      "Epoch 6098/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 29.6498\n",
      "Epoch 6099/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1783 - val_loss: 28.4134\n",
      "Epoch 6100/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1781 - val_loss: 34.4331\n",
      "Epoch 6101/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3868 - val_loss: 42.9448\n",
      "Epoch 6102/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2825 - val_loss: 52.7447\n",
      "Epoch 6103/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2529 - val_loss: 35.5712\n",
      "Epoch 6104/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2305 - val_loss: 46.0100\n",
      "Epoch 6105/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1995 - val_loss: 38.6286\n",
      "Epoch 6106/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1785 - val_loss: 38.3873\n",
      "Epoch 6107/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1861 - val_loss: 39.8382\n",
      "Epoch 6108/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1773 - val_loss: 43.0171\n",
      "Epoch 6109/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1809 - val_loss: 43.0588\n",
      "Epoch 6110/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1741 - val_loss: 40.3318\n",
      "Epoch 6111/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 39.5992\n",
      "Epoch 6112/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1750 - val_loss: 44.9795\n",
      "Epoch 6113/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1785 - val_loss: 40.5251\n",
      "Epoch 6114/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 38.7527\n",
      "Epoch 6115/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1743 - val_loss: 41.4395\n",
      "Epoch 6116/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1741 - val_loss: 37.6196\n",
      "Epoch 6117/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 38.0231\n",
      "Epoch 6118/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 39.1519\n",
      "Epoch 6119/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 41.9533\n",
      "Epoch 6120/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1742 - val_loss: 38.0757\n",
      "Epoch 6121/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 38.7870\n",
      "Epoch 6122/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1709 - val_loss: 40.0386\n",
      "Epoch 6123/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 40.2766\n",
      "Epoch 6124/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1739 - val_loss: 38.4461\n",
      "Epoch 6125/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 40.9657\n",
      "Epoch 6126/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 40.2291\n",
      "Epoch 6127/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 40.7131\n",
      "Epoch 6128/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 39.9812\n",
      "Epoch 6129/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 40.2413\n",
      "Epoch 6130/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 39.9711\n",
      "Epoch 6131/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1787 - val_loss: 33.3778\n",
      "Epoch 6132/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1938 - val_loss: 39.2787\n",
      "Epoch 6133/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1765 - val_loss: 40.9030\n",
      "Epoch 6134/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 41.7542\n",
      "Epoch 6135/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 40.9649\n",
      "Epoch 6136/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 39.9820\n",
      "Epoch 6137/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 41.7365\n",
      "Epoch 6138/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 40.0131\n",
      "Epoch 6139/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 41.4433\n",
      "Epoch 6140/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1741 - val_loss: 37.5300\n",
      "Epoch 6141/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 41.2985\n",
      "Epoch 6142/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 39.4490\n",
      "Epoch 6143/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 41.7124\n",
      "Epoch 6144/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1950 - val_loss: 32.7096\n",
      "Epoch 6145/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.5148 - val_loss: 40.3886\n",
      "Epoch 6146/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3397 - val_loss: 41.5985\n",
      "Epoch 6147/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2400 - val_loss: 41.3093\n",
      "Epoch 6148/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2956 - val_loss: 33.5026\n",
      "Epoch 6149/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2856 - val_loss: 44.8017\n",
      "Epoch 6150/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2619 - val_loss: 47.2228\n",
      "Epoch 6151/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2439 - val_loss: 44.8945\n",
      "Epoch 6152/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2436 - val_loss: 38.1802\n",
      "Epoch 6153/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1961 - val_loss: 46.5963\n",
      "Epoch 6154/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1835 - val_loss: 46.3030\n",
      "Epoch 6155/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1766 - val_loss: 43.8070\n",
      "Epoch 6156/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1758 - val_loss: 45.3921\n",
      "Epoch 6157/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1744 - val_loss: 44.3625\n",
      "Epoch 6158/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1769 - val_loss: 43.9895\n",
      "Epoch 6159/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1761 - val_loss: 43.3516\n",
      "Epoch 6160/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1747 - val_loss: 44.6434\n",
      "Epoch 6161/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 45.1566\n",
      "Epoch 6162/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 46.2865\n",
      "Epoch 6163/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 46.1663\n",
      "Epoch 6164/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 44.9856\n",
      "Epoch 6165/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 46.7949\n",
      "Epoch 6166/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 44.7186\n",
      "Epoch 6167/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1752 - val_loss: 45.5641\n",
      "Epoch 6168/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 46.4125\n",
      "Epoch 6169/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 46.7669\n",
      "Epoch 6170/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 45.3005\n",
      "Epoch 6171/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 45.2265\n",
      "Epoch 6172/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 46.7183\n",
      "Epoch 6173/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 47.0387\n",
      "Epoch 6174/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 46.8464\n",
      "Epoch 6175/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 46.5279\n",
      "Epoch 6176/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 46.2700\n",
      "Epoch 6177/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 47.8314\n",
      "Epoch 6178/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1741 - val_loss: 45.0290\n",
      "Epoch 6179/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1740 - val_loss: 45.4153\n",
      "Epoch 6180/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1750 - val_loss: 46.0293\n",
      "Epoch 6181/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1769 - val_loss: 43.8771\n",
      "Epoch 6182/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1740 - val_loss: 46.0183\n",
      "Epoch 6183/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 45.5611\n",
      "Epoch 6184/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1696 - val_loss: 45.8193\n",
      "Epoch 6185/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1744 - val_loss: 45.0672\n",
      "Epoch 6186/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 44.3283\n",
      "Epoch 6187/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 43.6223\n",
      "Epoch 6188/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 46.8741\n",
      "Epoch 6189/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1708 - val_loss: 44.9862\n",
      "Epoch 6190/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 45.3506\n",
      "Epoch 6191/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 46.3765\n",
      "Epoch 6192/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 41.4859\n",
      "Epoch 6193/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1780 - val_loss: 47.3959\n",
      "Epoch 6194/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1798 - val_loss: 41.9654\n",
      "Epoch 6195/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2232 - val_loss: 40.2631\n",
      "Epoch 6196/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2572 - val_loss: 40.7977\n",
      "Epoch 6197/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2875 - val_loss: 37.5861\n",
      "Epoch 6198/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3236 - val_loss: 51.4224\n",
      "Epoch 6199/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2762 - val_loss: 32.9231\n",
      "Epoch 6200/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2018 - val_loss: 31.9323\n",
      "Epoch 6201/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1909 - val_loss: 40.0176\n",
      "Epoch 6202/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1823 - val_loss: 38.1808\n",
      "Epoch 6203/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1789 - val_loss: 35.4421\n",
      "Epoch 6204/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1774 - val_loss: 35.4392\n",
      "Epoch 6205/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1756 - val_loss: 41.4767\n",
      "Epoch 6206/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1746 - val_loss: 35.9704\n",
      "Epoch 6207/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1791 - val_loss: 39.1545\n",
      "Epoch 6208/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1881 - val_loss: 38.1526\n",
      "Epoch 6209/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1777 - val_loss: 43.5568\n",
      "Epoch 6210/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1762 - val_loss: 39.3709\n",
      "Epoch 6211/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 39.7436\n",
      "Epoch 6212/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 40.4151\n",
      "Epoch 6213/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 39.3480\n",
      "Epoch 6214/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1720 - val_loss: 38.5196\n",
      "Epoch 6215/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1738 - val_loss: 40.3434\n",
      "Epoch 6216/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 38.8219\n",
      "Epoch 6217/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 39.9539\n",
      "Epoch 6218/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1693 - val_loss: 38.4737\n",
      "Epoch 6219/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1726 - val_loss: 40.3230\n",
      "Epoch 6220/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1724 - val_loss: 39.1748\n",
      "Epoch 6221/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 38.4548\n",
      "Epoch 6222/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1700 - val_loss: 39.1569\n",
      "Epoch 6223/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 39.2585\n",
      "Epoch 6224/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 40.5393\n",
      "Epoch 6225/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1748 - val_loss: 37.3194\n",
      "Epoch 6226/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 42.4682\n",
      "Epoch 6227/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1763 - val_loss: 39.2105\n",
      "Epoch 6228/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1744 - val_loss: 37.6801\n",
      "Epoch 6229/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1751 - val_loss: 40.1911\n",
      "Epoch 6230/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3487 - val_loss: 46.4195\n",
      "Epoch 6231/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2609 - val_loss: 52.4845\n",
      "Epoch 6232/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2263 - val_loss: 40.5135\n",
      "Epoch 6233/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3627 - val_loss: 49.6236\n",
      "Epoch 6234/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2161 - val_loss: 37.2453\n",
      "Epoch 6235/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2112 - val_loss: 41.0027\n",
      "Epoch 6236/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1942 - val_loss: 39.7873\n",
      "Epoch 6237/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1848 - val_loss: 38.2461\n",
      "Epoch 6238/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1792 - val_loss: 41.4415\n",
      "Epoch 6239/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1741 - val_loss: 43.6889\n",
      "Epoch 6240/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1758 - val_loss: 46.9012\n",
      "Epoch 6241/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 43.8155\n",
      "Epoch 6242/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 44.3669\n",
      "Epoch 6243/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 44.2141\n",
      "Epoch 6244/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 45.7402\n",
      "Epoch 6245/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 44.3708\n",
      "Epoch 6246/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 43.6820\n",
      "Epoch 6247/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 43.9510\n",
      "Epoch 6248/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 43.9866\n",
      "Epoch 6249/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 43.7860\n",
      "Epoch 6250/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 44.4801\n",
      "Epoch 6251/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1727 - val_loss: 43.7658\n",
      "Epoch 6252/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1697 - val_loss: 44.1611\n",
      "Epoch 6253/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 44.4158\n",
      "Epoch 6254/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1730 - val_loss: 46.5000\n",
      "Epoch 6255/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1798 - val_loss: 42.1615\n",
      "Epoch 6256/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1797 - val_loss: 45.2661\n",
      "Epoch 6257/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1883 - val_loss: 27.8608\n",
      "Epoch 6258/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2229 - val_loss: 45.6411\n",
      "Epoch 6259/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2085 - val_loss: 53.3217\n",
      "Epoch 6260/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.3798 - val_loss: 45.6974\n",
      "Epoch 6261/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2636 - val_loss: 53.3425\n",
      "Epoch 6262/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2137 - val_loss: 53.6295\n",
      "Epoch 6263/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1937 - val_loss: 44.6560\n",
      "Epoch 6264/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1782 - val_loss: 49.8698\n",
      "Epoch 6265/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1974 - val_loss: 41.5767\n",
      "Epoch 6266/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1994 - val_loss: 48.9978\n",
      "Epoch 6267/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1794 - val_loss: 50.4316\n",
      "Epoch 6268/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1744 - val_loss: 50.1092\n",
      "Epoch 6269/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 52.0517\n",
      "Epoch 6270/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1781 - val_loss: 51.6265\n",
      "Epoch 6271/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1747 - val_loss: 50.6591\n",
      "Epoch 6272/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 51.2088\n",
      "Epoch 6273/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 49.3892\n",
      "Epoch 6274/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1738 - val_loss: 48.8765\n",
      "Epoch 6275/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1763 - val_loss: 50.8716\n",
      "Epoch 6276/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 50.4105\n",
      "Epoch 6277/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 50.3152\n",
      "Epoch 6278/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 50.8020\n",
      "Epoch 6279/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 50.3733\n",
      "Epoch 6280/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1751 - val_loss: 50.8235\n",
      "Epoch 6281/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1712 - val_loss: 51.7025\n",
      "Epoch 6282/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 49.7868\n",
      "Epoch 6283/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1711 - val_loss: 51.5870\n",
      "Epoch 6284/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 50.1016\n",
      "Epoch 6285/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 50.1772\n",
      "Epoch 6286/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 51.1117\n",
      "Epoch 6287/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 51.9518\n",
      "Epoch 6288/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 51.3933\n",
      "Epoch 6289/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 51.8702\n",
      "Epoch 6290/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 51.7398\n",
      "Epoch 6291/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 51.5529\n",
      "Epoch 6292/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 52.1013\n",
      "Epoch 6293/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 50.5662\n",
      "Epoch 6294/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 49.7001\n",
      "Epoch 6295/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1767 - val_loss: 54.2607\n",
      "Epoch 6296/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2316 - val_loss: 48.7299\n",
      "Epoch 6297/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1912 - val_loss: 44.2209\n",
      "Epoch 6298/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2131 - val_loss: 48.5465\n",
      "Epoch 6299/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2152 - val_loss: 49.5256\n",
      "Epoch 6300/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3329 - val_loss: 63.5934\n",
      "Epoch 6301/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3430 - val_loss: 64.3171\n",
      "Epoch 6302/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2062 - val_loss: 62.0006\n",
      "Epoch 6303/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2037 - val_loss: 60.8003\n",
      "Epoch 6304/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1870 - val_loss: 60.3781\n",
      "Epoch 6305/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2107 - val_loss: 57.3038\n",
      "Epoch 6306/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2043 - val_loss: 59.6243\n",
      "Epoch 6307/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2089 - val_loss: 57.0720\n",
      "Epoch 6308/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1865 - val_loss: 59.3401\n",
      "Epoch 6309/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1816 - val_loss: 60.1561\n",
      "Epoch 6310/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2361 - val_loss: 54.4299\n",
      "Epoch 6311/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2261 - val_loss: 50.6095\n",
      "Epoch 6312/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1808 - val_loss: 51.1784\n",
      "Epoch 6313/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1774 - val_loss: 56.7392\n",
      "Epoch 6314/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1785 - val_loss: 52.2761\n",
      "Epoch 6315/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1740 - val_loss: 53.4894\n",
      "Epoch 6316/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 53.6121\n",
      "Epoch 6317/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 53.8247\n",
      "Epoch 6318/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 53.6499\n",
      "Epoch 6319/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 53.8059\n",
      "Epoch 6320/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1708 - val_loss: 53.5684\n",
      "Epoch 6321/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 53.2340\n",
      "Epoch 6322/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1724 - val_loss: 53.2209\n",
      "Epoch 6323/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1725 - val_loss: 53.6407\n",
      "Epoch 6324/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1731 - val_loss: 52.0340\n",
      "Epoch 6325/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 53.2593\n",
      "Epoch 6326/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 53.2430\n",
      "Epoch 6327/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1709 - val_loss: 53.9171\n",
      "Epoch 6328/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 52.2423\n",
      "Epoch 6329/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1686 - val_loss: 53.4506\n",
      "Epoch 6330/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1746 - val_loss: 53.5599\n",
      "Epoch 6331/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 54.4947\n",
      "Epoch 6332/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 54.3573\n",
      "Epoch 6333/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 53.1108\n",
      "Epoch 6334/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 53.4536\n",
      "Epoch 6335/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1741 - val_loss: 54.4337\n",
      "Epoch 6336/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 53.6095\n",
      "Epoch 6337/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1744 - val_loss: 51.3967\n",
      "Epoch 6338/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1752 - val_loss: 53.4794\n",
      "Epoch 6339/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1768 - val_loss: 53.0054\n",
      "Epoch 6340/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1744 - val_loss: 55.2023\n",
      "Epoch 6341/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1739 - val_loss: 53.6494\n",
      "Epoch 6342/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 52.3113\n",
      "Epoch 6343/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 52.5465\n",
      "Epoch 6344/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1746 - val_loss: 49.5028\n",
      "Epoch 6345/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2124 - val_loss: 42.5635\n",
      "Epoch 6346/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2125 - val_loss: 46.6209\n",
      "Epoch 6347/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1810 - val_loss: 44.0256\n",
      "Epoch 6348/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1788 - val_loss: 46.4991\n",
      "Epoch 6349/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1747 - val_loss: 47.8503\n",
      "Epoch 6350/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1793 - val_loss: 47.7870\n",
      "Epoch 6351/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1785 - val_loss: 46.6369\n",
      "Epoch 6352/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3515 - val_loss: 69.4483\n",
      "Epoch 6353/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.6930 - val_loss: 54.0789\n",
      "Epoch 6354/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3624 - val_loss: 56.7039\n",
      "Epoch 6355/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3022 - val_loss: 61.1527\n",
      "Epoch 6356/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2424 - val_loss: 62.0534\n",
      "Epoch 6357/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2333 - val_loss: 62.2587\n",
      "Epoch 6358/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2099 - val_loss: 62.6875\n",
      "Epoch 6359/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2125 - val_loss: 67.2840\n",
      "Epoch 6360/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2147 - val_loss: 64.0967\n",
      "Epoch 6361/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1995 - val_loss: 61.9954\n",
      "Epoch 6362/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2091 - val_loss: 61.9208\n",
      "Epoch 6363/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2063 - val_loss: 63.4630\n",
      "Epoch 6364/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2074 - val_loss: 59.3744\n",
      "Epoch 6365/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2044 - val_loss: 63.6151\n",
      "Epoch 6366/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1981 - val_loss: 64.3982\n",
      "Epoch 6367/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2062 - val_loss: 60.5075\n",
      "Epoch 6368/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2040 - val_loss: 61.6771\n",
      "Epoch 6369/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2417 - val_loss: 54.8539\n",
      "Epoch 6370/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2258 - val_loss: 59.4867\n",
      "Epoch 6371/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2004 - val_loss: 60.2302\n",
      "Epoch 6372/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2089 - val_loss: 61.8025\n",
      "Epoch 6373/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2129 - val_loss: 65.7226\n",
      "Epoch 6374/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2082 - val_loss: 64.7714\n",
      "Epoch 6375/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1999 - val_loss: 63.8683\n",
      "Epoch 6376/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2009 - val_loss: 62.3007\n",
      "Epoch 6377/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2100 - val_loss: 57.2155\n",
      "Epoch 6378/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1935 - val_loss: 60.3459\n",
      "Epoch 6379/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1976 - val_loss: 57.3149\n",
      "Epoch 6380/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2030 - val_loss: 58.4007\n",
      "Epoch 6381/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1965 - val_loss: 59.1513\n",
      "Epoch 6382/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1933 - val_loss: 57.9667\n",
      "Epoch 6383/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1851 - val_loss: 57.3070\n",
      "Epoch 6384/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1902 - val_loss: 55.2915\n",
      "Epoch 6385/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1914 - val_loss: 57.7261\n",
      "Epoch 6386/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1876 - val_loss: 58.8485\n",
      "Epoch 6387/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1865 - val_loss: 56.2149\n",
      "Epoch 6388/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1867 - val_loss: 57.9138\n",
      "Epoch 6389/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2034 - val_loss: 56.9798\n",
      "Epoch 6390/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1856 - val_loss: 55.3177\n",
      "Epoch 6391/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1891 - val_loss: 46.7666\n",
      "Epoch 6392/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1999 - val_loss: 52.1054\n",
      "Epoch 6393/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1837 - val_loss: 52.1429\n",
      "Epoch 6394/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1955 - val_loss: 45.6824\n",
      "Epoch 6395/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2092 - val_loss: 53.5004\n",
      "Epoch 6396/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1964 - val_loss: 55.0640\n",
      "Epoch 6397/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1871 - val_loss: 50.4136\n",
      "Epoch 6398/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2110 - val_loss: 45.1250\n",
      "Epoch 6399/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2114 - val_loss: 48.4654\n",
      "Epoch 6400/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1910 - val_loss: 45.4843\n",
      "Epoch 6401/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1952 - val_loss: 49.0352\n",
      "Epoch 6402/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1903 - val_loss: 44.1171\n",
      "Epoch 6403/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1859 - val_loss: 47.5116\n",
      "Epoch 6404/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1917 - val_loss: 49.1143\n",
      "Epoch 6405/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1868 - val_loss: 47.5226\n",
      "Epoch 6406/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1833 - val_loss: 50.5422\n",
      "Epoch 6407/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1776 - val_loss: 50.4947\n",
      "Epoch 6408/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1781 - val_loss: 50.0785\n",
      "Epoch 6409/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1780 - val_loss: 50.9603\n",
      "Epoch 6410/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1790 - val_loss: 51.9563\n",
      "Epoch 6411/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1974 - val_loss: 50.7947\n",
      "Epoch 6412/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1865 - val_loss: 52.8028\n",
      "Epoch 6413/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1801 - val_loss: 51.5114\n",
      "Epoch 6414/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1790 - val_loss: 52.3023\n",
      "Epoch 6415/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1824 - val_loss: 53.1906\n",
      "Epoch 6416/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1856 - val_loss: 54.8362\n",
      "Epoch 6417/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1875 - val_loss: 52.8531\n",
      "Epoch 6418/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1806 - val_loss: 55.0238\n",
      "Epoch 6419/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1793 - val_loss: 56.7358\n",
      "Epoch 6420/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2660 - val_loss: 50.9832\n",
      "Epoch 6421/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2897 - val_loss: 52.1985\n",
      "Epoch 6422/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2022 - val_loss: 46.6978\n",
      "Epoch 6423/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1840 - val_loss: 42.2507\n",
      "Epoch 6424/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1821 - val_loss: 46.8608\n",
      "Epoch 6425/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1824 - val_loss: 49.9721\n",
      "Epoch 6426/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1945 - val_loss: 43.9084\n",
      "Epoch 6427/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2114 - val_loss: 45.9528\n",
      "Epoch 6428/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1972 - val_loss: 47.0770\n",
      "Epoch 6429/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1998 - val_loss: 46.5883\n",
      "Epoch 6430/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2130 - val_loss: 49.5546\n",
      "Epoch 6431/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2216 - val_loss: 48.5444\n",
      "Epoch 6432/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2258 - val_loss: 54.9040\n",
      "Epoch 6433/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1972 - val_loss: 38.3946\n",
      "Epoch 6434/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1852 - val_loss: 38.9771\n",
      "Epoch 6435/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1808 - val_loss: 38.3008\n",
      "Epoch 6436/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1814 - val_loss: 39.2946\n",
      "Epoch 6437/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1776 - val_loss: 39.2227\n",
      "Epoch 6438/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1772 - val_loss: 39.5141\n",
      "Epoch 6439/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1807 - val_loss: 40.3025\n",
      "Epoch 6440/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1813 - val_loss: 41.9120\n",
      "Epoch 6441/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1826 - val_loss: 42.1866\n",
      "Epoch 6442/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1777 - val_loss: 40.3769\n",
      "Epoch 6443/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1868 - val_loss: 39.4236\n",
      "Epoch 6444/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2008 - val_loss: 38.0638\n",
      "Epoch 6445/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2308 - val_loss: 38.9216\n",
      "Epoch 6446/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2021 - val_loss: 40.0037\n",
      "Epoch 6447/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1798 - val_loss: 42.3465\n",
      "Epoch 6448/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1802 - val_loss: 40.8910\n",
      "Epoch 6449/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1843 - val_loss: 41.7486\n",
      "Epoch 6450/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1775 - val_loss: 39.9773\n",
      "Epoch 6451/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1797 - val_loss: 37.2055\n",
      "Epoch 6452/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1806 - val_loss: 34.1957\n",
      "Epoch 6453/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2109 - val_loss: 43.2978\n",
      "Epoch 6454/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1935 - val_loss: 46.2474\n",
      "Epoch 6455/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1962 - val_loss: 41.6858\n",
      "Epoch 6456/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1898 - val_loss: 43.0693\n",
      "Epoch 6457/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1909 - val_loss: 45.4454\n",
      "Epoch 6458/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2201 - val_loss: 40.8492\n",
      "Epoch 6459/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2401 - val_loss: 48.7440\n",
      "Epoch 6460/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1987 - val_loss: 45.9739\n",
      "Epoch 6461/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1833 - val_loss: 47.2501\n",
      "Epoch 6462/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1783 - val_loss: 44.2470\n",
      "Epoch 6463/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1820 - val_loss: 46.2324\n",
      "Epoch 6464/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1777 - val_loss: 43.9386\n",
      "Epoch 6465/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1760 - val_loss: 46.9574\n",
      "Epoch 6466/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1790 - val_loss: 43.9210\n",
      "Epoch 6467/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1882 - val_loss: 44.6155\n",
      "Epoch 6468/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2075 - val_loss: 47.7246\n",
      "Epoch 6469/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1916 - val_loss: 43.3799\n",
      "Epoch 6470/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1844 - val_loss: 40.5328\n",
      "Epoch 6471/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1774 - val_loss: 41.8938\n",
      "Epoch 6472/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1822 - val_loss: 37.7229\n",
      "Epoch 6473/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1800 - val_loss: 40.0214\n",
      "Epoch 6474/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1780 - val_loss: 37.0813\n",
      "Epoch 6475/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1774 - val_loss: 37.0599\n",
      "Epoch 6476/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1760 - val_loss: 37.8328\n",
      "Epoch 6477/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1807 - val_loss: 40.7196\n",
      "Epoch 6478/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1848 - val_loss: 45.2630\n",
      "Epoch 6479/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1758 - val_loss: 42.1221\n",
      "Epoch 6480/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1763 - val_loss: 42.3301\n",
      "Epoch 6481/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1758 - val_loss: 40.3875\n",
      "Epoch 6482/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1772 - val_loss: 40.5135\n",
      "Epoch 6483/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1756 - val_loss: 38.6239\n",
      "Epoch 6484/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 39.7608\n",
      "Epoch 6485/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2216 - val_loss: 36.9753\n",
      "Epoch 6486/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2932 - val_loss: 40.7151\n",
      "Epoch 6487/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2315 - val_loss: 57.5780\n",
      "Epoch 6488/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1925 - val_loss: 57.0011\n",
      "Epoch 6489/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2064 - val_loss: 47.3783\n",
      "Epoch 6490/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1964 - val_loss: 48.4887\n",
      "Epoch 6491/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1895 - val_loss: 57.3283\n",
      "Epoch 6492/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1833 - val_loss: 57.0999\n",
      "Epoch 6493/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1766 - val_loss: 56.5270\n",
      "Epoch 6494/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1835 - val_loss: 55.9385\n",
      "Epoch 6495/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1878 - val_loss: 57.6011\n",
      "Epoch 6496/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1799 - val_loss: 55.1638\n",
      "Epoch 6497/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1765 - val_loss: 57.9133\n",
      "Epoch 6498/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1771 - val_loss: 54.2902\n",
      "Epoch 6499/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1894 - val_loss: 58.0977\n",
      "Epoch 6500/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1821 - val_loss: 57.6755\n",
      "Epoch 6501/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1771 - val_loss: 60.0285\n",
      "Epoch 6502/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1764 - val_loss: 59.0342\n",
      "Epoch 6503/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1787 - val_loss: 56.4203\n",
      "Epoch 6504/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1769 - val_loss: 58.4989\n",
      "Epoch 6505/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1755 - val_loss: 55.0555\n",
      "Epoch 6506/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1818 - val_loss: 55.9358\n",
      "Epoch 6507/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2103 - val_loss: 58.7340\n",
      "Epoch 6508/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3305 - val_loss: 68.1363\n",
      "Epoch 6509/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3505 - val_loss: 56.7176\n",
      "Epoch 6510/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2553 - val_loss: 62.0975\n",
      "Epoch 6511/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2369 - val_loss: 52.8743\n",
      "Epoch 6512/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2268 - val_loss: 47.6429\n",
      "Epoch 6513/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2432 - val_loss: 54.7575\n",
      "Epoch 6514/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1977 - val_loss: 52.4948\n",
      "Epoch 6515/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1876 - val_loss: 52.4422\n",
      "Epoch 6516/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1888 - val_loss: 52.2399\n",
      "Epoch 6517/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1862 - val_loss: 47.1217\n",
      "Epoch 6518/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2071 - val_loss: 47.4986\n",
      "Epoch 6519/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2137 - val_loss: 52.7230\n",
      "Epoch 6520/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1949 - val_loss: 55.5531\n",
      "Epoch 6521/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2122 - val_loss: 62.1861\n",
      "Epoch 6522/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2384 - val_loss: 50.1123\n",
      "Epoch 6523/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2803 - val_loss: 55.1461\n",
      "Epoch 6524/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2316 - val_loss: 46.3274\n",
      "Epoch 6525/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2156 - val_loss: 47.4838\n",
      "Epoch 6526/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1940 - val_loss: 48.6797\n",
      "Epoch 6527/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1907 - val_loss: 43.8491\n",
      "Epoch 6528/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1931 - val_loss: 49.8916\n",
      "Epoch 6529/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1849 - val_loss: 46.5786\n",
      "Epoch 6530/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1928 - val_loss: 49.5916\n",
      "Epoch 6531/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1861 - val_loss: 45.4810\n",
      "Epoch 6532/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1773 - val_loss: 46.5211\n",
      "Epoch 6533/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1791 - val_loss: 49.0856\n",
      "Epoch 6534/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1781 - val_loss: 49.0493\n",
      "Epoch 6535/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1778 - val_loss: 45.6457\n",
      "Epoch 6536/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1947 - val_loss: 47.7580\n",
      "Epoch 6537/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1971 - val_loss: 44.3361\n",
      "Epoch 6538/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2224 - val_loss: 49.5447\n",
      "Epoch 6539/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2124 - val_loss: 46.8401\n",
      "Epoch 6540/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1842 - val_loss: 50.2044\n",
      "Epoch 6541/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1799 - val_loss: 49.1339\n",
      "Epoch 6542/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1798 - val_loss: 51.8337\n",
      "Epoch 6543/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1993 - val_loss: 47.9279\n",
      "Epoch 6544/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2215 - val_loss: 45.3277\n",
      "Epoch 6545/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2389 - val_loss: 52.4314\n",
      "Epoch 6546/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1821 - val_loss: 49.5405\n",
      "Epoch 6547/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1776 - val_loss: 49.6067\n",
      "Epoch 6548/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1772 - val_loss: 49.9166\n",
      "Epoch 6549/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1765 - val_loss: 49.8340\n",
      "Epoch 6550/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1763 - val_loss: 50.0028\n",
      "Epoch 6551/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1752 - val_loss: 50.3431\n",
      "Epoch 6552/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 51.6936\n",
      "Epoch 6553/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1753 - val_loss: 50.0931\n",
      "Epoch 6554/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1794 - val_loss: 53.0253\n",
      "Epoch 6555/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1763 - val_loss: 51.1774\n",
      "Epoch 6556/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 52.8412\n",
      "Epoch 6557/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1759 - val_loss: 50.1070\n",
      "Epoch 6558/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1745 - val_loss: 51.3186\n",
      "Epoch 6559/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1754 - val_loss: 51.3862\n",
      "Epoch 6560/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1762 - val_loss: 47.7252\n",
      "Epoch 6561/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1820 - val_loss: 52.6224\n",
      "Epoch 6562/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1886 - val_loss: 49.7698\n",
      "Epoch 6563/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1759 - val_loss: 54.3962\n",
      "Epoch 6564/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1761 - val_loss: 52.9269\n",
      "Epoch 6565/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1763 - val_loss: 54.4118\n",
      "Epoch 6566/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1754 - val_loss: 54.6938\n",
      "Epoch 6567/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1756 - val_loss: 54.0099\n",
      "Epoch 6568/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1795 - val_loss: 53.3364\n",
      "Epoch 6569/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1767 - val_loss: 55.7997\n",
      "Epoch 6570/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1743 - val_loss: 56.1330\n",
      "Epoch 6571/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1757 - val_loss: 56.0333\n",
      "Epoch 6572/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1776 - val_loss: 52.4768\n",
      "Epoch 6573/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1793 - val_loss: 51.8281\n",
      "Epoch 6574/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1816 - val_loss: 54.4256\n",
      "Epoch 6575/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3597 - val_loss: 31.4493\n",
      "Epoch 6576/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2517 - val_loss: 17.5852\n",
      "Epoch 6577/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2057 - val_loss: 7.7313\n",
      "Epoch 6578/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2103 - val_loss: 33.3149\n",
      "Epoch 6579/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2113 - val_loss: 30.7921\n",
      "Epoch 6580/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2168 - val_loss: 34.9142\n",
      "Epoch 6581/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2444 - val_loss: 39.4417\n",
      "Epoch 6582/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2298 - val_loss: 41.1399\n",
      "Epoch 6583/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1912 - val_loss: 32.2803\n",
      "Epoch 6584/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2096 - val_loss: 45.3071\n",
      "Epoch 6585/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2026 - val_loss: 38.2852\n",
      "Epoch 6586/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2048 - val_loss: 39.2393\n",
      "Epoch 6587/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2031 - val_loss: 47.8407\n",
      "Epoch 6588/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1876 - val_loss: 43.6380\n",
      "Epoch 6589/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1831 - val_loss: 49.3542\n",
      "Epoch 6590/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1779 - val_loss: 46.4685\n",
      "Epoch 6591/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1758 - val_loss: 45.7644\n",
      "Epoch 6592/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1762 - val_loss: 45.2259\n",
      "Epoch 6593/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1790 - val_loss: 45.8318\n",
      "Epoch 6594/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1759 - val_loss: 47.2228\n",
      "Epoch 6595/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 48.7263\n",
      "Epoch 6596/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1750 - val_loss: 50.7559\n",
      "Epoch 6597/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 51.9348\n",
      "Epoch 6598/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1760 - val_loss: 45.9740\n",
      "Epoch 6599/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1797 - val_loss: 48.1732\n",
      "Epoch 6600/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1780 - val_loss: 55.4691\n",
      "Epoch 6601/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1775 - val_loss: 47.8424\n",
      "Epoch 6602/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1745 - val_loss: 47.5683\n",
      "Epoch 6603/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1746 - val_loss: 49.8198\n",
      "Epoch 6604/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1743 - val_loss: 51.2741\n",
      "Epoch 6605/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 48.5087\n",
      "Epoch 6606/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 49.6370\n",
      "Epoch 6607/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1746 - val_loss: 49.9660\n",
      "Epoch 6608/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1742 - val_loss: 49.8639\n",
      "Epoch 6609/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1758 - val_loss: 49.1520\n",
      "Epoch 6610/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1758 - val_loss: 49.7312\n",
      "Epoch 6611/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1744 - val_loss: 49.7072\n",
      "Epoch 6612/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1743 - val_loss: 49.3717\n",
      "Epoch 6613/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1766 - val_loss: 47.3131\n",
      "Epoch 6614/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1766 - val_loss: 53.1527\n",
      "Epoch 6615/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 50.4547\n",
      "Epoch 6616/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1773 - val_loss: 51.0671\n",
      "Epoch 6617/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1754 - val_loss: 52.4975\n",
      "Epoch 6618/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 50.4076\n",
      "Epoch 6619/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1746 - val_loss: 49.5408\n",
      "Epoch 6620/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 51.8031\n",
      "Epoch 6621/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 47.3236\n",
      "Epoch 6622/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1766 - val_loss: 47.7803\n",
      "Epoch 6623/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2117 - val_loss: 41.4961\n",
      "Epoch 6624/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3928 - val_loss: 48.8236\n",
      "Epoch 6625/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2555 - val_loss: 47.4752\n",
      "Epoch 6626/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2257 - val_loss: 43.3230\n",
      "Epoch 6627/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2223 - val_loss: 52.6436\n",
      "Epoch 6628/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1974 - val_loss: 46.8485\n",
      "Epoch 6629/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1937 - val_loss: 47.7591\n",
      "Epoch 6630/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1878 - val_loss: 47.9971\n",
      "Epoch 6631/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1810 - val_loss: 51.8861\n",
      "Epoch 6632/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1765 - val_loss: 49.8333\n",
      "Epoch 6633/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1747 - val_loss: 51.9668\n",
      "Epoch 6634/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1783 - val_loss: 54.6343\n",
      "Epoch 6635/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1775 - val_loss: 53.3575\n",
      "Epoch 6636/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1861 - val_loss: 58.4049\n",
      "Epoch 6637/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2677 - val_loss: 39.5708\n",
      "Epoch 6638/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3720 - val_loss: 61.9652\n",
      "Epoch 6639/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2391 - val_loss: 48.2419\n",
      "Epoch 6640/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2314 - val_loss: 47.5058\n",
      "Epoch 6641/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2193 - val_loss: 25.3072\n",
      "Epoch 6642/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2677 - val_loss: 12.2410\n",
      "Epoch 6643/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3591 - val_loss: 31.6565\n",
      "Epoch 6644/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2192 - val_loss: 41.2761\n",
      "Epoch 6645/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1820 - val_loss: 45.9399\n",
      "Epoch 6646/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1812 - val_loss: 43.6758\n",
      "Epoch 6647/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1840 - val_loss: 44.3022\n",
      "Epoch 6648/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1831 - val_loss: 44.3157\n",
      "Epoch 6649/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1754 - val_loss: 45.6299\n",
      "Epoch 6650/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1771 - val_loss: 45.3969\n",
      "Epoch 6651/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1745 - val_loss: 48.4449\n",
      "Epoch 6652/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1751 - val_loss: 49.6459\n",
      "Epoch 6653/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 49.6700\n",
      "Epoch 6654/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1746 - val_loss: 51.0773\n",
      "Epoch 6655/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1754 - val_loss: 50.2468\n",
      "Epoch 6656/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1759 - val_loss: 53.0713\n",
      "Epoch 6657/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 56.0060\n",
      "Epoch 6658/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1818 - val_loss: 55.0678\n",
      "Epoch 6659/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1744 - val_loss: 57.6016\n",
      "Epoch 6660/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 55.3348\n",
      "Epoch 6661/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 54.3273\n",
      "Epoch 6662/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 55.6448\n",
      "Epoch 6663/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 57.3685\n",
      "Epoch 6664/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 55.1213\n",
      "Epoch 6665/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 56.0312\n",
      "Epoch 6666/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1759 - val_loss: 56.7029\n",
      "Epoch 6667/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1778 - val_loss: 52.3427\n",
      "Epoch 6668/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1744 - val_loss: 51.8775\n",
      "Epoch 6669/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 55.8779\n",
      "Epoch 6670/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 55.5834\n",
      "Epoch 6671/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 55.5114\n",
      "Epoch 6672/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1743 - val_loss: 53.6049\n",
      "Epoch 6673/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 54.2723\n",
      "Epoch 6674/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1700 - val_loss: 53.8190\n",
      "Epoch 6675/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 56.0016\n",
      "Epoch 6676/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 53.4736\n",
      "Epoch 6677/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1758 - val_loss: 55.6289\n",
      "Epoch 6678/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1761 - val_loss: 52.3385\n",
      "Epoch 6679/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2250 - val_loss: 57.4780\n",
      "Epoch 6680/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2690 - val_loss: 63.6225\n",
      "Epoch 6681/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2634 - val_loss: 56.7026\n",
      "Epoch 6682/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1859 - val_loss: 54.1721\n",
      "Epoch 6683/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1792 - val_loss: 47.4281\n",
      "Epoch 6684/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1803 - val_loss: 52.9198\n",
      "Epoch 6685/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1756 - val_loss: 55.4186\n",
      "Epoch 6686/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 54.9471\n",
      "Epoch 6687/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 54.6735\n",
      "Epoch 6688/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 52.5636\n",
      "Epoch 6689/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 55.1474\n",
      "Epoch 6690/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1742 - val_loss: 54.6004\n",
      "Epoch 6691/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1766 - val_loss: 52.5970\n",
      "Epoch 6692/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1841 - val_loss: 52.1403\n",
      "Epoch 6693/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1752 - val_loss: 56.6508\n",
      "Epoch 6694/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 56.9796\n",
      "Epoch 6695/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1750 - val_loss: 57.2148\n",
      "Epoch 6696/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 57.0590\n",
      "Epoch 6697/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1747 - val_loss: 56.3995\n",
      "Epoch 6698/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1778 - val_loss: 55.1610\n",
      "Epoch 6699/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1744 - val_loss: 53.1874\n",
      "Epoch 6700/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1753 - val_loss: 53.7658\n",
      "Epoch 6701/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1762 - val_loss: 51.7251\n",
      "Epoch 6702/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1830 - val_loss: 50.8770\n",
      "Epoch 6703/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2356 - val_loss: 65.8478\n",
      "Epoch 6704/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2487 - val_loss: 63.6711\n",
      "Epoch 6705/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2628 - val_loss: 58.1941\n",
      "Epoch 6706/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2187 - val_loss: 46.1148\n",
      "Epoch 6707/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2142 - val_loss: 54.2862\n",
      "Epoch 6708/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2337 - val_loss: 60.3342\n",
      "Epoch 6709/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2006 - val_loss: 52.0903\n",
      "Epoch 6710/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1837 - val_loss: 54.7139\n",
      "Epoch 6711/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2240 - val_loss: 53.3469\n",
      "Epoch 6712/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2030 - val_loss: 46.6765\n",
      "Epoch 6713/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1953 - val_loss: 56.0664\n",
      "Epoch 6714/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1779 - val_loss: 52.6184\n",
      "Epoch 6715/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1767 - val_loss: 53.7804\n",
      "Epoch 6716/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1803 - val_loss: 52.9187\n",
      "Epoch 6717/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1761 - val_loss: 52.8291\n",
      "Epoch 6718/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1760 - val_loss: 49.8818\n",
      "Epoch 6719/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 52.6810\n",
      "Epoch 6720/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 55.8736\n",
      "Epoch 6721/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1774 - val_loss: 53.2148\n",
      "Epoch 6722/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1883 - val_loss: 51.8479\n",
      "Epoch 6723/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2490 - val_loss: 55.1664\n",
      "Epoch 6724/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3111 - val_loss: 56.7010\n",
      "Epoch 6725/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2255 - val_loss: 54.6537\n",
      "Epoch 6726/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1928 - val_loss: 60.0207\n",
      "Epoch 6727/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1781 - val_loss: 62.9691\n",
      "Epoch 6728/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1762 - val_loss: 62.2048\n",
      "Epoch 6729/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1895 - val_loss: 64.3011\n",
      "Epoch 6730/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1994 - val_loss: 59.3554\n",
      "Epoch 6731/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2396 - val_loss: 62.9321\n",
      "Epoch 6732/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1859 - val_loss: 59.7878\n",
      "Epoch 6733/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1760 - val_loss: 62.3699\n",
      "Epoch 6734/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1775 - val_loss: 62.5493\n",
      "Epoch 6735/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1739 - val_loss: 61.9539\n",
      "Epoch 6736/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 62.1084\n",
      "Epoch 6737/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1749 - val_loss: 61.9045\n",
      "Epoch 6738/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1703 - val_loss: 62.2111\n",
      "Epoch 6739/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1709 - val_loss: 61.9601\n",
      "Epoch 6740/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 62.7915\n",
      "Epoch 6741/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 62.3870\n",
      "Epoch 6742/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1760 - val_loss: 62.3306\n",
      "Epoch 6743/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 60.6106\n",
      "Epoch 6744/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 60.9339\n",
      "Epoch 6745/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 61.8971\n",
      "Epoch 6746/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 61.6253\n",
      "Epoch 6747/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 61.2044\n",
      "Epoch 6748/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 61.7351\n",
      "Epoch 6749/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 61.3520\n",
      "Epoch 6750/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1708 - val_loss: 61.2408\n",
      "Epoch 6751/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 60.5624\n",
      "Epoch 6752/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1739 - val_loss: 61.7131\n",
      "Epoch 6753/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1712 - val_loss: 60.9306\n",
      "Epoch 6754/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 61.5648\n",
      "Epoch 6755/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 61.5882\n",
      "Epoch 6756/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 60.8518\n",
      "Epoch 6757/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 61.5021\n",
      "Epoch 6758/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 61.5642\n",
      "Epoch 6759/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1699 - val_loss: 61.1027\n",
      "Epoch 6760/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 61.5349\n",
      "Epoch 6761/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 61.6339\n",
      "Epoch 6762/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2170 - val_loss: 58.3528\n",
      "Epoch 6763/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2947 - val_loss: 66.0118\n",
      "Epoch 6764/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2433 - val_loss: 50.2477\n",
      "Epoch 6765/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2233 - val_loss: 47.9035\n",
      "Epoch 6766/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2178 - val_loss: 60.0064\n",
      "Epoch 6767/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2302 - val_loss: 56.6914\n",
      "Epoch 6768/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1917 - val_loss: 55.6980\n",
      "Epoch 6769/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1783 - val_loss: 49.7375\n",
      "Epoch 6770/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1768 - val_loss: 53.5539\n",
      "Epoch 6771/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1772 - val_loss: 53.0009\n",
      "Epoch 6772/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1779 - val_loss: 51.5205\n",
      "Epoch 6773/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1740 - val_loss: 54.6506\n",
      "Epoch 6774/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1751 - val_loss: 50.5772\n",
      "Epoch 6775/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1766 - val_loss: 52.3577\n",
      "Epoch 6776/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 52.1845\n",
      "Epoch 6777/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 51.7052\n",
      "Epoch 6778/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 53.3361\n",
      "Epoch 6779/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 51.9716\n",
      "Epoch 6780/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1705 - val_loss: 54.1700\n",
      "Epoch 6781/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 53.4825\n",
      "Epoch 6782/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 53.5642\n",
      "Epoch 6783/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 53.7716\n",
      "Epoch 6784/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 52.4615\n",
      "Epoch 6785/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1711 - val_loss: 53.2213\n",
      "Epoch 6786/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1706 - val_loss: 54.0654\n",
      "Epoch 6787/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 54.1266\n",
      "Epoch 6788/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 53.6965\n",
      "Epoch 6789/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 52.8050\n",
      "Epoch 6790/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 52.3561\n",
      "Epoch 6791/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 52.3787\n",
      "Epoch 6792/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 53.2322\n",
      "Epoch 6793/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 55.1934\n",
      "Epoch 6794/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1761 - val_loss: 49.9307\n",
      "Epoch 6795/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1772 - val_loss: 49.9039\n",
      "Epoch 6796/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3817 - val_loss: 64.6505\n",
      "Epoch 6797/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2905 - val_loss: 53.0861\n",
      "Epoch 6798/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1982 - val_loss: 61.6392\n",
      "Epoch 6799/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1820 - val_loss: 60.5619\n",
      "Epoch 6800/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1755 - val_loss: 58.3331\n",
      "Epoch 6801/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1750 - val_loss: 58.8793\n",
      "Epoch 6802/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1851 - val_loss: 60.9126\n",
      "Epoch 6803/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1894 - val_loss: 58.8246\n",
      "Epoch 6804/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1797 - val_loss: 57.8677\n",
      "Epoch 6805/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2159 - val_loss: 51.4262\n",
      "Epoch 6806/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2768 - val_loss: 67.2767\n",
      "Epoch 6807/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2528 - val_loss: 60.0777\n",
      "Epoch 6808/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2276 - val_loss: 59.4433\n",
      "Epoch 6809/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2585 - val_loss: 51.2881\n",
      "Epoch 6810/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2029 - val_loss: 53.1444\n",
      "Epoch 6811/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1882 - val_loss: 59.3765\n",
      "Epoch 6812/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1757 - val_loss: 56.5850\n",
      "Epoch 6813/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1756 - val_loss: 57.5260\n",
      "Epoch 6814/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1756 - val_loss: 58.2637\n",
      "Epoch 6815/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 56.5464\n",
      "Epoch 6816/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 57.3056\n",
      "Epoch 6817/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 57.5393\n",
      "Epoch 6818/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 56.5804\n",
      "Epoch 6819/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 57.6788\n",
      "Epoch 6820/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1742 - val_loss: 56.5701\n",
      "Epoch 6821/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 59.2707\n",
      "Epoch 6822/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1741 - val_loss: 55.1707\n",
      "Epoch 6823/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 55.8502\n",
      "Epoch 6824/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1744 - val_loss: 58.7741\n",
      "Epoch 6825/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1747 - val_loss: 55.3744\n",
      "Epoch 6826/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 57.8155\n",
      "Epoch 6827/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 58.4523\n",
      "Epoch 6828/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 56.8077\n",
      "Epoch 6829/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1704 - val_loss: 57.0300\n",
      "Epoch 6830/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1743 - val_loss: 56.3387\n",
      "Epoch 6831/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 55.1368\n",
      "Epoch 6832/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1743 - val_loss: 56.0316\n",
      "Epoch 6833/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1743 - val_loss: 59.5269\n",
      "Epoch 6834/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1779 - val_loss: 55.9345\n",
      "Epoch 6835/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1756 - val_loss: 53.4536\n",
      "Epoch 6836/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1838 - val_loss: 57.5249\n",
      "Epoch 6837/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1874 - val_loss: 59.1763\n",
      "Epoch 6838/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2941 - val_loss: 61.2352\n",
      "Epoch 6839/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2627 - val_loss: 63.8869\n",
      "Epoch 6840/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2317 - val_loss: 63.9246\n",
      "Epoch 6841/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1881 - val_loss: 62.4626\n",
      "Epoch 6842/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1818 - val_loss: 57.4603\n",
      "Epoch 6843/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1766 - val_loss: 59.6037\n",
      "Epoch 6844/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 61.2865\n",
      "Epoch 6845/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 59.0398\n",
      "Epoch 6846/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 60.8558\n",
      "Epoch 6847/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 61.7854\n",
      "Epoch 6848/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1748 - val_loss: 58.7574\n",
      "Epoch 6849/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1745 - val_loss: 61.8241\n",
      "Epoch 6850/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1792 - val_loss: 60.2103\n",
      "Epoch 6851/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1761 - val_loss: 59.1730\n",
      "Epoch 6852/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1754 - val_loss: 60.7804\n",
      "Epoch 6853/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 60.0474\n",
      "Epoch 6854/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 59.1409\n",
      "Epoch 6855/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 60.3941\n",
      "Epoch 6856/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 58.9036\n",
      "Epoch 6857/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 59.9317\n",
      "Epoch 6858/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 59.2075\n",
      "Epoch 6859/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 57.2820\n",
      "Epoch 6860/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 58.2877\n",
      "Epoch 6861/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1758 - val_loss: 57.9932\n",
      "Epoch 6862/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1787 - val_loss: 59.8829\n",
      "Epoch 6863/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1758 - val_loss: 56.3541\n",
      "Epoch 6864/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 55.3237\n",
      "Epoch 6865/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 56.1817\n",
      "Epoch 6866/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 56.2924\n",
      "Epoch 6867/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1707 - val_loss: 55.9673\n",
      "Epoch 6868/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 56.4870\n",
      "Epoch 6869/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 57.7935\n",
      "Epoch 6870/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 57.4007\n",
      "Epoch 6871/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 57.9403\n",
      "Epoch 6872/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 57.1764\n",
      "Epoch 6873/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 57.2488\n",
      "Epoch 6874/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 57.4205\n",
      "Epoch 6875/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 57.1206\n",
      "Epoch 6876/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 56.9907\n",
      "Epoch 6877/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 58.9739\n",
      "Epoch 6878/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1740 - val_loss: 58.4137\n",
      "Epoch 6879/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 57.2232\n",
      "Epoch 6880/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 58.6355\n",
      "Epoch 6881/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 54.3014\n",
      "Epoch 6882/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1773 - val_loss: 55.3919\n",
      "Epoch 6883/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1878 - val_loss: 47.2262\n",
      "Epoch 6884/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2971 - val_loss: 64.5055\n",
      "Epoch 6885/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.2981 - val_loss: 20.7259\n",
      "Epoch 6886/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.3831 - val_loss: 66.5958\n",
      "Epoch 6887/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1913 - val_loss: 66.3468\n",
      "Epoch 6888/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1818 - val_loss: 64.7664\n",
      "Epoch 6889/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1751 - val_loss: 65.4754\n",
      "Epoch 6890/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1774 - val_loss: 66.0281\n",
      "Epoch 6891/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1786 - val_loss: 64.5753\n",
      "Epoch 6892/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1750 - val_loss: 63.2274\n",
      "Epoch 6893/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 64.1116\n",
      "Epoch 6894/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1744 - val_loss: 64.0013\n",
      "Epoch 6895/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1742 - val_loss: 63.2329\n",
      "Epoch 6896/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 63.7696\n",
      "Epoch 6897/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 62.9152\n",
      "Epoch 6898/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 64.1189\n",
      "Epoch 6899/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 63.0843\n",
      "Epoch 6900/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 63.9927\n",
      "Epoch 6901/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 62.9106\n",
      "Epoch 6902/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1707 - val_loss: 63.1509\n",
      "Epoch 6903/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 63.0690\n",
      "Epoch 6904/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 61.5678\n",
      "Epoch 6905/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 63.1651\n",
      "Epoch 6906/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 62.8511\n",
      "Epoch 6907/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 62.8527\n",
      "Epoch 6908/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 60.6442\n",
      "Epoch 6909/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 61.2190\n",
      "Epoch 6910/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 63.6922\n",
      "Epoch 6911/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 62.2251\n",
      "Epoch 6912/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 62.7918\n",
      "Epoch 6913/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 60.7028\n",
      "Epoch 6914/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1787 - val_loss: 64.0097\n",
      "Epoch 6915/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1827 - val_loss: 60.4636\n",
      "Epoch 6916/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2409 - val_loss: 61.9382\n",
      "Epoch 6917/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4342 - val_loss: 69.5206\n",
      "Epoch 6918/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2502 - val_loss: 64.5354\n",
      "Epoch 6919/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2210 - val_loss: 65.4002\n",
      "Epoch 6920/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2048 - val_loss: 63.2418\n",
      "Epoch 6921/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1852 - val_loss: 61.4692\n",
      "Epoch 6922/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1775 - val_loss: 61.3127\n",
      "Epoch 6923/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1754 - val_loss: 63.0882\n",
      "Epoch 6924/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1742 - val_loss: 61.7474\n",
      "Epoch 6925/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1814 - val_loss: 62.2205\n",
      "Epoch 6926/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1796 - val_loss: 69.2998\n",
      "Epoch 6927/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2861 - val_loss: 58.6101\n",
      "Epoch 6928/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2524 - val_loss: 61.6724\n",
      "Epoch 6929/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2024 - val_loss: 59.4495\n",
      "Epoch 6930/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1847 - val_loss: 61.2905\n",
      "Epoch 6931/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1764 - val_loss: 60.4342\n",
      "Epoch 6932/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1745 - val_loss: 58.8208\n",
      "Epoch 6933/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1754 - val_loss: 56.6624\n",
      "Epoch 6934/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1825 - val_loss: 58.5493\n",
      "Epoch 6935/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1798 - val_loss: 58.6566\n",
      "Epoch 6936/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 58.6831\n",
      "Epoch 6937/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1754 - val_loss: 56.4841\n",
      "Epoch 6938/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 59.4716\n",
      "Epoch 6939/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1713 - val_loss: 59.2310\n",
      "Epoch 6940/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 58.6798\n",
      "Epoch 6941/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1748 - val_loss: 57.2518\n",
      "Epoch 6942/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 57.4206\n",
      "Epoch 6943/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 57.8013\n",
      "Epoch 6944/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 57.4927\n",
      "Epoch 6945/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 57.5021\n",
      "Epoch 6946/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 59.0887\n",
      "Epoch 6947/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 58.2705\n",
      "Epoch 6948/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 57.7878\n",
      "Epoch 6949/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 56.6154\n",
      "Epoch 6950/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 58.6093\n",
      "Epoch 6951/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1712 - val_loss: 59.5896\n",
      "Epoch 6952/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 59.6404\n",
      "Epoch 6953/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1827 - val_loss: 55.3729\n",
      "Epoch 6954/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2133 - val_loss: 43.7848\n",
      "Epoch 6955/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2575 - val_loss: 52.4691\n",
      "Epoch 6956/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3936 - val_loss: 55.1710\n",
      "Epoch 6957/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2072 - val_loss: 57.9897\n",
      "Epoch 6958/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1862 - val_loss: 61.2224\n",
      "Epoch 6959/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2390 - val_loss: 58.9440\n",
      "Epoch 6960/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2906 - val_loss: 62.5859\n",
      "Epoch 6961/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2333 - val_loss: 60.7986\n",
      "Epoch 6962/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1871 - val_loss: 58.0590\n",
      "Epoch 6963/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1762 - val_loss: 59.0120\n",
      "Epoch 6964/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1745 - val_loss: 58.6989\n",
      "Epoch 6965/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1744 - val_loss: 59.4616\n",
      "Epoch 6966/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1747 - val_loss: 60.9775\n",
      "Epoch 6967/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1759 - val_loss: 58.6311\n",
      "Epoch 6968/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 58.3118\n",
      "Epoch 6969/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 58.2644\n",
      "Epoch 6970/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 58.8260\n",
      "Epoch 6971/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 59.9783\n",
      "Epoch 6972/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 59.9613\n",
      "Epoch 6973/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 59.9952\n",
      "Epoch 6974/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 59.6605\n",
      "Epoch 6975/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 59.6150\n",
      "Epoch 6976/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 61.0340\n",
      "Epoch 6977/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1818 - val_loss: 55.3279\n",
      "Epoch 6978/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2530 - val_loss: 62.7364\n",
      "Epoch 6979/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2027 - val_loss: 58.6668\n",
      "Epoch 6980/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1780 - val_loss: 59.7859\n",
      "Epoch 6981/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 57.8643\n",
      "Epoch 6982/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1872 - val_loss: 65.4225\n",
      "Epoch 6983/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.5392 - val_loss: 52.4909\n",
      "Epoch 6984/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2911 - val_loss: 57.3854\n",
      "Epoch 6985/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2021 - val_loss: 53.9130\n",
      "Epoch 6986/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2002 - val_loss: 58.4819\n",
      "Epoch 6987/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1978 - val_loss: 56.3196\n",
      "Epoch 6988/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1895 - val_loss: 55.5459\n",
      "Epoch 6989/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1864 - val_loss: 55.2169\n",
      "Epoch 6990/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1817 - val_loss: 58.2544\n",
      "Epoch 6991/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1972 - val_loss: 55.0394\n",
      "Epoch 6992/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2148 - val_loss: 57.4388\n",
      "Epoch 6993/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2032 - val_loss: 58.7899\n",
      "Epoch 6994/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1942 - val_loss: 58.3837\n",
      "Epoch 6995/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1829 - val_loss: 57.1166\n",
      "Epoch 6996/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1786 - val_loss: 61.3847\n",
      "Epoch 6997/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1786 - val_loss: 59.4554\n",
      "Epoch 6998/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 60.3240\n",
      "Epoch 6999/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 59.1484\n",
      "Epoch 7000/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 60.5656\n",
      "Epoch 7001/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1742 - val_loss: 59.6680\n",
      "Epoch 7002/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 59.4472\n",
      "Epoch 7003/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 59.3553\n",
      "Epoch 7004/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1706 - val_loss: 59.5643\n",
      "Epoch 7005/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 58.9740\n",
      "Epoch 7006/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1841 - val_loss: 49.9123\n",
      "Epoch 7007/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2116 - val_loss: 62.9172\n",
      "Epoch 7008/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1769 - val_loss: 61.1788\n",
      "Epoch 7009/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 61.8743\n",
      "Epoch 7010/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1744 - val_loss: 60.1526\n",
      "Epoch 7011/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1749 - val_loss: 60.1791\n",
      "Epoch 7012/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1788 - val_loss: 62.3332\n",
      "Epoch 7013/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1757 - val_loss: 60.5510\n",
      "Epoch 7014/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 59.6408\n",
      "Epoch 7015/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 59.0331\n",
      "Epoch 7016/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 60.4605\n",
      "Epoch 7017/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 60.2037\n",
      "Epoch 7018/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1742 - val_loss: 61.2547\n",
      "Epoch 7019/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 60.5519\n",
      "Epoch 7020/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 58.7292\n",
      "Epoch 7021/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 59.0586\n",
      "Epoch 7022/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 61.1202\n",
      "Epoch 7023/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 60.6398\n",
      "Epoch 7024/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 59.2043\n",
      "Epoch 7025/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 61.0774\n",
      "Epoch 7026/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 59.4435\n",
      "Epoch 7027/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 59.0740\n",
      "Epoch 7028/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 60.1151\n",
      "Epoch 7029/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1756 - val_loss: 57.9016\n",
      "Epoch 7030/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1973 - val_loss: 53.4650\n",
      "Epoch 7031/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.5321 - val_loss: 67.0435\n",
      "Epoch 7032/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2592 - val_loss: 67.4022\n",
      "Epoch 7033/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2296 - val_loss: 63.8740\n",
      "Epoch 7034/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2309 - val_loss: 65.0567\n",
      "Epoch 7035/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2054 - val_loss: 67.4039\n",
      "Epoch 7036/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2089 - val_loss: 66.5189\n",
      "Epoch 7037/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1985 - val_loss: 65.6637\n",
      "Epoch 7038/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1922 - val_loss: 64.1394\n",
      "Epoch 7039/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1845 - val_loss: 66.5946\n",
      "Epoch 7040/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1920 - val_loss: 61.3782\n",
      "Epoch 7041/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2161 - val_loss: 67.6515\n",
      "Epoch 7042/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1997 - val_loss: 62.9825\n",
      "Epoch 7043/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3055 - val_loss: 45.0434\n",
      "Epoch 7044/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2769 - val_loss: 56.6683\n",
      "Epoch 7045/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2494 - val_loss: 62.8315\n",
      "Epoch 7046/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2058 - val_loss: 61.0915\n",
      "Epoch 7047/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1886 - val_loss: 61.2493\n",
      "Epoch 7048/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1809 - val_loss: 63.6521\n",
      "Epoch 7049/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1787 - val_loss: 62.4595\n",
      "Epoch 7050/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1741 - val_loss: 65.8416\n",
      "Epoch 7051/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1828 - val_loss: 63.7481\n",
      "Epoch 7052/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1802 - val_loss: 62.9707\n",
      "Epoch 7053/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1754 - val_loss: 64.3904\n",
      "Epoch 7054/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1749 - val_loss: 64.0210\n",
      "Epoch 7055/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1772 - val_loss: 64.5771\n",
      "Epoch 7056/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1754 - val_loss: 65.3169\n",
      "Epoch 7057/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1766 - val_loss: 64.4992\n",
      "Epoch 7058/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1780 - val_loss: 62.2013\n",
      "Epoch 7059/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1831 - val_loss: 64.3295\n",
      "Epoch 7060/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1774 - val_loss: 64.2401\n",
      "Epoch 7061/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2355 - val_loss: 57.8184\n",
      "Epoch 7062/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2399 - val_loss: 62.2850\n",
      "Epoch 7063/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1971 - val_loss: 64.4386\n",
      "Epoch 7064/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2322 - val_loss: 62.3486\n",
      "Epoch 7065/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1882 - val_loss: 66.2792\n",
      "Epoch 7066/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1824 - val_loss: 65.8520\n",
      "Epoch 7067/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1770 - val_loss: 60.8648\n",
      "Epoch 7068/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1800 - val_loss: 60.1063\n",
      "Epoch 7069/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1741 - val_loss: 62.1637\n",
      "Epoch 7070/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1740 - val_loss: 61.5945\n",
      "Epoch 7071/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1701 - val_loss: 62.9260\n",
      "Epoch 7072/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 61.1992\n",
      "Epoch 7073/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 61.0589\n",
      "Epoch 7074/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1691 - val_loss: 62.3390\n",
      "Epoch 7075/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 61.8242\n",
      "Epoch 7076/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 61.0763\n",
      "Epoch 7077/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 61.4131\n",
      "Epoch 7078/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 61.5854\n",
      "Epoch 7079/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 61.7175\n",
      "Epoch 7080/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 61.6584\n",
      "Epoch 7081/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 61.8311\n",
      "Epoch 7082/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 61.0249\n",
      "Epoch 7083/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 61.3364\n",
      "Epoch 7084/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 61.4740\n",
      "Epoch 7085/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 61.2915\n",
      "Epoch 7086/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1744 - val_loss: 61.7831\n",
      "Epoch 7087/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1744 - val_loss: 61.7771\n",
      "Epoch 7088/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 61.3957\n",
      "Epoch 7089/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1710 - val_loss: 61.1976\n",
      "Epoch 7090/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1742 - val_loss: 61.0087\n",
      "Epoch 7091/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 61.1505\n",
      "Epoch 7092/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 61.5879\n",
      "Epoch 7093/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 61.4332\n",
      "Epoch 7094/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1741 - val_loss: 61.7106\n",
      "Epoch 7095/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 60.4355\n",
      "Epoch 7096/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 61.0366\n",
      "Epoch 7097/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 61.3016\n",
      "Epoch 7098/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 61.2527\n",
      "Epoch 7099/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1748 - val_loss: 60.8197\n",
      "Epoch 7100/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2039 - val_loss: 62.7598\n",
      "Epoch 7101/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2251 - val_loss: 58.7627\n",
      "Epoch 7102/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2031 - val_loss: 59.9125\n",
      "Epoch 7103/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1943 - val_loss: 54.4803\n",
      "Epoch 7104/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2183 - val_loss: 59.2322\n",
      "Epoch 7105/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3218 - val_loss: 57.3518\n",
      "Epoch 7106/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2345 - val_loss: 57.7920\n",
      "Epoch 7107/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2005 - val_loss: 57.7453\n",
      "Epoch 7108/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1958 - val_loss: 53.3046\n",
      "Epoch 7109/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2011 - val_loss: 60.7809\n",
      "Epoch 7110/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2729 - val_loss: 35.4501\n",
      "Epoch 7111/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2586 - val_loss: 53.8033\n",
      "Epoch 7112/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2045 - val_loss: 53.2365\n",
      "Epoch 7113/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1887 - val_loss: 51.0214\n",
      "Epoch 7114/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2005 - val_loss: 61.8399\n",
      "Epoch 7115/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2075 - val_loss: 56.4833\n",
      "Epoch 7116/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1762 - val_loss: 57.8398\n",
      "Epoch 7117/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 57.4882\n",
      "Epoch 7118/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 57.2427\n",
      "Epoch 7119/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 56.8826\n",
      "Epoch 7120/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 56.7101\n",
      "Epoch 7121/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 56.7779\n",
      "Epoch 7122/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 56.7635\n",
      "Epoch 7123/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 57.4040\n",
      "Epoch 7124/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1707 - val_loss: 57.1853\n",
      "Epoch 7125/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1694 - val_loss: 56.2036\n",
      "Epoch 7126/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 56.7987\n",
      "Epoch 7127/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1701 - val_loss: 58.0467\n",
      "Epoch 7128/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 57.3078\n",
      "Epoch 7129/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1714 - val_loss: 57.2087\n",
      "Epoch 7130/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 56.2664\n",
      "Epoch 7131/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 57.6697\n",
      "Epoch 7132/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 56.3026\n",
      "Epoch 7133/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 55.8396\n",
      "Epoch 7134/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 58.0019\n",
      "Epoch 7135/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 57.0013\n",
      "Epoch 7136/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 57.4023\n",
      "Epoch 7137/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1754 - val_loss: 55.6880\n",
      "Epoch 7138/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1939 - val_loss: 60.2706\n",
      "Epoch 7139/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2187 - val_loss: 61.7205\n",
      "Epoch 7140/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1803 - val_loss: 61.4645\n",
      "Epoch 7141/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1797 - val_loss: 59.5983\n",
      "Epoch 7142/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 61.3882\n",
      "Epoch 7143/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2442 - val_loss: 63.0628\n",
      "Epoch 7144/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2753 - val_loss: 53.5288\n",
      "Epoch 7145/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3270 - val_loss: 32.1648\n",
      "Epoch 7146/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3437 - val_loss: 63.0115\n",
      "Epoch 7147/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2202 - val_loss: 59.4281\n",
      "Epoch 7148/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1919 - val_loss: 58.2254\n",
      "Epoch 7149/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1835 - val_loss: 58.5848\n",
      "Epoch 7150/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1810 - val_loss: 59.9296\n",
      "Epoch 7151/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2139 - val_loss: 57.4738\n",
      "Epoch 7152/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1832 - val_loss: 59.3797\n",
      "Epoch 7153/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1779 - val_loss: 59.2535\n",
      "Epoch 7154/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1749 - val_loss: 58.6533\n",
      "Epoch 7155/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 59.4101\n",
      "Epoch 7156/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 61.0161\n",
      "Epoch 7157/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1794 - val_loss: 60.2241\n",
      "Epoch 7158/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1884 - val_loss: 60.9555\n",
      "Epoch 7159/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1817 - val_loss: 60.1034\n",
      "Epoch 7160/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1928 - val_loss: 64.1823\n",
      "Epoch 7161/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2045 - val_loss: 62.6728\n",
      "Epoch 7162/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1912 - val_loss: 58.4263\n",
      "Epoch 7163/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1868 - val_loss: 62.7615\n",
      "Epoch 7164/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2052 - val_loss: 52.1673\n",
      "Epoch 7165/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2714 - val_loss: 62.9794\n",
      "Epoch 7166/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2172 - val_loss: 61.0004\n",
      "Epoch 7167/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1808 - val_loss: 56.0619\n",
      "Epoch 7168/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1755 - val_loss: 56.6791\n",
      "Epoch 7169/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 57.1486\n",
      "Epoch 7170/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1759 - val_loss: 56.2794\n",
      "Epoch 7171/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1768 - val_loss: 54.4095\n",
      "Epoch 7172/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 55.8651\n",
      "Epoch 7173/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1703 - val_loss: 56.2179\n",
      "Epoch 7174/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 54.8445\n",
      "Epoch 7175/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1745 - val_loss: 55.2731\n",
      "Epoch 7176/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 56.0539\n",
      "Epoch 7177/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1739 - val_loss: 52.2378\n",
      "Epoch 7178/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1755 - val_loss: 54.0303\n",
      "Epoch 7179/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 54.3600\n",
      "Epoch 7180/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 55.6596\n",
      "Epoch 7181/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 54.7535\n",
      "Epoch 7182/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 51.8927\n",
      "Epoch 7183/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 55.1802\n",
      "Epoch 7184/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 54.7892\n",
      "Epoch 7185/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 54.1587\n",
      "Epoch 7186/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 54.4903\n",
      "Epoch 7187/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 54.9830\n",
      "Epoch 7188/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 54.8306\n",
      "Epoch 7189/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 54.5874\n",
      "Epoch 7190/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1708 - val_loss: 54.8711\n",
      "Epoch 7191/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 55.2232\n",
      "Epoch 7192/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1704 - val_loss: 55.0494\n",
      "Epoch 7193/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 50.8771\n",
      "Epoch 7194/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 50.3251\n",
      "Epoch 7195/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1776 - val_loss: 53.5150\n",
      "Epoch 7196/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 52.6773\n",
      "Epoch 7197/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1761 - val_loss: 50.6293\n",
      "Epoch 7198/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1753 - val_loss: 47.1529\n",
      "Epoch 7199/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1746 - val_loss: 48.7099\n",
      "Epoch 7200/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1762 - val_loss: 50.5327\n",
      "Epoch 7201/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 51.6949\n",
      "Epoch 7202/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 50.3909\n",
      "Epoch 7203/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1768 - val_loss: 46.5252\n",
      "Epoch 7204/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2495 - val_loss: 37.8531\n",
      "Epoch 7205/10000\n",
      "34280/34280 [==============================] - ETA: 0s - loss: 0.245 - 0s 8us/sample - loss: 0.2399 - val_loss: 51.6768\n",
      "Epoch 7206/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2175 - val_loss: 51.4693\n",
      "Epoch 7207/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2223 - val_loss: 54.7439\n",
      "Epoch 7208/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2464 - val_loss: 40.7953\n",
      "Epoch 7209/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2243 - val_loss: 41.5805\n",
      "Epoch 7210/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2211 - val_loss: 50.9006\n",
      "Epoch 7211/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1913 - val_loss: 53.6794\n",
      "Epoch 7212/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1842 - val_loss: 51.3532\n",
      "Epoch 7213/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1860 - val_loss: 51.3712\n",
      "Epoch 7214/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1815 - val_loss: 52.7590\n",
      "Epoch 7215/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1843 - val_loss: 56.5374\n",
      "Epoch 7216/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2363 - val_loss: 45.7812\n",
      "Epoch 7217/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1866 - val_loss: 49.4969\n",
      "Epoch 7218/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1925 - val_loss: 55.4806\n",
      "Epoch 7219/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1959 - val_loss: 51.1741\n",
      "Epoch 7220/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1752 - val_loss: 48.3574\n",
      "Epoch 7221/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1739 - val_loss: 49.9907\n",
      "Epoch 7222/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 48.3036\n",
      "Epoch 7223/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 49.9965\n",
      "Epoch 7224/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 51.2771\n",
      "Epoch 7225/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 49.9198\n",
      "Epoch 7226/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 51.4410\n",
      "Epoch 7227/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1925 - val_loss: 34.6189\n",
      "Epoch 7228/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2244 - val_loss: 46.4029\n",
      "Epoch 7229/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2038 - val_loss: 48.0962\n",
      "Epoch 7230/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1828 - val_loss: 44.5799\n",
      "Epoch 7231/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2117 - val_loss: 48.9925\n",
      "Epoch 7232/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2004 - val_loss: 44.3042\n",
      "Epoch 7233/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2118 - val_loss: 54.3789\n",
      "Epoch 7234/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1910 - val_loss: 45.1685\n",
      "Epoch 7235/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1790 - val_loss: 45.7712\n",
      "Epoch 7236/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1744 - val_loss: 49.4126\n",
      "Epoch 7237/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 47.9134\n",
      "Epoch 7238/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 48.0753\n",
      "Epoch 7239/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 48.1323\n",
      "Epoch 7240/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 50.0301\n",
      "Epoch 7241/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 49.7396\n",
      "Epoch 7242/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 49.9050\n",
      "Epoch 7243/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1721 - val_loss: 50.4304\n",
      "Epoch 7244/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1702 - val_loss: 48.7606\n",
      "Epoch 7245/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 50.1900\n",
      "Epoch 7246/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 49.3534\n",
      "Epoch 7247/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1741 - val_loss: 51.3637\n",
      "Epoch 7248/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1790 - val_loss: 46.7548\n",
      "Epoch 7249/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1844 - val_loss: 49.5338\n",
      "Epoch 7250/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1764 - val_loss: 47.7853\n",
      "Epoch 7251/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1738 - val_loss: 47.8276\n",
      "Epoch 7252/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 46.1853\n",
      "Epoch 7253/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 45.6922\n",
      "Epoch 7254/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 45.9518\n",
      "Epoch 7255/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 48.1255\n",
      "Epoch 7256/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1747 - val_loss: 46.4998\n",
      "Epoch 7257/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 43.9449\n",
      "Epoch 7258/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 46.4742\n",
      "Epoch 7259/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 46.6502\n",
      "Epoch 7260/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1806 - val_loss: 40.2119\n",
      "Epoch 7261/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2673 - val_loss: 41.2377\n",
      "Epoch 7262/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3468 - val_loss: 42.4123\n",
      "Epoch 7263/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2540 - val_loss: 44.5886\n",
      "Epoch 7264/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1823 - val_loss: 38.4708\n",
      "Epoch 7265/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1757 - val_loss: 43.1023\n",
      "Epoch 7266/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1743 - val_loss: 45.7175\n",
      "Epoch 7267/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1741 - val_loss: 42.2578\n",
      "Epoch 7268/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 45.5139\n",
      "Epoch 7269/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 44.4314\n",
      "Epoch 7270/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 43.1875\n",
      "Epoch 7271/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1711 - val_loss: 43.9801\n",
      "Epoch 7272/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 43.1409\n",
      "Epoch 7273/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 45.9517\n",
      "Epoch 7274/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 45.9388\n",
      "Epoch 7275/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 43.5623\n",
      "Epoch 7276/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 47.1266\n",
      "Epoch 7277/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 46.3106\n",
      "Epoch 7278/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 45.1860\n",
      "Epoch 7279/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 45.8021\n",
      "Epoch 7280/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1691 - val_loss: 44.6744\n",
      "Epoch 7281/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1711 - val_loss: 42.7959\n",
      "Epoch 7282/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1700 - val_loss: 45.3107\n",
      "Epoch 7283/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 46.0269\n",
      "Epoch 7284/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1703 - val_loss: 44.3775\n",
      "Epoch 7285/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 44.1286\n",
      "Epoch 7286/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 43.8475\n",
      "Epoch 7287/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 45.6869\n",
      "Epoch 7288/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 45.2950\n",
      "Epoch 7289/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 45.3311\n",
      "Epoch 7290/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1711 - val_loss: 38.5975\n",
      "Epoch 7291/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 44.6572\n",
      "Epoch 7292/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 42.3042\n",
      "Epoch 7293/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1708 - val_loss: 47.4415\n",
      "Epoch 7294/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 45.1134\n",
      "Epoch 7295/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1711 - val_loss: 43.3826\n",
      "Epoch 7296/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1763 - val_loss: 37.7449\n",
      "Epoch 7297/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1920 - val_loss: 51.6827\n",
      "Epoch 7298/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.6233 - val_loss: 25.0345\n",
      "Epoch 7299/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3884 - val_loss: 56.6413\n",
      "Epoch 7300/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2350 - val_loss: 51.9484\n",
      "Epoch 7301/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1957 - val_loss: 48.2970\n",
      "Epoch 7302/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1831 - val_loss: 44.3941\n",
      "Epoch 7303/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1787 - val_loss: 48.7688\n",
      "Epoch 7304/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1997 - val_loss: 45.7600\n",
      "Epoch 7305/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1896 - val_loss: 54.0810\n",
      "Epoch 7306/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1884 - val_loss: 52.5779\n",
      "Epoch 7307/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1811 - val_loss: 46.6080\n",
      "Epoch 7308/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1795 - val_loss: 48.6742\n",
      "Epoch 7309/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1747 - val_loss: 50.3224\n",
      "Epoch 7310/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1806 - val_loss: 50.6139\n",
      "Epoch 7311/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1765 - val_loss: 46.0720\n",
      "Epoch 7312/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1862 - val_loss: 53.3704\n",
      "Epoch 7313/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1831 - val_loss: 45.9130\n",
      "Epoch 7314/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1777 - val_loss: 48.0420\n",
      "Epoch 7315/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 50.3262\n",
      "Epoch 7316/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1745 - val_loss: 51.0709\n",
      "Epoch 7317/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 47.2432\n",
      "Epoch 7318/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1832 - val_loss: 56.0795\n",
      "Epoch 7319/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1989 - val_loss: 49.8999\n",
      "Epoch 7320/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1862 - val_loss: 53.4095\n",
      "Epoch 7321/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1959 - val_loss: 41.4931\n",
      "Epoch 7322/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2016 - val_loss: 49.0986\n",
      "Epoch 7323/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1784 - val_loss: 41.6811\n",
      "Epoch 7324/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 47.4440\n",
      "Epoch 7325/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 46.8613\n",
      "Epoch 7326/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2092 - val_loss: 42.7853\n",
      "Epoch 7327/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1913 - val_loss: 41.1272\n",
      "Epoch 7328/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2186 - val_loss: 35.9657\n",
      "Epoch 7329/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2415 - val_loss: 52.7027\n",
      "Epoch 7330/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1853 - val_loss: 49.9194\n",
      "Epoch 7331/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1751 - val_loss: 50.2102\n",
      "Epoch 7332/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1740 - val_loss: 48.8369\n",
      "Epoch 7333/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 48.2865\n",
      "Epoch 7334/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1720 - val_loss: 48.8753\n",
      "Epoch 7335/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 48.3479\n",
      "Epoch 7336/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1696 - val_loss: 49.0192\n",
      "Epoch 7337/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 48.9636\n",
      "Epoch 7338/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 49.5843\n",
      "Epoch 7339/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1720 - val_loss: 49.7378\n",
      "Epoch 7340/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1711 - val_loss: 49.7338\n",
      "Epoch 7341/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1702 - val_loss: 49.4513\n",
      "Epoch 7342/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1709 - val_loss: 48.8330\n",
      "Epoch 7343/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1712 - val_loss: 48.6927\n",
      "Epoch 7344/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1712 - val_loss: 48.2867\n",
      "Epoch 7345/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 48.9654\n",
      "Epoch 7346/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 49.2374\n",
      "Epoch 7347/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 48.4021\n",
      "Epoch 7348/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1714 - val_loss: 49.9752\n",
      "Epoch 7349/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 48.3973\n",
      "Epoch 7350/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 48.2385\n",
      "Epoch 7351/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 49.2385\n",
      "Epoch 7352/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 48.9806\n",
      "Epoch 7353/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 49.8834\n",
      "Epoch 7354/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 47.7230\n",
      "Epoch 7355/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1710 - val_loss: 49.4202\n",
      "Epoch 7356/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 45.2909\n",
      "Epoch 7357/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 46.3273\n",
      "Epoch 7358/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2018 - val_loss: 27.3999\n",
      "Epoch 7359/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4134 - val_loss: 49.9135\n",
      "Epoch 7360/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2229 - val_loss: 52.8261\n",
      "Epoch 7361/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2005 - val_loss: 42.7677\n",
      "Epoch 7362/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1785 - val_loss: 47.7654\n",
      "Epoch 7363/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1781 - val_loss: 47.2391\n",
      "Epoch 7364/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 45.5260\n",
      "Epoch 7365/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 45.4806\n",
      "Epoch 7366/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 46.1047\n",
      "Epoch 7367/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 46.1246\n",
      "Epoch 7368/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 45.4810\n",
      "Epoch 7369/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 46.5609\n",
      "Epoch 7370/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 46.9689\n",
      "Epoch 7371/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 46.3273\n",
      "Epoch 7372/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 46.2066\n",
      "Epoch 7373/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1708 - val_loss: 47.7007\n",
      "Epoch 7374/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1688 - val_loss: 47.2930\n",
      "Epoch 7375/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 46.2805\n",
      "Epoch 7376/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 46.1911\n",
      "Epoch 7377/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1705 - val_loss: 49.6183\n",
      "Epoch 7378/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 45.9372\n",
      "Epoch 7379/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 45.6556\n",
      "Epoch 7380/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 45.9709\n",
      "Epoch 7381/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 46.3063\n",
      "Epoch 7382/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1695 - val_loss: 47.6115\n",
      "Epoch 7383/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1702 - val_loss: 45.0978\n",
      "Epoch 7384/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 47.5507\n",
      "Epoch 7385/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 46.7287\n",
      "Epoch 7386/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 47.9164\n",
      "Epoch 7387/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 45.9517\n",
      "Epoch 7388/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1705 - val_loss: 46.0507\n",
      "Epoch 7389/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 45.5119\n",
      "Epoch 7390/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 45.8525\n",
      "Epoch 7391/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 45.3853\n",
      "Epoch 7392/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 46.3148\n",
      "Epoch 7393/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 45.9265\n",
      "Epoch 7394/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1705 - val_loss: 45.5114\n",
      "Epoch 7395/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 46.4837\n",
      "Epoch 7396/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 46.6863\n",
      "Epoch 7397/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 46.5470\n",
      "Epoch 7398/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1709 - val_loss: 46.7130\n",
      "Epoch 7399/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 46.1571\n",
      "Epoch 7400/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 45.5261\n",
      "Epoch 7401/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 46.5673\n",
      "Epoch 7402/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1718 - val_loss: 45.5552\n",
      "Epoch 7403/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1713 - val_loss: 43.0300\n",
      "Epoch 7404/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 44.5089\n",
      "Epoch 7405/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2130 - val_loss: 37.0000\n",
      "Epoch 7406/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3944 - val_loss: 56.8399\n",
      "Epoch 7407/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3389 - val_loss: 44.4206\n",
      "Epoch 7408/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2788 - val_loss: 54.4568\n",
      "Epoch 7409/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2030 - val_loss: 58.4965\n",
      "Epoch 7410/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1814 - val_loss: 57.6278\n",
      "Epoch 7411/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1758 - val_loss: 55.7327\n",
      "Epoch 7412/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1743 - val_loss: 56.2726\n",
      "Epoch 7413/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1777 - val_loss: 56.3570\n",
      "Epoch 7414/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 56.6173\n",
      "Epoch 7415/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 55.3865\n",
      "Epoch 7416/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 56.1827\n",
      "Epoch 7417/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 56.2148\n",
      "Epoch 7418/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 56.7861\n",
      "Epoch 7419/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 56.8270\n",
      "Epoch 7420/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 54.9913\n",
      "Epoch 7421/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 55.9688\n",
      "Epoch 7422/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 55.6443\n",
      "Epoch 7423/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 55.4938\n",
      "Epoch 7424/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 53.3397\n",
      "Epoch 7425/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2319 - val_loss: 60.8166\n",
      "Epoch 7426/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3039 - val_loss: 60.9407\n",
      "Epoch 7427/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2308 - val_loss: 42.4875\n",
      "Epoch 7428/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2227 - val_loss: 53.7802\n",
      "Epoch 7429/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2026 - val_loss: 46.8841\n",
      "Epoch 7430/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1939 - val_loss: 49.1250\n",
      "Epoch 7431/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1847 - val_loss: 49.0542\n",
      "Epoch 7432/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1762 - val_loss: 52.1376\n",
      "Epoch 7433/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 52.1164\n",
      "Epoch 7434/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 53.2941\n",
      "Epoch 7435/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1944 - val_loss: 52.3387\n",
      "Epoch 7436/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1785 - val_loss: 51.6860\n",
      "Epoch 7437/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 51.7571\n",
      "Epoch 7438/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 52.6797\n",
      "Epoch 7439/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 52.5514\n",
      "Epoch 7440/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 52.4420\n",
      "Epoch 7441/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 52.5717\n",
      "Epoch 7442/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 53.0347\n",
      "Epoch 7443/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1705 - val_loss: 52.9114\n",
      "Epoch 7444/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1715 - val_loss: 52.1215\n",
      "Epoch 7445/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 51.9156\n",
      "Epoch 7446/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1725 - val_loss: 52.8261\n",
      "Epoch 7447/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1727 - val_loss: 52.5968\n",
      "Epoch 7448/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 51.8138\n",
      "Epoch 7449/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1724 - val_loss: 52.7562\n",
      "Epoch 7450/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1720 - val_loss: 51.7991\n",
      "Epoch 7451/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1724 - val_loss: 51.9472\n",
      "Epoch 7452/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 52.3125\n",
      "Epoch 7453/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1710 - val_loss: 51.9571\n",
      "Epoch 7454/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 51.4673\n",
      "Epoch 7455/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 52.5942\n",
      "Epoch 7456/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 49.8153\n",
      "Epoch 7457/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 52.1868\n",
      "Epoch 7458/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1707 - val_loss: 52.6798\n",
      "Epoch 7459/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1707 - val_loss: 52.1185\n",
      "Epoch 7460/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1712 - val_loss: 52.5353\n",
      "Epoch 7461/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1705 - val_loss: 52.1755\n",
      "Epoch 7462/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 49.8577\n",
      "Epoch 7463/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 52.0367\n",
      "Epoch 7464/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 52.4485\n",
      "Epoch 7465/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 51.5302\n",
      "Epoch 7466/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 52.1522\n",
      "Epoch 7467/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 49.5927\n",
      "Epoch 7468/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 52.1694\n",
      "Epoch 7469/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1692 - val_loss: 50.1428\n",
      "Epoch 7470/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 52.2228\n",
      "Epoch 7471/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 51.5797\n",
      "Epoch 7472/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 51.3581\n",
      "Epoch 7473/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 51.3697\n",
      "Epoch 7474/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 52.0093\n",
      "Epoch 7475/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 51.0472\n",
      "Epoch 7476/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1954 - val_loss: 49.3405\n",
      "Epoch 7477/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3525 - val_loss: 49.1578\n",
      "Epoch 7478/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3514 - val_loss: 51.4161\n",
      "Epoch 7479/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2668 - val_loss: 41.4479\n",
      "Epoch 7480/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2196 - val_loss: 49.6238\n",
      "Epoch 7481/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2004 - val_loss: 56.1722\n",
      "Epoch 7482/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2001 - val_loss: 47.9115\n",
      "Epoch 7483/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1881 - val_loss: 49.3937\n",
      "Epoch 7484/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1884 - val_loss: 46.2216\n",
      "Epoch 7485/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1857 - val_loss: 44.6397\n",
      "Epoch 7486/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2550 - val_loss: 42.5665\n",
      "Epoch 7487/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2044 - val_loss: 51.3733\n",
      "Epoch 7488/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1857 - val_loss: 53.8850\n",
      "Epoch 7489/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1853 - val_loss: 49.9258\n",
      "Epoch 7490/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1759 - val_loss: 49.1224\n",
      "Epoch 7491/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 47.7643\n",
      "Epoch 7492/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1795 - val_loss: 42.1217\n",
      "Epoch 7493/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1988 - val_loss: 48.4844\n",
      "Epoch 7494/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2143 - val_loss: 47.1489\n",
      "Epoch 7495/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1813 - val_loss: 48.5165\n",
      "Epoch 7496/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1763 - val_loss: 42.0801\n",
      "Epoch 7497/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2026 - val_loss: 48.2311\n",
      "Epoch 7498/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1913 - val_loss: 43.9035\n",
      "Epoch 7499/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 46.8090\n",
      "Epoch 7500/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 47.0308\n",
      "Epoch 7501/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 47.3932\n",
      "Epoch 7502/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 48.7340\n",
      "Epoch 7503/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1711 - val_loss: 47.7607\n",
      "Epoch 7504/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 47.4160\n",
      "Epoch 7505/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 48.3341\n",
      "Epoch 7506/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1712 - val_loss: 48.1516\n",
      "Epoch 7507/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 48.0021\n",
      "Epoch 7508/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1703 - val_loss: 47.9795\n",
      "Epoch 7509/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1712 - val_loss: 48.7742\n",
      "Epoch 7510/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 50.4695\n",
      "Epoch 7511/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 47.4541\n",
      "Epoch 7512/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 48.0178\n",
      "Epoch 7513/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 49.9890\n",
      "Epoch 7514/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 49.5812\n",
      "Epoch 7515/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 48.0827\n",
      "Epoch 7516/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 49.2473\n",
      "Epoch 7517/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 49.4888\n",
      "Epoch 7518/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1687 - val_loss: 48.4392\n",
      "Epoch 7519/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1703 - val_loss: 50.9731\n",
      "Epoch 7520/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 49.1558\n",
      "Epoch 7521/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 49.9423\n",
      "Epoch 7522/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 49.6015\n",
      "Epoch 7523/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 48.9180\n",
      "Epoch 7524/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 48.8848\n",
      "Epoch 7525/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 49.8676\n",
      "Epoch 7526/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 48.8518\n",
      "Epoch 7527/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 50.6119\n",
      "Epoch 7528/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 49.0111\n",
      "Epoch 7529/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 46.3476\n",
      "Epoch 7530/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 47.1868\n",
      "Epoch 7531/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 46.0701\n",
      "Epoch 7532/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 47.0586\n",
      "Epoch 7533/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 47.9920\n",
      "Epoch 7534/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1712 - val_loss: 47.4425\n",
      "Epoch 7535/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 47.3828\n",
      "Epoch 7536/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 49.1422\n",
      "Epoch 7537/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 48.9386\n",
      "Epoch 7538/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1707 - val_loss: 47.7438\n",
      "Epoch 7539/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1694 - val_loss: 48.4893\n",
      "Epoch 7540/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1709 - val_loss: 48.2709\n",
      "Epoch 7541/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 48.4437\n",
      "Epoch 7542/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 48.3773\n",
      "Epoch 7543/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 46.7890\n",
      "Epoch 7544/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 46.7945\n",
      "Epoch 7545/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1802 - val_loss: 41.9196\n",
      "Epoch 7546/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3163 - val_loss: 64.8379\n",
      "Epoch 7547/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3188 - val_loss: 54.7780\n",
      "Epoch 7548/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2942 - val_loss: 59.6528\n",
      "Epoch 7549/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2477 - val_loss: 56.5130\n",
      "Epoch 7550/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2571 - val_loss: 61.6140\n",
      "Epoch 7551/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2952 - val_loss: 59.0882\n",
      "Epoch 7552/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2466 - val_loss: 50.1572\n",
      "Epoch 7553/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2022 - val_loss: 46.2707\n",
      "Epoch 7554/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1872 - val_loss: 48.6890\n",
      "Epoch 7555/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2046 - val_loss: 34.8508\n",
      "Epoch 7556/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2366 - val_loss: 54.2832\n",
      "Epoch 7557/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1819 - val_loss: 56.6826\n",
      "Epoch 7558/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1970 - val_loss: 49.8262\n",
      "Epoch 7559/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1859 - val_loss: 51.7237\n",
      "Epoch 7560/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1951 - val_loss: 53.5371\n",
      "Epoch 7561/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1800 - val_loss: 51.4242\n",
      "Epoch 7562/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1797 - val_loss: 54.2922\n",
      "Epoch 7563/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 53.2796\n",
      "Epoch 7564/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 52.8526\n",
      "Epoch 7565/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 52.5414\n",
      "Epoch 7566/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1766 - val_loss: 50.0003\n",
      "Epoch 7567/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1749 - val_loss: 51.1113\n",
      "Epoch 7568/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1707 - val_loss: 51.1145\n",
      "Epoch 7569/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 50.9646\n",
      "Epoch 7570/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 51.5417\n",
      "Epoch 7571/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 50.6536\n",
      "Epoch 7572/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 51.2783\n",
      "Epoch 7573/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 50.6899\n",
      "Epoch 7574/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 49.1692\n",
      "Epoch 7575/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1849 - val_loss: 51.8364\n",
      "Epoch 7576/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1804 - val_loss: 49.4556\n",
      "Epoch 7577/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1743 - val_loss: 47.0379\n",
      "Epoch 7578/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2000 - val_loss: 47.3295\n",
      "Epoch 7579/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2166 - val_loss: 52.2131\n",
      "Epoch 7580/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1949 - val_loss: 48.8811\n",
      "Epoch 7581/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1781 - val_loss: 49.5478\n",
      "Epoch 7582/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1709 - val_loss: 50.8106\n",
      "Epoch 7583/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1757 - val_loss: 46.7024\n",
      "Epoch 7584/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2162 - val_loss: 46.9539\n",
      "Epoch 7585/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1897 - val_loss: 50.5580\n",
      "Epoch 7586/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1748 - val_loss: 47.8451\n",
      "Epoch 7587/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 50.9790\n",
      "Epoch 7588/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 48.4447\n",
      "Epoch 7589/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 49.7803\n",
      "Epoch 7590/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 50.0608\n",
      "Epoch 7591/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1703 - val_loss: 49.5042\n",
      "Epoch 7592/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 49.9884\n",
      "Epoch 7593/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 48.8372\n",
      "Epoch 7594/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 49.0350\n",
      "Epoch 7595/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 50.1369\n",
      "Epoch 7596/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 50.1516\n",
      "Epoch 7597/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 50.4035\n",
      "Epoch 7598/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1704 - val_loss: 49.7465\n",
      "Epoch 7599/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 50.4325\n",
      "Epoch 7600/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 49.7733\n",
      "Epoch 7601/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 50.6375\n",
      "Epoch 7602/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 49.3139\n",
      "Epoch 7603/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 50.2939\n",
      "Epoch 7604/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 49.3982\n",
      "Epoch 7605/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1739 - val_loss: 47.9101\n",
      "Epoch 7606/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 48.0243\n",
      "Epoch 7607/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 49.7924\n",
      "Epoch 7608/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 49.7276\n",
      "Epoch 7609/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1776 - val_loss: 45.2089\n",
      "Epoch 7610/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2274 - val_loss: 27.3434\n",
      "Epoch 7611/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3730 - val_loss: 45.0836\n",
      "Epoch 7612/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2917 - val_loss: 45.0616\n",
      "Epoch 7613/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2094 - val_loss: 40.6254\n",
      "Epoch 7614/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2091 - val_loss: 42.6561\n",
      "Epoch 7615/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1914 - val_loss: 48.4501\n",
      "Epoch 7616/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1784 - val_loss: 50.3504\n",
      "Epoch 7617/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1743 - val_loss: 50.5228\n",
      "Epoch 7618/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1743 - val_loss: 52.6200\n",
      "Epoch 7619/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 50.4959\n",
      "Epoch 7620/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 52.8506\n",
      "Epoch 7621/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 50.8668\n",
      "Epoch 7622/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 52.4252\n",
      "Epoch 7623/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1703 - val_loss: 51.8843\n",
      "Epoch 7624/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 51.9064\n",
      "Epoch 7625/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 50.8150\n",
      "Epoch 7626/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 52.0583\n",
      "Epoch 7627/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1711 - val_loss: 51.2084\n",
      "Epoch 7628/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 50.6402\n",
      "Epoch 7629/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 50.5573\n",
      "Epoch 7630/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1706 - val_loss: 52.4324\n",
      "Epoch 7631/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1705 - val_loss: 51.9362\n",
      "Epoch 7632/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1705 - val_loss: 53.0176\n",
      "Epoch 7633/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1707 - val_loss: 52.4248\n",
      "Epoch 7634/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1696 - val_loss: 51.7174\n",
      "Epoch 7635/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1708 - val_loss: 50.5362\n",
      "Epoch 7636/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 52.7873\n",
      "Epoch 7637/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1688 - val_loss: 52.7588\n",
      "Epoch 7638/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 51.4688\n",
      "Epoch 7639/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 52.1610\n",
      "Epoch 7640/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1702 - val_loss: 52.1637\n",
      "Epoch 7641/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1715 - val_loss: 52.3081\n",
      "Epoch 7642/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 52.0364\n",
      "Epoch 7643/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1707 - val_loss: 52.6375\n",
      "Epoch 7644/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 52.0808\n",
      "Epoch 7645/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 52.7421\n",
      "Epoch 7646/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1699 - val_loss: 52.5831\n",
      "Epoch 7647/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1751 - val_loss: 53.8076\n",
      "Epoch 7648/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1878 - val_loss: 46.8893\n",
      "Epoch 7649/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3018 - val_loss: 51.0376\n",
      "Epoch 7650/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2572 - val_loss: 55.8831\n",
      "Epoch 7651/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2025 - val_loss: 49.2351\n",
      "Epoch 7652/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1774 - val_loss: 50.4104\n",
      "Epoch 7653/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 50.6572\n",
      "Epoch 7654/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 49.7856\n",
      "Epoch 7655/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1766 - val_loss: 50.6039\n",
      "Epoch 7656/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1763 - val_loss: 49.3309\n",
      "Epoch 7657/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1794 - val_loss: 45.9538\n",
      "Epoch 7658/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1745 - val_loss: 49.8046\n",
      "Epoch 7659/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 48.5982\n",
      "Epoch 7660/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1702 - val_loss: 48.7368\n",
      "Epoch 7661/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 49.7375\n",
      "Epoch 7662/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 50.8672\n",
      "Epoch 7663/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 49.9953\n",
      "Epoch 7664/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 49.3630\n",
      "Epoch 7665/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 50.5206\n",
      "Epoch 7666/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 49.3676\n",
      "Epoch 7667/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 48.2033\n",
      "Epoch 7668/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 49.8450\n",
      "Epoch 7669/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1746 - val_loss: 52.5700\n",
      "Epoch 7670/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1965 - val_loss: 38.0761\n",
      "Epoch 7671/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4436 - val_loss: 47.2693\n",
      "Epoch 7672/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3785 - val_loss: 50.3771\n",
      "Epoch 7673/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3019 - val_loss: 37.6875\n",
      "Epoch 7674/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3481 - val_loss: 39.3156\n",
      "Epoch 7675/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2809 - val_loss: 45.1183\n",
      "Epoch 7676/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2244 - val_loss: 47.5310\n",
      "Epoch 7677/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2098 - val_loss: 46.2013\n",
      "Epoch 7678/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2093 - val_loss: 43.0770\n",
      "Epoch 7679/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2060 - val_loss: 40.8235\n",
      "Epoch 7680/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2818 - val_loss: 50.8301\n",
      "Epoch 7681/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2798 - val_loss: 40.3851\n",
      "Epoch 7682/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2463 - val_loss: 31.1877\n",
      "Epoch 7683/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2286 - val_loss: 30.9486\n",
      "Epoch 7684/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1983 - val_loss: 30.4153\n",
      "Epoch 7685/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1961 - val_loss: 36.7622\n",
      "Epoch 7686/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1894 - val_loss: 38.2893\n",
      "Epoch 7687/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1886 - val_loss: 35.4960\n",
      "Epoch 7688/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1879 - val_loss: 35.3725\n",
      "Epoch 7689/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1891 - val_loss: 42.0028\n",
      "Epoch 7690/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2115 - val_loss: 33.1254\n",
      "Epoch 7691/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1939 - val_loss: 35.7315\n",
      "Epoch 7692/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2040 - val_loss: 47.4828\n",
      "Epoch 7693/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2014 - val_loss: 37.8850\n",
      "Epoch 7694/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1885 - val_loss: 38.5701\n",
      "Epoch 7695/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1972 - val_loss: 43.2354\n",
      "Epoch 7696/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2161 - val_loss: 29.2617\n",
      "Epoch 7697/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2168 - val_loss: 44.4995\n",
      "Epoch 7698/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2158 - val_loss: 40.4077\n",
      "Epoch 7699/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1909 - val_loss: 43.0640\n",
      "Epoch 7700/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1868 - val_loss: 45.7055\n",
      "Epoch 7701/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1924 - val_loss: 42.7571\n",
      "Epoch 7702/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1911 - val_loss: 37.2498\n",
      "Epoch 7703/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1910 - val_loss: 32.2912\n",
      "Epoch 7704/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1884 - val_loss: 42.2666\n",
      "Epoch 7705/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1804 - val_loss: 44.6781\n",
      "Epoch 7706/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1822 - val_loss: 40.6955\n",
      "Epoch 7707/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1826 - val_loss: 38.7505\n",
      "Epoch 7708/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1818 - val_loss: 39.2107\n",
      "Epoch 7709/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2008 - val_loss: 32.6542\n",
      "Epoch 7710/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2171 - val_loss: 33.9360\n",
      "Epoch 7711/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1901 - val_loss: 32.5164\n",
      "Epoch 7712/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1823 - val_loss: 30.9897\n",
      "Epoch 7713/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1808 - val_loss: 32.1856\n",
      "Epoch 7714/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1790 - val_loss: 32.5115\n",
      "Epoch 7715/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1820 - val_loss: 29.1773\n",
      "Epoch 7716/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1884 - val_loss: 33.7785\n",
      "Epoch 7717/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1862 - val_loss: 34.2221\n",
      "Epoch 7718/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1842 - val_loss: 33.3025\n",
      "Epoch 7719/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1815 - val_loss: 34.0219\n",
      "Epoch 7720/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1913 - val_loss: 32.2908\n",
      "Epoch 7721/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1889 - val_loss: 39.4416\n",
      "Epoch 7722/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1893 - val_loss: 38.4815\n",
      "Epoch 7723/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1930 - val_loss: 28.0506\n",
      "Epoch 7724/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1971 - val_loss: 36.2609\n",
      "Epoch 7725/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1875 - val_loss: 35.3731\n",
      "Epoch 7726/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1823 - val_loss: 37.1238\n",
      "Epoch 7727/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1804 - val_loss: 37.6506\n",
      "Epoch 7728/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1822 - val_loss: 35.8129\n",
      "Epoch 7729/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1997 - val_loss: 36.7851\n",
      "Epoch 7730/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1918 - val_loss: 28.7801\n",
      "Epoch 7731/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2503 - val_loss: 43.0628\n",
      "Epoch 7732/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2164 - val_loss: 39.7891\n",
      "Epoch 7733/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2295 - val_loss: 32.7311\n",
      "Epoch 7734/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2013 - val_loss: 36.7307\n",
      "Epoch 7735/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2372 - val_loss: 39.0882\n",
      "Epoch 7736/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2561 - val_loss: 44.6959\n",
      "Epoch 7737/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2332 - val_loss: 35.3807\n",
      "Epoch 7738/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2133 - val_loss: 40.0032\n",
      "Epoch 7739/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1931 - val_loss: 46.2925\n",
      "Epoch 7740/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1852 - val_loss: 45.4172\n",
      "Epoch 7741/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1838 - val_loss: 46.8459\n",
      "Epoch 7742/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2204 - val_loss: 43.1218\n",
      "Epoch 7743/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1902 - val_loss: 46.0353\n",
      "Epoch 7744/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1914 - val_loss: 46.1884\n",
      "Epoch 7745/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1815 - val_loss: 42.4660\n",
      "Epoch 7746/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1882 - val_loss: 42.0916\n",
      "Epoch 7747/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1846 - val_loss: 42.0476\n",
      "Epoch 7748/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1813 - val_loss: 43.4025\n",
      "Epoch 7749/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1776 - val_loss: 43.3358\n",
      "Epoch 7750/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1769 - val_loss: 42.1804\n",
      "Epoch 7751/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1768 - val_loss: 41.3895\n",
      "Epoch 7752/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1845 - val_loss: 42.5484\n",
      "Epoch 7753/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2113 - val_loss: 42.4089\n",
      "Epoch 7754/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1860 - val_loss: 38.1462\n",
      "Epoch 7755/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1791 - val_loss: 40.3168\n",
      "Epoch 7756/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1773 - val_loss: 42.5157\n",
      "Epoch 7757/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1921 - val_loss: 33.4881\n",
      "Epoch 7758/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2039 - val_loss: 29.6569\n",
      "Epoch 7759/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1970 - val_loss: 36.9600\n",
      "Epoch 7760/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1767 - val_loss: 39.4347\n",
      "Epoch 7761/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1747 - val_loss: 37.9648\n",
      "Epoch 7762/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1739 - val_loss: 41.2612\n",
      "Epoch 7763/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1743 - val_loss: 37.1068\n",
      "Epoch 7764/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1760 - val_loss: 34.2863\n",
      "Epoch 7765/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2127 - val_loss: 36.1881\n",
      "Epoch 7766/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1864 - val_loss: 42.5445\n",
      "Epoch 7767/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1789 - val_loss: 42.2025\n",
      "Epoch 7768/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1773 - val_loss: 40.3305\n",
      "Epoch 7769/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1771 - val_loss: 43.9376\n",
      "Epoch 7770/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1739 - val_loss: 39.2222\n",
      "Epoch 7771/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 40.6192\n",
      "Epoch 7772/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 37.8465\n",
      "Epoch 7773/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 37.5097\n",
      "Epoch 7774/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 38.4302\n",
      "Epoch 7775/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 35.5495\n",
      "Epoch 7776/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1759 - val_loss: 39.5828\n",
      "Epoch 7777/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1793 - val_loss: 37.6397\n",
      "Epoch 7778/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1752 - val_loss: 38.6035\n",
      "Epoch 7779/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1746 - val_loss: 37.0172\n",
      "Epoch 7780/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1749 - val_loss: 36.1735\n",
      "Epoch 7781/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1989 - val_loss: 37.8846\n",
      "Epoch 7782/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2116 - val_loss: 44.2132\n",
      "Epoch 7783/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1771 - val_loss: 43.7861\n",
      "Epoch 7784/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 43.0017\n",
      "Epoch 7785/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 42.7889\n",
      "Epoch 7786/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1771 - val_loss: 38.7369\n",
      "Epoch 7787/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1929 - val_loss: 35.0488\n",
      "Epoch 7788/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1861 - val_loss: 45.7704\n",
      "Epoch 7789/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1828 - val_loss: 43.2865\n",
      "Epoch 7790/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1762 - val_loss: 43.7064\n",
      "Epoch 7791/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 39.7088\n",
      "Epoch 7792/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 42.9979\n",
      "Epoch 7793/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 41.3718\n",
      "Epoch 7794/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 39.8333\n",
      "Epoch 7795/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1709 - val_loss: 39.8195\n",
      "Epoch 7796/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 39.4559\n",
      "Epoch 7797/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1702 - val_loss: 38.8540\n",
      "Epoch 7798/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 37.0354\n",
      "Epoch 7799/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1710 - val_loss: 39.8974\n",
      "Epoch 7800/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 35.4278\n",
      "Epoch 7801/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 35.5060\n",
      "Epoch 7802/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 37.3255\n",
      "Epoch 7803/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1702 - val_loss: 36.4170\n",
      "Epoch 7804/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 37.0220\n",
      "Epoch 7805/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 38.2614\n",
      "Epoch 7806/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1751 - val_loss: 35.7050\n",
      "Epoch 7807/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 35.1596\n",
      "Epoch 7808/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1712 - val_loss: 34.0047\n",
      "Epoch 7809/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 31.6699\n",
      "Epoch 7810/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1807 - val_loss: 28.7924\n",
      "Epoch 7811/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2684 - val_loss: 32.8149\n",
      "Epoch 7812/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3230 - val_loss: 46.1094\n",
      "Epoch 7813/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2299 - val_loss: 43.2901\n",
      "Epoch 7814/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1944 - val_loss: 44.0648\n",
      "Epoch 7815/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1824 - val_loss: 46.3810\n",
      "Epoch 7816/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1796 - val_loss: 39.3592\n",
      "Epoch 7817/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1835 - val_loss: 41.0355\n",
      "Epoch 7818/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1799 - val_loss: 40.3659\n",
      "Epoch 7819/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1764 - val_loss: 43.8779\n",
      "Epoch 7820/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2141 - val_loss: 27.1392\n",
      "Epoch 7821/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2002 - val_loss: 33.7421\n",
      "Epoch 7822/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1778 - val_loss: 37.8521\n",
      "Epoch 7823/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1773 - val_loss: 40.5972\n",
      "Epoch 7824/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1770 - val_loss: 39.5004\n",
      "Epoch 7825/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 38.4527\n",
      "Epoch 7826/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 36.1086\n",
      "Epoch 7827/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 37.7354\n",
      "Epoch 7828/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1723 - val_loss: 36.1099\n",
      "Epoch 7829/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 36.5468\n",
      "Epoch 7830/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 37.8354\n",
      "Epoch 7831/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 36.9757\n",
      "Epoch 7832/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 35.4982\n",
      "Epoch 7833/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1707 - val_loss: 35.9092\n",
      "Epoch 7834/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 36.4153\n",
      "Epoch 7835/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1746 - val_loss: 38.3040\n",
      "Epoch 7836/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1760 - val_loss: 37.0997\n",
      "Epoch 7837/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 31.9022\n",
      "Epoch 7838/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1750 - val_loss: 36.4619\n",
      "Epoch 7839/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 35.4548\n",
      "Epoch 7840/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 35.6462\n",
      "Epoch 7841/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 37.2705\n",
      "Epoch 7842/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1711 - val_loss: 36.3673\n",
      "Epoch 7843/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1695 - val_loss: 36.4177\n",
      "Epoch 7844/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 36.0037\n",
      "Epoch 7845/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1705 - val_loss: 36.8056\n",
      "Epoch 7846/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 34.6068\n",
      "Epoch 7847/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 38.0198\n",
      "Epoch 7848/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1711 - val_loss: 35.5669\n",
      "Epoch 7849/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1711 - val_loss: 34.9359\n",
      "Epoch 7850/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1895 - val_loss: 29.1775\n",
      "Epoch 7851/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2207 - val_loss: 31.2315\n",
      "Epoch 7852/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3002 - val_loss: 49.2689\n",
      "Epoch 7853/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2043 - val_loss: 42.7473\n",
      "Epoch 7854/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1788 - val_loss: 40.0545\n",
      "Epoch 7855/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1784 - val_loss: 39.5978\n",
      "Epoch 7856/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2212 - val_loss: 44.1580\n",
      "Epoch 7857/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2548 - val_loss: 37.8691\n",
      "Epoch 7858/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1993 - val_loss: 40.3958\n",
      "Epoch 7859/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1795 - val_loss: 42.2647\n",
      "Epoch 7860/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1757 - val_loss: 37.0242\n",
      "Epoch 7861/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1785 - val_loss: 41.8000\n",
      "Epoch 7862/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 45.0460\n",
      "Epoch 7863/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1779 - val_loss: 39.7579\n",
      "Epoch 7864/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 45.4454\n",
      "Epoch 7865/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1740 - val_loss: 42.2410\n",
      "Epoch 7866/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 39.6881\n",
      "Epoch 7867/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1712 - val_loss: 40.3793\n",
      "Epoch 7868/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1711 - val_loss: 41.4698\n",
      "Epoch 7869/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1709 - val_loss: 41.5086\n",
      "Epoch 7870/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 39.7682\n",
      "Epoch 7871/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 41.7042\n",
      "Epoch 7872/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 39.0969\n",
      "Epoch 7873/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1705 - val_loss: 40.7803\n",
      "Epoch 7874/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 39.9643\n",
      "Epoch 7875/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1712 - val_loss: 39.9536\n",
      "Epoch 7876/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1705 - val_loss: 40.4476\n",
      "Epoch 7877/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1712 - val_loss: 38.2685\n",
      "Epoch 7878/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 40.8012\n",
      "Epoch 7879/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 40.0501\n",
      "Epoch 7880/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 41.2568\n",
      "Epoch 7881/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 39.9273\n",
      "Epoch 7882/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1706 - val_loss: 38.5321\n",
      "Epoch 7883/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 38.7172\n",
      "Epoch 7884/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1708 - val_loss: 40.0546\n",
      "Epoch 7885/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1705 - val_loss: 38.0633\n",
      "Epoch 7886/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 38.6193\n",
      "Epoch 7887/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 37.5681\n",
      "Epoch 7888/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1706 - val_loss: 39.5194\n",
      "Epoch 7889/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 37.1366\n",
      "Epoch 7890/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1705 - val_loss: 35.4779\n",
      "Epoch 7891/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1696 - val_loss: 39.5035\n",
      "Epoch 7892/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 38.5158\n",
      "Epoch 7893/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1924 - val_loss: 33.3588\n",
      "Epoch 7894/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3738 - val_loss: 35.4443\n",
      "Epoch 7895/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2897 - val_loss: 38.6785\n",
      "Epoch 7896/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2251 - val_loss: 43.5158\n",
      "Epoch 7897/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2160 - val_loss: 32.4453\n",
      "Epoch 7898/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1897 - val_loss: 29.4938\n",
      "Epoch 7899/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2004 - val_loss: 40.6787\n",
      "Epoch 7900/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2369 - val_loss: 46.4139\n",
      "Epoch 7901/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2317 - val_loss: 39.0460\n",
      "Epoch 7902/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1865 - val_loss: 39.2599\n",
      "Epoch 7903/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1911 - val_loss: 35.0375\n",
      "Epoch 7904/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1903 - val_loss: 40.9279\n",
      "Epoch 7905/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1834 - val_loss: 40.4199\n",
      "Epoch 7906/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1773 - val_loss: 37.4778\n",
      "Epoch 7907/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1772 - val_loss: 29.6956\n",
      "Epoch 7908/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2599 - val_loss: 46.7238\n",
      "Epoch 7909/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1922 - val_loss: 44.3030\n",
      "Epoch 7910/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1770 - val_loss: 43.5835\n",
      "Epoch 7911/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 43.2529\n",
      "Epoch 7912/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 40.2676\n",
      "Epoch 7913/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 41.5231\n",
      "Epoch 7914/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 41.1397\n",
      "Epoch 7915/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 39.8923\n",
      "Epoch 7916/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 41.0682\n",
      "Epoch 7917/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1747 - val_loss: 42.6620\n",
      "Epoch 7918/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 43.4050\n",
      "Epoch 7919/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 41.8885\n",
      "Epoch 7920/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1694 - val_loss: 42.4528\n",
      "Epoch 7921/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 42.1044\n",
      "Epoch 7922/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 39.0377\n",
      "Epoch 7923/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1746 - val_loss: 42.2335\n",
      "Epoch 7924/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 43.0749\n",
      "Epoch 7925/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1702 - val_loss: 42.4893\n",
      "Epoch 7926/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1712 - val_loss: 43.4810\n",
      "Epoch 7927/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1711 - val_loss: 41.9571\n",
      "Epoch 7928/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 42.0666\n",
      "Epoch 7929/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 41.2463\n",
      "Epoch 7930/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1711 - val_loss: 42.5332\n",
      "Epoch 7931/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 40.1618\n",
      "Epoch 7932/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 42.1660\n",
      "Epoch 7933/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 40.8289\n",
      "Epoch 7934/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1817 - val_loss: 41.4083\n",
      "Epoch 7935/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1776 - val_loss: 37.5045\n",
      "Epoch 7936/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1778 - val_loss: 38.8981\n",
      "Epoch 7937/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 43.2368\n",
      "Epoch 7938/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1768 - val_loss: 37.9410\n",
      "Epoch 7939/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 40.9227\n",
      "Epoch 7940/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1774 - val_loss: 34.9670\n",
      "Epoch 7941/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1760 - val_loss: 33.1855\n",
      "Epoch 7942/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1873 - val_loss: 40.8482\n",
      "Epoch 7943/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1746 - val_loss: 37.4033\n",
      "Epoch 7944/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 34.5157\n",
      "Epoch 7945/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 34.7798\n",
      "Epoch 7946/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 36.4806\n",
      "Epoch 7947/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1709 - val_loss: 36.7500\n",
      "Epoch 7948/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1703 - val_loss: 33.7326\n",
      "Epoch 7949/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 39.2937\n",
      "Epoch 7950/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3007 - val_loss: 58.8133\n",
      "Epoch 7951/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4205 - val_loss: 58.2126\n",
      "Epoch 7952/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2503 - val_loss: 53.9306\n",
      "Epoch 7953/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2937 - val_loss: 47.3682\n",
      "Epoch 7954/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4315 - val_loss: 38.8746\n",
      "Epoch 7955/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3419 - val_loss: 48.1326\n",
      "Epoch 7956/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3708 - val_loss: 41.2795\n",
      "Epoch 7957/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2675 - val_loss: 44.2431\n",
      "Epoch 7958/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2282 - val_loss: 39.5361\n",
      "Epoch 7959/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2041 - val_loss: 37.2988\n",
      "Epoch 7960/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1882 - val_loss: 41.5445\n",
      "Epoch 7961/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1843 - val_loss: 37.6829\n",
      "Epoch 7962/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1778 - val_loss: 37.3229\n",
      "Epoch 7963/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1787 - val_loss: 43.9695\n",
      "Epoch 7964/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2018 - val_loss: 39.3554\n",
      "Epoch 7965/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1970 - val_loss: 51.2356\n",
      "Epoch 7966/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1854 - val_loss: 35.6641\n",
      "Epoch 7967/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1785 - val_loss: 40.2042\n",
      "Epoch 7968/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1748 - val_loss: 41.7626\n",
      "Epoch 7969/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 39.0119\n",
      "Epoch 7970/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 39.5341\n",
      "Epoch 7971/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 39.9008\n",
      "Epoch 7972/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 41.6599\n",
      "Epoch 7973/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 36.3556\n",
      "Epoch 7974/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 40.8601\n",
      "Epoch 7975/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1707 - val_loss: 40.8978\n",
      "Epoch 7976/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 41.1807\n",
      "Epoch 7977/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 41.5297\n",
      "Epoch 7978/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 40.2592\n",
      "Epoch 7979/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 41.5031\n",
      "Epoch 7980/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1723 - val_loss: 40.9864\n",
      "Epoch 7981/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1729 - val_loss: 41.1227\n",
      "Epoch 7982/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 43.1958\n",
      "Epoch 7983/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1776 - val_loss: 42.4036\n",
      "Epoch 7984/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 41.5753\n",
      "Epoch 7985/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1710 - val_loss: 40.5512\n",
      "Epoch 7986/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1709 - val_loss: 41.7698\n",
      "Epoch 7987/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 40.3966\n",
      "Epoch 7988/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 40.7285\n",
      "Epoch 7989/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 41.7421\n",
      "Epoch 7990/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1707 - val_loss: 40.2841\n",
      "Epoch 7991/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 40.1735\n",
      "Epoch 7992/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1709 - val_loss: 40.6705\n",
      "Epoch 7993/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 40.0030\n",
      "Epoch 7994/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 40.4554\n",
      "Epoch 7995/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1697 - val_loss: 40.1604\n",
      "Epoch 7996/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1711 - val_loss: 40.1290\n",
      "Epoch 7997/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1711 - val_loss: 39.9271\n",
      "Epoch 7998/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1762 - val_loss: 37.2377\n",
      "Epoch 7999/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1778 - val_loss: 41.7226\n",
      "Epoch 8000/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1710 - val_loss: 39.8106\n",
      "Epoch 8001/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 40.9714\n",
      "Epoch 8002/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 40.1112\n",
      "Epoch 8003/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 39.3918\n",
      "Epoch 8004/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1716 - val_loss: 40.8606\n",
      "Epoch 8005/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1704 - val_loss: 38.5355\n",
      "Epoch 8006/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1712 - val_loss: 39.2621\n",
      "Epoch 8007/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1708 - val_loss: 39.6416\n",
      "Epoch 8008/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1706 - val_loss: 40.3763\n",
      "Epoch 8009/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 40.7541\n",
      "Epoch 8010/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 38.9844\n",
      "Epoch 8011/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 41.0958\n",
      "Epoch 8012/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 39.2183\n",
      "Epoch 8013/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1700 - val_loss: 39.5281\n",
      "Epoch 8014/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1707 - val_loss: 39.6973\n",
      "Epoch 8015/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 38.0034\n",
      "Epoch 8016/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 39.8614\n",
      "Epoch 8017/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1712 - val_loss: 39.9942\n",
      "Epoch 8018/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1837 - val_loss: 40.5663\n",
      "Epoch 8019/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1970 - val_loss: 33.1849\n",
      "Epoch 8020/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1882 - val_loss: 32.9355\n",
      "Epoch 8021/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1929 - val_loss: 41.6514\n",
      "Epoch 8022/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1922 - val_loss: 37.6505\n",
      "Epoch 8023/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1799 - val_loss: 39.6992\n",
      "Epoch 8024/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2155 - val_loss: 34.0411\n",
      "Epoch 8025/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2252 - val_loss: 36.3311\n",
      "Epoch 8026/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1863 - val_loss: 36.1381\n",
      "Epoch 8027/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 37.7114\n",
      "Epoch 8028/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 36.8422\n",
      "Epoch 8029/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 38.1519\n",
      "Epoch 8030/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 36.4624\n",
      "Epoch 8031/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1710 - val_loss: 36.6854\n",
      "Epoch 8032/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 36.4818\n",
      "Epoch 8033/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 38.2584\n",
      "Epoch 8034/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1710 - val_loss: 38.5150\n",
      "Epoch 8035/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 37.2902\n",
      "Epoch 8036/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 36.7619\n",
      "Epoch 8037/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 38.6779\n",
      "Epoch 8038/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 36.8077\n",
      "Epoch 8039/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1699 - val_loss: 36.2830\n",
      "Epoch 8040/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1701 - val_loss: 37.0153\n",
      "Epoch 8041/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1705 - val_loss: 36.9676\n",
      "Epoch 8042/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 37.1404\n",
      "Epoch 8043/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 35.5785\n",
      "Epoch 8044/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 35.3785\n",
      "Epoch 8045/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 38.1295\n",
      "Epoch 8046/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 36.0350\n",
      "Epoch 8047/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 38.1970\n",
      "Epoch 8048/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 36.1296\n",
      "Epoch 8049/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 36.3825\n",
      "Epoch 8050/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 36.2566\n",
      "Epoch 8051/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1709 - val_loss: 35.2849\n",
      "Epoch 8052/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 36.5778\n",
      "Epoch 8053/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1695 - val_loss: 36.8263\n",
      "Epoch 8054/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 34.4492\n",
      "Epoch 8055/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 36.0105\n",
      "Epoch 8056/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1712 - val_loss: 35.7644\n",
      "Epoch 8057/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 36.0890\n",
      "Epoch 8058/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 35.9509\n",
      "Epoch 8059/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 35.8815\n",
      "Epoch 8060/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 34.0269\n",
      "Epoch 8061/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 33.5427\n",
      "Epoch 8062/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 35.4814\n",
      "Epoch 8063/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1739 - val_loss: 35.7917\n",
      "Epoch 8064/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 34.6015\n",
      "Epoch 8065/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1766 - val_loss: 33.7733\n",
      "Epoch 8066/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1752 - val_loss: 36.1925\n",
      "Epoch 8067/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 34.7570\n",
      "Epoch 8068/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 34.3455\n",
      "Epoch 8069/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 34.6955\n",
      "Epoch 8070/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 33.7643\n",
      "Epoch 8071/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1701 - val_loss: 34.0280\n",
      "Epoch 8072/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 33.8682\n",
      "Epoch 8073/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 33.7983\n",
      "Epoch 8074/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 35.0588\n",
      "Epoch 8075/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1918 - val_loss: 32.9890\n",
      "Epoch 8076/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4307 - val_loss: 42.7899\n",
      "Epoch 8077/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3270 - val_loss: 53.1361\n",
      "Epoch 8078/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3221 - val_loss: 54.0819\n",
      "Epoch 8079/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2494 - val_loss: 49.8953\n",
      "Epoch 8080/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2229 - val_loss: 54.2600\n",
      "Epoch 8081/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2135 - val_loss: 38.2492\n",
      "Epoch 8082/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2028 - val_loss: 40.8303\n",
      "Epoch 8083/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2051 - val_loss: 42.0010\n",
      "Epoch 8084/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1956 - val_loss: 34.6656\n",
      "Epoch 8085/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1851 - val_loss: 38.4055\n",
      "Epoch 8086/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2113 - val_loss: 38.0634\n",
      "Epoch 8087/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1909 - val_loss: 42.8663\n",
      "Epoch 8088/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1765 - val_loss: 37.3007\n",
      "Epoch 8089/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 37.0414\n",
      "Epoch 8090/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 37.2419\n",
      "Epoch 8091/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1739 - val_loss: 35.3413\n",
      "Epoch 8092/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 37.4487\n",
      "Epoch 8093/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 36.1292\n",
      "Epoch 8094/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 35.7468\n",
      "Epoch 8095/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 34.0995\n",
      "Epoch 8096/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 36.2413\n",
      "Epoch 8097/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1728 - val_loss: 35.6524\n",
      "Epoch 8098/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 34.1852\n",
      "Epoch 8099/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 36.3933\n",
      "Epoch 8100/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 35.0092\n",
      "Epoch 8101/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 35.7885\n",
      "Epoch 8102/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 36.9421\n",
      "Epoch 8103/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 35.5834\n",
      "Epoch 8104/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 34.6307\n",
      "Epoch 8105/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 36.4949\n",
      "Epoch 8106/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1697 - val_loss: 35.7903\n",
      "Epoch 8107/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 33.7135\n",
      "Epoch 8108/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1710 - val_loss: 37.3451\n",
      "Epoch 8109/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 32.1903\n",
      "Epoch 8110/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 35.6933\n",
      "Epoch 8111/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1743 - val_loss: 36.3287\n",
      "Epoch 8112/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1711 - val_loss: 35.0219\n",
      "Epoch 8113/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 37.3287\n",
      "Epoch 8114/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 35.6332\n",
      "Epoch 8115/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 35.9169\n",
      "Epoch 8116/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 33.6831\n",
      "Epoch 8117/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 35.5431\n",
      "Epoch 8118/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 34.5084\n",
      "Epoch 8119/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 33.7790\n",
      "Epoch 8120/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1740 - val_loss: 34.1644\n",
      "Epoch 8121/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 36.9369\n",
      "Epoch 8122/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 37.8561\n",
      "Epoch 8123/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1979 - val_loss: 43.5694\n",
      "Epoch 8124/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2256 - val_loss: 42.4040\n",
      "Epoch 8125/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2019 - val_loss: 27.3809\n",
      "Epoch 8126/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3963 - val_loss: 42.4316\n",
      "Epoch 8127/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3669 - val_loss: 55.9431\n",
      "Epoch 8128/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2302 - val_loss: 38.5498\n",
      "Epoch 8129/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1973 - val_loss: 46.9816\n",
      "Epoch 8130/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1922 - val_loss: 40.8576\n",
      "Epoch 8131/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1967 - val_loss: 43.3435\n",
      "Epoch 8132/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1749 - val_loss: 40.5699\n",
      "Epoch 8133/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 42.9237\n",
      "Epoch 8134/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 43.0592\n",
      "Epoch 8135/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 42.0333\n",
      "Epoch 8136/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 41.4260\n",
      "Epoch 8137/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 41.8233\n",
      "Epoch 8138/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 42.9710\n",
      "Epoch 8139/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 42.0784\n",
      "Epoch 8140/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 42.3683\n",
      "Epoch 8141/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1707 - val_loss: 41.6294\n",
      "Epoch 8142/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 41.8664\n",
      "Epoch 8143/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1709 - val_loss: 41.8951\n",
      "Epoch 8144/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 42.2485\n",
      "Epoch 8145/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 43.0235\n",
      "Epoch 8146/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 42.8643\n",
      "Epoch 8147/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1710 - val_loss: 43.1687\n",
      "Epoch 8148/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1694 - val_loss: 42.4631\n",
      "Epoch 8149/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1686 - val_loss: 43.0357\n",
      "Epoch 8150/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1694 - val_loss: 41.2286\n",
      "Epoch 8151/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 43.3429\n",
      "Epoch 8152/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 45.3635\n",
      "Epoch 8153/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 40.4748\n",
      "Epoch 8154/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 42.8784\n",
      "Epoch 8155/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 42.5616\n",
      "Epoch 8156/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 42.1934\n",
      "Epoch 8157/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 42.0895\n",
      "Epoch 8158/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1698 - val_loss: 41.9729\n",
      "Epoch 8159/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1704 - val_loss: 41.9853\n",
      "Epoch 8160/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 42.7724\n",
      "Epoch 8161/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1707 - val_loss: 42.8556\n",
      "Epoch 8162/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1707 - val_loss: 41.1908\n",
      "Epoch 8163/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1706 - val_loss: 43.9945\n",
      "Epoch 8164/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 42.1849\n",
      "Epoch 8165/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 42.3572\n",
      "Epoch 8166/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1699 - val_loss: 41.9020\n",
      "Epoch 8167/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 42.7919\n",
      "Epoch 8168/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 44.2107\n",
      "Epoch 8169/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 38.5245\n",
      "Epoch 8170/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1756 - val_loss: 38.5538\n",
      "Epoch 8171/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1739 - val_loss: 40.5799\n",
      "Epoch 8172/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1712 - val_loss: 38.9669\n",
      "Epoch 8173/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 39.4636\n",
      "Epoch 8174/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 39.0862\n",
      "Epoch 8175/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 38.4138\n",
      "Epoch 8176/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 39.5167\n",
      "Epoch 8177/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1709 - val_loss: 39.9266\n",
      "Epoch 8178/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 40.5746\n",
      "Epoch 8179/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1708 - val_loss: 40.8024\n",
      "Epoch 8180/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 40.5599\n",
      "Epoch 8181/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1712 - val_loss: 40.8268\n",
      "Epoch 8182/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1701 - val_loss: 40.9334\n",
      "Epoch 8183/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1790 - val_loss: 25.6016\n",
      "Epoch 8184/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2765 - val_loss: 42.7406\n",
      "Epoch 8185/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2460 - val_loss: 36.2912\n",
      "Epoch 8186/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3084 - val_loss: 53.3315\n",
      "Epoch 8187/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3041 - val_loss: 44.6341\n",
      "Epoch 8188/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2291 - val_loss: 41.7120\n",
      "Epoch 8189/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2303 - val_loss: 39.8363\n",
      "Epoch 8190/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2182 - val_loss: 43.0813\n",
      "Epoch 8191/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2246 - val_loss: 48.9914\n",
      "Epoch 8192/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2501 - val_loss: 42.8706\n",
      "Epoch 8193/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2264 - val_loss: 45.0774\n",
      "Epoch 8194/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2115 - val_loss: 45.8290\n",
      "Epoch 8195/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2041 - val_loss: 46.8977\n",
      "Epoch 8196/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2033 - val_loss: 54.3175\n",
      "Epoch 8197/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2336 - val_loss: 40.4850\n",
      "Epoch 8198/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2185 - val_loss: 44.2469\n",
      "Epoch 8199/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2020 - val_loss: 47.4971\n",
      "Epoch 8200/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2167 - val_loss: 41.8233\n",
      "Epoch 8201/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1918 - val_loss: 42.3082\n",
      "Epoch 8202/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1781 - val_loss: 42.2020\n",
      "Epoch 8203/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1789 - val_loss: 39.9868\n",
      "Epoch 8204/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2109 - val_loss: 41.1509\n",
      "Epoch 8205/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1976 - val_loss: 40.5103\n",
      "Epoch 8206/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1836 - val_loss: 39.7062\n",
      "Epoch 8207/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1751 - val_loss: 41.4189\n",
      "Epoch 8208/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1743 - val_loss: 39.0629\n",
      "Epoch 8209/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 39.5534\n",
      "Epoch 8210/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1696 - val_loss: 41.4900\n",
      "Epoch 8211/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 42.8833\n",
      "Epoch 8212/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 42.0610\n",
      "Epoch 8213/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 43.7494\n",
      "Epoch 8214/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 43.6535\n",
      "Epoch 8215/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 43.1884\n",
      "Epoch 8216/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 44.1072\n",
      "Epoch 8217/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 43.8845\n",
      "Epoch 8218/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 43.8548\n",
      "Epoch 8219/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1711 - val_loss: 43.0689\n",
      "Epoch 8220/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 44.7654\n",
      "Epoch 8221/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 44.3410\n",
      "Epoch 8222/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 44.7528\n",
      "Epoch 8223/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1709 - val_loss: 44.7391\n",
      "Epoch 8224/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 44.0771\n",
      "Epoch 8225/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1705 - val_loss: 44.6814\n",
      "Epoch 8226/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 45.2110\n",
      "Epoch 8227/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1705 - val_loss: 44.5180\n",
      "Epoch 8228/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1716 - val_loss: 44.3392\n",
      "Epoch 8229/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 43.0708\n",
      "Epoch 8230/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 44.4220\n",
      "Epoch 8231/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1748 - val_loss: 49.0423\n",
      "Epoch 8232/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3537 - val_loss: 46.1322\n",
      "Epoch 8233/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2145 - val_loss: 54.1460\n",
      "Epoch 8234/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4044 - val_loss: 37.2143\n",
      "Epoch 8235/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2692 - val_loss: 44.2930\n",
      "Epoch 8236/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1994 - val_loss: 41.1316\n",
      "Epoch 8237/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1790 - val_loss: 41.9895\n",
      "Epoch 8238/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1753 - val_loss: 41.0666\n",
      "Epoch 8239/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1744 - val_loss: 39.2616\n",
      "Epoch 8240/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 39.5238\n",
      "Epoch 8241/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 37.0004\n",
      "Epoch 8242/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 38.8370\n",
      "Epoch 8243/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1707 - val_loss: 35.5884\n",
      "Epoch 8244/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 35.5098\n",
      "Epoch 8245/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 35.6519\n",
      "Epoch 8246/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1704 - val_loss: 34.5219\n",
      "Epoch 8247/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1712 - val_loss: 36.5122\n",
      "Epoch 8248/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1711 - val_loss: 34.5213\n",
      "Epoch 8249/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 35.0114\n",
      "Epoch 8250/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 33.4270\n",
      "Epoch 8251/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 34.0895\n",
      "Epoch 8252/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 30.4241\n",
      "Epoch 8253/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 34.9577\n",
      "Epoch 8254/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 32.7329\n",
      "Epoch 8255/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 34.2561\n",
      "Epoch 8256/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 33.8007\n",
      "Epoch 8257/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 32.9526\n",
      "Epoch 8258/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1692 - val_loss: 31.5168\n",
      "Epoch 8259/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1708 - val_loss: 30.7687\n",
      "Epoch 8260/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1694 - val_loss: 32.2919\n",
      "Epoch 8261/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1699 - val_loss: 34.4539\n",
      "Epoch 8262/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 34.5841\n",
      "Epoch 8263/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 35.1222\n",
      "Epoch 8264/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 33.4423\n",
      "Epoch 8265/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 34.9894\n",
      "Epoch 8266/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1695 - val_loss: 35.3801\n",
      "Epoch 8267/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 36.2469\n",
      "Epoch 8268/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 34.4946\n",
      "Epoch 8269/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1706 - val_loss: 33.5560\n",
      "Epoch 8270/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 34.7101\n",
      "Epoch 8271/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1953 - val_loss: 31.8138\n",
      "Epoch 8272/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2792 - val_loss: 51.3331\n",
      "Epoch 8273/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2646 - val_loss: 45.1882\n",
      "Epoch 8274/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1944 - val_loss: 31.5081\n",
      "Epoch 8275/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1759 - val_loss: 30.1069\n",
      "Epoch 8276/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1999 - val_loss: 45.3697\n",
      "Epoch 8277/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2646 - val_loss: 49.2152\n",
      "Epoch 8278/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2663 - val_loss: 40.5639\n",
      "Epoch 8279/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2244 - val_loss: 29.8819\n",
      "Epoch 8280/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1937 - val_loss: 27.9089\n",
      "Epoch 8281/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2455 - val_loss: 23.9941\n",
      "Epoch 8282/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2058 - val_loss: 16.8212\n",
      "Epoch 8283/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1820 - val_loss: 22.5643\n",
      "Epoch 8284/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1811 - val_loss: 20.7543\n",
      "Epoch 8285/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1766 - val_loss: 21.6593\n",
      "Epoch 8286/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 21.9174\n",
      "Epoch 8287/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1733 - val_loss: 24.7168\n",
      "Epoch 8288/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 24.5552\n",
      "Epoch 8289/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 26.7175\n",
      "Epoch 8290/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 27.3735\n",
      "Epoch 8291/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1709 - val_loss: 27.4758\n",
      "Epoch 8292/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 29.7564\n",
      "Epoch 8293/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 29.9753\n",
      "Epoch 8294/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1708 - val_loss: 29.8126\n",
      "Epoch 8295/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 30.0295\n",
      "Epoch 8296/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1719 - val_loss: 30.5270\n",
      "Epoch 8297/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 30.4681\n",
      "Epoch 8298/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 29.6582\n",
      "Epoch 8299/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 30.6552\n",
      "Epoch 8300/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1711 - val_loss: 31.6245\n",
      "Epoch 8301/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1712 - val_loss: 31.4036\n",
      "Epoch 8302/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1706 - val_loss: 31.6280\n",
      "Epoch 8303/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 30.8172\n",
      "Epoch 8304/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1711 - val_loss: 29.3968\n",
      "Epoch 8305/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 30.4619\n",
      "Epoch 8306/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 31.4760\n",
      "Epoch 8307/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 31.8788\n",
      "Epoch 8308/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1698 - val_loss: 34.0422\n",
      "Epoch 8309/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 35.0312\n",
      "Epoch 8310/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 32.4809\n",
      "Epoch 8311/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 32.3402\n",
      "Epoch 8312/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1699 - val_loss: 32.0447\n",
      "Epoch 8313/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1679 - val_loss: 32.9708\n",
      "Epoch 8314/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1696 - val_loss: 32.4386\n",
      "Epoch 8315/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 33.2739\n",
      "Epoch 8316/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1711 - val_loss: 33.3035\n",
      "Epoch 8317/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 33.8686\n",
      "Epoch 8318/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 33.7873\n",
      "Epoch 8319/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1711 - val_loss: 32.7978\n",
      "Epoch 8320/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1778 - val_loss: 32.0206\n",
      "Epoch 8321/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1830 - val_loss: 34.5573\n",
      "Epoch 8322/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3715 - val_loss: 41.7325\n",
      "Epoch 8323/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.5382 - val_loss: 34.6845\n",
      "Epoch 8324/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3285 - val_loss: 70.3579\n",
      "Epoch 8325/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2741 - val_loss: 59.9537\n",
      "Epoch 8326/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2435 - val_loss: 62.0044\n",
      "Epoch 8327/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2520 - val_loss: 53.3915\n",
      "Epoch 8328/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2208 - val_loss: 50.2125\n",
      "Epoch 8329/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2349 - val_loss: 54.0340\n",
      "Epoch 8330/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2071 - val_loss: 47.2418\n",
      "Epoch 8331/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1974 - val_loss: 45.0767\n",
      "Epoch 8332/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2146 - val_loss: 46.0734\n",
      "Epoch 8333/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1977 - val_loss: 44.1937\n",
      "Epoch 8334/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2057 - val_loss: 45.4412\n",
      "Epoch 8335/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2029 - val_loss: 41.0304\n",
      "Epoch 8336/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1933 - val_loss: 41.1790\n",
      "Epoch 8337/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2012 - val_loss: 34.7774\n",
      "Epoch 8338/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1932 - val_loss: 35.4383\n",
      "Epoch 8339/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1972 - val_loss: 30.7243\n",
      "Epoch 8340/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1888 - val_loss: 28.5000\n",
      "Epoch 8341/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1787 - val_loss: 32.3503\n",
      "Epoch 8342/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1817 - val_loss: 36.2612\n",
      "Epoch 8343/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1756 - val_loss: 37.3903\n",
      "Epoch 8344/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1853 - val_loss: 29.2641\n",
      "Epoch 8345/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1792 - val_loss: 32.7527\n",
      "Epoch 8346/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1788 - val_loss: 24.8086\n",
      "Epoch 8347/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 28.1524\n",
      "Epoch 8348/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 27.2679\n",
      "Epoch 8349/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1757 - val_loss: 32.1940\n",
      "Epoch 8350/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1750 - val_loss: 25.9342\n",
      "Epoch 8351/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1750 - val_loss: 26.1443\n",
      "Epoch 8352/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1760 - val_loss: 24.2596\n",
      "Epoch 8353/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1740 - val_loss: 28.0291\n",
      "Epoch 8354/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 25.4034\n",
      "Epoch 8355/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 28.4895\n",
      "Epoch 8356/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 29.8011\n",
      "Epoch 8357/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 31.2150\n",
      "Epoch 8358/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 24.8932\n",
      "Epoch 8359/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 26.5873\n",
      "Epoch 8360/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1763 - val_loss: 29.9635\n",
      "Epoch 8361/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 30.6802\n",
      "Epoch 8362/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 26.1277\n",
      "Epoch 8363/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 29.7810\n",
      "Epoch 8364/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 29.0458\n",
      "Epoch 8365/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 28.0934\n",
      "Epoch 8366/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1764 - val_loss: 32.0458\n",
      "Epoch 8367/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1942 - val_loss: 23.3810\n",
      "Epoch 8368/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2079 - val_loss: 22.5092\n",
      "Epoch 8369/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1840 - val_loss: 25.4818\n",
      "Epoch 8370/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1749 - val_loss: 25.4248\n",
      "Epoch 8371/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 24.4690\n",
      "Epoch 8372/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1751 - val_loss: 20.9227\n",
      "Epoch 8373/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1755 - val_loss: 26.0274\n",
      "Epoch 8374/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1772 - val_loss: 24.5037\n",
      "Epoch 8375/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2035 - val_loss: 21.6142\n",
      "Epoch 8376/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2124 - val_loss: 19.2393\n",
      "Epoch 8377/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2134 - val_loss: 20.2725\n",
      "Epoch 8378/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1884 - val_loss: 26.7072\n",
      "Epoch 8379/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1766 - val_loss: 22.4530\n",
      "Epoch 8380/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1766 - val_loss: 23.9314\n",
      "Epoch 8381/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 23.3542\n",
      "Epoch 8382/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 22.4011\n",
      "Epoch 8383/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 25.4079\n",
      "Epoch 8384/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 24.6526\n",
      "Epoch 8385/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1705 - val_loss: 23.2110\n",
      "Epoch 8386/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 24.4326\n",
      "Epoch 8387/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 25.0045\n",
      "Epoch 8388/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 24.2754\n",
      "Epoch 8389/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1711 - val_loss: 25.6867\n",
      "Epoch 8390/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 23.9441\n",
      "Epoch 8391/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 26.2256\n",
      "Epoch 8392/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 23.9496\n",
      "Epoch 8393/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 25.4799\n",
      "Epoch 8394/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 25.9581\n",
      "Epoch 8395/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1705 - val_loss: 26.0174\n",
      "Epoch 8396/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 24.7922\n",
      "Epoch 8397/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 25.3821\n",
      "Epoch 8398/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1692 - val_loss: 25.9240\n",
      "Epoch 8399/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1698 - val_loss: 26.1079\n",
      "Epoch 8400/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 24.4193\n",
      "Epoch 8401/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1755 - val_loss: 27.4641\n",
      "Epoch 8402/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1800 - val_loss: 20.3320\n",
      "Epoch 8403/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2092 - val_loss: 19.8110\n",
      "Epoch 8404/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2296 - val_loss: 30.7684\n",
      "Epoch 8405/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2791 - val_loss: 43.4666\n",
      "Epoch 8406/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2516 - val_loss: 47.9847\n",
      "Epoch 8407/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2281 - val_loss: 52.2305\n",
      "Epoch 8408/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2236 - val_loss: 37.4427\n",
      "Epoch 8409/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1921 - val_loss: 25.3371\n",
      "Epoch 8410/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1850 - val_loss: 23.7042\n",
      "Epoch 8411/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1756 - val_loss: 25.3690\n",
      "Epoch 8412/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1790 - val_loss: 20.0160\n",
      "Epoch 8413/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1809 - val_loss: 21.1028\n",
      "Epoch 8414/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1741 - val_loss: 21.0209\n",
      "Epoch 8415/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 22.5597\n",
      "Epoch 8416/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 22.7188\n",
      "Epoch 8417/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 22.0424\n",
      "Epoch 8418/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 20.5435\n",
      "Epoch 8419/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 20.1338\n",
      "Epoch 8420/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 21.5058\n",
      "Epoch 8421/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 23.1841\n",
      "Epoch 8422/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 21.0276\n",
      "Epoch 8423/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 20.2643\n",
      "Epoch 8424/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 20.7307\n",
      "Epoch 8425/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 22.0627\n",
      "Epoch 8426/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 22.1092\n",
      "Epoch 8427/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 21.6675\n",
      "Epoch 8428/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 21.7845\n",
      "Epoch 8429/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1710 - val_loss: 19.3727\n",
      "Epoch 8430/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1712 - val_loss: 18.9112\n",
      "Epoch 8431/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1773 - val_loss: 18.9247\n",
      "Epoch 8432/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1824 - val_loss: 18.6242\n",
      "Epoch 8433/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 17.9022\n",
      "Epoch 8434/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1834 - val_loss: 14.2005\n",
      "Epoch 8435/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1868 - val_loss: 22.7398\n",
      "Epoch 8436/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2663 - val_loss: 18.1504\n",
      "Epoch 8437/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3141 - val_loss: 42.0535\n",
      "Epoch 8438/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2582 - val_loss: 27.5243\n",
      "Epoch 8439/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2093 - val_loss: 35.0469\n",
      "Epoch 8440/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1966 - val_loss: 17.8016\n",
      "Epoch 8441/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1904 - val_loss: 21.3348\n",
      "Epoch 8442/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1816 - val_loss: 25.6848\n",
      "Epoch 8443/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1809 - val_loss: 26.6846\n",
      "Epoch 8444/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1803 - val_loss: 24.4235\n",
      "Epoch 8445/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1755 - val_loss: 22.5250\n",
      "Epoch 8446/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 20.8413\n",
      "Epoch 8447/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 22.2495\n",
      "Epoch 8448/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 22.5629\n",
      "Epoch 8449/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 22.9216\n",
      "Epoch 8450/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 20.9287\n",
      "Epoch 8451/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1711 - val_loss: 20.0671\n",
      "Epoch 8452/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 21.3893\n",
      "Epoch 8453/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 19.7377\n",
      "Epoch 8454/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1711 - val_loss: 20.6140\n",
      "Epoch 8455/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 20.0850\n",
      "Epoch 8456/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1698 - val_loss: 20.7270\n",
      "Epoch 8457/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 21.3308\n",
      "Epoch 8458/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1708 - val_loss: 21.7125\n",
      "Epoch 8459/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1707 - val_loss: 21.2061\n",
      "Epoch 8460/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 21.5138\n",
      "Epoch 8461/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1701 - val_loss: 20.1971\n",
      "Epoch 8462/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1717 - val_loss: 20.8803\n",
      "Epoch 8463/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1707 - val_loss: 19.7313\n",
      "Epoch 8464/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 24.1594\n",
      "Epoch 8465/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1712 - val_loss: 19.6239\n",
      "Epoch 8466/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 20.0763\n",
      "Epoch 8467/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1710 - val_loss: 21.3617\n",
      "Epoch 8468/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 21.2238\n",
      "Epoch 8469/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 20.0039\n",
      "Epoch 8470/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1722 - val_loss: 21.1834\n",
      "Epoch 8471/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 20.2885\n",
      "Epoch 8472/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 19.8066\n",
      "Epoch 8473/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 17.9748\n",
      "Epoch 8474/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1741 - val_loss: 22.2113\n",
      "Epoch 8475/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1766 - val_loss: 20.8213\n",
      "Epoch 8476/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3366 - val_loss: 57.2835\n",
      "Epoch 8477/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3208 - val_loss: 39.4938\n",
      "Epoch 8478/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2870 - val_loss: 44.0857\n",
      "Epoch 8479/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.5489 - val_loss: 30.5641\n",
      "Epoch 8480/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2631 - val_loss: 37.1182\n",
      "Epoch 8481/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2433 - val_loss: 35.1349\n",
      "Epoch 8482/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2266 - val_loss: 35.5558\n",
      "Epoch 8483/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2682 - val_loss: 39.8946\n",
      "Epoch 8484/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2329 - val_loss: 40.1768\n",
      "Epoch 8485/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2275 - val_loss: 34.6336\n",
      "Epoch 8486/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2146 - val_loss: 30.1390\n",
      "Epoch 8487/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2077 - val_loss: 24.6298\n",
      "Epoch 8488/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1960 - val_loss: 25.2947\n",
      "Epoch 8489/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2010 - val_loss: 28.2928\n",
      "Epoch 8490/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1973 - val_loss: 34.7612\n",
      "Epoch 8491/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2120 - val_loss: 19.3062\n",
      "Epoch 8492/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2170 - val_loss: 24.6091\n",
      "Epoch 8493/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1887 - val_loss: 17.1703\n",
      "Epoch 8494/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1880 - val_loss: 18.3155\n",
      "Epoch 8495/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1857 - val_loss: 21.8844\n",
      "Epoch 8496/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1804 - val_loss: 17.8581\n",
      "Epoch 8497/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1833 - val_loss: 20.1591\n",
      "Epoch 8498/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1836 - val_loss: 19.1478\n",
      "Epoch 8499/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1859 - val_loss: 14.1135\n",
      "Epoch 8500/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1877 - val_loss: 15.9230\n",
      "Epoch 8501/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1751 - val_loss: 13.9282\n",
      "Epoch 8502/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 16.1022\n",
      "Epoch 8503/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 16.0059\n",
      "Epoch 8504/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 14.6609\n",
      "Epoch 8505/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 16.0402\n",
      "Epoch 8506/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1708 - val_loss: 15.1016\n",
      "Epoch 8507/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 15.8877\n",
      "Epoch 8508/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 15.0983\n",
      "Epoch 8509/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 16.2635\n",
      "Epoch 8510/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 14.4775\n",
      "Epoch 8511/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 15.1282\n",
      "Epoch 8512/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 15.9189\n",
      "Epoch 8513/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1705 - val_loss: 13.8901\n",
      "Epoch 8514/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 15.4582\n",
      "Epoch 8515/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 14.7443\n",
      "Epoch 8516/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1706 - val_loss: 16.3926\n",
      "Epoch 8517/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1749 - val_loss: 11.7828\n",
      "Epoch 8518/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1746 - val_loss: 14.4288\n",
      "Epoch 8519/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 14.0568\n",
      "Epoch 8520/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 15.4639\n",
      "Epoch 8521/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1711 - val_loss: 15.4966\n",
      "Epoch 8522/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 14.8858\n",
      "Epoch 8523/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 16.0757\n",
      "Epoch 8524/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 15.1058\n",
      "Epoch 8525/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 17.0807\n",
      "Epoch 8526/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 16.6925\n",
      "Epoch 8527/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1705 - val_loss: 15.9989\n",
      "Epoch 8528/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 17.1547\n",
      "Epoch 8529/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1709 - val_loss: 15.9704\n",
      "Epoch 8530/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 15.2716\n",
      "Epoch 8531/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 15.6990\n",
      "Epoch 8532/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 16.7407\n",
      "Epoch 8533/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 15.9177\n",
      "Epoch 8534/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 16.6439\n",
      "Epoch 8535/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1766 - val_loss: 10.1346\n",
      "Epoch 8536/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2308 - val_loss: 14.6438\n",
      "Epoch 8537/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3436 - val_loss: 30.8274\n",
      "Epoch 8538/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2666 - val_loss: 27.3528\n",
      "Epoch 8539/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2344 - val_loss: 17.4327\n",
      "Epoch 8540/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2152 - val_loss: 15.9250\n",
      "Epoch 8541/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1935 - val_loss: 14.9913\n",
      "Epoch 8542/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1800 - val_loss: 15.7336\n",
      "Epoch 8543/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1741 - val_loss: 18.4127\n",
      "Epoch 8544/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 17.7476\n",
      "Epoch 8545/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 17.0238\n",
      "Epoch 8546/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 16.6192\n",
      "Epoch 8547/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 16.6769\n",
      "Epoch 8548/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 16.2505\n",
      "Epoch 8549/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1747 - val_loss: 17.0369\n",
      "Epoch 8550/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 15.5366\n",
      "Epoch 8551/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1761 - val_loss: 23.2966\n",
      "Epoch 8552/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1778 - val_loss: 18.3121\n",
      "Epoch 8553/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 19.1836\n",
      "Epoch 8554/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1711 - val_loss: 16.8774\n",
      "Epoch 8555/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 16.1281\n",
      "Epoch 8556/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1743 - val_loss: 13.9129\n",
      "Epoch 8557/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1747 - val_loss: 14.2709\n",
      "Epoch 8558/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 16.6843\n",
      "Epoch 8559/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 15.7984\n",
      "Epoch 8560/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 17.1252\n",
      "Epoch 8561/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 17.0572\n",
      "Epoch 8562/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 16.7595\n",
      "Epoch 8563/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 15.0920\n",
      "Epoch 8564/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1698 - val_loss: 16.8734\n",
      "Epoch 8565/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 15.2010\n",
      "Epoch 8566/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 17.4446\n",
      "Epoch 8567/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1715 - val_loss: 17.5345\n",
      "Epoch 8568/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1714 - val_loss: 17.1959\n",
      "Epoch 8569/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1707 - val_loss: 15.7015\n",
      "Epoch 8570/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 17.4514\n",
      "Epoch 8571/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 17.2555\n",
      "Epoch 8572/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 16.6376\n",
      "Epoch 8573/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 17.2102\n",
      "Epoch 8574/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1711 - val_loss: 16.9275\n",
      "Epoch 8575/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 15.2465\n",
      "Epoch 8576/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1708 - val_loss: 17.3978\n",
      "Epoch 8577/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1711 - val_loss: 16.3853\n",
      "Epoch 8578/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 16.1394\n",
      "Epoch 8579/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 17.0705\n",
      "Epoch 8580/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 15.3729\n",
      "Epoch 8581/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 14.8913\n",
      "Epoch 8582/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1710 - val_loss: 17.2419\n",
      "Epoch 8583/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 15.9544\n",
      "Epoch 8584/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 17.1289\n",
      "Epoch 8585/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1743 - val_loss: 19.6722\n",
      "Epoch 8586/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1864 - val_loss: 13.1680\n",
      "Epoch 8587/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2434 - val_loss: 38.8866\n",
      "Epoch 8588/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2684 - val_loss: 10.2638\n",
      "Epoch 8589/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2677 - val_loss: 20.6993\n",
      "Epoch 8590/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2048 - val_loss: 24.0767\n",
      "Epoch 8591/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1789 - val_loss: 24.8065\n",
      "Epoch 8592/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1792 - val_loss: 24.2454\n",
      "Epoch 8593/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 27.2458\n",
      "Epoch 8594/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1739 - val_loss: 31.5803\n",
      "Epoch 8595/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1779 - val_loss: 33.1388\n",
      "Epoch 8596/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1844 - val_loss: 28.0244\n",
      "Epoch 8597/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2037 - val_loss: 23.3738\n",
      "Epoch 8598/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2175 - val_loss: 33.3989\n",
      "Epoch 8599/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2502 - val_loss: 29.6915\n",
      "Epoch 8600/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1908 - val_loss: 31.9792\n",
      "Epoch 8601/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1749 - val_loss: 33.2964\n",
      "Epoch 8602/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1774 - val_loss: 38.0236\n",
      "Epoch 8603/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1753 - val_loss: 30.7536\n",
      "Epoch 8604/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1735 - val_loss: 29.3166\n",
      "Epoch 8605/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 28.9580\n",
      "Epoch 8606/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 29.0629\n",
      "Epoch 8607/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 32.7356\n",
      "Epoch 8608/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 29.7007\n",
      "Epoch 8609/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 29.2622\n",
      "Epoch 8610/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 28.3681\n",
      "Epoch 8611/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 29.3846\n",
      "Epoch 8612/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 26.8781\n",
      "Epoch 8613/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 27.8126\n",
      "Epoch 8614/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 28.5218\n",
      "Epoch 8615/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 27.0980\n",
      "Epoch 8616/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1708 - val_loss: 27.1641\n",
      "Epoch 8617/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1702 - val_loss: 26.9641\n",
      "Epoch 8618/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 26.1096\n",
      "Epoch 8619/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1721 - val_loss: 25.7705\n",
      "Epoch 8620/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1707 - val_loss: 26.2753\n",
      "Epoch 8621/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 27.3188\n",
      "Epoch 8622/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1697 - val_loss: 26.7616\n",
      "Epoch 8623/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1708 - val_loss: 25.3051\n",
      "Epoch 8624/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1707 - val_loss: 26.8616\n",
      "Epoch 8625/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 25.6017\n",
      "Epoch 8626/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1710 - val_loss: 25.2469\n",
      "Epoch 8627/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 27.4957\n",
      "Epoch 8628/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1706 - val_loss: 24.8817\n",
      "Epoch 8629/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 25.5217\n",
      "Epoch 8630/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1691 - val_loss: 25.8667\n",
      "Epoch 8631/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1707 - val_loss: 25.4501\n",
      "Epoch 8632/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 23.2016\n",
      "Epoch 8633/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1712 - val_loss: 25.1326\n",
      "Epoch 8634/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 28.0660\n",
      "Epoch 8635/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1825 - val_loss: 7.1595\n",
      "Epoch 8636/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.6089 - val_loss: 37.2886\n",
      "Epoch 8637/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.8417 - val_loss: 11.6795\n",
      "Epoch 8638/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4367 - val_loss: 60.8826\n",
      "Epoch 8639/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.3129 - val_loss: 58.8554\n",
      "Epoch 8640/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2509 - val_loss: 62.9880\n",
      "Epoch 8641/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2628 - val_loss: 61.0052\n",
      "Epoch 8642/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2221 - val_loss: 66.6018\n",
      "Epoch 8643/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2277 - val_loss: 59.8006\n",
      "Epoch 8644/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2154 - val_loss: 53.2242\n",
      "Epoch 8645/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2090 - val_loss: 59.0138\n",
      "Epoch 8646/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2300 - val_loss: 55.5308\n",
      "Epoch 8647/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2026 - val_loss: 56.7445\n",
      "Epoch 8648/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1921 - val_loss: 55.3520\n",
      "Epoch 8649/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1929 - val_loss: 51.2750\n",
      "Epoch 8650/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2033 - val_loss: 53.3851\n",
      "Epoch 8651/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1942 - val_loss: 60.1966\n",
      "Epoch 8652/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1905 - val_loss: 53.8655\n",
      "Epoch 8653/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1921 - val_loss: 54.6387\n",
      "Epoch 8654/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1981 - val_loss: 49.9855\n",
      "Epoch 8655/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1921 - val_loss: 52.9860\n",
      "Epoch 8656/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1929 - val_loss: 55.2078\n",
      "Epoch 8657/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2078 - val_loss: 52.1797\n",
      "Epoch 8658/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1928 - val_loss: 51.2615\n",
      "Epoch 8659/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1913 - val_loss: 49.0217\n",
      "Epoch 8660/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1981 - val_loss: 46.3903\n",
      "Epoch 8661/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2076 - val_loss: 50.9368\n",
      "Epoch 8662/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1967 - val_loss: 53.1300\n",
      "Epoch 8663/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1956 - val_loss: 51.3578\n",
      "Epoch 8664/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1848 - val_loss: 49.9427\n",
      "Epoch 8665/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1969 - val_loss: 52.4512\n",
      "Epoch 8666/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1864 - val_loss: 55.0182\n",
      "Epoch 8667/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1831 - val_loss: 49.4116\n",
      "Epoch 8668/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2076 - val_loss: 40.0547\n",
      "Epoch 8669/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2173 - val_loss: 55.8655\n",
      "Epoch 8670/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2389 - val_loss: 57.4948\n",
      "Epoch 8671/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2153 - val_loss: 55.8486\n",
      "Epoch 8672/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2229 - val_loss: 31.6931\n",
      "Epoch 8673/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2384 - val_loss: 62.1405\n",
      "Epoch 8674/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2163 - val_loss: 58.7929\n",
      "Epoch 8675/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2139 - val_loss: 54.8702\n",
      "Epoch 8676/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1967 - val_loss: 40.4944\n",
      "Epoch 8677/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1976 - val_loss: 48.8559\n",
      "Epoch 8678/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1960 - val_loss: 46.7756\n",
      "Epoch 8679/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1875 - val_loss: 50.2437\n",
      "Epoch 8680/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1873 - val_loss: 44.3049\n",
      "Epoch 8681/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1798 - val_loss: 44.0734\n",
      "Epoch 8682/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1815 - val_loss: 49.2777\n",
      "Epoch 8683/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1780 - val_loss: 43.0764\n",
      "Epoch 8684/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1839 - val_loss: 44.7048\n",
      "Epoch 8685/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1770 - val_loss: 43.7111\n",
      "Epoch 8686/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1764 - val_loss: 45.9884\n",
      "Epoch 8687/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1758 - val_loss: 41.0723\n",
      "Epoch 8688/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1773 - val_loss: 40.4430\n",
      "Epoch 8689/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3108 - val_loss: 21.5444\n",
      "Epoch 8690/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2342 - val_loss: 38.1188\n",
      "Epoch 8691/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2043 - val_loss: 47.7602\n",
      "Epoch 8692/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1838 - val_loss: 49.2688\n",
      "Epoch 8693/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1951 - val_loss: 28.2138\n",
      "Epoch 8694/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1843 - val_loss: 40.6186\n",
      "Epoch 8695/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1761 - val_loss: 39.6301\n",
      "Epoch 8696/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 41.4354\n",
      "Epoch 8697/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1751 - val_loss: 41.3532\n",
      "Epoch 8698/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1744 - val_loss: 37.9335\n",
      "Epoch 8699/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1755 - val_loss: 39.7045\n",
      "Epoch 8700/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1751 - val_loss: 41.6567\n",
      "Epoch 8701/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1748 - val_loss: 40.8127\n",
      "Epoch 8702/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1963 - val_loss: 46.1804\n",
      "Epoch 8703/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2500 - val_loss: 52.7865\n",
      "Epoch 8704/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2002 - val_loss: 41.0321\n",
      "Epoch 8705/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1775 - val_loss: 39.4782\n",
      "Epoch 8706/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1777 - val_loss: 44.8659\n",
      "Epoch 8707/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2027 - val_loss: 58.5562\n",
      "Epoch 8708/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1921 - val_loss: 51.9209\n",
      "Epoch 8709/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2005 - val_loss: 34.2363\n",
      "Epoch 8710/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1904 - val_loss: 29.2611\n",
      "Epoch 8711/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1884 - val_loss: 27.9017\n",
      "Epoch 8712/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1929 - val_loss: 36.6574\n",
      "Epoch 8713/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1950 - val_loss: 39.7310\n",
      "Epoch 8714/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2769 - val_loss: 21.9046\n",
      "Epoch 8715/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2149 - val_loss: 18.8799\n",
      "Epoch 8716/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2039 - val_loss: 16.7525\n",
      "Epoch 8717/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1795 - val_loss: 20.7118\n",
      "Epoch 8718/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1749 - val_loss: 24.5982\n",
      "Epoch 8719/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1749 - val_loss: 17.9842\n",
      "Epoch 8720/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 20.1234\n",
      "Epoch 8721/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 19.1507\n",
      "Epoch 8722/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 17.9808\n",
      "Epoch 8723/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1721 - val_loss: 18.5715\n",
      "Epoch 8724/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 21.2527\n",
      "Epoch 8725/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1761 - val_loss: 13.2974\n",
      "Epoch 8726/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1769 - val_loss: 20.8415\n",
      "Epoch 8727/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1783 - val_loss: 19.6588\n",
      "Epoch 8728/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 18.1725\n",
      "Epoch 8729/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 21.6862\n",
      "Epoch 8730/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 21.7307\n",
      "Epoch 8731/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 19.7285\n",
      "Epoch 8732/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 20.2191\n",
      "Epoch 8733/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 20.8556\n",
      "Epoch 8734/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 21.5004\n",
      "Epoch 8735/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 17.7391\n",
      "Epoch 8736/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 21.8309\n",
      "Epoch 8737/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 18.9384\n",
      "Epoch 8738/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 17.6550\n",
      "Epoch 8739/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1751 - val_loss: 17.3299\n",
      "Epoch 8740/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 21.7149\n",
      "Epoch 8741/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1739 - val_loss: 18.4572\n",
      "Epoch 8742/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 21.4371\n",
      "Epoch 8743/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 17.0081\n",
      "Epoch 8744/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 22.9537\n",
      "Epoch 8745/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 17.4991\n",
      "Epoch 8746/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 21.0524\n",
      "Epoch 8747/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1958 - val_loss: 14.9697\n",
      "Epoch 8748/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1942 - val_loss: 23.6087\n",
      "Epoch 8749/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2056 - val_loss: 14.0126\n",
      "Epoch 8750/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1899 - val_loss: 13.5401\n",
      "Epoch 8751/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1750 - val_loss: 14.1743\n",
      "Epoch 8752/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1769 - val_loss: 20.1199\n",
      "Epoch 8753/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1929 - val_loss: 26.8825\n",
      "Epoch 8754/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2281 - val_loss: 17.6445\n",
      "Epoch 8755/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1823 - val_loss: 17.9324\n",
      "Epoch 8756/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1741 - val_loss: 19.2458\n",
      "Epoch 8757/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 17.9282\n",
      "Epoch 8758/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 15.0341\n",
      "Epoch 8759/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 19.9789\n",
      "Epoch 8760/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 19.9197\n",
      "Epoch 8761/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1696 - val_loss: 18.5130\n",
      "Epoch 8762/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 19.2888\n",
      "Epoch 8763/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 16.8378\n",
      "Epoch 8764/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 16.6746\n",
      "Epoch 8765/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 20.2069\n",
      "Epoch 8766/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 14.6811\n",
      "Epoch 8767/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 19.2397\n",
      "Epoch 8768/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 16.3727\n",
      "Epoch 8769/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 17.4236\n",
      "Epoch 8770/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 21.0495\n",
      "Epoch 8771/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 18.5396\n",
      "Epoch 8772/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 13.2857\n",
      "Epoch 8773/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1714 - val_loss: 16.2239\n",
      "Epoch 8774/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1705 - val_loss: 17.4707\n",
      "Epoch 8775/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 17.2197\n",
      "Epoch 8776/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 15.7609\n",
      "Epoch 8777/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 17.5530\n",
      "Epoch 8778/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 18.5879\n",
      "Epoch 8779/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1830 - val_loss: 17.4806\n",
      "Epoch 8780/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4253 - val_loss: 46.0751\n",
      "Epoch 8781/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3223 - val_loss: 14.9358\n",
      "Epoch 8782/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3766 - val_loss: 71.6627\n",
      "Epoch 8783/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2444 - val_loss: 65.2815\n",
      "Epoch 8784/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2421 - val_loss: 57.9800\n",
      "Epoch 8785/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2205 - val_loss: 57.5754\n",
      "Epoch 8786/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2193 - val_loss: 63.7812\n",
      "Epoch 8787/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2009 - val_loss: 53.4609\n",
      "Epoch 8788/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2393 - val_loss: 55.6162\n",
      "Epoch 8789/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1991 - val_loss: 55.4426\n",
      "Epoch 8790/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2543 - val_loss: 48.4404\n",
      "Epoch 8791/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1923 - val_loss: 57.8956\n",
      "Epoch 8792/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2136 - val_loss: 48.5933\n",
      "Epoch 8793/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2450 - val_loss: 59.7868\n",
      "Epoch 8794/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2133 - val_loss: 62.7963\n",
      "Epoch 8795/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2092 - val_loss: 57.3078\n",
      "Epoch 8796/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1910 - val_loss: 62.2362\n",
      "Epoch 8797/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1846 - val_loss: 51.0688\n",
      "Epoch 8798/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1768 - val_loss: 54.5344\n",
      "Epoch 8799/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 55.2738\n",
      "Epoch 8800/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1779 - val_loss: 51.9032\n",
      "Epoch 8801/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1750 - val_loss: 51.0604\n",
      "Epoch 8802/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 51.2688\n",
      "Epoch 8803/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2044 - val_loss: 41.7448\n",
      "Epoch 8804/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1991 - val_loss: 47.1278\n",
      "Epoch 8805/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2299 - val_loss: 49.6552\n",
      "Epoch 8806/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1955 - val_loss: 61.4233\n",
      "Epoch 8807/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2152 - val_loss: 51.1741\n",
      "Epoch 8808/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1910 - val_loss: 44.8588\n",
      "Epoch 8809/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1877 - val_loss: 48.3158\n",
      "Epoch 8810/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1882 - val_loss: 43.0525\n",
      "Epoch 8811/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1846 - val_loss: 45.9634\n",
      "Epoch 8812/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1747 - val_loss: 45.5604\n",
      "Epoch 8813/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 47.4463\n",
      "Epoch 8814/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1711 - val_loss: 46.3186\n",
      "Epoch 8815/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 46.9003\n",
      "Epoch 8816/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1739 - val_loss: 46.7558\n",
      "Epoch 8817/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 45.3631\n",
      "Epoch 8818/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 46.8126\n",
      "Epoch 8819/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 46.5704\n",
      "Epoch 8820/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1709 - val_loss: 44.2750\n",
      "Epoch 8821/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1699 - val_loss: 45.1246\n",
      "Epoch 8822/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 47.5127\n",
      "Epoch 8823/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 44.0432\n",
      "Epoch 8824/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 45.6964\n",
      "Epoch 8825/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1712 - val_loss: 47.7950\n",
      "Epoch 8826/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1746 - val_loss: 46.4384\n",
      "Epoch 8827/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 46.1467\n",
      "Epoch 8828/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 46.2719\n",
      "Epoch 8829/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1712 - val_loss: 45.4436\n",
      "Epoch 8830/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 46.1146\n",
      "Epoch 8831/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 46.3463\n",
      "Epoch 8832/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1747 - val_loss: 44.3215\n",
      "Epoch 8833/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 46.3568\n",
      "Epoch 8834/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 40.3707\n",
      "Epoch 8835/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1990 - val_loss: 47.4535\n",
      "Epoch 8836/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1795 - val_loss: 43.7414\n",
      "Epoch 8837/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2334 - val_loss: 27.7527\n",
      "Epoch 8838/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2663 - val_loss: 48.2751\n",
      "Epoch 8839/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2627 - val_loss: 34.1879\n",
      "Epoch 8840/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2726 - val_loss: 61.7504\n",
      "Epoch 8841/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3022 - val_loss: 42.7480\n",
      "Epoch 8842/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3124 - val_loss: 57.6248\n",
      "Epoch 8843/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2147 - val_loss: 53.0297\n",
      "Epoch 8844/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2049 - val_loss: 57.7434\n",
      "Epoch 8845/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2115 - val_loss: 48.8694\n",
      "Epoch 8846/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1858 - val_loss: 42.8552\n",
      "Epoch 8847/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1824 - val_loss: 41.1637\n",
      "Epoch 8848/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1828 - val_loss: 30.8892\n",
      "Epoch 8849/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1955 - val_loss: 46.6479\n",
      "Epoch 8850/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1843 - val_loss: 43.3328\n",
      "Epoch 8851/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1745 - val_loss: 41.5099\n",
      "Epoch 8852/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 40.5528\n",
      "Epoch 8853/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1739 - val_loss: 42.9117\n",
      "Epoch 8854/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 42.0942\n",
      "Epoch 8855/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 41.8737\n",
      "Epoch 8856/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 42.2197\n",
      "Epoch 8857/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 42.3903\n",
      "Epoch 8858/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 44.0901\n",
      "Epoch 8859/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 40.6294\n",
      "Epoch 8860/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 41.5537\n",
      "Epoch 8861/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1711 - val_loss: 39.8763\n",
      "Epoch 8862/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 40.1673\n",
      "Epoch 8863/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 38.7632\n",
      "Epoch 8864/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 42.2991\n",
      "Epoch 8865/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 40.1323\n",
      "Epoch 8866/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 37.0351\n",
      "Epoch 8867/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 40.4083\n",
      "Epoch 8868/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 39.3634\n",
      "Epoch 8869/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 38.7350\n",
      "Epoch 8870/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 41.6737\n",
      "Epoch 8871/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 39.0495\n",
      "Epoch 8872/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 40.4942\n",
      "Epoch 8873/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1702 - val_loss: 40.4715\n",
      "Epoch 8874/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 38.7904\n",
      "Epoch 8875/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 40.2007\n",
      "Epoch 8876/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1769 - val_loss: 35.3428\n",
      "Epoch 8877/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1760 - val_loss: 34.7152\n",
      "Epoch 8878/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 34.4062\n",
      "Epoch 8879/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 36.4448\n",
      "Epoch 8880/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 33.5175\n",
      "Epoch 8881/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 33.7358\n",
      "Epoch 8882/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1711 - val_loss: 37.1160\n",
      "Epoch 8883/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1710 - val_loss: 36.3806\n",
      "Epoch 8884/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1711 - val_loss: 33.3299\n",
      "Epoch 8885/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1712 - val_loss: 33.2745\n",
      "Epoch 8886/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 33.4785\n",
      "Epoch 8887/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 35.5780\n",
      "Epoch 8888/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 33.6670\n",
      "Epoch 8889/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1712 - val_loss: 36.3217\n",
      "Epoch 8890/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 29.9534\n",
      "Epoch 8891/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 33.4611\n",
      "Epoch 8892/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1705 - val_loss: 35.6972\n",
      "Epoch 8893/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1760 - val_loss: 40.5495\n",
      "Epoch 8894/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1974 - val_loss: 39.3846\n",
      "Epoch 8895/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2605 - val_loss: 45.2995\n",
      "Epoch 8896/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2238 - val_loss: 28.5464\n",
      "Epoch 8897/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1797 - val_loss: 29.4639\n",
      "Epoch 8898/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1770 - val_loss: 29.0425\n",
      "Epoch 8899/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1931 - val_loss: 31.0578\n",
      "Epoch 8900/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1877 - val_loss: 30.0820\n",
      "Epoch 8901/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1848 - val_loss: 30.9533\n",
      "Epoch 8902/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1894 - val_loss: 29.0965\n",
      "Epoch 8903/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1930 - val_loss: 16.2220\n",
      "Epoch 8904/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3291 - val_loss: 12.0070\n",
      "Epoch 8905/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3021 - val_loss: 33.3573\n",
      "Epoch 8906/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2449 - val_loss: 25.5013\n",
      "Epoch 8907/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2137 - val_loss: 38.1084\n",
      "Epoch 8908/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1878 - val_loss: 29.9599\n",
      "Epoch 8909/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2194 - val_loss: 16.0036\n",
      "Epoch 8910/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2400 - val_loss: 28.7459\n",
      "Epoch 8911/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2289 - val_loss: 36.0835\n",
      "Epoch 8912/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2018 - val_loss: 37.8067\n",
      "Epoch 8913/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1879 - val_loss: 26.6056\n",
      "Epoch 8914/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1753 - val_loss: 28.3895\n",
      "Epoch 8915/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1743 - val_loss: 33.3813\n",
      "Epoch 8916/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 29.0651\n",
      "Epoch 8917/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 28.4968\n",
      "Epoch 8918/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1767 - val_loss: 32.8455\n",
      "Epoch 8919/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 32.1452\n",
      "Epoch 8920/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 31.8684\n",
      "Epoch 8921/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 33.8937\n",
      "Epoch 8922/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1955 - val_loss: 35.4866\n",
      "Epoch 8923/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2009 - val_loss: 24.4123\n",
      "Epoch 8924/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2373 - val_loss: 24.3693\n",
      "Epoch 8925/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2017 - val_loss: 34.0630\n",
      "Epoch 8926/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1911 - val_loss: 39.1973\n",
      "Epoch 8927/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1802 - val_loss: 40.8914\n",
      "Epoch 8928/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1777 - val_loss: 33.9978\n",
      "Epoch 8929/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 36.8904\n",
      "Epoch 8930/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1695 - val_loss: 36.2244\n",
      "Epoch 8931/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 34.5093\n",
      "Epoch 8932/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1707 - val_loss: 33.9803\n",
      "Epoch 8933/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1704 - val_loss: 35.8366\n",
      "Epoch 8934/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1728 - val_loss: 31.5714\n",
      "Epoch 8935/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 35.3026\n",
      "Epoch 8936/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 36.0900\n",
      "Epoch 8937/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 34.2462\n",
      "Epoch 8938/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 36.9556\n",
      "Epoch 8939/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1705 - val_loss: 33.7433\n",
      "Epoch 8940/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 34.7766\n",
      "Epoch 8941/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 37.8438\n",
      "Epoch 8942/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 35.9065\n",
      "Epoch 8943/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 35.6290\n",
      "Epoch 8944/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1703 - val_loss: 36.4963\n",
      "Epoch 8945/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1700 - val_loss: 36.8688\n",
      "Epoch 8946/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1706 - val_loss: 37.8250\n",
      "Epoch 8947/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 36.7430\n",
      "Epoch 8948/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1707 - val_loss: 35.8455\n",
      "Epoch 8949/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 36.7008\n",
      "Epoch 8950/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1702 - val_loss: 36.5549\n",
      "Epoch 8951/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 37.4467\n",
      "Epoch 8952/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 35.0928\n",
      "Epoch 8953/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1711 - val_loss: 33.9841\n",
      "Epoch 8954/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 34.0241\n",
      "Epoch 8955/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 34.0139\n",
      "Epoch 8956/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 34.4661\n",
      "Epoch 8957/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1705 - val_loss: 32.5534\n",
      "Epoch 8958/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 36.6654\n",
      "Epoch 8959/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 36.8660\n",
      "Epoch 8960/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 33.9308\n",
      "Epoch 8961/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 35.8878\n",
      "Epoch 8962/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 36.6049\n",
      "Epoch 8963/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1710 - val_loss: 35.0087\n",
      "Epoch 8964/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 35.4576\n",
      "Epoch 8965/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 36.5716\n",
      "Epoch 8966/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 35.6625\n",
      "Epoch 8967/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 32.3423\n",
      "Epoch 8968/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1703 - val_loss: 37.4543\n",
      "Epoch 8969/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 34.8802\n",
      "Epoch 8970/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 36.1302\n",
      "Epoch 8971/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1706 - val_loss: 34.2151\n",
      "Epoch 8972/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 37.4261\n",
      "Epoch 8973/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1708 - val_loss: 39.3848\n",
      "Epoch 8974/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 35.2225\n",
      "Epoch 8975/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 35.6695\n",
      "Epoch 8976/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1837 - val_loss: 30.2654\n",
      "Epoch 8977/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4692 - val_loss: 47.1014\n",
      "Epoch 8978/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2639 - val_loss: 46.0194\n",
      "Epoch 8979/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2341 - val_loss: 49.1171\n",
      "Epoch 8980/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2177 - val_loss: 42.1865\n",
      "Epoch 8981/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1861 - val_loss: 33.0864\n",
      "Epoch 8982/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1796 - val_loss: 22.5976\n",
      "Epoch 8983/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1795 - val_loss: 19.1302\n",
      "Epoch 8984/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1804 - val_loss: 15.9839\n",
      "Epoch 8985/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2106 - val_loss: 29.6846\n",
      "Epoch 8986/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2301 - val_loss: 53.7050\n",
      "Epoch 8987/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2555 - val_loss: 57.3484\n",
      "Epoch 8988/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2240 - val_loss: 52.5698\n",
      "Epoch 8989/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2165 - val_loss: 36.6834\n",
      "Epoch 8990/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2224 - val_loss: 33.2806\n",
      "Epoch 8991/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2173 - val_loss: 42.3963\n",
      "Epoch 8992/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1864 - val_loss: 31.7032\n",
      "Epoch 8993/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1968 - val_loss: 32.6379\n",
      "Epoch 8994/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1793 - val_loss: 27.7945\n",
      "Epoch 8995/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1767 - val_loss: 24.4884\n",
      "Epoch 8996/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1741 - val_loss: 23.5926\n",
      "Epoch 8997/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1758 - val_loss: 31.5451\n",
      "Epoch 8998/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 29.0780\n",
      "Epoch 8999/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1719 - val_loss: 27.7011\n",
      "Epoch 9000/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1702 - val_loss: 26.6563\n",
      "Epoch 9001/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 26.1726\n",
      "Epoch 9002/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 25.9251\n",
      "Epoch 9003/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1709 - val_loss: 24.9944\n",
      "Epoch 9004/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 25.0749\n",
      "Epoch 9005/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 25.2976\n",
      "Epoch 9006/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1704 - val_loss: 24.3402\n",
      "Epoch 9007/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1703 - val_loss: 24.1125\n",
      "Epoch 9008/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1692 - val_loss: 24.2711\n",
      "Epoch 9009/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 22.9907\n",
      "Epoch 9010/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 22.1114\n",
      "Epoch 9011/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 22.2225\n",
      "Epoch 9012/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1703 - val_loss: 22.1668\n",
      "Epoch 9013/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 21.8506\n",
      "Epoch 9014/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 23.1952\n",
      "Epoch 9015/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 23.2028\n",
      "Epoch 9016/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 24.1982\n",
      "Epoch 9017/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1702 - val_loss: 22.5504\n",
      "Epoch 9018/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 22.1057\n",
      "Epoch 9019/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1708 - val_loss: 26.1341\n",
      "Epoch 9020/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1706 - val_loss: 21.3643\n",
      "Epoch 9021/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1705 - val_loss: 21.3261\n",
      "Epoch 9022/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1710 - val_loss: 26.5213\n",
      "Epoch 9023/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1696 - val_loss: 23.3247\n",
      "Epoch 9024/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 23.8403\n",
      "Epoch 9025/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1701 - val_loss: 24.8846\n",
      "Epoch 9026/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 22.1639\n",
      "Epoch 9027/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 22.5498\n",
      "Epoch 9028/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 22.6820\n",
      "Epoch 9029/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 22.3471\n",
      "Epoch 9030/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 23.9246\n",
      "Epoch 9031/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1746 - val_loss: 21.7129\n",
      "Epoch 9032/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 23.5242\n",
      "Epoch 9033/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1711 - val_loss: 21.5552\n",
      "Epoch 9034/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1710 - val_loss: 22.7599\n",
      "Epoch 9035/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 25.2360\n",
      "Epoch 9036/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1959 - val_loss: 22.9134\n",
      "Epoch 9037/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3516 - val_loss: 15.3791\n",
      "Epoch 9038/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2053 - val_loss: 18.9440\n",
      "Epoch 9039/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1859 - val_loss: 15.0727\n",
      "Epoch 9040/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1835 - val_loss: 26.0199\n",
      "Epoch 9041/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1770 - val_loss: 19.6119\n",
      "Epoch 9042/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1767 - val_loss: 31.0105\n",
      "Epoch 9043/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1842 - val_loss: 19.2588\n",
      "Epoch 9044/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 18.7615\n",
      "Epoch 9045/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 18.7682\n",
      "Epoch 9046/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 18.2194\n",
      "Epoch 9047/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 16.0800\n",
      "Epoch 9048/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 18.3599\n",
      "Epoch 9049/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 19.3000\n",
      "Epoch 9050/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 18.3714\n",
      "Epoch 9051/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 19.0173\n",
      "Epoch 9052/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1709 - val_loss: 18.0207\n",
      "Epoch 9053/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 19.5326\n",
      "Epoch 9054/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 16.7676\n",
      "Epoch 9055/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 20.7132\n",
      "Epoch 9056/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 17.4032\n",
      "Epoch 9057/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1695 - val_loss: 18.0410\n",
      "Epoch 9058/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1704 - val_loss: 17.2116\n",
      "Epoch 9059/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 16.5313\n",
      "Epoch 9060/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 18.8746\n",
      "Epoch 9061/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1707 - val_loss: 19.5268\n",
      "Epoch 9062/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1698 - val_loss: 16.7871\n",
      "Epoch 9063/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 19.4632\n",
      "Epoch 9064/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 16.6171\n",
      "Epoch 9065/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 17.8407\n",
      "Epoch 9066/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1703 - val_loss: 21.0721\n",
      "Epoch 9067/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 18.7515\n",
      "Epoch 9068/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 20.5423\n",
      "Epoch 9069/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 17.3717\n",
      "Epoch 9070/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 14.7220\n",
      "Epoch 9071/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 16.4480\n",
      "Epoch 9072/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 18.7574\n",
      "Epoch 9073/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1695 - val_loss: 17.0596\n",
      "Epoch 9074/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1707 - val_loss: 18.9894\n",
      "Epoch 9075/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1705 - val_loss: 17.3650\n",
      "Epoch 9076/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 17.3715\n",
      "Epoch 9077/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 14.6770\n",
      "Epoch 9078/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1835 - val_loss: 37.7969\n",
      "Epoch 9079/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2313 - val_loss: 52.3921\n",
      "Epoch 9080/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2344 - val_loss: 7.3173\n",
      "Epoch 9081/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4111 - val_loss: 41.7963\n",
      "Epoch 9082/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2586 - val_loss: 50.9230\n",
      "Epoch 9083/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2175 - val_loss: 52.3244\n",
      "Epoch 9084/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2328 - val_loss: 43.5485\n",
      "Epoch 9085/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2061 - val_loss: 36.8705\n",
      "Epoch 9086/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2951 - val_loss: 29.2158\n",
      "Epoch 9087/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3302 - val_loss: 47.5704\n",
      "Epoch 9088/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2473 - val_loss: 45.7653\n",
      "Epoch 9089/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2095 - val_loss: 50.9138\n",
      "Epoch 9090/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1902 - val_loss: 42.4303\n",
      "Epoch 9091/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1833 - val_loss: 39.7902\n",
      "Epoch 9092/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1804 - val_loss: 38.4085\n",
      "Epoch 9093/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1803 - val_loss: 40.6964\n",
      "Epoch 9094/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1780 - val_loss: 43.3370\n",
      "Epoch 9095/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1794 - val_loss: 42.6152\n",
      "Epoch 9096/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1790 - val_loss: 36.7998\n",
      "Epoch 9097/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1788 - val_loss: 41.0216\n",
      "Epoch 9098/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1790 - val_loss: 38.0077\n",
      "Epoch 9099/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1766 - val_loss: 41.3513\n",
      "Epoch 9100/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1743 - val_loss: 43.6990\n",
      "Epoch 9101/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1758 - val_loss: 40.3720\n",
      "Epoch 9102/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1760 - val_loss: 38.9264\n",
      "Epoch 9103/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1742 - val_loss: 40.9948\n",
      "Epoch 9104/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 40.6434\n",
      "Epoch 9105/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 40.2628\n",
      "Epoch 9106/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1744 - val_loss: 37.7849\n",
      "Epoch 9107/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 43.2458\n",
      "Epoch 9108/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 40.6365\n",
      "Epoch 9109/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 41.4060\n",
      "Epoch 9110/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 41.6471\n",
      "Epoch 9111/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 44.7037\n",
      "Epoch 9112/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 41.5448\n",
      "Epoch 9113/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 40.8584\n",
      "Epoch 9114/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 40.3330\n",
      "Epoch 9115/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1684 - val_loss: 39.9313\n",
      "Epoch 9116/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 41.4044\n",
      "Epoch 9117/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 40.9866\n",
      "Epoch 9118/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 40.7499\n",
      "Epoch 9119/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 40.8176\n",
      "Epoch 9120/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 38.3064\n",
      "Epoch 9121/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 41.2743\n",
      "Epoch 9122/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 41.0995\n",
      "Epoch 9123/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1711 - val_loss: 40.3179\n",
      "Epoch 9124/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 38.2621\n",
      "Epoch 9125/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1704 - val_loss: 37.7743\n",
      "Epoch 9126/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1707 - val_loss: 39.1305\n",
      "Epoch 9127/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 39.6543\n",
      "Epoch 9128/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 37.7180\n",
      "Epoch 9129/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 39.0338\n",
      "Epoch 9130/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 39.4689\n",
      "Epoch 9131/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1707 - val_loss: 40.4512\n",
      "Epoch 9132/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 38.7533\n",
      "Epoch 9133/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 37.3926\n",
      "Epoch 9134/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1704 - val_loss: 38.4660\n",
      "Epoch 9135/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 38.2920\n",
      "Epoch 9136/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1742 - val_loss: 36.5490\n",
      "Epoch 9137/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 40.1101\n",
      "Epoch 9138/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 39.0247\n",
      "Epoch 9139/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 38.7628\n",
      "Epoch 9140/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 36.2697\n",
      "Epoch 9141/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1706 - val_loss: 37.2766\n",
      "Epoch 9142/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1707 - val_loss: 37.7952\n",
      "Epoch 9143/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 34.6374\n",
      "Epoch 9144/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 37.0729\n",
      "Epoch 9145/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 35.0692\n",
      "Epoch 9146/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 36.2178\n",
      "Epoch 9147/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 35.2468\n",
      "Epoch 9148/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 33.2263\n",
      "Epoch 9149/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1748 - val_loss: 45.4827\n",
      "Epoch 9150/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4250 - val_loss: 45.6584\n",
      "Epoch 9151/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.5388 - val_loss: 60.1428\n",
      "Epoch 9152/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4279 - val_loss: 67.6240\n",
      "Epoch 9153/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3524 - val_loss: 59.4610\n",
      "Epoch 9154/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3513 - val_loss: 63.7911\n",
      "Epoch 9155/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3198 - val_loss: 44.5761\n",
      "Epoch 9156/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4861 - val_loss: 72.9089\n",
      "Epoch 9157/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3378 - val_loss: 70.2169\n",
      "Epoch 9158/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2504 - val_loss: 69.2671\n",
      "Epoch 9159/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2448 - val_loss: 72.3949\n",
      "Epoch 9160/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2386 - val_loss: 70.5106\n",
      "Epoch 9161/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2400 - val_loss: 69.9961\n",
      "Epoch 9162/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2222 - val_loss: 62.1405\n",
      "Epoch 9163/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2143 - val_loss: 62.2002\n",
      "Epoch 9164/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.2064 - val_loss: 60.8351\n",
      "Epoch 9165/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2220 - val_loss: 47.6512\n",
      "Epoch 9166/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2829 - val_loss: 61.5871\n",
      "Epoch 9167/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2117 - val_loss: 59.2840\n",
      "Epoch 9168/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2203 - val_loss: 55.4505\n",
      "Epoch 9169/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2077 - val_loss: 60.7547\n",
      "Epoch 9170/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1950 - val_loss: 54.9671\n",
      "Epoch 9171/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2072 - val_loss: 59.6513\n",
      "Epoch 9172/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2004 - val_loss: 58.7389\n",
      "Epoch 9173/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2049 - val_loss: 63.5763\n",
      "Epoch 9174/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2032 - val_loss: 57.4213\n",
      "Epoch 9175/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1932 - val_loss: 58.6743\n",
      "Epoch 9176/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2017 - val_loss: 55.0300\n",
      "Epoch 9177/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1959 - val_loss: 58.5066\n",
      "Epoch 9178/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1901 - val_loss: 57.1387\n",
      "Epoch 9179/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1887 - val_loss: 52.0857\n",
      "Epoch 9180/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1872 - val_loss: 52.9392\n",
      "Epoch 9181/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2047 - val_loss: 56.1907\n",
      "Epoch 9182/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1894 - val_loss: 54.0990\n",
      "Epoch 9183/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1996 - val_loss: 52.2247\n",
      "Epoch 9184/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2323 - val_loss: 60.8655\n",
      "Epoch 9185/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2118 - val_loss: 54.7210\n",
      "Epoch 9186/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1882 - val_loss: 52.1412\n",
      "Epoch 9187/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1876 - val_loss: 47.5976\n",
      "Epoch 9188/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1852 - val_loss: 46.8186\n",
      "Epoch 9189/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1920 - val_loss: 39.8295\n",
      "Epoch 9190/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1972 - val_loss: 52.0968\n",
      "Epoch 9191/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1886 - val_loss: 43.6703\n",
      "Epoch 9192/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1851 - val_loss: 46.3262\n",
      "Epoch 9193/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1899 - val_loss: 41.1030\n",
      "Epoch 9194/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1843 - val_loss: 46.5504\n",
      "Epoch 9195/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1892 - val_loss: 47.0081\n",
      "Epoch 9196/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1921 - val_loss: 48.1595\n",
      "Epoch 9197/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2003 - val_loss: 36.0969\n",
      "Epoch 9198/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1898 - val_loss: 49.7504\n",
      "Epoch 9199/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1857 - val_loss: 39.7713\n",
      "Epoch 9200/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1847 - val_loss: 43.4457\n",
      "Epoch 9201/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1940 - val_loss: 35.2153\n",
      "Epoch 9202/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1865 - val_loss: 28.6438\n",
      "Epoch 9203/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1873 - val_loss: 40.4882\n",
      "Epoch 9204/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1930 - val_loss: 34.2507\n",
      "Epoch 9205/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2093 - val_loss: 48.3976\n",
      "Epoch 9206/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2375 - val_loss: 52.6350\n",
      "Epoch 9207/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2183 - val_loss: 34.2498\n",
      "Epoch 9208/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2003 - val_loss: 35.0619\n",
      "Epoch 9209/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1939 - val_loss: 36.7876\n",
      "Epoch 9210/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2002 - val_loss: 38.2179\n",
      "Epoch 9211/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1972 - val_loss: 35.8640\n",
      "Epoch 9212/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1916 - val_loss: 40.5301\n",
      "Epoch 9213/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2006 - val_loss: 23.3453\n",
      "Epoch 9214/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1948 - val_loss: 35.5600\n",
      "Epoch 9215/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1926 - val_loss: 32.7640\n",
      "Epoch 9216/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1816 - val_loss: 31.9102\n",
      "Epoch 9217/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1855 - val_loss: 32.6341\n",
      "Epoch 9218/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1953 - val_loss: 24.6936\n",
      "Epoch 9219/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1849 - val_loss: 28.5905\n",
      "Epoch 9220/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1896 - val_loss: 30.9376\n",
      "Epoch 9221/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1832 - val_loss: 38.0283\n",
      "Epoch 9222/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1853 - val_loss: 32.6823\n",
      "Epoch 9223/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1818 - val_loss: 25.4428\n",
      "Epoch 9224/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1798 - val_loss: 32.2112\n",
      "Epoch 9225/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1781 - val_loss: 31.5674\n",
      "Epoch 9226/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1794 - val_loss: 24.7315\n",
      "Epoch 9227/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1881 - val_loss: 36.8767\n",
      "Epoch 9228/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1960 - val_loss: 33.3464\n",
      "Epoch 9229/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1966 - val_loss: 41.9988\n",
      "Epoch 9230/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1814 - val_loss: 38.9271\n",
      "Epoch 9231/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1843 - val_loss: 37.0260\n",
      "Epoch 9232/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1830 - val_loss: 38.5467\n",
      "Epoch 9233/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1829 - val_loss: 33.7141\n",
      "Epoch 9234/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1813 - val_loss: 37.7236\n",
      "Epoch 9235/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1810 - val_loss: 34.3572\n",
      "Epoch 9236/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1908 - val_loss: 28.4692\n",
      "Epoch 9237/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1831 - val_loss: 30.0246\n",
      "Epoch 9238/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1841 - val_loss: 43.3805\n",
      "Epoch 9239/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1850 - val_loss: 33.7499\n",
      "Epoch 9240/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1775 - val_loss: 36.9547\n",
      "Epoch 9241/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1826 - val_loss: 29.5163\n",
      "Epoch 9242/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1843 - val_loss: 49.7552\n",
      "Epoch 9243/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2068 - val_loss: 45.5939\n",
      "Epoch 9244/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2106 - val_loss: 35.9349\n",
      "Epoch 9245/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1788 - val_loss: 42.0819\n",
      "Epoch 9246/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1809 - val_loss: 28.6696\n",
      "Epoch 9247/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2307 - val_loss: 45.6850\n",
      "Epoch 9248/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1933 - val_loss: 33.5686\n",
      "Epoch 9249/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1808 - val_loss: 38.6936\n",
      "Epoch 9250/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1881 - val_loss: 39.3171\n",
      "Epoch 9251/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1859 - val_loss: 38.4053\n",
      "Epoch 9252/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1922 - val_loss: 32.7680\n",
      "Epoch 9253/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1893 - val_loss: 34.5719\n",
      "Epoch 9254/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1861 - val_loss: 40.9657\n",
      "Epoch 9255/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2027 - val_loss: 35.5867\n",
      "Epoch 9256/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1856 - val_loss: 42.5991\n",
      "Epoch 9257/10000\n",
      "34280/34280 [==============================] - 0s 7us/sample - loss: 0.1765 - val_loss: 33.5183\n",
      "Epoch 9258/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1911 - val_loss: 36.4569\n",
      "Epoch 9259/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1822 - val_loss: 33.1045\n",
      "Epoch 9260/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1910 - val_loss: 51.7725\n",
      "Epoch 9261/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2059 - val_loss: 28.5472\n",
      "Epoch 9262/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2301 - val_loss: 46.5193\n",
      "Epoch 9263/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2208 - val_loss: 34.3025\n",
      "Epoch 9264/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1916 - val_loss: 43.7711\n",
      "Epoch 9265/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2249 - val_loss: 42.3460\n",
      "Epoch 9266/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1926 - val_loss: 32.8754\n",
      "Epoch 9267/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1803 - val_loss: 36.1257\n",
      "Epoch 9268/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3169 - val_loss: 40.3660\n",
      "Epoch 9269/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2822 - val_loss: 28.5020\n",
      "Epoch 9270/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2265 - val_loss: 38.7082\n",
      "Epoch 9271/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2076 - val_loss: 46.1305\n",
      "Epoch 9272/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1819 - val_loss: 41.7528\n",
      "Epoch 9273/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1814 - val_loss: 44.8689\n",
      "Epoch 9274/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1878 - val_loss: 45.0633\n",
      "Epoch 9275/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1820 - val_loss: 32.5739\n",
      "Epoch 9276/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1793 - val_loss: 39.8912\n",
      "Epoch 9277/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1763 - val_loss: 34.7904\n",
      "Epoch 9278/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1812 - val_loss: 40.2094\n",
      "Epoch 9279/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1781 - val_loss: 41.4236\n",
      "Epoch 9280/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1763 - val_loss: 41.4305\n",
      "Epoch 9281/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1806 - val_loss: 40.9510\n",
      "Epoch 9282/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2046 - val_loss: 12.6837\n",
      "Epoch 9283/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2159 - val_loss: 28.3803\n",
      "Epoch 9284/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1956 - val_loss: 37.2036\n",
      "Epoch 9285/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1815 - val_loss: 41.0720\n",
      "Epoch 9286/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1776 - val_loss: 40.8714\n",
      "Epoch 9287/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1767 - val_loss: 39.2096\n",
      "Epoch 9288/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1767 - val_loss: 40.0899\n",
      "Epoch 9289/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1760 - val_loss: 36.1055\n",
      "Epoch 9290/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1746 - val_loss: 41.2023\n",
      "Epoch 9291/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1753 - val_loss: 41.5673\n",
      "Epoch 9292/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1744 - val_loss: 36.9128\n",
      "Epoch 9293/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1757 - val_loss: 34.0186\n",
      "Epoch 9294/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1798 - val_loss: 36.7349\n",
      "Epoch 9295/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1769 - val_loss: 43.6469\n",
      "Epoch 9296/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1771 - val_loss: 33.6064\n",
      "Epoch 9297/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1836 - val_loss: 31.9714\n",
      "Epoch 9298/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1780 - val_loss: 31.6194\n",
      "Epoch 9299/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1767 - val_loss: 39.6002\n",
      "Epoch 9300/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1758 - val_loss: 40.9693\n",
      "Epoch 9301/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1766 - val_loss: 33.8935\n",
      "Epoch 9302/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1740 - val_loss: 34.9644\n",
      "Epoch 9303/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1788 - val_loss: 35.7541\n",
      "Epoch 9304/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1776 - val_loss: 27.9099\n",
      "Epoch 9305/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1870 - val_loss: 42.1400\n",
      "Epoch 9306/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1851 - val_loss: 21.0647\n",
      "Epoch 9307/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1932 - val_loss: 34.0618\n",
      "Epoch 9308/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2438 - val_loss: 42.9203\n",
      "Epoch 9309/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3397 - val_loss: 34.5814\n",
      "Epoch 9310/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2517 - val_loss: 48.2460\n",
      "Epoch 9311/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2477 - val_loss: 47.5873\n",
      "Epoch 9312/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2363 - val_loss: 48.8696\n",
      "Epoch 9313/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2274 - val_loss: 40.3656\n",
      "Epoch 9314/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1978 - val_loss: 41.6030\n",
      "Epoch 9315/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2000 - val_loss: 41.3490\n",
      "Epoch 9316/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2024 - val_loss: 40.5514\n",
      "Epoch 9317/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2199 - val_loss: 50.0409\n",
      "Epoch 9318/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2466 - val_loss: 33.3748\n",
      "Epoch 9319/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2137 - val_loss: 34.7772\n",
      "Epoch 9320/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2025 - val_loss: 31.3602\n",
      "Epoch 9321/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2018 - val_loss: 28.8592\n",
      "Epoch 9322/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2319 - val_loss: 19.6246\n",
      "Epoch 9323/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2108 - val_loss: 38.0107\n",
      "Epoch 9324/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2111 - val_loss: 29.9524\n",
      "Epoch 9325/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1883 - val_loss: 30.0440\n",
      "Epoch 9326/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1872 - val_loss: 38.8986\n",
      "Epoch 9327/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1848 - val_loss: 29.8350\n",
      "Epoch 9328/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1873 - val_loss: 33.5026\n",
      "Epoch 9329/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2640 - val_loss: 34.7728\n",
      "Epoch 9330/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1998 - val_loss: 37.4635\n",
      "Epoch 9331/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1837 - val_loss: 34.6823\n",
      "Epoch 9332/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1849 - val_loss: 32.0385\n",
      "Epoch 9333/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1845 - val_loss: 37.5126\n",
      "Epoch 9334/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1797 - val_loss: 33.5045\n",
      "Epoch 9335/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1771 - val_loss: 35.4715\n",
      "Epoch 9336/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1790 - val_loss: 34.7197\n",
      "Epoch 9337/10000\n",
      "34280/34280 [==============================] - ETA: 0s - loss: 0.181 - 0s 8us/sample - loss: 0.1791 - val_loss: 32.3199\n",
      "Epoch 9338/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1895 - val_loss: 42.9092\n",
      "Epoch 9339/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1830 - val_loss: 31.0592\n",
      "Epoch 9340/10000\n",
      "34280/34280 [==============================] - 0s 12us/sample - loss: 0.1796 - val_loss: 34.1526\n",
      "Epoch 9341/10000\n",
      "34280/34280 [==============================] - 0s 14us/sample - loss: 0.1901 - val_loss: 30.6557\n",
      "Epoch 9342/10000\n",
      "34280/34280 [==============================] - 0s 13us/sample - loss: 0.2038 - val_loss: 28.0889\n",
      "Epoch 9343/10000\n",
      "34280/34280 [==============================] - 0s 12us/sample - loss: 0.2022 - val_loss: 32.1820\n",
      "Epoch 9344/10000\n",
      "34280/34280 [==============================] - 0s 12us/sample - loss: 0.1850 - val_loss: 31.6852\n",
      "Epoch 9345/10000\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 0.1780 - val_loss: 24.8303\n",
      "Epoch 9346/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1802 - val_loss: 29.3823\n",
      "Epoch 9347/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1760 - val_loss: 31.1696\n",
      "Epoch 9348/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1745 - val_loss: 29.8866\n",
      "Epoch 9349/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1748 - val_loss: 32.1623\n",
      "Epoch 9350/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1760 - val_loss: 31.2789\n",
      "Epoch 9351/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1755 - val_loss: 28.1175\n",
      "Epoch 9352/10000\n",
      "34280/34280 [==============================] - 0s 13us/sample - loss: 0.1836 - val_loss: 32.3657\n",
      "Epoch 9353/10000\n",
      "34280/34280 [==============================] - 0s 13us/sample - loss: 0.1807 - val_loss: 33.8918\n",
      "Epoch 9354/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1744 - val_loss: 30.1619\n",
      "Epoch 9355/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1753 - val_loss: 33.5453\n",
      "Epoch 9356/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1781 - val_loss: 36.5887\n",
      "Epoch 9357/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1765 - val_loss: 34.3057\n",
      "Epoch 9358/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1755 - val_loss: 31.9435\n",
      "Epoch 9359/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1845 - val_loss: 33.1892\n",
      "Epoch 9360/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1891 - val_loss: 36.7054\n",
      "Epoch 9361/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1823 - val_loss: 34.4997\n",
      "Epoch 9362/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1766 - val_loss: 34.2322\n",
      "Epoch 9363/10000\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 0.1803 - val_loss: 37.5322\n",
      "Epoch 9364/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1803 - val_loss: 34.0364\n",
      "Epoch 9365/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1866 - val_loss: 39.6372\n",
      "Epoch 9366/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1820 - val_loss: 38.2731\n",
      "Epoch 9367/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1777 - val_loss: 35.1781\n",
      "Epoch 9368/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1783 - val_loss: 28.8115\n",
      "Epoch 9369/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1846 - val_loss: 39.3781\n",
      "Epoch 9370/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1770 - val_loss: 40.7653\n",
      "Epoch 9371/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1768 - val_loss: 36.2415\n",
      "Epoch 9372/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1772 - val_loss: 29.1566\n",
      "Epoch 9373/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1740 - val_loss: 33.1508\n",
      "Epoch 9374/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1739 - val_loss: 32.7884\n",
      "Epoch 9375/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 31.8876\n",
      "Epoch 9376/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1741 - val_loss: 31.5096\n",
      "Epoch 9377/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1743 - val_loss: 33.1173\n",
      "Epoch 9378/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 36.0669\n",
      "Epoch 9379/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1751 - val_loss: 31.4844\n",
      "Epoch 9380/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1751 - val_loss: 32.4300\n",
      "Epoch 9381/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1843 - val_loss: 33.6335\n",
      "Epoch 9382/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1940 - val_loss: 47.4777\n",
      "Epoch 9383/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2034 - val_loss: 38.4612\n",
      "Epoch 9384/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2018 - val_loss: 37.3610\n",
      "Epoch 9385/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2611 - val_loss: 29.7272\n",
      "Epoch 9386/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2016 - val_loss: 42.5728\n",
      "Epoch 9387/10000\n",
      "34280/34280 [==============================] - 0s 12us/sample - loss: 0.1794 - val_loss: 42.2629\n",
      "Epoch 9388/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1755 - val_loss: 38.3557\n",
      "Epoch 9389/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1747 - val_loss: 37.0321\n",
      "Epoch 9390/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1745 - val_loss: 35.5302\n",
      "Epoch 9391/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1744 - val_loss: 35.2167\n",
      "Epoch 9392/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1732 - val_loss: 36.8218\n",
      "Epoch 9393/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1701 - val_loss: 34.1429\n",
      "Epoch 9394/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1735 - val_loss: 35.4655\n",
      "Epoch 9395/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1737 - val_loss: 33.6132\n",
      "Epoch 9396/10000\n",
      "34280/34280 [==============================] - 0s 12us/sample - loss: 0.1729 - val_loss: 35.6576\n",
      "Epoch 9397/10000\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 0.1734 - val_loss: 32.3226\n",
      "Epoch 9398/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1730 - val_loss: 34.8276\n",
      "Epoch 9399/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1717 - val_loss: 32.4531\n",
      "Epoch 9400/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1731 - val_loss: 30.9722\n",
      "Epoch 9401/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1721 - val_loss: 37.2679\n",
      "Epoch 9402/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1751 - val_loss: 29.2253\n",
      "Epoch 9403/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1760 - val_loss: 26.9305\n",
      "Epoch 9404/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1741 - val_loss: 32.6720\n",
      "Epoch 9405/10000\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 0.1738 - val_loss: 25.8804\n",
      "Epoch 9406/10000\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 0.1719 - val_loss: 27.6417\n",
      "Epoch 9407/10000\n",
      "34280/34280 [==============================] - 0s 12us/sample - loss: 0.1721 - val_loss: 25.8422\n",
      "Epoch 9408/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1726 - val_loss: 28.5215\n",
      "Epoch 9409/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1769 - val_loss: 29.0950\n",
      "Epoch 9410/10000\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 0.2656 - val_loss: 19.7727\n",
      "Epoch 9411/10000\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 0.2473 - val_loss: 36.8768\n",
      "Epoch 9412/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1906 - val_loss: 48.8724\n",
      "Epoch 9413/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1936 - val_loss: 28.5749\n",
      "Epoch 9414/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1769 - val_loss: 23.8654\n",
      "Epoch 9415/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1741 - val_loss: 27.2674\n",
      "Epoch 9416/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1745 - val_loss: 25.4874\n",
      "Epoch 9417/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1742 - val_loss: 26.7802\n",
      "Epoch 9418/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 24.6671\n",
      "Epoch 9419/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 26.8048\n",
      "Epoch 9420/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1739 - val_loss: 20.8429\n",
      "Epoch 9421/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1742 - val_loss: 14.3563\n",
      "Epoch 9422/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 22.0931\n",
      "Epoch 9423/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 25.2451\n",
      "Epoch 9424/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 20.9582\n",
      "Epoch 9425/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 25.1269\n",
      "Epoch 9426/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1724 - val_loss: 23.3620\n",
      "Epoch 9427/10000\n",
      "34280/34280 [==============================] - 0s 12us/sample - loss: 0.1739 - val_loss: 22.9267\n",
      "Epoch 9428/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 23.8038\n",
      "Epoch 9429/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 21.3182\n",
      "Epoch 9430/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1731 - val_loss: 23.5315\n",
      "Epoch 9431/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1848 - val_loss: 13.5962\n",
      "Epoch 9432/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.4320 - val_loss: 22.4170\n",
      "Epoch 9433/10000\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 0.2444 - val_loss: 31.4295\n",
      "Epoch 9434/10000\n",
      "34280/34280 [==============================] - 1s 15us/sample - loss: 0.2007 - val_loss: 25.1324\n",
      "Epoch 9435/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.2044 - val_loss: 30.3137\n",
      "Epoch 9436/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1888 - val_loss: 39.3967\n",
      "Epoch 9437/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1790 - val_loss: 41.2321\n",
      "Epoch 9438/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1774 - val_loss: 34.6186\n",
      "Epoch 9439/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1739 - val_loss: 28.9530\n",
      "Epoch 9440/10000\n",
      "34280/34280 [==============================] - 0s 12us/sample - loss: 0.1735 - val_loss: 32.0844\n",
      "Epoch 9441/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1726 - val_loss: 31.7398\n",
      "Epoch 9442/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1715 - val_loss: 29.6615\n",
      "Epoch 9443/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1738 - val_loss: 29.1677\n",
      "Epoch 9444/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1719 - val_loss: 27.8007\n",
      "Epoch 9445/10000\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 0.1738 - val_loss: 32.1224\n",
      "Epoch 9446/10000\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 0.1737 - val_loss: 30.1674\n",
      "Epoch 9447/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1759 - val_loss: 31.0487\n",
      "Epoch 9448/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1760 - val_loss: 23.0294\n",
      "Epoch 9449/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1717 - val_loss: 28.5575\n",
      "Epoch 9450/10000\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 0.1744 - val_loss: 19.9157\n",
      "Epoch 9451/10000\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 0.1743 - val_loss: 23.3259\n",
      "Epoch 9452/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1732 - val_loss: 25.2395\n",
      "Epoch 9453/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1728 - val_loss: 22.8333\n",
      "Epoch 9454/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1731 - val_loss: 23.1820\n",
      "Epoch 9455/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1741 - val_loss: 26.7543\n",
      "Epoch 9456/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1754 - val_loss: 24.3025\n",
      "Epoch 9457/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1727 - val_loss: 23.2082\n",
      "Epoch 9458/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1724 - val_loss: 22.3329\n",
      "Epoch 9459/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1735 - val_loss: 24.7965\n",
      "Epoch 9460/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1715 - val_loss: 23.3621\n",
      "Epoch 9461/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1723 - val_loss: 22.6125\n",
      "Epoch 9462/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1707 - val_loss: 24.5580\n",
      "Epoch 9463/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1713 - val_loss: 24.3227\n",
      "Epoch 9464/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1728 - val_loss: 23.3040\n",
      "Epoch 9465/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 20.0883\n",
      "Epoch 9466/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 22.6911\n",
      "Epoch 9467/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1766 - val_loss: 28.5423\n",
      "Epoch 9468/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2737 - val_loss: 26.0414\n",
      "Epoch 9469/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2531 - val_loss: 9.7497\n",
      "Epoch 9470/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2586 - val_loss: 11.7003\n",
      "Epoch 9471/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2761 - val_loss: 11.3045\n",
      "Epoch 9472/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2040 - val_loss: 15.7060\n",
      "Epoch 9473/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2131 - val_loss: 29.0171\n",
      "Epoch 9474/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2252 - val_loss: 12.5647\n",
      "Epoch 9475/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2047 - val_loss: 7.5050\n",
      "Epoch 9476/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1870 - val_loss: 10.1049\n",
      "Epoch 9477/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1857 - val_loss: 12.4105\n",
      "Epoch 9478/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1825 - val_loss: 15.3128\n",
      "Epoch 9479/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1859 - val_loss: 14.6543\n",
      "Epoch 9480/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1920 - val_loss: 21.8720\n",
      "Epoch 9481/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1790 - val_loss: 15.7341\n",
      "Epoch 9482/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1783 - val_loss: 18.8531\n",
      "Epoch 9483/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1748 - val_loss: 20.4063\n",
      "Epoch 9484/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1755 - val_loss: 19.2000\n",
      "Epoch 9485/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 17.1235\n",
      "Epoch 9486/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 21.1547\n",
      "Epoch 9487/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1748 - val_loss: 14.9349\n",
      "Epoch 9488/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1769 - val_loss: 16.1399\n",
      "Epoch 9489/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1740 - val_loss: 17.7715\n",
      "Epoch 9490/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 13.0691\n",
      "Epoch 9491/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1742 - val_loss: 15.4732\n",
      "Epoch 9492/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 13.9156\n",
      "Epoch 9493/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 17.7733\n",
      "Epoch 9494/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1739 - val_loss: 15.7359\n",
      "Epoch 9495/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1783 - val_loss: 12.1727\n",
      "Epoch 9496/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1777 - val_loss: 15.7886\n",
      "Epoch 9497/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1753 - val_loss: 16.0822\n",
      "Epoch 9498/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1723 - val_loss: 15.9784\n",
      "Epoch 9499/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1726 - val_loss: 18.1193\n",
      "Epoch 9500/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1712 - val_loss: 16.5971\n",
      "Epoch 9501/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1724 - val_loss: 18.8770\n",
      "Epoch 9502/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1734 - val_loss: 13.4734\n",
      "Epoch 9503/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1737 - val_loss: 13.0685\n",
      "Epoch 9504/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 14.1305\n",
      "Epoch 9505/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1707 - val_loss: 18.8144\n",
      "Epoch 9506/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 17.2161\n",
      "Epoch 9507/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1723 - val_loss: 16.5129\n",
      "Epoch 9508/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1706 - val_loss: 14.2812\n",
      "Epoch 9509/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 13.5403\n",
      "Epoch 9510/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 19.1827\n",
      "Epoch 9511/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 16.4857\n",
      "Epoch 9512/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 16.8067\n",
      "Epoch 9513/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 16.9491\n",
      "Epoch 9514/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 20.3794\n",
      "Epoch 9515/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 16.8771\n",
      "Epoch 9516/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 18.3176\n",
      "Epoch 9517/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 15.9340\n",
      "Epoch 9518/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 16.4828\n",
      "Epoch 9519/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 16.4450\n",
      "Epoch 9520/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 16.3114\n",
      "Epoch 9521/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1760 - val_loss: 16.4394\n",
      "Epoch 9522/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1744 - val_loss: 14.8757\n",
      "Epoch 9523/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 16.1718\n",
      "Epoch 9524/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 17.2668\n",
      "Epoch 9525/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1712 - val_loss: 19.1500\n",
      "Epoch 9526/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 14.5701\n",
      "Epoch 9527/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 11.4517\n",
      "Epoch 9528/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1749 - val_loss: 13.4370\n",
      "Epoch 9529/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 20.1418\n",
      "Epoch 9530/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1895 - val_loss: 32.8989\n",
      "Epoch 9531/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.4639 - val_loss: 29.6647\n",
      "Epoch 9532/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3451 - val_loss: 29.9148\n",
      "Epoch 9533/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2478 - val_loss: 20.3656\n",
      "Epoch 9534/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2317 - val_loss: 20.9081\n",
      "Epoch 9535/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2178 - val_loss: 11.6041\n",
      "Epoch 9536/10000\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 0.2169 - val_loss: 5.4677\n",
      "Epoch 9537/10000\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 0.2112 - val_loss: 22.1543\n",
      "Epoch 9538/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2539 - val_loss: 10.0036\n",
      "Epoch 9539/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2063 - val_loss: 10.9008\n",
      "Epoch 9540/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1885 - val_loss: 13.7254\n",
      "Epoch 9541/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1822 - val_loss: 17.3902\n",
      "Epoch 9542/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1801 - val_loss: 15.5841\n",
      "Epoch 9543/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1773 - val_loss: 16.2280\n",
      "Epoch 9544/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1787 - val_loss: 15.5362\n",
      "Epoch 9545/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1769 - val_loss: 17.8207\n",
      "Epoch 9546/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1771 - val_loss: 14.3932\n",
      "Epoch 9547/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1776 - val_loss: 14.8960\n",
      "Epoch 9548/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1758 - val_loss: 13.7781\n",
      "Epoch 9549/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1752 - val_loss: 14.1800\n",
      "Epoch 9550/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1753 - val_loss: 12.4210\n",
      "Epoch 9551/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1752 - val_loss: 13.7036\n",
      "Epoch 9552/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1759 - val_loss: 12.8933\n",
      "Epoch 9553/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1758 - val_loss: 13.2990\n",
      "Epoch 9554/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1748 - val_loss: 16.4497\n",
      "Epoch 9555/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1760 - val_loss: 11.9652\n",
      "Epoch 9556/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1752 - val_loss: 12.9095\n",
      "Epoch 9557/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1755 - val_loss: 14.6528\n",
      "Epoch 9558/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1747 - val_loss: 12.0531\n",
      "Epoch 9559/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1752 - val_loss: 13.4824\n",
      "Epoch 9560/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1748 - val_loss: 11.2881\n",
      "Epoch 9561/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1750 - val_loss: 14.7532\n",
      "Epoch 9562/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1763 - val_loss: 12.1902\n",
      "Epoch 9563/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1915 - val_loss: 11.5170\n",
      "Epoch 9564/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1786 - val_loss: 8.1086\n",
      "Epoch 9565/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1749 - val_loss: 10.7754\n",
      "Epoch 9566/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1749 - val_loss: 9.6727\n",
      "Epoch 9567/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 7.9969\n",
      "Epoch 9568/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1752 - val_loss: 10.9975\n",
      "Epoch 9569/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1746 - val_loss: 9.6522\n",
      "Epoch 9570/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 8.9804\n",
      "Epoch 9571/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1748 - val_loss: 10.9701\n",
      "Epoch 9572/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1811 - val_loss: 12.1338\n",
      "Epoch 9573/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1804 - val_loss: 11.1966\n",
      "Epoch 9574/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1823 - val_loss: 6.8639\n",
      "Epoch 9575/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1782 - val_loss: 6.9819\n",
      "Epoch 9576/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1828 - val_loss: 13.6251\n",
      "Epoch 9577/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1754 - val_loss: 12.8365\n",
      "Epoch 9578/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1751 - val_loss: 10.2300\n",
      "Epoch 9579/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 10.9384\n",
      "Epoch 9580/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1754 - val_loss: 9.2750\n",
      "Epoch 9581/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1759 - val_loss: 9.3223\n",
      "Epoch 9582/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1745 - val_loss: 10.4708\n",
      "Epoch 9583/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1745 - val_loss: 10.7466\n",
      "Epoch 9584/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 10.1903\n",
      "Epoch 9585/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 12.1616\n",
      "Epoch 9586/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 10.6734\n",
      "Epoch 9587/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1740 - val_loss: 10.4933\n",
      "Epoch 9588/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1762 - val_loss: 9.9223\n",
      "Epoch 9589/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1739 - val_loss: 7.2987\n",
      "Epoch 9590/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1743 - val_loss: 8.7867\n",
      "Epoch 9591/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 8.2437\n",
      "Epoch 9592/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 8.8501\n",
      "Epoch 9593/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1747 - val_loss: 9.3393\n",
      "Epoch 9594/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 8.6331\n",
      "Epoch 9595/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 9.3235\n",
      "Epoch 9596/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 8.5491\n",
      "Epoch 9597/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1749 - val_loss: 9.6106\n",
      "Epoch 9598/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 11.5874\n",
      "Epoch 9599/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1732 - val_loss: 12.5298\n",
      "Epoch 9600/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1725 - val_loss: 9.3931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9601/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1726 - val_loss: 9.7595\n",
      "Epoch 9602/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1749 - val_loss: 7.4825\n",
      "Epoch 9603/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1781 - val_loss: 12.8722\n",
      "Epoch 9604/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1772 - val_loss: 8.2045\n",
      "Epoch 9605/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1734 - val_loss: 8.9851\n",
      "Epoch 9606/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1721 - val_loss: 11.4331\n",
      "Epoch 9607/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1733 - val_loss: 7.8616\n",
      "Epoch 9608/10000\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 0.1777 - val_loss: 11.8909\n",
      "Epoch 9609/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1879 - val_loss: 8.1085\n",
      "Epoch 9610/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.2885 - val_loss: 16.9430\n",
      "Epoch 9611/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.4706 - val_loss: 27.4578\n",
      "Epoch 9612/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.3017 - val_loss: 34.3000\n",
      "Epoch 9613/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3082 - val_loss: 28.1347\n",
      "Epoch 9614/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1982 - val_loss: 31.1256\n",
      "Epoch 9615/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1817 - val_loss: 20.5562\n",
      "Epoch 9616/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1785 - val_loss: 23.5064\n",
      "Epoch 9617/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1781 - val_loss: 19.7424\n",
      "Epoch 9618/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1773 - val_loss: 22.3883\n",
      "Epoch 9619/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1770 - val_loss: 18.0522\n",
      "Epoch 9620/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1747 - val_loss: 23.7720\n",
      "Epoch 9621/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1746 - val_loss: 17.0773\n",
      "Epoch 9622/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1745 - val_loss: 18.7838\n",
      "Epoch 9623/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 17.2160\n",
      "Epoch 9624/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 23.7028\n",
      "Epoch 9625/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1923 - val_loss: 14.6417\n",
      "Epoch 9626/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1833 - val_loss: 12.8124\n",
      "Epoch 9627/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 19.5727\n",
      "Epoch 9628/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1750 - val_loss: 11.7776\n",
      "Epoch 9629/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 16.9730\n",
      "Epoch 9630/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1743 - val_loss: 16.7509\n",
      "Epoch 9631/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 14.7462\n",
      "Epoch 9632/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 16.7850\n",
      "Epoch 9633/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 14.6009\n",
      "Epoch 9634/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 13.8599\n",
      "Epoch 9635/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1747 - val_loss: 18.9201\n",
      "Epoch 9636/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1736 - val_loss: 16.6206\n",
      "Epoch 9637/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1732 - val_loss: 15.4529\n",
      "Epoch 9638/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1734 - val_loss: 16.9578\n",
      "Epoch 9639/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1730 - val_loss: 15.4202\n",
      "Epoch 9640/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1716 - val_loss: 15.7344\n",
      "Epoch 9641/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1722 - val_loss: 16.2536\n",
      "Epoch 9642/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1728 - val_loss: 14.8557\n",
      "Epoch 9643/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1729 - val_loss: 17.2682\n",
      "Epoch 9644/10000\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 0.1720 - val_loss: 14.6200\n",
      "Epoch 9645/10000\n",
      "34280/34280 [==============================] - 0s 12us/sample - loss: 0.1733 - val_loss: 16.7532\n",
      "Epoch 9646/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1731 - val_loss: 16.7089\n",
      "Epoch 9647/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1731 - val_loss: 16.8234\n",
      "Epoch 9648/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 16.0901\n",
      "Epoch 9649/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1718 - val_loss: 12.7157\n",
      "Epoch 9650/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 13.2379\n",
      "Epoch 9651/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1836 - val_loss: 18.8216\n",
      "Epoch 9652/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2478 - val_loss: 27.3328\n",
      "Epoch 9653/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2409 - val_loss: 20.8917\n",
      "Epoch 9654/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2489 - val_loss: 7.4808\n",
      "Epoch 9655/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2302 - val_loss: 16.8599\n",
      "Epoch 9656/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1954 - val_loss: 3.9200\n",
      "Epoch 9657/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1922 - val_loss: 2.8809\n",
      "Epoch 9658/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2150 - val_loss: 11.3124\n",
      "Epoch 9659/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1812 - val_loss: 13.6159\n",
      "Epoch 9660/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2265 - val_loss: 1.5914\n",
      "Epoch 9661/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.3381 - val_loss: 18.2177\n",
      "Epoch 9662/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1946 - val_loss: 19.0570\n",
      "Epoch 9663/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1822 - val_loss: 13.9667\n",
      "Epoch 9664/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1756 - val_loss: 10.2140\n",
      "Epoch 9665/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1752 - val_loss: 20.6725\n",
      "Epoch 9666/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2128 - val_loss: 6.8973\n",
      "Epoch 9667/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1825 - val_loss: 14.6356\n",
      "Epoch 9668/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1757 - val_loss: 11.4276\n",
      "Epoch 9669/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1728 - val_loss: 9.4216\n",
      "Epoch 9670/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 10.0550\n",
      "Epoch 9671/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1730 - val_loss: 11.3293\n",
      "Epoch 9672/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1738 - val_loss: 10.2686\n",
      "Epoch 9673/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1739 - val_loss: 10.2426\n",
      "Epoch 9674/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 10.4077\n",
      "Epoch 9675/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1732 - val_loss: 11.4872\n",
      "Epoch 9676/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1757 - val_loss: 12.6353\n",
      "Epoch 9677/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1737 - val_loss: 9.4450\n",
      "Epoch 9678/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1713 - val_loss: 10.4205\n",
      "Epoch 9679/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1727 - val_loss: 11.3056\n",
      "Epoch 9680/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1718 - val_loss: 8.6779\n",
      "Epoch 9681/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1733 - val_loss: 13.3119\n",
      "Epoch 9682/10000\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 0.1722 - val_loss: 11.1405\n",
      "Epoch 9683/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1725 - val_loss: 9.6425\n",
      "Epoch 9684/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1714 - val_loss: 10.7013\n",
      "Epoch 9685/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1724 - val_loss: 10.2755\n",
      "Epoch 9686/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1725 - val_loss: 10.3909\n",
      "Epoch 9687/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1733 - val_loss: 11.1272\n",
      "Epoch 9688/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1734 - val_loss: 11.1213\n",
      "Epoch 9689/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 11.8892\n",
      "Epoch 9690/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1694 - val_loss: 12.2521\n",
      "Epoch 9691/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1730 - val_loss: 15.3250\n",
      "Epoch 9692/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1733 - val_loss: 12.5931\n",
      "Epoch 9693/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 12.4010\n",
      "Epoch 9694/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 12.5167\n",
      "Epoch 9695/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 11.3028\n",
      "Epoch 9696/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1740 - val_loss: 13.4644\n",
      "Epoch 9697/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1736 - val_loss: 12.9696\n",
      "Epoch 9698/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1742 - val_loss: 15.5045\n",
      "Epoch 9699/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 14.5726\n",
      "Epoch 9700/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 16.3864\n",
      "Epoch 9701/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 12.9939\n",
      "Epoch 9702/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1704 - val_loss: 14.0368\n",
      "Epoch 9703/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 13.1720\n",
      "Epoch 9704/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 15.2072\n",
      "Epoch 9705/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 12.8595\n",
      "Epoch 9706/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1684 - val_loss: 13.0812\n",
      "Epoch 9707/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 12.5669\n",
      "Epoch 9708/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 12.3144\n",
      "Epoch 9709/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 13.9109\n",
      "Epoch 9710/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 13.0749\n",
      "Epoch 9711/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1756 - val_loss: 8.4161\n",
      "Epoch 9712/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1775 - val_loss: 10.7226\n",
      "Epoch 9713/10000\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 0.1799 - val_loss: 12.0930\n",
      "Epoch 9714/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1741 - val_loss: 16.8838\n",
      "Epoch 9715/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1732 - val_loss: 11.8858\n",
      "Epoch 9716/10000\n",
      "34280/34280 [==============================] - 0s 12us/sample - loss: 0.3226 - val_loss: 1.7237\n",
      "Epoch 9717/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.5377 - val_loss: 26.1220\n",
      "Epoch 9718/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.3039 - val_loss: 23.4510\n",
      "Epoch 9719/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2094 - val_loss: 31.1589\n",
      "Epoch 9720/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1940 - val_loss: 21.2262\n",
      "Epoch 9721/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1850 - val_loss: 22.1729\n",
      "Epoch 9722/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1786 - val_loss: 23.7957\n",
      "Epoch 9723/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1741 - val_loss: 21.6235\n",
      "Epoch 9724/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1759 - val_loss: 22.8840\n",
      "Epoch 9725/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1739 - val_loss: 24.8089\n",
      "Epoch 9726/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1732 - val_loss: 22.9929\n",
      "Epoch 9727/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 25.2312\n",
      "Epoch 9728/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1734 - val_loss: 22.2027\n",
      "Epoch 9729/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 24.5649\n",
      "Epoch 9730/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 22.2903\n",
      "Epoch 9731/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1702 - val_loss: 23.5603\n",
      "Epoch 9732/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1728 - val_loss: 25.6340\n",
      "Epoch 9733/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1730 - val_loss: 23.0859\n",
      "Epoch 9734/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1723 - val_loss: 22.0367\n",
      "Epoch 9735/10000\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 0.1723 - val_loss: 25.4091\n",
      "Epoch 9736/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1709 - val_loss: 19.3968\n",
      "Epoch 9737/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1716 - val_loss: 27.1873\n",
      "Epoch 9738/10000\n",
      "34280/34280 [==============================] - 0s 13us/sample - loss: 0.1736 - val_loss: 20.4513\n",
      "Epoch 9739/10000\n",
      "34280/34280 [==============================] - 0s 12us/sample - loss: 0.1710 - val_loss: 23.9756\n",
      "Epoch 9740/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1714 - val_loss: 23.4209\n",
      "Epoch 9741/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 23.6316\n",
      "Epoch 9742/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1704 - val_loss: 20.4887\n",
      "Epoch 9743/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1712 - val_loss: 23.9716\n",
      "Epoch 9744/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1705 - val_loss: 24.4804\n",
      "Epoch 9745/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1699 - val_loss: 22.5622\n",
      "Epoch 9746/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1775 - val_loss: 19.8561\n",
      "Epoch 9747/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1755 - val_loss: 21.1291\n",
      "Epoch 9748/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 20.3217\n",
      "Epoch 9749/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 21.9374\n",
      "Epoch 9750/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1728 - val_loss: 22.7764\n",
      "Epoch 9751/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 19.8006\n",
      "Epoch 9752/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 21.1960\n",
      "Epoch 9753/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1726 - val_loss: 23.0387\n",
      "Epoch 9754/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 21.0098\n",
      "Epoch 9755/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 22.0275\n",
      "Epoch 9756/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1704 - val_loss: 20.9911\n",
      "Epoch 9757/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1722 - val_loss: 23.7912\n",
      "Epoch 9758/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 19.4881\n",
      "Epoch 9759/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 21.8110\n",
      "Epoch 9760/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1720 - val_loss: 18.6401\n",
      "Epoch 9761/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1728 - val_loss: 23.0637\n",
      "Epoch 9762/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1726 - val_loss: 16.7685\n",
      "Epoch 9763/10000\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 0.1738 - val_loss: 21.0824\n",
      "Epoch 9764/10000\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 0.1718 - val_loss: 21.2237\n",
      "Epoch 9765/10000\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 0.1752 - val_loss: 19.3265\n",
      "Epoch 9766/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1894 - val_loss: 21.9609\n",
      "Epoch 9767/10000\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 0.1856 - val_loss: 10.1807\n",
      "Epoch 9768/10000\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 0.3351 - val_loss: 3.1453\n",
      "Epoch 9769/10000\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 0.2789 - val_loss: 25.5661\n",
      "Epoch 9770/10000\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 0.2711 - val_loss: 1.5087\n",
      "Epoch 9771/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.3469 - val_loss: 12.2404\n",
      "Epoch 9772/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2419 - val_loss: 13.2937\n",
      "Epoch 9773/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2208 - val_loss: 26.6118\n",
      "Epoch 9774/10000\n",
      "34280/34280 [==============================] - ETA: 0s - loss: 0.194 - 0s 8us/sample - loss: 0.1965 - val_loss: 21.5651\n",
      "Epoch 9775/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1877 - val_loss: 23.8069\n",
      "Epoch 9776/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1846 - val_loss: 24.0472\n",
      "Epoch 9777/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1880 - val_loss: 33.4723\n",
      "Epoch 9778/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1789 - val_loss: 25.3285\n",
      "Epoch 9779/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1863 - val_loss: 25.9952\n",
      "Epoch 9780/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1841 - val_loss: 37.0764\n",
      "Epoch 9781/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1750 - val_loss: 32.5862\n",
      "Epoch 9782/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1759 - val_loss: 38.3929\n",
      "Epoch 9783/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1744 - val_loss: 36.9125\n",
      "Epoch 9784/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1751 - val_loss: 37.3939\n",
      "Epoch 9785/10000\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 0.1726 - val_loss: 36.6900\n",
      "Epoch 9786/10000\n",
      "34280/34280 [==============================] - 0s 11us/sample - loss: 0.1754 - val_loss: 35.1586\n",
      "Epoch 9787/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1739 - val_loss: 39.0431\n",
      "Epoch 9788/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1754 - val_loss: 31.0133\n",
      "Epoch 9789/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1736 - val_loss: 29.0062\n",
      "Epoch 9790/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1766 - val_loss: 31.6232\n",
      "Epoch 9791/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1811 - val_loss: 38.3152\n",
      "Epoch 9792/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1768 - val_loss: 20.9426\n",
      "Epoch 9793/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1806 - val_loss: 27.5590\n",
      "Epoch 9794/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1761 - val_loss: 24.8753\n",
      "Epoch 9795/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1747 - val_loss: 25.0308\n",
      "Epoch 9796/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1742 - val_loss: 23.8295\n",
      "Epoch 9797/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1739 - val_loss: 23.3206\n",
      "Epoch 9798/10000\n",
      "34280/34280 [==============================] - ETA: 0s - loss: 0.1775- ETA: 0s - loss: 0.16 - 0s 9us/sample - loss: 0.1750 - val_loss: 19.9133\n",
      "Epoch 9799/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1732 - val_loss: 22.7593\n",
      "Epoch 9800/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1749 - val_loss: 14.0464\n",
      "Epoch 9801/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1744 - val_loss: 20.9836\n",
      "Epoch 9802/10000\n",
      "34280/34280 [==============================] - 0s 10us/sample - loss: 0.1714 - val_loss: 24.3250\n",
      "Epoch 9803/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1717 - val_loss: 19.8411\n",
      "Epoch 9804/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1731 - val_loss: 24.1700\n",
      "Epoch 9805/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1713 - val_loss: 22.2421\n",
      "Epoch 9806/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1724 - val_loss: 22.3358\n",
      "Epoch 9807/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1735 - val_loss: 19.6947\n",
      "Epoch 9808/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1718 - val_loss: 23.0087\n",
      "Epoch 9809/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 25.5077\n",
      "Epoch 9810/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 22.7452\n",
      "Epoch 9811/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1718 - val_loss: 19.4177\n",
      "Epoch 9812/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 19.0950\n",
      "Epoch 9813/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 18.7150\n",
      "Epoch 9814/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 20.9913\n",
      "Epoch 9815/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1702 - val_loss: 19.0366\n",
      "Epoch 9816/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 20.3914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9817/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 21.6699\n",
      "Epoch 9818/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1706 - val_loss: 19.0302\n",
      "Epoch 9819/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1702 - val_loss: 20.8928\n",
      "Epoch 9820/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1709 - val_loss: 20.1424\n",
      "Epoch 9821/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1721 - val_loss: 18.0784\n",
      "Epoch 9822/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2178 - val_loss: 9.7591\n",
      "Epoch 9823/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.5607 - val_loss: 57.7222\n",
      "Epoch 9824/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.5120 - val_loss: 36.4788\n",
      "Epoch 9825/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2745 - val_loss: 47.3044\n",
      "Epoch 9826/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2519 - val_loss: 36.6149\n",
      "Epoch 9827/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2449 - val_loss: 48.2333\n",
      "Epoch 9828/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2297 - val_loss: 48.4488\n",
      "Epoch 9829/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2396 - val_loss: 43.3207\n",
      "Epoch 9830/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2260 - val_loss: 47.5607\n",
      "Epoch 9831/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2424 - val_loss: 39.6031\n",
      "Epoch 9832/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2249 - val_loss: 39.1721\n",
      "Epoch 9833/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2218 - val_loss: 35.4572\n",
      "Epoch 9834/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2308 - val_loss: 29.2953\n",
      "Epoch 9835/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2290 - val_loss: 40.4857\n",
      "Epoch 9836/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2073 - val_loss: 42.2209\n",
      "Epoch 9837/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2081 - val_loss: 41.7287\n",
      "Epoch 9838/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2087 - val_loss: 39.9273\n",
      "Epoch 9839/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2153 - val_loss: 37.0189\n",
      "Epoch 9840/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2051 - val_loss: 37.3019\n",
      "Epoch 9841/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2063 - val_loss: 46.5783\n",
      "Epoch 9842/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2216 - val_loss: 39.5976\n",
      "Epoch 9843/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2038 - val_loss: 34.6654\n",
      "Epoch 9844/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2015 - val_loss: 35.2081\n",
      "Epoch 9845/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2154 - val_loss: 37.7385\n",
      "Epoch 9846/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2015 - val_loss: 41.3529\n",
      "Epoch 9847/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2334 - val_loss: 25.1042\n",
      "Epoch 9848/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2018 - val_loss: 29.3291\n",
      "Epoch 9849/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2000 - val_loss: 22.0726\n",
      "Epoch 9850/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1968 - val_loss: 29.2896\n",
      "Epoch 9851/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2111 - val_loss: 20.0333\n",
      "Epoch 9852/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1983 - val_loss: 38.1386\n",
      "Epoch 9853/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2021 - val_loss: 17.5233\n",
      "Epoch 9854/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2012 - val_loss: 25.7808\n",
      "Epoch 9855/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1988 - val_loss: 27.4813\n",
      "Epoch 9856/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2351 - val_loss: 32.7406\n",
      "Epoch 9857/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2079 - val_loss: 29.7019\n",
      "Epoch 9858/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1953 - val_loss: 39.8578\n",
      "Epoch 9859/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2155 - val_loss: 28.6919\n",
      "Epoch 9860/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1930 - val_loss: 24.4677\n",
      "Epoch 9861/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1840 - val_loss: 25.0746\n",
      "Epoch 9862/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1871 - val_loss: 24.4244\n",
      "Epoch 9863/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1930 - val_loss: 19.8834\n",
      "Epoch 9864/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1874 - val_loss: 27.6704\n",
      "Epoch 9865/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2162 - val_loss: 23.5099\n",
      "Epoch 9866/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1898 - val_loss: 22.9674\n",
      "Epoch 9867/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1858 - val_loss: 25.5534\n",
      "Epoch 9868/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1848 - val_loss: 32.9538\n",
      "Epoch 9869/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1948 - val_loss: 21.8453\n",
      "Epoch 9870/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1930 - val_loss: 26.6834\n",
      "Epoch 9871/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1817 - val_loss: 33.1533\n",
      "Epoch 9872/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1849 - val_loss: 31.7397\n",
      "Epoch 9873/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1859 - val_loss: 35.2289\n",
      "Epoch 9874/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2016 - val_loss: 34.6272\n",
      "Epoch 9875/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.2112 - val_loss: 13.5047\n",
      "Epoch 9876/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1913 - val_loss: 31.3875\n",
      "Epoch 9877/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1863 - val_loss: 25.9714\n",
      "Epoch 9878/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1860 - val_loss: 24.3825\n",
      "Epoch 9879/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1827 - val_loss: 21.1066\n",
      "Epoch 9880/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1810 - val_loss: 25.0996\n",
      "Epoch 9881/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1790 - val_loss: 20.2148\n",
      "Epoch 9882/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1856 - val_loss: 25.1651\n",
      "Epoch 9883/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1842 - val_loss: 25.1549\n",
      "Epoch 9884/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1821 - val_loss: 27.5385\n",
      "Epoch 9885/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1974 - val_loss: 24.4708\n",
      "Epoch 9886/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1849 - val_loss: 17.2132\n",
      "Epoch 9887/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1865 - val_loss: 22.2726\n",
      "Epoch 9888/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1871 - val_loss: 31.7568\n",
      "Epoch 9889/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1824 - val_loss: 26.1722\n",
      "Epoch 9890/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1784 - val_loss: 20.9495\n",
      "Epoch 9891/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1803 - val_loss: 20.1615\n",
      "Epoch 9892/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2243 - val_loss: 27.9719\n",
      "Epoch 9893/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2213 - val_loss: 1.7441\n",
      "Epoch 9894/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3474 - val_loss: 17.7815\n",
      "Epoch 9895/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2239 - val_loss: 17.1681\n",
      "Epoch 9896/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1956 - val_loss: 22.3285\n",
      "Epoch 9897/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1817 - val_loss: 27.5851\n",
      "Epoch 9898/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1921 - val_loss: 27.2457\n",
      "Epoch 9899/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1853 - val_loss: 26.4196\n",
      "Epoch 9900/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1826 - val_loss: 31.9167\n",
      "Epoch 9901/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1807 - val_loss: 29.9567\n",
      "Epoch 9902/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1789 - val_loss: 29.8205\n",
      "Epoch 9903/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1878 - val_loss: 32.5250\n",
      "Epoch 9904/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1811 - val_loss: 29.0989\n",
      "Epoch 9905/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1795 - val_loss: 31.1766\n",
      "Epoch 9906/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1832 - val_loss: 35.0650\n",
      "Epoch 9907/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1823 - val_loss: 33.5551\n",
      "Epoch 9908/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1804 - val_loss: 33.0851\n",
      "Epoch 9909/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1775 - val_loss: 25.2190\n",
      "Epoch 9910/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1801 - val_loss: 30.6662\n",
      "Epoch 9911/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2101 - val_loss: 10.3115\n",
      "Epoch 9912/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2721 - val_loss: 45.7579\n",
      "Epoch 9913/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1996 - val_loss: 47.8963\n",
      "Epoch 9914/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1862 - val_loss: 36.9790\n",
      "Epoch 9915/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1829 - val_loss: 34.9632\n",
      "Epoch 9916/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1798 - val_loss: 24.6944\n",
      "Epoch 9917/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2055 - val_loss: 28.3246\n",
      "Epoch 9918/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2000 - val_loss: 29.4283\n",
      "Epoch 9919/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1859 - val_loss: 37.2547\n",
      "Epoch 9920/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1826 - val_loss: 34.3844\n",
      "Epoch 9921/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1808 - val_loss: 35.5873\n",
      "Epoch 9922/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1810 - val_loss: 26.7034\n",
      "Epoch 9923/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1878 - val_loss: 33.5064\n",
      "Epoch 9924/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1837 - val_loss: 27.1093\n",
      "Epoch 9925/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1832 - val_loss: 36.0788\n",
      "Epoch 9926/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1798 - val_loss: 24.5490\n",
      "Epoch 9927/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1770 - val_loss: 24.4244\n",
      "Epoch 9928/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1787 - val_loss: 25.7639\n",
      "Epoch 9929/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1768 - val_loss: 26.3226\n",
      "Epoch 9930/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1758 - val_loss: 25.5779\n",
      "Epoch 9931/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1821 - val_loss: 27.6937\n",
      "Epoch 9932/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1813 - val_loss: 24.6344\n",
      "Epoch 9933/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1759 - val_loss: 25.8896\n",
      "Epoch 9934/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1733 - val_loss: 25.3675\n",
      "Epoch 9935/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1805 - val_loss: 29.6502\n",
      "Epoch 9936/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2200 - val_loss: 10.0593\n",
      "Epoch 9937/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2002 - val_loss: 31.9954\n",
      "Epoch 9938/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1859 - val_loss: 25.3254\n",
      "Epoch 9939/10000\n",
      "34280/34280 [==============================] - 0s 12us/sample - loss: 0.1765 - val_loss: 16.6087\n",
      "Epoch 9940/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1788 - val_loss: 24.4398\n",
      "Epoch 9941/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1828 - val_loss: 15.8311\n",
      "Epoch 9942/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1844 - val_loss: 22.9938\n",
      "Epoch 9943/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2193 - val_loss: 38.7250\n",
      "Epoch 9944/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2122 - val_loss: 33.9155\n",
      "Epoch 9945/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1815 - val_loss: 31.8336\n",
      "Epoch 9946/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2028 - val_loss: 35.3481\n",
      "Epoch 9947/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1778 - val_loss: 23.6768\n",
      "Epoch 9948/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1758 - val_loss: 35.3988\n",
      "Epoch 9949/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1771 - val_loss: 30.7448\n",
      "Epoch 9950/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 34.5822\n",
      "Epoch 9951/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1775 - val_loss: 35.2540\n",
      "Epoch 9952/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1754 - val_loss: 33.5562\n",
      "Epoch 9953/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1740 - val_loss: 38.8942\n",
      "Epoch 9954/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1759 - val_loss: 28.4447\n",
      "Epoch 9955/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 30.5925\n",
      "Epoch 9956/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 30.7787\n",
      "Epoch 9957/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1741 - val_loss: 25.3579\n",
      "Epoch 9958/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1808 - val_loss: 27.2104\n",
      "Epoch 9959/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2659 - val_loss: 27.3719\n",
      "Epoch 9960/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3158 - val_loss: 43.2630\n",
      "Epoch 9961/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2214 - val_loss: 21.3579\n",
      "Epoch 9962/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1914 - val_loss: 36.2605\n",
      "Epoch 9963/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1804 - val_loss: 37.6475\n",
      "Epoch 9964/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1768 - val_loss: 39.4294\n",
      "Epoch 9965/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1748 - val_loss: 34.9307\n",
      "Epoch 9966/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1756 - val_loss: 42.2867\n",
      "Epoch 9967/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1762 - val_loss: 36.9895\n",
      "Epoch 9968/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 39.2171\n",
      "Epoch 9969/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1759 - val_loss: 35.7521\n",
      "Epoch 9970/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1750 - val_loss: 42.1867\n",
      "Epoch 9971/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1795 - val_loss: 25.7844\n",
      "Epoch 9972/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1769 - val_loss: 30.8579\n",
      "Epoch 9973/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1816 - val_loss: 33.1674\n",
      "Epoch 9974/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1794 - val_loss: 35.3040\n",
      "Epoch 9975/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1917 - val_loss: 28.0160\n",
      "Epoch 9976/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.3406 - val_loss: 33.3946\n",
      "Epoch 9977/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.2027 - val_loss: 36.4107\n",
      "Epoch 9978/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1795 - val_loss: 40.7046\n",
      "Epoch 9979/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1756 - val_loss: 39.4533\n",
      "Epoch 9980/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1745 - val_loss: 41.6594\n",
      "Epoch 9981/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1746 - val_loss: 41.5041\n",
      "Epoch 9982/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 36.5523\n",
      "Epoch 9983/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1726 - val_loss: 41.5354\n",
      "Epoch 9984/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1745 - val_loss: 41.0398\n",
      "Epoch 9985/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1702 - val_loss: 38.3424\n",
      "Epoch 9986/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1725 - val_loss: 42.3134\n",
      "Epoch 9987/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1723 - val_loss: 43.7400\n",
      "Epoch 9988/10000\n",
      "34280/34280 [==============================] - 0s 9us/sample - loss: 0.1731 - val_loss: 38.3935\n",
      "Epoch 9989/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1737 - val_loss: 37.9713\n",
      "Epoch 9990/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1734 - val_loss: 44.6792\n",
      "Epoch 9991/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 40.1160\n",
      "Epoch 9992/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 43.9761\n",
      "Epoch 9993/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 43.2606\n",
      "Epoch 9994/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 42.9661\n",
      "Epoch 9995/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1716 - val_loss: 40.7127\n",
      "Epoch 9996/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1720 - val_loss: 49.8298\n",
      "Epoch 9997/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1747 - val_loss: 38.9672\n",
      "Epoch 9998/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1738 - val_loss: 40.8956\n",
      "Epoch 9999/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 38.7236\n",
      "Epoch 10000/10000\n",
      "34280/34280 [==============================] - 0s 8us/sample - loss: 0.1739 - val_loss: 36.8314\n"
     ]
    }
   ],
   "source": [
    "sys.argv = sys.argv[:1]\n",
    "\n",
    "@tf.function\n",
    "def bezier_loss(y_actual, y_pred):\n",
    "    \"\"\"Applies a SSE error from a predicted Bezier Curve.\n",
    "    \n",
    "    Description: Bezier Curves are polynomial curves formed by points parametarized by t \\in [0,1].\n",
    "        A polynomial curve of degree D is established using D+1 points which allows for a continuous output.\n",
    "        There is not a restriction on the points such that they be either unique or specifically spaced so\n",
    "        the shapes can be very tailorable. This loss function takes N samples of M points and returns the N sum\n",
    "        of squared errors of the M points from the D+1 output points.\n",
    "    \n",
    "    Args:\n",
    "        y_actual: NxMx(K+1) tensor where y[:,:,0] is the t value of the interval and  y[:, :, 1:] is the output value\n",
    "                  in K dimensional space. t should be in the interval [0, 1] but it is not necessary.\n",
    "        y_pred: Nx(D+1)xK tensor, with same dimension allocations expect the t variable is excluded.\n",
    "    \n",
    "    Returns: float error representing (1/N)\\sum_{n\\in N} \\sum_{m\\in M} \\sum_{k=1}^{K-1} (y_{n,m,k} - b_k(t_{n,m}))^2\n",
    "    \"\"\"\n",
    "    \n",
    "    # Determine output dimension size and polynomial degree\n",
    "    Dp1 = tf.shape(y_pred)[1]  # Degree plus 1\n",
    "    K = tf.shape(y_pred)[2]\n",
    "    \n",
    "    # Preallocate factorial parts\n",
    "    d = tf.range(Dp1)\n",
    "    factorial = tf.math.cumprod(tf.range(tf.constant(1), Dp1 + tf.constant(1)), exclusive=True)\n",
    "    nchoosek = tf.keras.backend.cast_to_floatx(factorial[Dp1 - tf.constant(1)]/(factorial*factorial[::-1]))\n",
    "    \n",
    "    \"\"\"\n",
    "    # modified n choose k\n",
    "    def mod_nchoosek(k):\n",
    "        n = Dp1 - tf.constant(1)\n",
    "        \n",
    "        lower_bound = tf.math.minimum(k, n-k)\n",
    "        def default_val():\n",
    "            return tf.keras.backend.cast_to_floatx(tf.constant(1.))\n",
    "        def calc_val():\n",
    "            return tf.keras.backend.cast_to_floatx(\n",
    "                tf.math.reduce_prod(tf.range(\n",
    "                    start=n,\n",
    "                    limit=(n-k),\n",
    "                    delta=tf.constant(-1)\n",
    "                ))/\\\n",
    "                tf.math.reduce_prod(tf.range(\n",
    "                    start=tf.constant(1),\n",
    "                    limit=(lower_bound + tf.constant(1))\n",
    "                ))\n",
    "            )\n",
    "        return tf.keras.backend.cast_to_floatx(tf.case(\n",
    "            [(tf.math.equal(k, n), default_val),\n",
    "             (tf.math.equal(k, tf.constant(0)), default_val)],\n",
    "            default=calc_val\n",
    "        ))\n",
    "        return tf.keras.backend.cast_to_floatx(factorial[n]/(factorial[k]*factorial[n-k]))\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get bezier coefficients for all \n",
    "    def bezier_coefficients(t):\n",
    "        \"\"\"Given t, generates the D+1 coefficents for the spline\"\"\"\n",
    "        tk = tf.math.pow(\n",
    "            tf.repeat(t, repeats=Dp1),\n",
    "            tf.range(tf.keras.backend.cast_to_floatx(Dp1),dtype=tf.float32)\n",
    "        )  # t^k\n",
    "        Omtnmk = tf.math.pow(\n",
    "            tf.repeat(tf.constant(1.) - t, repeats=Dp1),\n",
    "            tf.keras.backend.cast_to_floatx(tf.range(\n",
    "                start=(Dp1 - tf.constant(1)),\n",
    "                limit=tf.constant(-1),\n",
    "                delta=tf.constant(-1)\n",
    "            ))\n",
    "        )  # (1-t)^{n-k}\n",
    "        # nchoosek = tf.vectorized_map(fn=mod_nchoosek, elems=d) # n choose k\n",
    "        return nchoosek*tk*Omtnmk\n",
    "    \n",
    "    def bezier_coefficient_list(sample):\n",
    "        \"\"\"Find bezier coefficients for each training point of a sample.\"\"\"\n",
    "        bc_list = tf.vectorized_map(\n",
    "            fn=bezier_coefficients,\n",
    "            elems=sample[:,0]  # M list of t\n",
    "        ) # Mx(D+1)\n",
    "        return bc_list\n",
    "    \n",
    "    ts = y_actual[:,:,0]\n",
    "    \n",
    "    coefficients = tf.vectorized_map(\n",
    "        fn=bezier_coefficient_list,\n",
    "        elems=y_actual\n",
    "    )  # NxMx(D+1)\n",
    "    \n",
    "    # With the coefficients, find the NxMxK tensor of predicted values\n",
    "    predicted_points = tf.matmul(coefficients, y_pred) # a NxMx(D+1) times Nx(D+1)xK -> NxMxK tensor\n",
    "    \n",
    "    error = y_actual[:, :, 1:] - predicted_points\n",
    "    \n",
    "    # Find sum of squared l2 norm\n",
    "    return tf.keras.backend.sum(tf.keras.backend.square(\n",
    "        error\n",
    "    ))\n",
    "\n",
    "# Setting training\n",
    "train_epochs = 10000\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=bezier_loss,\n",
    "    # metrics=['mse'],  #Can't use mse\n",
    "    loss_weights=None,\n",
    "    weighted_metrics=None,\n",
    "    run_eagerly=None,\n",
    ")\n",
    "\n",
    "# Train with smoothness\n",
    "hist = model.fit(\n",
    "    x=X, y=Yb,\n",
    "    batch_size=1000,\n",
    "    epochs=train_epochs,\n",
    "    verbose=1,\n",
    "    validation_split=0.1,  # Adjust validation split?\n",
    "    shuffle=True,\n",
    "    validation_freq=1,\n",
    ")\n",
    "\n",
    "ypred_b = 1000.*model.predict(X) + 1000.  # Nx(D+1)xK points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (mpl.ratio !== 1) {\n",
       "            fig.send_message('set_dpi_ratio', { dpi_ratio: mpl.ratio });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    var resizeObserver = new ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * mpl.ratio);\n",
       "                canvas.setAttribute('height', height * mpl.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    resizeObserver.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / mpl.ratio,\n",
       "        fig.canvas.height / mpl.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch (cursor) {\n",
       "        case 0:\n",
       "            cursor = 'pointer';\n",
       "            break;\n",
       "        case 1:\n",
       "            cursor = 'default';\n",
       "            break;\n",
       "        case 2:\n",
       "            cursor = 'crosshair';\n",
       "            break;\n",
       "        case 3:\n",
       "            cursor = 'move';\n",
       "            break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = 'image/png';\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.which === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.which;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which !== 17) {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    if (event.altKey && event.which !== 18) {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    if (event.shiftKey && event.which !== 16) {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data']);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / mpl.ratio;\n",
       "    fig.root.removeEventListener('remove', this._remove_fig_handler);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / mpl.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function () {\n",
       "    this.close_ws(this, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "    el.addEventListener('remove', this._remove_fig_handler);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager) {\n",
       "        manager = IPython.keyboard_manager;\n",
       "    }\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"639.9999861283738\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "# Plotting the control outputs\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "# Targets\n",
    "ax.plot(tvec, pwms[:,0], label='PWM1 Filtered', color='C0')\n",
    "ax.plot(tvec, pwms[:,1], label='PWM2 Filtered', color='C1')\n",
    "ax.plot(tvec, pwms[:,2], label='PWM3 Filtered', color='C2')\n",
    "ax.plot(tvec, pwms[:,3], label='PWM4 Filtered', color='C3')\n",
    "\n",
    "# Trained outputs\n",
    "n = 500 # 1000\n",
    "t_span = 1.  # 1 second future window\n",
    "t_b_plot = np.linspace(0., 1., 101)  # vector for plotting continuous function\n",
    "\n",
    "b_weights = np.zeros((n_b_points,)+t_b_plot.shape)  # memory allocation\n",
    "for i in range(n_b_points):\n",
    "    b_weights[i,:] = scipy.special.comb(n_b_points - 1, i)*((1. - t_b_plot)**(n_b_points - 1 - i))*(t_b_plot**i)\n",
    "    \n",
    "ypred_b_plotting = np.einsum('ijk,jl->ikl', ypred_b, b_weights)\n",
    "\n",
    "for i in range(int(ypred.shape[0]/n)):\n",
    "    for j in range(4):\n",
    "        ax.plot(\n",
    "            tvec_y[n*i,0] + t_span*t_b_plot,\n",
    "            ypred_b_plotting[n*i, j, :],\n",
    "            color=('C%i' % j),\n",
    "            alpha=0.4,\n",
    "            label=(('' if i == 0  else '_') + ('PWM%i' % (j+1)) + ' Predicted')\n",
    "        )\n",
    "\n",
    "ax.legend(bbox_to_anchor=(1, 1), loc='upper left', fontsize='xx-small', handlelength=1)\n",
    "\n",
    "ax.set_xlabel('Time ($t$), [sec]')\n",
    "ax.set_ylabel('Pulse Width Modulation [$\\mu$sec]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (mpl.ratio !== 1) {\n",
       "            fig.send_message('set_dpi_ratio', { dpi_ratio: mpl.ratio });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    var resizeObserver = new ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * mpl.ratio);\n",
       "                canvas.setAttribute('height', height * mpl.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    resizeObserver.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / mpl.ratio,\n",
       "        fig.canvas.height / mpl.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch (cursor) {\n",
       "        case 0:\n",
       "            cursor = 'pointer';\n",
       "            break;\n",
       "        case 1:\n",
       "            cursor = 'default';\n",
       "            break;\n",
       "        case 2:\n",
       "            cursor = 'crosshair';\n",
       "            break;\n",
       "        case 3:\n",
       "            cursor = 'move';\n",
       "            break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = 'image/png';\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.which === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.which;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which !== 17) {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    if (event.altKey && event.which !== 18) {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    if (event.shiftKey && event.which !== 16) {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data']);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / mpl.ratio;\n",
       "    fig.root.removeEventListener('remove', this._remove_fig_handler);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / mpl.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function () {\n",
       "    this.close_ws(this, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "    el.addEventListener('remove', this._remove_fig_handler);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager) {\n",
       "        manager = IPython.keyboard_manager;\n",
       "    }\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"639.9999861283738\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax_t = plt.subplots(1, 1)\n",
    "\n",
    "lvec = np.array(hist.history['loss'])\n",
    "vlvec = np.array(hist.history['val_loss'])\n",
    "epoch_vec = np.array(list(range(lvec.shape[0])))\n",
    "    \n",
    "ax_t.plot(epoch_vec, lvec, label='Training loss')\n",
    "ax_t.plot(epoch_vec, vlvec, linestyle=':', label='Validation loss')\n",
    "\n",
    "ax_t.set_xlim(left=0)\n",
    "ax_t.set_ylim(bottom=0)\n",
    "\n",
    "fig.suptitle('Training Losses')\n",
    "ax_t.legend(fontsize='xx-small', handlelength=1)\n",
    "ax_t.set_xlabel('Epochs')\n",
    "ax_t.set_ylabel('Losses (Bezier)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
